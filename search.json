[{"title":"交叉验证与模型堆叠混合","url":"/post/cross-stack-blend.html","content":"\n# 交叉验证与模型堆叠混合\n\n## 1. 交叉验证 (Cross-Validation)\n\n**交叉验证**是一种用于评估模型性能和鲁棒性的技术。它通过将数据集划分为多个子集，并在不同的子集组合上进行训练和验证，从而更可靠地估计模型在未知数据上的表现。\n\n- **目的 (重点内容):**\n  - **更准确地评估模型泛化能力:** 避免模型评估结果对特定训练/测试集划分的依赖。\n  - **防止过拟合评估集:** 在模型开发和调参过程中，如果反复使用同一验证集来评估和调整模型，模型可能会“记住”验证集的特征，导致在真正的未知数据上性能下降。交叉验证通过使用不同的验证集来减轻这个问题。\n  - **充分利用数据:** 在数据集较小的情况下，交叉验证可以确保所有数据都用于训练和验证。\n- **基本思想:**\n  1. 将整个数据集随机分成 $k$ 个互斥的子集（称为“折”或“folds”）。\n  2. 进行 $k$ 轮训练和验证：\n     - 每一轮，选择其中一个子集作为验证集，剩下的 $k-1$ 个子集作为训练集。\n     - 在训练集上训练模型。\n     - 在验证集上评估模型性能。\n  3. 最终的模型性能评估是 $k$ 轮验证结果的平均值。\n- **常用类型 (重点内容):**\n  - **k-Fold Cross-Validation:** 将数据集分成 $k$ 等份。最常用。\n  - **Stratified k-Fold Cross-Validation:** 在分类问题中，确保每一折中的类别分布与整个数据集的类别分布大致相同。对于不平衡数据集尤其重要。\n  - **Leave-One-Out Cross-Validation (LOOCV):** $k$ 等于样本数量 $n$。每一轮用 $n-1$ 个样本训练，1个样本验证。计算量巨大，适用于极小数据集。\n  - **Group K-Fold:** 根据样本的分组进行划分，确保同一组的样本不会同时出现在训练集和验证集中（例如，患者 ID）。用于避免数据泄露。\n- **在 GBDT/Tree Models 中的应用:**\n  - **模型评估:** 使用交叉验证来获取模型性能的平均分数和标准差，作为模型泛化能力的估计。\n  - **超参数调优:** 与网格搜索、随机搜索等结合使用，在交叉验证的每一折上评估一组超参数的效果，选择平均性能最好的参数组合。\n  - **早期停止 (Early Stopping):** 在 GBDT 的训练过程中，通常会在训练时提供一个单独的验证集（或在交叉验证中使用某一折作为验证集），监控模型在该验证集上的性能，如果连续多轮性能没有提升，则提前停止训练。这是防止过拟合的重要手段。XGBoost 的 `cv` 函数，以及 XGBoost, LightGBM, CatBoost 的 `fit` 方法中，都可以指定 `eval_set` 和 `early_stopping_rounds`/`callbacks` 来实现。\n\n## 2. 网格搜索 (Grid Search)\n\n**网格搜索**是一种超参数优化技术。它通过在预先指定的超参数值网格中进行**穷举搜索**，找到在指定评估标准下性能最好的参数组合。\n\n- **目的 (重点内容):** 寻找模型的**最佳超参数组合**，以最大化模型在未知数据上的性能。\n- **基本思想:**\n  1. 定义一个字典，指定要调优的超参数名称以及每个参数要尝试的值列表。\n  2. 网格搜索会生成所有可能的超参数组合。\n  3. 对于每个超参数组合，使用交叉验证（通常是 k-fold CV）来评估模型性能。\n  4. 选择在交叉验证中平均性能最好的超参数组合。\n- **与交叉验证结合 (重点内容):**\n  - 网格搜索**通常与交叉验证一起使用**。例如，在使用 scikit-learn 的 `GridSearchCV` 时，它会自动对参数网格中的每个组合进行交叉验证。\n  - 在每一折交叉验证中，模型都在该折的训练集上训练，并在对应的验证集上评估。\n  - 最终选择的参数是使**交叉验证平均得分**最高的那个组合。\n- **在 GBDT/Tree Models 中的应用:** 用于调优 XGBoost, LightGBM, CatBoost 等模型的参数，例如 `n_estimators`, `learning_rate`, `max_depth`/`num_leaves`/`depth`, `subsample`, `colsample_bytree`, `reg_alpha`, `reg_lambda`/`l2_leaf_reg` 等。\n- **优缺点:**\n  - **优点:** 简单易懂，保证找到网格中最好的参数组合。\n  - **缺点:** 计算量巨大，特别是当参数数量多或每个参数尝试的值范围大时；无法探索网格之外的参数空间。对于计算资源有限或数据集很大的情况可能不实用。\n\n## 3. 模型堆叠 (Stacking)\n\n**模型堆叠 (Stacking)** 是一种**集成学习**技术，它结合了多个不同模型（称为**基础模型**或第一层模型）的预测，然后使用另一个模型（称为**元模型**或第二层模型）来学习如何最佳地组合这些预测。\n\n- **目的 (重点内容):** 通过结合多个模型来提高预测性能，特别是当基础模型具有不同的优势和劣势时。\n- **核心思想:** 使用基础模型的预测作为新的特征，训练一个元模型来做出最终预测。\n- **过程 (重点内容):**\n  1. **训练集划分:** 将原始训练集划分为两部分（例如，使用交叉验证）。\n  2. **训练基础模型 (Layer 1):**\n     - 对原始训练集使用 $k$-fold 交叉验证。\n     - 在每一折中，用 $k-1$ 折的数据训练基础模型（例如，XGBoost, Logistic Regression, SVM 等）。\n     - 用训练好的模型对剩余的 1 折数据进行预测（这部分数据在训练当前模型时是未见过的）。\n     - 重复 $k$ 次，将所有折的预测结果拼接起来，得到与原始训练集大小相同的“**out-of-fold (OOF) 预测**”数据集。这些 OOF 预测将作为元模型的训练数据。\n     - （可选）在整个原始训练集上训练基础模型，用于对测试集进行预测。\n  3. **生成元模型训练数据:** 将所有基础模型在训练集上生成的 OOF 预测结果作为新的特征集 $X_{\\text{meta_train}}$。原始训练集的标签 $y_{\\text{train}}$ 作为元模型的标签。\n  4. **训练元模型 (Layer 2):** 在 $X_{\\text{meta_train}}$ 和 $y_{\\text{train}}$ 上训练元模型（例如，简单的线性模型、树模型、神经网络等）。\n  5. **对测试集进行预测:**\n     - 用所有基础模型对原始测试集进行预测。\n     - 将所有基础模型在测试集上的预测结果作为新的特征集 $X_{\\text{meta_test}}$。\n     - 使用训练好的元模型对 $X_{\\text{meta_test}}$ 进行预测，得到最终的预测结果。\n- **在 GBDT/Tree Models 中的应用:**\n  - GBDT/Tree Models (XGBoost, LightGBM, CatBoost) 可以用作强大的**基础模型**。\n  - 简单的模型（如 Logistic Regression, Ridge Regression）或 Tree Models 也可以用作**元模型**。简单的元模型有助于防止过拟合。\n- **优缺点:**\n  - **优点:** 通常能获得比任何单个基础模型更好的性能，是 Kaggle 比赛等场景中常用的技术。\n  - **缺点:** 过程复杂，需要训练多个模型；训练时间较长；如果基础模型相似或元模型选择不当，可能提升不明显甚至过拟合。\n\n## 4. 模型混合 (Blending)\n\n**模型混合 (Blending)** 是一种比 Stacking 更简单的集成技术，也可以用来组合多个模型的预测。它与 Stacking 的主要区别在于，它使用一个**单独的保持集 (Hold-out Set)** 来生成元模型的训练数据，而不是使用交叉验证。\n\n- **目的 (重点内容):** 类似于 Stacking，通过组合多个模型的预测来提高性能，但实现更简单快捷。\n- **核心思想:** 将一部分数据完全分离出来作为“混合集”，用于训练元模型。\n- **过程 (重点内容):**\n  1. **数据集划分:** 将原始数据集划分为三个不重叠的部分：**训练集** (Training Set)、**混合集** (Blending Set) 和 **测试集** (Test Set)。\n  2. **训练基础模型 (Layer 1):** 在**训练集**上训练所有基础模型。\n  3. **生成元模型训练数据:** 用在训练集上训练好的基础模型对**混合集**进行预测。这些预测结果作为新的特征集 $X_{\\text{meta_blend}}$。混合集的标签 $y_{\\text{blend}}$ 作为元模型的标签。\n  4. **训练元模型 (Layer 2):** 在 $X_{\\text{meta_blend}}$ 和 $y_{\\text{blend}}$ 上训练元模型。\n  5. **对测试集进行预测:**\n     - 用在训练集上训练好的所有基础模型对**测试集**进行预测。\n     - 将所有基础模型在测试集上的预测结果作为新的特征集 $X_{\\text{meta_test}}$。\n     - 使用训练好的元模型对 $X_{\\text{meta_test}}$ 进行预测，得到最终的预测结果。\n- **在 GBDT/Tree Models 中的应用:**\n  - GBDT/Tree Models (XGBoost, LightGBM, CatBoost) 可以用作强大的**基础模型**。\n  - 简单的模型（如 Logistic Regression, Ridge Regression）或 Tree Models 也可以用作**元模型**。\n- **优缺点:**\n  - **优点:** 实现简单快捷，避免了 Stacking 中的 OOF 预测计算复杂性；对训练集和混合集有明确的分离，避免了信息泄露。\n  - **缺点:** 基础模型只在训练集上训练，可能没有充分利用所有可用数据；混合集的大小对元模型的训练效果影响很大；容易过拟合到特定的混合集划分。\n\n## 数据、公式与示例列表 (交叉验证, 网格搜索, Stacking, Blending)\n\n### 数据与数值:\n\n- **k-Fold 交叉验证的折数:** $k$ (通常取 5 或 10)\n- **LOOCV 的折数:** $n$ (样本数量)\n- **Grid Search:** 需要指定参数网格（例如 `{'param_name': [value1, value2, ...], ...}`）\n- **Stacking:** 需要 $k$-fold 交叉验证 (通常 $k \\ge 5$)\n- **Blending 数据集划分比例:** 没有固定比例，常见如 60% 训练，20% 混合，20% 测试。\n\n### 公式:\n\n- **交叉验证平均分数:**\n  $$\n  \\text{AvgScore} = \\frac{1}{k} \\sum_{i=1}^k \\text{Score}_i\n  $$\n  ($\\text{Score}_i$ 是第 $i$ 轮交叉验证在验证集上的得分)\n\n- **Stacking 元模型输入:** \n  $$\n  X_{\\text{meta}} = [\\text{Prediction}_{\\text{BaseModel}_1}, \\text{Prediction}_{\\text{BaseModel}_2}, \\dots]\n  $$\n\n- **Blending 元模型输入:** \n  $$\n  X_{\\text{meta_blend}} = [\\text{Prediction}_{\\text{BaseModel}_1}(\\text{BlendingSet}), \\text{Prediction}_{\\text{BaseModel}_2}(\\text{BlendingSet}), \\dots]\n  $$\n\n### 示例:\n\n- **k-Fold Cross-Validation (Scikit-learn):**\n\n  ```python\n  from sklearn.model_selection import cross_val_score, KFold\n  # model = ... # 你的模型 (e.g., lgb.LGBMClassifier)\n  # X, y = ... # 数据\n  kf = KFold(n_splits=5, shuffle=True, random_state=42)\n  scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n  print(f\"CV Scores: {scores}\")\n  print(f\"Mean Accuracy: {scores.mean():.4f}\")\n  ```\n\n- **Grid Search with Cross-Validation (Scikit-learn):**\n\n  ```python\n  from sklearn.model_selection import GridSearchCV\n  # model = ... # 你的模型\n  # param_grid = {'param1': [v1, v2], 'param2': [v3, v4]}\n  # X, y = ... # 数据\n  grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n  grid_search.fit(X, y)\n  print(f\"Best Parameters: {grid_search.best_params_}\")\n  print(f\"Best Cross-validated Score: {grid_search.best_score_:.4f}\")\n  ```\n\n- **Stacking (概念性示例 - 实际实现通常使用更高级库或手动编写):**\n\n  ```python\n  # 假设 base_models 是一个基础模型列表\n  # 假设 meta_model 是一个元模型\n  # 使用 KFold 生成 OOF 预测\n  # train_meta_features = np.zeros((X_train.shape[0], len(base_models)))\n  # test_meta_features = np.zeros((X_test.shape[0], len(base_models)))\n  \n  # for i, model in enumerate(base_models):\n  #     oof_preds = cross_val_predict(model, X_train, y_train, cv=5, method='predict_proba') # 或 predict\n  #     test_preds = model.fit(X_train, y_train).predict_proba(X_test) # 或 predict\n  #     train_meta_features[:, i] = oof_preds[:, 1] # 对于二分类\n  #     test_meta_features[:, i] = test_preds[:, 1] # 对于二分类\n  \n  # meta_model.fit(train_meta_features, y_train)\n  # final_predictions = meta_model.predict(test_meta_features)\n  ```\n\n  (注意: scikit-learn 提供了 `StackingClassifier` 和 `StackingRegressor`，但需要 Python 3.6+ 和较新版本。)\n\n- **Blending (概念性示例 - 实际代码):**\n\n  ```python\n  # 假设 X_train, X_blend, X_test, y_train, y_blend 是已经划分好的数据\n  # base_models = [...] # 基础模型列表\n  # meta_model = ... # 元模型\n  \n  # # 训练基础模型\n  # trained_base_models = [model.fit(X_train, y_train) for model in base_models]\n  \n  # # 生成混合集上的预测 (元模型的训练数据)\n  # blend_meta_features = np.column_stack([\n  #     model.predict_proba(X_blend)[:, 1] for model in trained_base_models # 二分类\n  # ])\n  \n  # # 训练元模型\n  # meta_model.fit(blend_meta_features, y_blend)\n  \n  # # 生成测试集上的预测 (元模型的测试数据)\n  # test_meta_features = np.column_stack([\n  #     model.predict_proba(X_test)[:, 1] for model in trained_base_models # 二分类\n  # ])\n  \n  # # 最终预测\n  # final_predictions = meta_model.predict(test_meta_features)\n  ```","tags":["python"],"categories":["机器学习"]},{"title":"CatBoost内容补充","url":"/post/CatBoost.html","content":"\n# CatBoost内容补充\n\n## 1. CatBoost (Categorical Boosting)\n\nCatBoost (Categorical Boosting) 是俄罗斯搜索巨头 Yandex 开发的一个开源梯度提升框架。它在 GBDT 的基础上进行了优化，**尤其擅长处理类别特征**，并且在训练过程中引入了独特的机制来**缓解预测偏移 (Prediction Shift) 问题**，提高了模型的鲁棒性和泛化能力。\n\n- **核心思想:** CatBoost 延续了梯度提升框架，迭代地构建决策树来优化目标函数。其最大的特点和创新在于其针对**类别特征的处理方式**以及**有序提升 (Ordered Boosting)** 算法。\n- **与 XGBoost / LightGBM 的主要区别和改进 (重点内容):**\n  1. **类别特征处理 (Categorical Feature Handling):** 这是 CatBoost 的核心优势。它使用了一种被称为**有序目标编码 (Ordered Target Encoding)** 或 \"Middles\" 的方法，结合**特征组合**来有效地处理类别特征，避免了传统方法（如 One-Hot 或标准目标编码）可能带来的问题（维度爆炸、信息丢失、预测偏移）。\n  2. **预测偏移问题与有序提升 (Prediction Shift & Ordered Boosting):** 标准的 Boosting 算法在计算梯度时使用了基于整个数据集的模型，这可能导致训练和预测分布不一致（预测偏移）。CatBoost 引入了**有序提升**，在计算每个样本的梯度时，仅使用基于**该样本之前**的数据子集训练的模型，从而缓解了这个问题。\n  3. **决策树结构 (Tree Structure):** CatBoost 默认使用**对称的决策树 (Symmetric Trees)**。在构建树时，同一深度的节点都使用相同的特征和分裂阈值进行分裂。这使得树结构更加规则，预测速度快，并且有一定的正则化效果。\n  4. **基于直方图的数值特征处理 (Histogram-based Numerical Feature Handling):** 对于数值特征，CatBoost 也采用了类似于 LightGBM 的直方图算法，将连续值离散化，提高了分裂点查找的效率。\n  5. **更少的参数调优 (Less Parameter Tuning):** 相比 XGBoost 和 LightGBM，CatBoost 在许多数据集上使用默认参数就能获得不错的效果，减少了调参的复杂性（尽管依然有很多参数可供调整）。\n  6. **支持 GPU 训练:** 对 GPU 的支持良好，可以显著加速训练过程。\n\n### 1.1 类别特征处理 (Categorical Feature Handling)\n\n标准的处理类别特征的方法有 One-Hot Encoding 和 Target Encoding。\n\n- **One-Hot Encoding (独热编码):** 对于高基数（类别数量多）的类别特征，One-Hot Encoding 会产生大量的稀疏特征，增加模型复杂度和内存消耗。\n- **Target Encoding (目标编码):** 将类别特征的值替换为该类别对应目标变量的统计量（如均值）。例如，对于分类问题，可以将类别替换为该类别下样本属于正类的比例 $E[y | \\text{category}]$. 这种方法虽然有效，但在标准的 Boosting 框架下，容易导致**信息泄露 (Data Leakage)** 或**预测偏移 (Prediction Shift)**：在训练时，计算目标编码使用了整个数据集的信息，包括当前样本的目标值，这使得模型在训练集上表现很好，但在未见过的数据（测试集）上性能下降。\n\nCatBoost 针对这些问题提出了解决方案：\n\n1. **有序目标编码 (Ordered Target Encoding) / \"Middles\":**\n\n   - 为了避免信息泄露，CatBoost 在计算类别特征的目标编码时，采用了一种基于**随机排列**的方法。\n\n   - 对于训练集的一个随机排列，当计算样本 $i$ 的某个类别特征的目标编码时，**只使用在该排列中位于样本 $i$ 之前的样本**来计算统计量。\n\n   - 具体公式通常为：\n     $$\n     \\text{EncodedValue}_i = \\frac{\\sum_{j=1}^{i-1} [\\text{category}_j = \\text{category}_i] \\cdot \\text{target}_j + \\text{prior} \\cdot \\text{weight}}{\\sum_{j=1}^{i-1} [\\text{category}_j = \\text{category}_i] \\cdot \\text{weight} + \\text{prior}}\n     $$\n     其中，$[\\cdot]$ 是指示函数，$\\text{prior}$ 是一个先验值（如整个数据集的目标均值），$\\text{weight}$ 是先验的权重。使用先验可以减少低频类别带来的噪声。\n\n   - CatBoost 可以使用多个随机排列来计算不同的编码，增加鲁棒性。\n\n   - **优点:** 有效地处理了类别特征，避免了信息泄露和预测偏移，无需手动进行 One-Hot 或目标编码。\n\n   - **缺点:** 需要对数据进行排序和多次统计计算，增加了训练时间。\n\n2. **特征组合 (Feature Combinations):**\n\n   - CatBoost 可以在训练过程中自动地将某些类别特征进行组合，生成新的组合特征（例如，将 `Country=USA` 和 `City=NewYork` 组合成 `Country=USA_City=NewYork`）。\n   - 这些组合特征也使用有序目标编码进行处理。\n   - **优点:** 可以发现特征之间的交互作用，提高模型的表达能力。\n\n### 1.2 预测偏移与有序提升 (Prediction Shift & Ordered Boosting)\n\n- **预测偏移问题:** 在标准的梯度提升算法中，训练第 $t$ 棵树时计算的梯度是基于前 $t-1$ 棵树的模型对整个训练集的预测误差。这个模型是使用整个训练集的信息构建的。这意味着，当前用来计算梯度的模型，包含了未来将被用来训练第 $t$ 棵树的数据的信息。这导致训练过程中使用的预测分布与最终模型在全新数据上的预测分布之间存在差异，即预测偏移。这个问题在使用基于目标统计量的特征（如目标编码）时尤其突出。\n- **有序提升 (Ordered Boosting):**\n  - CatBoost 提出有序提升来解决预测偏移问题。\n  - 在训练第 $t$ 棵树时，它使用**两个不同的模型**：一个用于计算梯度和 Hessian（基于随机子集训练），一个用于构建当前的树。\n  - 更直观地理解：对于一个随机排列的训练集，当训练用于预测样本 $i$ 的模型时，**只使用该排列中位于样本 $i$ 之前的样本**来构建这棵树。然后用这棵树在样本 $i$ 上计算梯度。\n  - 实际上，为了效率，CatBoost 通常会使用多组随机排列，并对每个排列独立地训练一个模型来计算梯度。\n  - **优点:** 显著减轻了预测偏移问题，提高了模型的泛化能力和鲁棒性。\n  - **缺点:** 相比标准提升（Plain Boosting），计算成本更高，训练时间可能更长。\n\n### 1.3 对称树结构 (Symmetric Tree Structure)\n\n- **策略:** CatBoost 默认构建对称树。在每一层，它找到一个最佳的分裂 (特征 + 阈值)，然后将该分裂应用到该层的所有叶子节点上。\n- **优点:**\n  - **预测速度快:** 由于结构规则，可以高效地进行矢量化计算。\n  - **防止过拟合:** 对称结构限制了树的灵活性，起到一定的正则化作用。\n- **缺点:**\n  - 可能不如非对称树（如 Leaf-wise）灵活，在某些问题上可能无法达到理论上的最优解。\n  - 可以通过 `grow_policy` 参数切换到非对称结构（Lossguide）。\n\n### 1.4 LightGBM 的目标函数与优化\n\nCatBoost 基于 GBDT 框架，目标函数与 XGBoost 类似，也是最小化损失函数加上正则化项。虽然它也使用了二阶泰勒展开来近似损失函数，但在有序提升框架下，计算梯度 $g_i$ 和 Hessian $h_i$ 的模型是不同的。\n\n假设要优化的简化目标函数（类似 XGBoost）：\n$$\n\\text{Obj}^{(t)} \\approx \\sum_{i=1}^n \\left[ g_i h_t(x_i) + \\frac{1}{2} h_i h_t(x_i)^2 \\right] + \\Omega(h_t)\n$$\n在有序提升中，计算 $g_i$ 和 $h_i$ 时，$\\hat{y}_i^{(t-1)}$ 是由一个只训练到样本 $i$ 之前的数据的模型产生的预测。\n\n### 1.5 CatBoost 参数解释 (部分关键参数)\n\nCatBoost 也有很多参数，许多与 XGBoost 和 LightGBM 类似，但处理类别特征和有序提升相关的参数是其特色。\n\n| 参数/属性                     | 描述                                                         | 默认值                                | 类型/选项                                        | 重要性级别              | 与XGBoost/LightGBM对比                        |\n| :---------------------------- | :----------------------------------------------------------- | :------------------------------------ | :----------------------------------------------- | :---------------------- | :-------------------------------------------- |\n| `loss_function` / `objective` | 定义学习任务及损失函数。类似 XGBoost/LightGBM。支持多种损失函数。 | `'RMSE'` (回归), `'Logloss'` (二分类) | string                                           | **高**                  | 类似                                          |\n| `eval_metric`                 | 评估指标。类似 XGBoost/LightGBM 的 `eval_metric`/`metric`。  | 根据 `loss_function`                  | string or list of strings                        | **高 (用于评估)**       | 类似                                          |\n| `iterations` / `n_estimators` | Boosting 迭代次数，即树的数量。                              | 100                                   | int                                              | **高**                  | 类似                                          |\n| `learning_rate`               | **学习率 (Learning Rate)。** 缩放每棵树的贡献。              | 0.03                                  | float                                            | **高**                  | 默认值通常较低                                |\n| `depth`                       | **树的深度。** 对于默认的对称树结构，这是严格的最大深度。    | 6                                     | int                                              | **高**                  | 类似 XGBoost 的 `max_depth`，但针对对称树结构 |\n| `l2_leaf_reg`                 | **L2 正则化系数。** 叶子节点权重的 L2 正则化。与 XGBoost 的 `reg_lambda` 类似。 | 3                                     | float                                            | **高**                  | 类似                                          |\n| `model_shrink_rate`           | **[仅用于 Ordered Boosting] 模型收缩率。** 影响 Leaf Estimation 计算过程。 | 0                                     | float                                            | 中                      | CatBoost 独有 (Ordered Boosting)              |\n| `random_seed`                 | 随机种子。用于数据采样、排列等随机过程，确保结果可复现。     | 0                                     | int                                              | **实用**                | 类似                                          |\n| `cat_features`                | **指定哪些特征是类别特征。** 可以是特征索引列表或特征名称列表。**非常重要！** | None                                  | list of int or list of str                       | **高 (处理类别特征时)** | CatBoost 核心参数                             |\n| `verbose`                     | 控制训练过程输出信息的详细程度。可以指定整数（如 0, 100 表示每 100 轮打印一次）或布尔值。 | True                                  | bool or int                                      | **实用**                | 类似                                          |\n| `early_stopping_rounds`       | **[fit 方法参数] 早期停止轮数。** 在 `fit` 方法中指定。如果在验证集上经过 `early_stopping_rounds` 轮迭代后，评估指标没有提升，训练就会停止。需要同时提供验证集和 `eval_metric`。**非常重要！** | N/A                                   | int                                              | **高 (用于早期停止)**   | 类似                                          |\n| `border_count`                | **[数值特征参数] 用于构建数值特征直方图的桶的数量。** 值越大，分裂点选择越精确，但训练越慢。 | 254                                   | int                                              | 实用                    | 类似 LightGBM                                 |\n| `grow_policy`                 | **树的生长策略。** `'SymmetricTrees'` (默认，对称生长)，`'Depthwise'` (按层生长)，`'Lossguide'` (按损失最佳优先生长，类似 LightGBM 的 Leaf-wise)。 | `'SymmetricTrees'`                    | `'SymmetricTrees'`, `'Depthwise'`, `'Lossguide'` | **高**                  | 控制树结构，与 XGBoost/LightGBM 策略对应      |\n| `min_data_in_leaf`            | **叶子节点中所需的最小样本数。** 与 LightGBM 的 `min_child_samples` 类似。 | 1                                     | int                                              | 中                      | 类似 LightGBM 的 `min_child_samples`          |\n| `boosting_type`               | **Boosting 类型。** `'Ordered'` (有序提升，默认), `'Plain'` (标准提升)。使用 Ordered 可以缓解预测偏移，但训练较慢。 | `'Ordered'`                           | `'Ordered'`, `'Plain'`                           | **高**                  | CatBoost 核心参数                             |\n| `allow_writing_files`         | 是否允许 CatBoost 在训练期间创建临时文件（用于存储中间计算结果，如有序统计量）。禁用可以避免生成文件，但在处理大规模数据时可能需要更多内存。 | True                                  | bool                                             | 实用                    | CatBoost 相关                                 |\n| `feature_importances_`        | **[属性] 特征重要性。** 拟合后可用。CatBoost 支持多种计算方式。 | N/A                                   | array                                            | N/A                     | 类似                                          |\n\n### 1.6 Scikit-learn API 示例 (CatBoost)\n\nCatBoost 也提供了与 scikit-learn 兼容的 API (`CatBoostClassifier` 和 `CatBoostRegressor`)。\n\n```python\n# 导入 CatBoost 的 Scikit-learn API\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.datasets import load_iris # 使用一个简单数据集\nimport pandas as pd # 方便处理数据和指定类别特征\n\n# 加载数据集\niris = load_iris()\nX, y = iris.data, iris.target\nfeature_names = iris.feature_names\ntarget_names = iris.target_names\n\n# 转换为 Pandas DataFrame，并添加一个模拟的类别特征\nX_df = pd.DataFrame(X, columns=feature_names)\n# 假设第一个特征（sepal length）根据某个阈值（例如 5.5）分为两类\nX_df['sepal length category'] = X_df['sepal length (cm)'].apply(lambda x: 'long' if x > 5.5 else 'short')\n# 确保类别特征的 dtype 是 'category' 或 'object'\nX_df['sepal length category'] = X_df['sepal length category'].astype('category')\n\ny_series = pd.Series(y)\n\n# 分割数据集\nX_train, X_test, y_train, y_test = train_test_split(X_df, y_series, test_size=0.3, random_state=42, stratify=y_series)\n\nprint(\"\\n--- CatBoost Classifier 示例 ---\")\n\n# 初始化 CatBoost 分类器\n# loss_function='MultiClass' 用于多分类\n# eval_metric='MultiClass' 或 'MultiLogloss'\n# cat_features 指定类别特征列的索引或名称\n# CatBoost 默认使用有序提升和对称树\ncatb_clf = CatBoostClassifier(iterations=500, # 迭代次数，配合 early stopping\n                              learning_rate=0.1,\n                              depth=6, # 树的深度\n                              l2_leaf_reg=3, # L2 正则化\n                              loss_function='MultiClass', # 损失函数\n                              eval_metric='MultiClass', # 评估指标\n                              random_seed=42,\n                              verbose=100, # 每100轮打印一次信息\n                              # cat_features=[4] # 如果指定列索引，这里是新加的类别列索引\n                              cat_features=['sepal length category'], # 指定列名称更直观\n                              early_stopping_rounds=10, # 早期停止轮数\n                              # boosting_type='Ordered' # 默认就是Ordered，也可以显式指定\n                              # grow_policy='SymmetricTrees' # 默认就是SymmetricTrees\n                              # allow_writing_files=False # 如果不希望生成文件，可以设为False\n                              )\n\n# CatBoost 的 fit 方法可以直接传入类别特征信息\n# eval_set 参数用于指定验证集\ncatb_clf.fit(X_train, y_train,\n             eval_set=(X_test, y_test), # 验证集\n             # cat_features 指定类别特征列的索引或名称 (也可以在这里指定)\n             # cat_features=['sepal length category']\n             )\n\n# 预测\ny_pred_catb = catb_clf.predict(X_test)\n# CatBoost predict 默认返回原始预测结果（类别索引或回归值），对于分类问题通常需要 predict_proba 获取概率\n# y_pred_proba_catb = catb_clf.predict_proba(X_test)\n\n# 如果是多分类且 loss_function 为 MultiClass，predict 返回的是类别索引\n# 如果是二分类且 loss_function 为 Logloss，predict 返回的是原始预测值，需要 sigmoid 转换为概率或使用 predict_proba\naccuracy_catb = accuracy_score(y_test, y_pred_catb)\nprint(f\"\\n准确率: {accuracy_catb:.4f}\")\n# print(\"分类报告:\\n\", classification_report(y_test, y_pred_catb, target_names=target_names))\n\n# 打印实际训练的树数量\nprint(f\"实际训练的树数量: {catb_clf.get_best_iteration() + 1 if catb_clf.get_best_iteration() else catb_clf.get_params()['iterations']}\")\n\n# 打印特征重要性 (默认是基于分裂次数)\nprint(\"特征重要性 (CatBoost - Default):\")\nfeature_names_with_cat = feature_names + ['sepal length category']\nimportances = catb_clf.get_feature_importance()\nfor name, importance in zip(feature_names_with_cat, importances):\n     print(f\"  {name}: {importance:.4f}\")\n\n# 也可以获取基于增益的特征重要性\n# print(\"\\n特征重要性 (CatBoost - Gain):\")\n# importances_gain = catb_clf.get_feature_importance(prettified=True, importance_type='Gain')\n# print(importances_gain) # prettified=True 返回DataFrame\n```\n\n### 1.7 CatBoost 的优点和缺点\n\n- **优点:**\n  - **强大的类别特征处理能力:** 内置的有序目标编码和特征组合，无需复杂的预处理。\n  - **缓解预测偏移:** 有序提升算法提高了模型的鲁棒性和泛化能力。\n  - **较少的参数调优:** 通常使用默认参数就能获得不错的效果。\n  - **预测速度快:** 默认的对称树结构有助于加速预测。\n  - **支持 GPU:** 可以利用 GPU 加速训练。\n  - **鲁棒性:** 对异常值和缺失值不敏感（部分程度上）。\n- **缺点:**\n  - **训练速度可能不如 LightGBM (特别是Plain模式下):** 有序提升增加了计算复杂度。\n  - **内存消耗相对较高:** 特别是 Ordered 模式和处理大量类别特征时，需要存储中间统计信息。\n  - **默认对称树的限制:** 在某些问题上可能限制了模型的灵活性，不如 Leaf-wise 策略能更快地逼近最优解。\n  - **模型大小:** 模型文件可能较大。\n  - **需要显式指定类别特征:** 必须通过 `cat_features` 参数告知 CatBoost 哪些列是类别特征。\n\n### 1.8 小结\n\nCatBoost 是一个专注于**类别特征处理**和**缓解预测偏移**的梯度提升框架。它通过独特的**有序目标编码**和**有序提升**算法，解决了传统方法在处理类别特征时遇到的问题。其默认的**对称树结构**提供了快速预测和一定的正则化效果。尽管在训练速度上可能不如 LightGBM，但其在处理类别特征时的便利性和由此带来的模型鲁棒性，使其成为许多实际应用中的有力选择，尤其当数据包含大量类别特征时。相比 XGBoost 和 LightGBM，CatBoost 的默认参数往往更“开箱即用”。","tags":["python","决策树"],"categories":["机器学习"]},{"title":"LightGBM内容补充","url":"/post/LightGBM.html","content":"\n# LightGBM内容补充\n\n## 1. LightGBM (Light Gradient Boosting Machine)\n\nLightGBM (Light Gradient Boosting Machine) 是微软亚洲研究院开发的一个开源梯度提升框架。它设计的目标是提供一个快速、分布式、高性能的梯度提升框架，特别适用于处理大规模数据。LightGBM 在许多方面对传统的 GBDT（包括 XGBoost）进行了优化，使其在训练速度和内存消耗上具有显著优势。\n\n- **核心思想:** 与 XGBoost 类似，LightGBM 也基于梯度提升框架，通过迭代地添加决策树来优化目标函数。其主要创新在于引入了一系列**高效的算法**来加速训练过程和降低内存消耗，同时保持较高的精度。\n- **与 XGBoost 的主要区别和改进 (重点内容):**\n  1. **决策树生长策略 (Tree Growth Strategy):** XGBoost 默认采用**按层生长 (Level-wise / Depth-wise)** 策略，而 LightGBM 默认采用**按叶生长 (Leaf-wise / Best-first)** 策略。Leaf-wise 可以在找到最佳分裂点后，在当前层或更深层生长，可能生成不对称的树，但通常能更快地降低损失函数，达到更高的精度，代价是可能更容易过拟合。\n  2. **分裂点查找算法 (Split Finding Algorithm):** LightGBM 使用基于**直方图 (Histogram-based)** 的决策树算法，而不是 XGBoost 默认的精确贪婪算法。直方图算法将连续特征离散化到多个桶中，然后基于桶的离散值寻找分裂点。这大大减少了计算量和内存消耗。\n  3. **特征采样 (Feature Sampling):** LightGBM 提出了 **Exclusive Feature Bundling (EFB)** 算法，用于处理高维稀疏特征。EFB 可以将一些互斥（或很少同时出现）的特征捆绑成一个，减少特征数量。\n  4. **样本采样 (Sample Sampling):** LightGBM 提出了 **Gradient-based One-Side Sampling (GOSS)** 算法，用于处理样本。GOSS 会保留所有梯度较大的样本（错误分类的样本），并随机采样部分梯度较小的样本，以此减少样本数量，加速训练，同时保持模型的准确性。\n  5. **对类别特征的处理 (Categorical Feature Handling):** LightGBM 对类别特征有**内置优化**，可以直接处理类别特征，无需进行 One-Hot 编码，这对于具有大量类别特征的数据集非常有效。\n  6. **并行化优化 (Parallelism):** LightGBM 在数据并行、特征并行和模型并行方面都进行了优化，特别是在特征并行和数据并行方面，其直方图算法带来了额外的效率提升。\n\n### 1.1 LightGBM 的核心算法\n\nLightGBM 引入了两个主要的创新算法来提高效率：GOSS 和 EFB。\n\n#### 1.1.1 Gradient-based One-Side Sampling (GOSS)\n\n- **问题:** GBDT 在训练时，每个样本的权重或重要性是不同的，梯度大的样本对模型训练的贡献更大（因为它们是当前模型未很好预测的样本）。如果简单地随机下采样，可能会丢失一些重要样本的信息。\n- **思想:** GOSS 算法保留所有梯度较大的样本（\"大梯度\"样本），并对梯度较小的样本（\"小梯度\"样本）进行随机采样。为了补偿小梯度样本被采样丢弃的信息，它会将采样到的小梯度样本乘以一个常数因子进行放大。\n- **步骤:**\n  1. 根据样本的梯度大小将样本排序。\n  2. 选择 Top $a \\times 100\\%$ 的样本作为大梯度样本 ($a$ 是一个超参数，如 `top_rate`)。\n  3. 从剩下 $(1-a) \\times 100\\%$ 的小梯度样本中，随机采样 $b \\times 100\\%$ 的样本作为采样到的小梯度样本 ($b$ 是一个超参数，如 `other_rate`)。\n  4. 在计算增益时，对于采样到的小梯度样本，将其梯度乘以一个缩放因子 $\\frac{1-a}{b}$。大梯度样本的梯度保持不变。\n- **效果:** 在减少样本数量的同时，保留了更多重要的信息，从而在保证精度的情况下加速训练。\n\n#### 1.1.2 Exclusive Feature Bundling (EFB)\n\n- **问题:** 在高维稀疏数据集中，许多特征是稀疏的，并且许多特征在同一行样本中是互斥的（例如，One-Hot 编码后的特征，不同类别的 One-Hot 特征在同一行只有一个是 1）。基于直方图的算法仍然需要遍历每个特征来构建直方图。\n- **思想:** EFB 算法可以识别出那些互斥的特征集合，并将它们**捆绑 (Bundle)** 成一个单一的特征。通过捆绑，减少了特征数量，从而降低了构建直方图和计算增益的计算复杂度。\n- **机制:** 通过构建特征之间的关系图（非零值是否同时出现）或使用贪婪算法，将互斥特征或冲突很少（冲突在可接受范围内，通过参数控制）的特征合并。\n- **效果:** 显著减少了特征数量，特别适用于 One-Hot 编码或具有大量稀疏特征的数据集，提高了训练速度。\n\n### 1.2 基于直方图的树分裂 (Histogram-based Tree Splitting)\n\n- **思想:** LightGBM 不像精确贪婪算法那样遍历所有可能的连续分裂点，而是将连续特征离散化到固定的 $k$ 个桶中。在分裂时，只考虑这 $k$ 个桶边界作为分裂点。\n- **过程:**\n  1. 训练前，对每个特征，构建一个具有 $k$ 个桶的直方图。每个桶存储落入该范围内的样本的一阶和二阶梯度和。\n  2. 在树节点分裂时，遍历特征，不再需要对样本排序。而是直接遍历这 $k$ 个桶，计算每个桶边界作为分裂点的增益。\n  3. 选择最佳桶边界作为分裂点。\n- **优点:**\n  - 计算效率: 构建直方图的复杂度是 $O(N \\times D)$，寻找最佳分裂点的复杂度是 $O(k \\times D)$。远小于精确算法的 $O(N \\log N)$ 或 $O(N \\times D)$。\n  - **内存消耗:** 只需存储直方图而不是所有样本的排序特征值。\n- **缺点:** 是一种近似算法，找到的分裂点不是最优的，可能损失微小精度（在实际应用中通常可以忽略）。\n\n### 1.3 按叶生长策略 (Leaf-wise / Best-first Tree Growth)\n\n- **对比:**\n  - **Level-wise (XGBoost 默认):** 每次分裂扩展同一层的所有叶子节点。树结构是对称的，易于并行化。\n  - **Leaf-wise (LightGBM 默认):** 每次分裂只选择当前具有最大分裂增益的叶子节点进行分裂。\n- **优点:**\n  - 在分裂次数相同的情况下，Leaf-wise 可以比 Level-wise 降低更多的损失，因为它总是优先分裂那些最具“增益潜力”的节点。这通常意味着可以用更少的迭代次数或分裂次数达到目标精度。\n- **缺点:**\n  - 可能生成不对称的树结构，在同一层深度上的节点数差异较大。\n  - 由于每次只扩展一个叶子，如果不对最大深度进行限制 (`max_depth` 参数)，Leaf-wise 可能会生成很深的树，导致过拟合。因此，在使用 Leaf-wise 时，通常需要配合限制最大深度或叶子节点数 (`num_leaves`) 来控制模型复杂度。\n\n### 1.4 LightGBM 的目标函数\n\nLightGBM 基于 GBDT 框架，其目标函数与 XGBoost 非常相似，也是在每一步迭代中找到一棵树 $h_t(x)$ 来优化损失函数和正则化项。使用二阶泰勒展开近似损失函数后，其目标函数形式与 XGBoost 基本一致：\n$$\n\\text{Obj}^{(t)} \\approx \\sum_{i=1}^n \\left[ g_i h_t(x_i) + \\frac{1}{2} h_i h_t(x_i)^2 \\right] + \\Omega(h_t)\n$$\n其中 $g_i$ 和 $h_i$ 是一阶和二阶导数，$\\Omega(h_t)$ 是正则化项（形式与 XGBoost 类似）。\n\n主要的区别在于，在基于直方图的分裂过程中，这些 $g_i$ 和 $h_i$ 会被累加到对应的桶中，分裂增益的计算也基于这些桶的统计信息。\n\n### 1.5 LightGBM 参数解释 (部分关键参数)\n\nLightGBM 的参数也很多，许多参数与 XGBoost 含义类似，但也有一些独特参数或常用值范围不同。\n\n| 参数/属性                  | 描述                                                         | 默认值           | 类型/选项                             | 重要性级别              | 与XGBoost对比                                                |\n| :------------------------- | :----------------------------------------------------------- | :--------------- | :------------------------------------ | :---------------------- | :----------------------------------------------------------- |\n| `objective`                | 定义学习任务及损失函数。类似 XGBoost。                       | `'regression'`   | string                                | **高**                  | 类似                                                         |\n| `metric`                   | 评估指标。类似 XGBoost 的 `eval_metric`。                    | 根据 `objective` | string or list of strings             | **高 (用于评估)**       | 类似                                                         |\n| `boosting_type`            | Boosting 类型。`'gbdt'` (标准梯度提升)，`'dart'` (Dropout)，`'goss'` (Gradient-based One-Side Sampling)。**重要！** 控制是否使用 GOSS。 | `'gbdt'`         | `'gbdt'`, `'dart'`, `'goss'`          | **高**                  | XGBoost 无此直接控制 GOSS 的参数                             |\n| `num_leaves`               | **每棵树的最大叶子节点数。** 这是控制树模型复杂度的主要参数，优先于 `max_depth`。 Leaf-wise 策略下，节点数越多，树越复杂。通常设置为 $2^k$ (其中 $k$ 是期望的深度)。常见值在 32-128 之间。 | 31               | int                                   | **高**                  | LightGBM Leaf-wise 策略下的关键参数，XGBoost 主要是 `max_depth` |\n| `max_depth`                | 树的最大深度。在 Leaf-wise 模式下，这不是严格的限制，但可以用来防止树长得太深过拟合。 `-1` 表示无限制。在 Level-wise 模式下，与 XGBoost 含义相同。 | -1               | int                                   | **高 (防过拟合)**       | LightGBM 优先 `num_leaves`，XGBoost 优先 `max_depth`         |\n| `learning_rate`            | **学习率 (Learning Rate)。** 等同于 XGBoost 的 `eta`。缩放每棵树的贡献。 | 0.1              | float                                 | **高**                  | 类似                                                         |\n| `n_estimators`             | Boosting 迭代次数，即树的数量。                              | 100              | int                                   | **高**                  | 类似                                                         |\n| `subsample`                | 训练每棵树时，随机采样的训练样本比例 (行采样)。与 XGBoost 含义相同。 | 1.0              | float                                 | 中                      | 类似                                                         |\n| `colsample_bytree`         | 训练每棵树时，随机采样的特征比例 (列采样)。与 XGBoost 含义相同。 | 1.0              | float                                 | 中                      | 类似                                                         |\n| `min_child_samples`        | **子节点中所需的最小样本数。** 类似于 XGBoost 的 `min_child_weight`，但基于样本数量。值越大，模型越保守。 | 20               | int                                   | **高**                  | 类似于 XGBoost 的 `min_child_weight` 但更直接基于样本数      |\n| `min_child_weight`         | 子节点中所需的最小样本权重和。与 XGBoost 含义类似。          | 0.001            | float                                 | 中                      | 类似                                                         |\n| `gamma` (`min_split_gain`) | **在节点分裂时，只有分裂后损失函数的减少量（增益）大于等于 `min_split_gain` 时，才会进行分裂。** 与 XGBoost 的 `gamma` 含义相同。 | 0.0              | float                                 | **高**                  | 类似                                                         |\n| `reg_alpha`                | L1 正则化系数。与 XGBoost 含义相同。                         | 0.0              | float                                 | 中                      | 类似                                                         |\n| `reg_lambda`               | L2 正则化系数。与 XGBoost 的 `reg_lambda` 含义相同。         | 0.0              | float                                 | **高**                  | 类似                                                         |\n| `colsample_bynode`         | 在树的每个节点分裂时，随机采样的特征比例。与 XGBoost 含义相同。 | 1.0              | float                                 | 低                      | 类似                                                         |\n| `subsample_freq`           | 对 `subsample` 参数进行采样的频率。每隔 `subsample_freq` 次迭代执行一次 `subsample`。 | 1                | int                                   | 低                      | XGBoost 无此参数                                             |\n| `top_rate`                 | **[GOSS 参数] GOSS 算法中保留的大梯度样本比例。**            | 0.1              | float                                 | **高 (使用 GOSS时)**    | LightGBM 独有 (GOSS)                                         |\n| `other_rate`               | **[GOSS 参数] GOSS 算法中随机采样的小梯度样本比例。**        | 0.07             | float                                 | **高 (使用 GOSS时)**    | LightGBM 独有 (GOSS)                                         |\n| `bin_construct_sample_cnt` | **[直方图参数] 用于构建特征直方图的样本数。** 通过采样部分样本来构建直方图可以加速，尤其在数据量巨大时。 | 200000           | int                                   | 实用                    | XGBoost 无此参数                                             |\n| `num_iterations`           | Boosting 迭代次数。与 `n_estimators` 相同，但更推荐使用 `n_estimators` 以兼容 scikit-learn API。 | 100              | int                                   | **高**                  | 类似                                                         |\n| `n_jobs`                   | 并行计算使用的CPU数量。`-1` 表示使用所有可用的处理器。       | -1               | int                                   | **实用**                | 类似                                                         |\n| `random_state`             | 随机种子。控制随机性，确保结果可复现。                       | None             | int                                   | **实用**                | 类似                                                         |\n| `categorical_feature`      | 指定哪些特征是类别特征。可以是特征索引列表或特征名称列表。 `'auto'` 表示自动检测。 **重要！** LightGBM 内置优化类别特征处理。 | `'auto'`         | list of int, list of str, or `'auto'` | **高 (处理类别特征时)** | XGBoost 需要手动处理 (如 One-Hot)                            |\n| `early_stopping_rounds`    | **[fit 方法参数] 早期停止轮数。** 在 `fit` 方法中指定。如果在验证集上经过 `early_stopping_rounds` 轮迭代后，评估指标没有提升，训练就会停止。需要同时提供验证集和 `metric`。**非常重要！** | N/A              | int                                   | **高 (用于早期停止)**   | 类似                                                         |\n| `callbacks`                | **[fit 方法参数] 回调函数列表。** 可以用来实现早停、日志记录等功能。`EarlyStopping` 回调函数提供了早期停止功能。 | None             | list of callback objects              | **实用 (用于早期停止)** | 类似                                                         |\n| `feature_importances_`     | **[属性] 特征重要性。** 拟合后可用。LightGBM 默认是基于分裂次数 (`split`) 或增益 (`gain`)。 | N/A              | array                                 | N/A                     | 类似，但 LightGBM 默认是 `split` 或 `gain`，XGBoost 默认是 `gain` |\n\n### 1.6 Scikit-learn API 示例 (LightGBM)\n\nLightGBM 也提供了与 scikit-learn 兼容的 API (`LGBMClassifier` 和 `LGBMRegressor`)。\n\n```python\n# 导入 LightGBM 的 Scikit-learn API\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.datasets import load_iris # 假设使用 Iris 数据集\nimport pandas as pd # LightGBM 对 Pandas DataFrame 支持更好\n\n# 加载数据集\niris = load_iris()\nX, y = iris.data, iris.target\nfeature_names = iris.feature_names\ntarget_names = iris.target_names\n\n# 转换为 Pandas DataFrame (LightGBM 对 Pandas 支持很好)\nX_df = pd.DataFrame(X, columns=feature_names)\ny_series = pd.Series(y) # Target can also be a Series\n\n# 分割数据集\nX_train, X_test, y_train, y_test = train_test_split(X_df, y_series, test_size=0.3, random_state=42, stratify=y_series)\n\nprint(\"\\n--- LightGBM Classifier 示例 ---\")\n\n# 初始化 LightGBM 分类器\n# objective='multiclass' 或 'softmax' 用于多分类\n# num_class=3 指定类别数量\n# metric='multi_logloss' 是多分类常用的评估指标\nlgb_clf = lgb.LGBMClassifier(objective='multiclass',\n                             num_class=3, # 多分类时需要指定类别数量\n                             metric='multi_logloss', # 评估指标\n                             n_estimators=500, # 初始设置多一些树，配合 early stopping\n                             learning_rate=0.1,\n                             num_leaves=31, # 默认值，或根据 max_depth 设置\n                             max_depth=-1, # 无严格深度限制，主要靠 num_leaves 控制复杂度\n                             min_child_samples=20, # 最小叶子样本数\n                             subsample=0.8, # 行采样\n                             colsample_bytree=0.8, # 列采样\n                             reg_alpha=0.1, # L1 正则化\n                             reg_lambda=0.1, # L2 正则化\n                             n_jobs=-1, # 使用所有CPU\n                             random_state=42,\n                             boosting_type='gbdt' # 或者 'goss' 使用GOSS\n                             # categorical_feature='auto' # 自动检测类别特征，或指定索引列表\n                             )\n\n# 使用 Early Stopping 进行训练\n# 需要提供评估数据集和评估指标名称\neval_set = [(X_test, y_test)]\n# early_stopping_rounds 参数直接在 fit 方法中使用\nlgb_clf.fit(X_train, y_train,\n            eval_set=eval_set,\n            eval_metric='multi_logloss', # 需要在fit方法中再次指定评估指标\n            callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=True)] # 新版本推荐使用 callbacks\n            # early_stopping_rounds=10 # 旧版本用法\n            )\n\n# 预测\ny_pred_lgb = lgb_clf.predict(X_test)\naccuracy_lgb = accuracy_score(y_test, y_pred_lgb)\nprint(f\"\\n准确率: {accuracy_lgb:.4f}\")\n# print(\"分类报告:\\n\", classification_report(y_test, y_pred_lgb, target_names=target_names))\n\n# 打印实际训练的树数量\n# 在 callbacks 中使用 early_stopping 时，可以通过 .best_iteration_ 获取\nif hasattr(lgb_clf, 'booster_'):\n    print(f\"实际训练的树数量: {lgb_clf.booster_.current_iteration()}\")\nelif hasattr(lgb_clf, '_best_iteration'):\n    print(f\"实际训练的树数量: {lgb_clf._best_iteration + 1}\")\nelse:\n     print(f\"实际训练的树数量: {lgb_clf.n_estimators}\")\n\n# 打印特征重要性 (默认是 'split')\nprint(\"特征重要性 (LightGBM - Split):\")\nfor name, importance in zip(feature_names, lgb_clf.feature_importances_):\n     print(f\"  {name}: {importance}\") # LightGBM split importances are integers\n\n# 也可以获取基于增益的特征重要性\n# print(\"\\n特征重要性 (LightGBM - Gain):\")\n# feature_importances_gain = lgb_clf.booster_.feature_importance(importance_type='gain')\n# for name, importance in zip(feature_names, feature_importances_gain):\n#      print(f\"  {name}: {importance:.4f}\")\n```\n\n> **注意:** LightGBM 的 `early_stopping_rounds` 参数在较新版本中被移除，推荐使用 `callbacks` 参数列表中的 `lgb.early_stopping` 函数。示例代码中展示了新版用法。\n\n### 1.7 LightGBM 的优点和缺点\n\n- **优点:**\n  - **速度快:** 基于直方图的算法、GOSS、EFB 等技术使其训练速度通常比 XGBoost 快很多。\n  - **内存消耗低:** 基于直方图的算法和 EFB 显著减少了内存占用。\n  - **支持大规模数据:** 高效的算法和内存优化使其能够轻松处理大规模数据集。\n  - **支持类别特征:** 内置优化处理，无需 One-Hot 编码。\n  - **更高的精度 (有时):** Leaf-wise 策略可能在相同迭代次数下达到更高精度。\n- **缺点:**\n  - **可能容易过拟合:** Leaf-wise 策略容易生成深而不平衡的树，需要小心调整 `num_leaves` 和 `max_depth` 参数。\n  - **对稀疏数据处理不如 XGBoost:** 虽然有 EFB，但对于某些特定的稀疏数据，其效果可能不如 XGBoost 内置的稀疏分裂处理机制。\n  - **需要仔细调参:** 虽然参数比 XGBoost 少一些，但核心参数如 `num_leaves` 和 GOSS/EFB 参数需要仔细调整。\n\n### 1.8 小结\n\nLightGBM 是一个面向大规模数据的**高效**梯度提升框架。它通过采用**基于直方图**的决策树算法、独特的**按叶生长**策略、**GOSS**（梯度单边采样）和 **EFB**（互斥特征捆绑）等技术，显著提升了训练速度和降低了内存消耗。这些创新使其成为处理大规模数据集和进行快速模型训练的有力工具。与 XGBoost 相比，LightGBM 在速度和内存方面通常有优势，尤其是在 Leaf-wise 策略和直方图算法的加持下。然而，其 Leaf-wise 策略也带来了更容易过拟合的风险，需要通过 `num_leaves` 等参数进行额外控制。内置的类别特征处理也是其一大亮点。","tags":["python","决策树"],"categories":["机器学习"]},{"title":"XGBoost内容补充","url":"/post/XGBoost.html","content":"\n# XGB内容补充\n\n## 1. 集成学习 (Ensemble Learning) \n\n![集成学习](https://s2.loli.net/2025/05/27/VYIAqMkhXwxJPNZ.png)\n\n## 2. Boosting 方法的核心优化思想\n\nBoosting 方法，尤其是像 GBDT 和 XGBoost 这样的梯度提升算法，其核心在于**迭代优化**一个目标函数（通常是训练数据的损失函数加上可能的正则化项）。与传统的机器学习模型（如线性回归、SVM）在参数空间中寻找最优解不同，Boosting 是在**函数空间**中进行优化，即每一步迭代添加一个函数（弱学习器，通常是决策树）来改进当前的集成模型。\n\n### 2.1 从参数空间到函数空间 (From Parameter Space to Function Space)\n\n- **参数空间优化:** 大多数机器学习模型通过调整模型内部的参数（如线性模型的系数、神经网络的权重）来最小化损失函数。例如，线性回归 $y = w^T x + b$，优化的是参数 $w$ 和 $b$。目标函数通常是 $\\min L(y, f(x; w, b)) = \\min L(y, w^T x + b)$。\n- **函数空间优化:** Boosting 的思想是将模型表示为一系列函数的加法：$F(x) = \\sum_{t=1}^T h_t(x)$。每一步迭代 $t$，我们固定前面 $t-1$ 步得到的模型 $F_{t-1}(x) = \\sum_{k=1}^{t-1} h_k(x)$，然后寻找一个新的函数 $h_t(x)$，使得加入 $h_t(x)$ 后，整体模型 $F_t(x) = F_{t-1}(x) + h_t(x)$ 的目标函数最小化。目标函数是 $\\min L(y, F_{t-1}(x) + h_t(x))$.\n\n### 2.2 梯度下降与牛顿法 (Gradient Descent vs. Newton's Method)\n\n优化目标函数常用的迭代方法是梯度下降。\n\n- **梯度下降 (Gradient Descent):**\n  - 基本思想: 在当前点沿着函数梯度的反方向移动，因为梯度指向函数值增加最快的方向。\n  - 更新规则 (参数空间): $w_{k+1} = w_k - \\eta \\nabla J(w_k)$，其中 $J$ 是目标函数，$\\eta$ 是学习率。\n  - 在函数空间中，梯度提升（GBDT）可以理解为在函数空间中应用梯度下降。要找到下一个要添加的函数 $h_t(x)$，我们希望它能最大程度地降低目标函数 $L(y, F_{t-1}(x) + h_t(x))$。如果我们将 $h_t(x)$ 视为“函数步长”，最快的下降方向是负梯度方向。所以，GBDT 训练的下一棵树就是去拟合当前模型的负梯度。\n- **牛顿法 (Newton's Method):**\n  - 基本思想: 使用函数的二阶导数（Hessian 矩阵）信息。它通过在当前点用二次函数近似目标函数，然后跳到二次函数的最低点。\n  - 更新规则 (参数空间): $w_{k+1} = w_k - [H J(w_k)]^{-1} \\nabla J(w_k)$，其中 $H$ 是 Hessian 矩阵（二阶导数矩阵）。牛顿法通常比梯度下降收敛更快，尤其是在目标函数接近二次函数时。\n  - 牛顿法使用了一阶和二阶导数信息。这启发了 XGBoost 的目标函数优化。\n\n### 2.3 误差函数的二阶泰勒展开 (Second-order Taylor Expansion of the Loss Function)\n\n为了更精确地优化目标函数 $L(y_i, \\hat{y}_i^{(t-1)} + h_t(x_i))$ 关于 $h_t(x_i)$，XGBoost 借鉴了牛顿法的思想，使用了二阶泰勒展开来近似损失函数。\n对于一个在点 $x_0$ 附近可微的函数 $f(x)$，其在 $x_0$ 处的泰勒展开式为：\n$$\nf(x) = f(x_0) + f'(x_0)(x-x_0) + \\frac{1}{2} f''(x_0)(x-x_0)^2 + R_2(x)\n$$\n其中 $R_2(x)$ 是余项。\n在 XGBoost 中，我们将损失函数 $L(y_i, \\hat{y}_i)$ 视为关于当前预测值 $\\hat{y}_i$ 的函数，并在 $\\hat{y}_i^{(t-1)}$ 处进行泰勒展开，展开变量是我们要添加的函数 $h_t(x_i)$ 的输出。令 $x_0 = \\hat{y}_i^{(t-1)}$，变量为 $\\Delta x = h_t(x_i)$，则：\n$$\nL(y_i, \\hat{y}_i^{(t-1)} + h_t(x_i)) \\approx L(y_i, \\hat{y}_i^{(t-1)}) + \\left[ \\frac{\\partial L(y_i, \\hat{y})}{\\partial \\hat{y}} \\right]_{\\hat{y}=\\hat{y}_i^{(t-1)}} h_t(x_i) + \\frac{1}{2} \\left[ \\frac{\\partial^2 L(y_i, \\hat{y})}{\\partial \\hat{y}^2} \\right]_{\\hat{y}=\\hat{y}_i^{(t-1)}} h_t(x_i)^2\n$$\n记 $g_i = \\left[ \\frac{\\partial L(y_i, \\hat{y})}{\\partial \\hat{y}} \\right]_{\\hat{y}=\\hat{y}_i^{(t-1)}}$ 为损失函数对当前预测的一阶偏导数（梯度），$h_i = \\left[ \\frac{\\partial^2 L(y_i, \\hat{y})}{\\partial \\hat{y}^2} \\right]_{\\hat{y}=\\hat{y}_i^{(t-1)}}$ 为二阶偏导数（Hessian）。则近似公式变为：\n$$\nL(y_i, \\hat{y}_i^{(t-1)} + h_t(x_i)) \\approx L(y_i, \\hat{y}_i^{(t-1)}) + g_i h_t(x_i) + \\frac{1}{2} h_i h_t(x_i)^2\n$$\n这个近似形式是一个关于 $h_t(x_i)$ 的二次函数，类似于牛顿法中的目标函数近似。\n\n### 2.4 回归树的学习策略（作为基学习器）\n\n在 Boosting 中，个体学习器通常是回归树（即使解决分类问题，也是拟合伪残差或负梯度等数值）。回归树的学习策略是：\n\n1. 从根节点开始，遍历所有特征和所有可能的分裂点。\n2. 对于每个分裂点，计算分裂后两个子节点的“纯度”或“损失减少量”。\n3. 选择能够带来最大损失减少（或增益）的分裂点。\n4. 将节点分裂，递归进行，直到满足停止条件（如达到最大深度、叶子节点样本数少于阈值、分裂增益小于阈值等）。\n5. 对于每个叶子节点，其输出值（预测值）是落在该节点上所有样本的目标值的某种聚合（如平均值，或在 Boosting 中是经过优化的值）。\n   在 GBDT 中，回归树拟合的是当前模型的负梯度。在 XGBoost 中，回归树拟合的是一个可以使目标函数（包含一阶和二阶导数）最小化的值。\n\n## 3. XGBoost (eXtreme Gradient Boosting)\n\nXGBoost (eXtreme Gradient Boosting) 是由陈天奇等人提出的一种高效、灵活且可移植的梯度提升算法实现。它在 GBDT 的基础上进行了多方面的优化和改进，使其在许多机器学习任务中表现出色，尤其是在结构化数据上的应用。\n\n- **核心思想:** XGBoost 仍然基于梯度提升框架，通过迭代地添加决策树来优化目标函数。但它对目标函数和优化过程进行了**深度优化**，并加入了正则化项，使其在性能和计算效率上远超标准 GBDT。\n\n### 3.1 与标准 GBDT 的主要区别和改进\n\n1. **正则化 (Regularization):** 在目标函数中加入了**正则化项** (L1 和 L2 正则化)，用于控制模型的复杂度，有效防止过拟合。这是 XGBoost 区别于传统 GBDT 的一个重要特性。\n2. **目标函数优化 (Objective Function):** 使用了**二阶泰勒展开**来近似损失函数，这使得目标函数不仅考虑了一阶导数（梯度），还考虑了二阶导数（Hessian），从而可以更精确地找到下降方向，加快收敛。\n3. **分裂策略 (Split Finding):** 引入了新的**最优分裂点查找算法**，包括精确贪婪算法 (Exact Greedy) 和近似算法 (Approximate) / 直方图算法 (Hist)，可以在考虑正则化的情况下选择最佳分裂点。分裂的衡量标准是**增益 (Gain)**。\n4. **对稀疏值处理 (Sparse Value Handling):** XGBoost 对稀疏值（包括缺失值）有内置的处理机制。在特征分裂时，它可以自动学习将缺失值样本划分到左子树或右子树，无需额外的填充或预处理。\n5. **工程优化 (Engineering Optimizations):** 进行了多项工程优化，如并行计算 (Parallelism)、列块存储 (Column Block)、核外计算 (Out-of-Core Computing) 等，显著提高了训练速度和对大规模数据的处理能力。\n6. **收缩 (Shrinkage):** 同样使用学习率 (`eta`) 对每棵树的贡献进行收缩，帮助防止过拟合。\n7. **列采样 (Column Subsampling):** 借鉴了随机森林的思想，支持在构建每棵树或每个节点分裂时进行特征采样，进一步减少过拟合和提高计算速度。\n8. **早期停止 (Early Stopping):** 支持在验证集上监控性能并提前停止训练，有效控制迭代次数，防止过拟合。\n\n### 3.2 XGBoost 的目标函数\n\nXGBoost 在第 $t$ 轮迭代中要训练第 $t$ 棵树 $h_t(x)$，以最小化整体目标函数。目标函数包括训练损失和正则化项：\n$$\n\\text{Obj}^{(t)} = \\sum_{i=1}^n L(y_i, \\hat{y}_i^{(t-1)} + h_t(x_i)) + \\Omega(h_t)\n$$\n其中：\n\n- $L(y_i, \\hat{y}_i)$ 是损失函数，衡量预测值 $\\hat{y}_i$ 与真实值 $y_i$ 的差异。\n- $\\hat{y}_i^{(t-1)}$ 是前 $t-1$ 棵树的集成预测结果。\n- $h_t(x_i)$ 是第 $t$ 棵树的预测结果。\n- $\\Omega(h_t)$ 是第 $t$ 棵树的正则化项。\n\n为了优化这个目标函数，XGBoost 使用**二阶泰勒展开**来近似损失函数。对损失函数在当前模型 $\\hat{y}_i^{(t-1)}$ 处进行二阶泰勒展开：\n$$\nL(y_i, \\hat{y}_i^{(t-1)} + h_t(x_i)) \\approx L(y_i, \\hat{y}_i^{(t-1)}) + g_i h_t(x_i) + \\frac{1}{2} h_i h_t(x_i)^2\n$$\n其中 $g_i$ 是损失函数对 $\\hat{y}_i^{(t-1)}$ 的**一阶导数**（梯度），$h_i$ 是**二阶导数**（Hessian）：\n$$\ng_i = \\frac{\\partial L(y_i, \\hat{y}_i)}{\\partial \\hat{y}_i} \\Big|_{\\hat{y}_i = \\hat{y}_i^{(t-1)}} \\quad, \\quad h_i = \\frac{\\partial^2 L(y_i, \\hat{y}_i)}{\\partial \\hat{y}_i^2} \\Big|_{\\hat{y}_i = \\hat{y}_i^{(t-1)}}\n$$\n将泰勒展开代入目标函数，并忽略常数项 $L(y_i, \\hat{y}_i^{(t-1)})$，得到简化后的目标函数：\n$$\n\\text{Obj}^{(t)} \\approx \\sum_{i=1}^n \\left[ g_i h_t(x_i) + \\frac{1}{2} h_i h_t(x_i)^2 \\right] + \\Omega(h_t)\n$$\n这个目标函数只与当前要学习的树 $h_t$ 有关，是关于树结构和叶子节点权重的函数。\n\n### 3.3 XGBoost 的正则化项\n\n正则化项 $\\Omega(h_t)$ 用于控制树的复杂度，定义为：\n$$\n\\Omega(h_t) = \\gamma T + \\frac{1}{2}\\lambda \\sum_{j=1}^T w_j^2 + \\alpha \\sum_{j=1}^T |w_j|\n$$\n在提供的笔记中只包含了 L2 正则化，标准 XGBoost 也支持 L1 正则化，对应参数 `reg_alpha`。\n其中：\n\n- $T$ 是树中叶子节点的数量。\n- $w_j$ 是第 $j$ 个叶子节点的预测值（权重）。\n- $\\gamma$ (`gamma` 参数) 是一个惩罚系数，惩罚叶子节点的数量。树的叶子节点越多，复杂度越高，惩罚越大。\n- $\\lambda$ (`reg_lambda` 参数) 是 L2 正则化系数，惩罚叶子节点权重的平方和。叶子节点权重越大，模型越可能过度依赖个别样本，惩罚越大。\n- $\\alpha$ (`reg_alpha` 参数) 是 L1 正则化系数，惩罚叶子节点权重的绝对值和。有助于产生稀疏的叶子节点权重，实现特征选择。\n\n### 3.4 树结构与叶子节点权重的确定 (打分函数)\n\n对于一个**已经确定的树结构**，我们将简化目标函数按叶子节点进行分组求和。每个叶子节点 $j$ 上的所有样本 $i \\in I_j$ 具有相同的预测值 $w_j = h_t(x_i)$。结合正则化项，目标函数可以重写为：\n$$\n\\text{Obj}^{(t)} = \\sum_{j=1}^T \\left[ \\left( \\sum_{i \\in I_j} g_i \\right) w_j + \\frac{1}{2} \\left( \\sum_{i \\in I_j} h_i + \\lambda \\right) w_j^2 + \\alpha |w_j| \\right] + \\gamma T\n$$\n为了使目标函数最小化，对于每个叶子节点 $j$，我们可以独立地找到最优的权重 $w_j$。忽略 L1 项（为了简化推导，L1 项使得导数在 0 处不可导，但可以通过次梯度或坐标下降求解），对只包含 L2 正则化的目标函数求导并令导数等于 0：\n$$\n\\frac{\\partial}{\\partial w_j} \\left[ \\left( \\sum_{i \\in I_j} g_i \\right) w_j + \\frac{1}{2} \\left( \\sum_{i \\in I_j} h_i + \\lambda \\right) w_j^2 \\right] = \\sum_{i \\in I_j} g_i + (\\sum_{i \\in I_j} h_i + \\lambda) w_j = 0\n$$\n解出最优的叶子节点权重 $w_j^*$ (只考虑 L2 正则化)：\n$$\nw_j^* = - \\frac{\\sum_{i \\in I_j} g_i}{\\sum_{i \\in I_j} h_i + \\lambda}\n$$\n将最优权重 $w_j^*$ 代回目标函数（仅 L2 正则化部分），得到在**给定树结构**下，每个叶子节点 $j$ 对整体目标函数的贡献（不含 $\\gamma T$），也称为该节点的**打分 (Score)**：\n$$\n\\text{Score}_j = - \\frac{1}{2} \\frac{(\\sum_{i \\in I_j} g_i)^2}{\\sum_{i \\in I_j} h_i + \\lambda}\n$$\n整个树结构的最终打分（即最优目标函数值）是所有叶子节点打分之和，加上叶子节点数量的惩罚：\n$$\n\\text{Obj}^{(t)*} = \\sum_{j=1}^T \\text{Score}_j + \\gamma T = \\sum_{j=1}^T \\left[ - \\frac{1}{2} \\frac{(\\sum_{i \\in I_j} g_i)^2}{\\sum_{i \\in I_j} h_i + \\lambda} \\right] + \\gamma T\n$$\n最小化这个打分函数就是 XGBoost 学习树结构的目标。\n\n### 3.5 树节点分裂方法与增益计算 (Split Finding and Gain Calculation)\n\nXGBoost 在构建树时，会从根节点开始，递归地寻找最佳分裂点。寻找最佳分裂点的策略是**贪婪算法**：在当前节点，遍历所有特征和该特征所有可能的分裂阈值，计算分裂后的目标函数下降量（即增益），选择增益最大的分裂作为当前节点的最佳分裂。\n对于一个节点，假设分裂前包含样本集合 $I$，分裂后变为左子节点 $I_L$ 和右子节点 $I_R$ ($I = I_L \\cup I_R$)。分裂带来的**增益 (Gain)** 计算公式为：\n$$\n\\text{Gain} = \\text{Obj}_{\\text{before split}} - (\\text{Obj}_{\\text{after split}})\n$$\n根据前面推导的叶子节点打分公式，分裂前的节点可以看作只有一个叶子节点 $I_L \\cup I_R$，分裂后变成两个叶子节点 $I_L$ 和 $I_R$。其对应的目标函数值变化为：\n$$\n\\text{Gain} = \\left[ - \\frac{1}{2} \\frac{(\\sum_{i \\in I_L \\cup I_R} g_i)^2}{\\sum_{i \\in I_L \\cup I_R} h_i + \\lambda} + \\gamma \\right] - \\left[ \\left( - \\frac{1}{2} \\frac{(\\sum_{i \\in I_L} g_i)^2}{\\sum_{i \\in I_L} h_i + \\lambda} + \\gamma \\right) + \\left( - \\frac{1}{2} \\frac{(\\sum_{i \\in I_R} g_i)^2}{\\sum_{i \\in I_R} h_i + \\lambda} + \\gamma \\right) \\right]\n$$\n化简后得到：\n$$\n\\text{Gain} = \\frac{1}{2} \\left[ \\frac{(\\sum_{i \\in I_L} g_i)^2}{\\sum_{i \\in I_L} h_i + \\lambda} + \\frac{(\\sum_{i \\in I_R} g_i)^2}{\\sum_{i \\in I_R} h_i + \\lambda} - \\frac{(\\sum_{i \\in I_L \\cup I_R} g_i)^2}{\\sum_{i \\in I_L \\cup I_R} h_i + \\lambda} \\right] - \\gamma\n$$\n增益越大，表示分裂带来的目标函数下降越多。 $-\\gamma$ 项是引入新叶子节点的惩罚，如果计算出的最大增益小于 $\\gamma$，则这个分裂不值得进行，节点将停止分裂。\n\nXGBoost 提供了多种分裂点查找算法 (`tree_method` 参数)：\n\n- **精确贪婪算法 (Exact Greedy Algorithm):** (`tree_method='exact'`) 在每个节点遍历所有特征和所有可能的取值作为分裂点。适用于小到中等数据集。\n- **近似算法 (Approximate Algorithm):** (`tree_method='approx'`) 对连续特征根据分位数构造候选分裂点，在候选点中寻找最佳分裂。适用于大数据集。\n- **直方图算法 (Histograms):** (`tree_method='hist'`) 将连续特征离散化为多个离散桶，基于直方图计算增益。进一步提高了效率，在大数据集上表现出色，类似 LightGBM。\n\n### 3.6 稀疏值处理 (Sparse Value Handling)\n\nXGBoost 对稀疏特征（包括缺失值 `NaN`）有内置的支持，无需额外的填充。\n\n- **机制:** 在进行特征分裂时，XGBoost 不仅考虑将非缺失值样本根据阈值划分，还会**同时计算**将所有缺失值样本统一放入左子节点或右子节点所带来的增益。\n- **学习:** 通过比较将缺失值放入左、右子节点的增益，算法自动选择增益更大的方向作为缺失值的默认分裂方向。\n- **优点:** 这种基于数据学习的处理方式通常比简单的填充更有效。\n\n### 3.7 工程优化：核外计算与并行化 (Engineering Optimizations: Out-of-Core Computation and Parallelism)\n\nXGBoost 进行了大量工程优化，使其能够高效地处理大规模数据集：\n\n- **列块存储 (Column Block):** 训练数据按**列**存储并在内存块中预先排序。方便快速按特征访问数据和计算梯度统计量。\n- **核外计算 (Out-of-Core Computing):** 支持处理无法完全载入内存的数据集，通过独立的线程将数据块流式读入内存进行计算。\n- **并行计算 (Parallelism):** 支持多核 CPU 并行。特征并行（分裂点查找时并行计算不同特征）、数据并行（近似算法/直方图算法时分块并行处理）。\n\n### 3.8 XGBoost 参数解释 (部分关键参数)\n\nXGBoost 参数众多，下表列举一些重要的参数：\n\n| 参数/属性               | 描述                                                         | 默认值                    | 类型/选项                 | 重要性级别            |\n| :---------------------- | :----------------------------------------------------------- | :------------------------ | :------------------------ | :-------------------- |\n| `objective`             | 定义学习任务及相应的损失函数。**重要！** 例如 `'reg:squarederror'` (回归)，`'binary:logistic'` (二分类概率)，`'multi:softmax'` (多分类类别)。 | `'reg:squarederror'`      | string                    | **高**                |\n| `eval_metric`           | 验证数据所使用的评估指标。**重要！** 用于早期停止。例如 `'rmse'` (回归), `'logloss'` (分类), `'error'` (分类错误率), `'auc'` (AUC)。 | 根据 `objective` 自动设置 | string or list of strings | **高 (用于评估)**     |\n| `eta`                   | **学习率 (Learning Rate)。** 缩放每棵树的贡献。小值通常需要更多树，但泛化能力更好。 | 0.3                       | float                     | **高**                |\n| `n_estimators`          | **Boosting 迭代次数，即树的数量。** 通常设置较大值，配合早期停止。 | 100                       | int                       | **高**                |\n| `max_depth`             | **树的最大深度。** 控制单棵树的复杂度。通常设置在 3-10 之间。 | 6                         | int                       | **高**                |\n| `min_child_weight`      | **子节点中样本的二阶导数（Hessian）之和的最小值。** 如果一个分裂导致的子节点的 Hessian 和小于此值，则分裂被放弃。类似于 `min_samples_leaf`，但基于二阶信息。值越大，模型越保守。 | 1                         | float                     | **高**                |\n| `gamma`                 | **在节点分裂时，只有分裂后损失函数的减少量大于等于 $\\gamma$ 时，才会进行分裂。** 控制树的剪枝（或最小增益分裂）。值越大，模型越保守。 | 0                         | float                     | **高**                |\n| `subsample`             | **训练每棵树时，随机采样的训练样本比例。** (`[0, 1]`) 小于 1.0 用于行采样，防止过拟合。 | 1                         | float                     | 中                    |\n| `colsample_bytree`      | **训练每棵树时，随机采样的特征比例。** (`[0, 1]`) 用于列采样，防止过拟合。 | 1                         | float                     | 中                    |\n| `colsample_bylevel`     | **在树的每个层级分裂时，随机采样的特征比例。** (`[0, 1]`) 更细粒度的列采样。 | 1                         | float                     | 低                    |\n| `colsample_bynode`      | **在树的每个节点分裂时，随机采样的特征比例。** (`[0, 1]`) 最细粒度的列采样。 | 1                         | float                     | 低                    |\n| `reg_alpha`             | **L1 正则化系数。** (`[0, $\\infty$)`) 惩罚叶子节点权重的 L1 范数。 | 0                         | float                     | 中                    |\n| `reg_lambda`            | **L2 正则化系数。** (`[0, $\\infty$)`) 惩罚叶子节点权重的 L2 范数。等同于公式中的 $\\lambda$。 | 1                         | float                     | **高**                |\n| `tree_method`           | **构建树的算法。** `'auto'`, `'exact'`, `'approx'`, `'hist'`. `'hist'` 通常更快且内存占用低，推荐用于大数据集。 | `'auto'`                  | string                    | **实用**              |\n| `n_jobs`                | **并行计算使用的CPU数量。** `-1` 表示使用所有可用处理器。    | 1                         | int                       | **实用**              |\n| `random_state`          | **随机种子。** 控制数据采样等随机性，确保结果可复现。        | 0                         | int                       | **实用**              |\n| `early_stopping_rounds` | **[fit 方法参数] 早期停止轮数。** 在 `fit` 方法中指定。如果在验证集上经过此轮数后评估指标没有提升，训练停止。**非常重要！** | N/A                       | int                       | **高 (用于早期停止)** |\n| `eval_set`              | **[fit 方法参数] 验证集列表。** 格式为 `[(X_val, y_val), ...]`. 用于早期停止和评估。**非常重要！** | N/A                       | list of tuples            | **高 (用于早期停止)** |\n\n### 3.9 Scikit-learn API 示例 (XGBoost)\n\nXGBoost 提供了与 scikit-learn 兼容的 API (`XGBClassifier` 和 `XGBRegressor`)，使用非常方便。\n\n```python\n# 导入 XGBoost 的 Scikit-learn API\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.datasets import load_iris # 假设使用 Iris 数据集\nimport warnings # 用于忽略一些警告\n\n# 忽略 XGBoost 相关的警告\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module='xgboost')\n\n# 加载数据集\niris = load_iris()\nX, y = iris.data, iris.target\nfeature_names = iris.feature_names\ntarget_names = iris.target_names\n\n# 分割数据集\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\nprint(\"\\n--- XGBoost Classifier 示例 ---\")\n\n# 初始化 XGBoost 分类器\n# objective='multi:softmax' 用于多分类，返回预测类别索引\n# eval_metric='mlogloss' 是多分类常用的评估指标\n# num_class 需要指定多分类的类别数量\nxgb_clf = xgb.XGBClassifier(objective='multi:softmax',\n                            num_class=3, # 多分类时需要指定类别数量\n                            eval_metric='mlogloss', # 评估指标\n                            n_estimators=500, # 初始设置多一些树，配合 early stopping\n                            learning_rate=0.1, # 学习率\n                            max_depth=3, # 最大深度\n                            subsample=0.8, # 样本采样比例\n                            colsample_bytree=0.8, # 列采样比例 (每棵树)\n                            gamma=0.1, # 最小分裂增益\n                            reg_alpha=0.1, # L1 正则化\n                            reg_lambda=1, # L2 正则化\n                            n_jobs=-1, # 使用所有CPU\n                            random_state=42 # 随机种子\n                            )\n\n# 使用 Early Stopping 进行训练\n# 需要提供评估数据集和评估指标\n# eval_set 是包含 (X_val, y_val) 的列表\neval_set = [(X_test, y_test)] # 这里使用测试集作为验证集演示，实际应使用单独验证集\nprint(\"开始训练 (可能因 Early Stopping 提前结束)...\")\nxgb_clf.fit(X_train, y_train,\n            eval_set=eval_set,\n            early_stopping_rounds=10, # 连续10轮验证集分数没有提升则停止\n            verbose=False # 关闭详细训练日志，设置为 True 会打印每轮结果\n            )\n\n# 预测\ny_pred_xgb = xgb_clf.predict(X_test)\naccuracy_xgb = accuracy_score(y_test, y_pred_xgb)\nprint(f\"准确率: {accuracy_xgb:.4f}\")\nprint(\"分类报告:\")\nprint(classification_report(y_test, y_pred_xgb, target_names=target_names))\n\n# 打印实际训练的树数量 (如果使用了 Early Stopping)\nif hasattr(xgb_clf, 'best_iteration'):\n    print(f\"实际训练的树数量 (Early Stopped): {xgb_clf.best_iteration + 1}\")\nelse:\n     print(f\"实际训练的树数量: {xgb_clf.n_estimators}\") # 未 Early Stop 则使用全部树\n\n# 打印特征重要性 (默认基于 'gain')\nprint(\"\\n特征重要性 (XGBoost - Gain):\")\nfor name, importance in zip(feature_names, xgb_clf.feature_importances_):\n     print(f\"  {name}: {importance:.4f}\")\n\n# 也可以获取其他类型的特征重要性 ('weight', 'cover', 'total_gain', 'total_cover')\n# booster = xgb_clf.get_booster()\n# importance_weight = booster.get_score(importance_type='weight')\n# print(\"\\n特征重要性 (XGBoost - Weight):\")\n# for name in feature_names:\n#      # Use .get(key, default_value) as some features might have 0 weight\n#      print(f\"  {name}: {importance_weight.get(name, 0):.0f}\")\n```\n\n### 3.10 XGBoost 的优点和缺点\n\n- 优点:\n  - **高性能:** 在许多结构化数据任务中通常能达到最先进的精度。\n  - **鲁棒性:** 通过二阶泰勒展开、正则化、列采样、子样本采样等技术，有效控制过拟合。\n  - **高效:** 工程优化（如列块存储、核外计算、并行计算）使其训练速度快，能处理大规模数据。\n  - **灵活:** 支持自定义损失函数和评估指标。\n  - **处理稀疏值:** 内置缺失值等稀疏数据的处理机制。\n  - **丰富的参数:** 提供了细粒度的控制，可以针对不同问题进行调优。\n- 缺点:\n  - **参数众多:** 调参难度较大，需要经验和交叉验证。\n  - **模型可解释性相对差:** 与决策树本身类似，集成后可解释性更差。\n  - **训练仍然是串行的核心:** 虽然内部计算并行化，但树与树之间依赖前一棵树的结果，整体 Boosting 过程是串行的。\n  - **对内存要求较高:** 特别是当使用精确分裂算法或处理高基数类别特征时，需要存储排序后的列块或直方图信息。\n\n### 3.11 小结\n\nXGBoost 作为 GBDT 的一个强大升级版本，通过在目标函数中引入基于**二阶泰勒展开**的优化、增加**正则化项**、改进**分裂点查找算法**、内置**稀疏值处理**以及大量的**工程优化**（如列块存储、核外计算、并行化），极大地提升了模型性能和训练效率。它在实践中被广泛应用并成为许多数据竞赛的首选算法。理解其基于二阶信息的**目标函数**、控制复杂度的**正则化**、以及高效的**分裂策略**和**工程实现**对于高效使用 XGBoost 至关重要。**Early Stopping** 是防止过拟合和提高效率的必备技巧。","tags":["python","决策树"],"categories":["机器学习"]},{"title":"集成学习RF-Adaboost-GBDT","url":"/post/Ensemble-Learning.html","content":"\n# 集成学习\n\n## 1. 集成学习 (Ensemble Learning)\n\n集成学习（Ensemble Learning）是一种机器学习范式，其核心思想是 **组合多个学习器 (Individual Learners)** 来完成学习任务。与单个学习器相比，集成学习通常能够获得比单一最优学习器更好的泛化性能。\n\n- **核心思想:** 通过将多个弱学习器（Weak Learners）组合起来，可以形成一个强学习器（Strong Learner）。\n- **为什么有效:** 集成学习能够从不同角度学习数据，通过结合多个模型的预测结果来**降低整体误差**。具体来说：\n  - **统计:** 当学习任务的真实模型复杂，单个模型可能因样本不足而陷入局部最优。集成学习在搜索空间中可能找到更接近全局最优的解。\n  - **计算:** 某些学习算法可能因计算限制而无法获得最优解。集成学习通过组合多个次优解来逼近最优。\n  - **表示:** 真实任务可能非常复杂，无法通过一个简单的模型来准确描述。集成学习可以通过组合多个模型来表达更复杂的函数关系。\n- **关键点:** 集成学习要求个体学习器**好而不同**。\n  - **“好”:** 个体学习器自身的性能不能太差，至少不能低于随机猜测的水平。\n  - **“不同”:** 个体学习器之间应该具有差异性，即预测结果不应高度相关。差异性越大，集成后效果越好。\n\n### 1.1 集成学习的类型\n\n根据个体学习器的生成方式，目前的集成学习方法大致可以分为两大类：\n\n1. **并行集成方法 (Parallel Ensemble Methods):**\n   - 个体学习器之间不存在强依赖关系，可以同时生成。\n   - 代表：**Bagging (Bootstrap Aggregating)** 及其变种 **随机森林 (Random Forest)**。\n   - 主要用于降低**方差 (Variance)**，提高模型稳定性。\n2. **串行集成方法 (Sequential Ensemble Methods):**\n   - 个体学习器之间存在强依赖关系，必须串行生成。后一个学习器需要根据前一个学习器的表现进行调整（通常是关注前一个学习器预测错误的样本或难以预测的区域）。\n   - 代表：**Boosting** 及其变种 **AdaBoost (Adaptive Boosting)**、**Gradient Boosting (梯度提升)** (GBDT, XGBoost, LightGBM 等)。\n   - 主要用于降低**偏差 (Bias)**，提高模型精度。\n\n### 1.2 结合策略 (Combining Strategy)\n\n在生成个体学习器后，如何将它们的预测结果进行组合以获得最终的集成结果？常用的结合策略包括：\n\n- **平均法 (Averaging):**\n\n  - 对于回归任务，简单平均 (Simple Averaging):\n    $$\n    H(x) = \\frac{1}{T} \\sum_{i=1}^{T} h_i(x)\n    $$\n\n  - 加权平均 (Weighted Averaging):\n    $$\n    H(x) = \\sum_{i=1}^{T} w_i h_i(x) \\quad \\text{s.t.} \\quad \\sum_{i=1}^{T} w_i = 1, w_i \\ge 0\n    $$\n    通常个体学习器性能越好，权重越大。\n\n- **投票法 (Voting):**\n\n  - 对于分类任务。\n\n  - 绝对多数投票 (Majority Voting): 投某一类票数超过总票数一半，预测为该类；否则拒绝预测（或交给其他方法）。\n    $$\n    H(x) = \\begin{cases} c_j & \\text{if } \\sum_{i=1}^{T} \\mathbb{I}(h_i(x) = c_j) > 0.5 \\sum_{k=1}^{N} 1 \\\\ \\text{reject} & \\text{otherwise} \\end{cases}\n    $$\n    其中 $\\mathbb{I}(\\cdot)$ 是指示函数。\n\n  - 相对多数投票 (Plurality Voting): 预测为得票最多的类。\n    $$\n    H(x) = \\arg \\max_{c_j} \\sum_{i=1}^{T} \\mathbb{I}(h_i(x) = c_j)\n    $$\n\n  - 加权投票 (Weighted Voting):\n    $$\n    H(x) = \\arg \\max_{c_j} \\sum_{i=1}^{T} w_i \\mathbb{I}(h_i(x) = c_j) \\quad \\text{s.t.} \\quad \\sum_{i=1}^{T} w_i = 1, w_i \\ge 0\n    $$\n\n- **学习法 (Learning):**\n\n  - 通过一个独立的学习器（称为**元学习器 (Meta-learner)** 或 **堆叠器 (Stacker)**）来结合个体学习器的预测结果。\n  - 代表：**Stacking**。先训练个体学习器，然后将个体学习器的输出作为新的特征，用于训练元学习器。\n\n## 2. 基于树模型的集成方法 (Tree-based Ensemble Methods)\n\n决策树是集成学习中最常用的个体学习器之一，因为它非线性、可以处理多种数据类型且易于实现。\n\n### 2.1 Bagging 与随机森林 (Random Forest)\n\n#### 2.1.1 Bagging (Bootstrap Aggregating)\n\n- **原理:** 通过 **自助采样 (Bootstrap Sampling)** 生成不同的数据集，并在每个数据集上独立训练一个决策树（或其他学习器）。\n- **自助采样:** 从原始包含 m 个样本的数据集 D 中，**有放回地**随机抽取 m 个样本，构成新的数据集 D'。重复此过程 T 次，得到 T 个不同的训练集 D₁, D₂, ..., Dₜ。\n- **个体学习器训练:** 在每个数据集 Dᵢ 上独立训练一个决策树模型 hᵢ。这些树之间是并行的。个体决策树通常**不进行剪枝**或只进行少量预剪枝，因为Bagging的目标是通过组合降低方差，即使个体树的方差较高。\n- **预测:**\n  - **分类:** 对新样本进行预测时，所有树独立给出预测结果，最后通过**投票法**（如相对多数投票）决定最终类别。\n  - **回归:** 对新样本进行预测时，所有树独立给出预测结果，最后通过**简单平均法**求平均值作为最终预测结果。\n- **优点:**\n  - 有效地降低**方差**，对噪声数据不那么敏感。\n  - 个体学习器之间无依赖，可并行计算。\n  - 自助采样会产生一部分未被采样的样本，称为 **包外样本 (Out-of-Bag, OOB) 样本**，可以用于模型的无偏估计，无需额外的验证集。平均约有 36.8% ($ (1 - 1/m)^m \\approx e^{-1} \\approx 0.368 $) 的原始样本不会出现在某个自助采样集中。\n- **缺点:**\n  - 不能降低个体学习器的**偏差**。\n  - 模型的可解释性变差。\n\n#### 2.1.2 随机森林 (Random Forest, RF)\n\n- **原理:** 是 Bagging 的一个扩展。它在 Bagging 的基础上，在训练每个决策树时，在每个节点进行分裂时引入了**特征随机性**。\n- **特征随机性:** 对于节点上的数据集，不再考虑所有的特征来选择最优分裂属性，而是从当前节点的特征集合中随机抽取一个包含 `k` 个特征的子集，再从这个子集中选择最优特征进行分裂。\n- **参数 `k`:** 通常推荐 `k = sqrt(d)` (d为特征总数) 用于分类任务，`k = d` 或 `k = d/3` 用于回归任务。Scikit-learn 中 `max_features` 参数控制 `k`。\n- **为何引入特征随机性?** Bagging 中，如果数据中存在一个或几个非常强的特征，那么几乎所有生成的树在根节点都会使用这些强特征进行分裂，导致生成的树之间高度相关，限制了方差的进一步降低。特征随机性强制每棵树使用不同的特征子集，增加了树之间的差异性，从而进一步降低了方差。\n- **随机森林的步骤:**\n  1. 从原始数据集 D 中通过自助采样生成 T 个训练集 D₁, ..., Dₜ\n  2. 对于每个训练集 Dᵢ，训练一棵决策树 hᵢ。在训练过程中，对于树的每个节点，从所有特征中随机选择 `max_features` 个特征子集，并仅基于这些子集选择最优分裂点。树的生长通常是完全分裂的（不进行剪枝），或者只进行少量预剪枝。\n  3. 集成 T 棵树的预测结果（分类投票，回归平均）。\n\n![随机森林工作流程](https://s2.loli.net/2025/05/26/21q394hAzlLXxoW.png)\n\n- **优点:**\n  - 相比 Bagging，由于引入特征随机性，进一步降低了模型方差，泛化能力更强。\n  - 不容易过拟合（个体树的随机性使得它们不过于依赖训练数据的特定模式，且整体通过集成降低方差）。\n  - 能够处理高维数据。\n  - 可以自然地计算**特征重要性 (Feature Importance)**：通过某个特征在所有树中作为分裂特征时，平均带来的不纯度减少总量来衡量。\n  - OOB 样本可以用于内部评估，提供了一个无需额外验证集的性能估计。\n- **缺点:**\n  - 模型可解释性差。\n  - 训练时间和预测时间随树的数量增加而增加。\n  - 在某些数据集上，尤其是 Boosting 方法能够捕捉复杂相互作用的情况下，表现可能不如 Boosting 方法。\n\n**特征重要性计算 (Feature Importance Calculation)**\n随机森林能够计算特征重要性，这通常基于某个特征在森林中所有树中作为分裂特征时带来的平均不纯度减少（如使用 Gini 作为 `criterion` 时的 Gini 不纯度减少）。我们将变量重要性评分表示为 $VIM$，对于基于 Gini 指数的，记为 $VIM^{(Gini)}$。\n假设数据集有 $c$ 个特征 $X_1, X_2, X_3, ..., X_c$。现在要计算每个特征 $X_j$ 的 $Gini$ 指数评分 $VIM_j^{(Gini)}$，即特征 $X_j$ 在随机森林所有决策树中节点分裂不纯度的平均改变量。\n如果在决策树 $i$ 中，特征 $X_j$ 出现的节点集合是 $M$，那么 $X_j$ 在第 $i$ 棵树中的重要性为：\n$$\nVIM_{ij}^{(Gini)} = \\sum_{m \\in M} VIM_{jm}^{(Gini)}\n$$\n其中，$VIM_{jm}^{(Gini)}$ 是特征 $X_j$ 在树 $i$ 的节点 $m$ 处分裂时带来的 Gini 不纯度减少量。\n假设随机森林 $RF$ 中共有 $n$ 棵树，那么特征 $X_j$ 在整个随机森林中的原始总重要性为：\n$$\nVIM_j^{(Gini)} = \\sum_{i=1}^{n} VIM_{ij}^{(Gini)}\n$$\n(注意：Scikit-learn 实现中通常是计算平均不纯度减少，可能是在累加前或累加后除以树的数量 $n$)。\n最后，把所有特征求得的原始重要性评分做一个归一化处理，得到最终的特征重要性得分：\n$$\nVIM_j = \\frac{VIM_j^{(Gini)}}{\\sum_{k=1}^{c} VIM_k^{(Gini)}}\n$$\nScikit-learn 中的 `random_state.feature_importances_` 属性提供了这个归一化后的得分数组。这个得分越高，表示该特征在模型预测中起到的作用越大。\n\n**sklearn中的参数**\n\n| 参数/属性              | 描述                                                         | 默认值 | 类型/选项                                         | 重要性级别 |\n| :--------------------- | :----------------------------------------------------------- | :----- | :------------------------------------------------ | :--------- |\n| `n_estimators`         | **森林中树的数量。** 数量越多通常模型越稳健，但也增加计算开销。 | 100    | integer, optional                                 | **高**     |\n| `criterion`            | **衡量分裂质量的函数。** 常用的有 \"gini\" (基尼不纯度) 和 \"entropy\" (信息增益)。 | \"gini\" | string, optional (\"gini\", \"entropy\")              | 中         |\n| `max_depth`            | **树的最大深度。** 限制深度有助于防止过拟合。`None` 表示树会完全生长直到叶子纯净或达到 `min_samples_split` 的限制。RF通常不限制深度以降低偏差，但可能会引入一些方差，通过集成解决。 | None   | integer or None, optional                         | 中/低      |\n| `min_samples_split`    | **分裂内部节点所需的最小样本数。** 数量太小可能导致过拟合。  | 2      | int or float, optional                            | 中         |\n| `min_samples_leaf`     | **叶子节点所需的最小样本数。** 数量太小可能导致过拟合，数量太大有平滑模型作用。特别影响回归任务。 | 1      | int or float, optional                            | 中         |\n| `max_features`         | **寻找最佳分裂时考虑的特征数量。** 控制特征随机性。`auto` 或 `sqrt` 通常指 `sqrt(n_features)`，`log2` 指 `log2(n_features)`，`None` 指 `n_features`。 这是 RF 区别于 Bagging 的关键参数。 | \"auto\" | int, float, string or None, optional              | **高**     |\n| `bootstrap`            | **建树时是否采用有放回抽样 (bootstrap)。** `True` 开启随机性（Bagging的核心），`False` 使用整个数据集。RF 通常使用 `True`。 | True   | boolean, optional                                 | **高**     |\n| `oob_score`            | **是否使用外包样本 (OOB) 评估模型的泛化准确性。** 需要 `bootstrap=True` 才能计算。提供无需额外验证集的性能评估。 | False  | boolean, optional                                 | 中         |\n| `n_jobs`               | **并行计算使用的CPU数量。** `-1` 表示使用所有可用的处理器。  | None   | int or None, optional                             | **实用**   |\n| `random_state`         | **随机状态/种子。** 设置后可确保自助采样、特征随机性等的可复现性。 | None   | int, RandomState instance or None, optional       | **实用**   |\n| `feature_importances_` | **[属性] 特征重要性系数。** 拟合后可用此属性查看每个特征的重要性得分。**基于特征在树中分裂节点时平均带来的不纯度减少计算并归一化。** | N/A    | array of shape = `[n_features_]`                  | N/A        |\n| `oob_score_`           | **[属性] 外包样本评估分数。** 在 `oob_score=True` 且 `bootstrap=True` 时可用，存储计算出的 OOB 分数。 | N/A    | float                                             | N/A        |\n| `classes_`             | **[属性] 模型知道的类别标签。** 对于分类问题，这个属性存储了训练集中出现的唯一类别。 | N/A    | array of shape = `[n_classes_]` or list of arrays | N/A        |\n| `n_features_`          | **[属性] 训练时使用的特征数量。**                            | N/A    | int                                               | N/A        |\n| `n_classes_`           | **[属性] 类别数量。** 对于多分类，指类别的总数。             | N/A    | int or list                                       | N/A        |\n\n### 2.2 Boosting\n\n- **原理:** 是一种迭代的集成方法，个体学习器之间是**串行**的。每次迭代都会根据前一次迭代的预测结果来调整样本权重（如 AdaBoost）或学习前一轮模型的**残差或负梯度**（如 GBDT），使得新的学习器更关注之前被错误预测的样本或难以预测的区域。\n- **核心思想:** 每一棵树都尝试去弥补前面所有树的不足。\n- **常用个体学习器:** 弱学习器，尤其是**决策树桩 (Decision Stump)**（深度为1的决策树）或非常浅的决策树。这是因为 Boosting 主要目的是降低偏差，而弱学习器本身偏差高方差低，通过Boosting组合后，偏差可以降低，同时保持较低的方差。使用浅树也能显著提高模型的泛化能力和训练速度。\n\n#### 2.2.1 AdaBoost (Adaptive Boosting)\n\n- **原理:** 通过不断修改样本的权重来训练一系列弱分类器。它会给错误分类的样本更高的权重，使得后续的弱分类器更关注这些样本。\n\n- **过程:**\n\n  1. 初始化所有样本的权重相等，设为 $1/m$，其中 m 是样本总数。\n\n  2. 迭代 T 次，训练 T 个弱分类器 h₁, ..., hₜ：\n     a.  使用当前样本权重分布 $D_t$ 训练弱分类器 $h_t(x)$。\n     b.  计算当前弱分类器 $h_t$ 在加权训练数据集上的**分类误差率** $\\epsilon_t$：\n     $$\n     \\epsilon_t = P(h_t(x_i) \\neq y_i) = \\sum_{i=1}^{m} w_i^{(t)} \\mathbb{I}(h_t(x_i) \\neq y_i)\n     $$\n     c.  计算当前弱分类器 $h_t$ 的**权重** $\\alpha_t$（该分类器在最终集成结果中的重要性）：\n     $$\n         \\alpha_t = \\frac{1}{2} \\ln \\left( \\frac{1 - \\epsilon_t}{\\epsilon_t} \\right)\n     $$\n\n     > 这里的 $\\epsilon_t$ 必须小于 0.5（弱分类器性能必须好于随机猜测），否则算法停止。 $\\epsilon_t$ 越小，$\\alpha_t$ 越大。\n\n     d.  **更新样本权重:** 增加被 $h_t$ 错误分类的样本的权重，减少被正确分类的样本的权重。\n     $$\n     w_i^{(t+1)} = w_i^{(t)} \\exp(-\\alpha_t y_i h_t(x_i))\n     $$\n\n     > 其中 $y_i$ 是真实标签（对于二分类通常取 +1 或 -1），$h_t(x_i)$ 是预测结果。如果预测正确， $y_i h_t(x_i) > 0$，权重减小；如果预测错误，$y_i h_t(x_i) < 0$，权重增加。\n\n     e.  **归一化样本权重:** 将 $w^{(t+1)}$ 归一化，使其总和为 1，得到新的样本权重分布 $D_{t+1}$。\n\n  3. 最终的强分类器由所有弱分类器加权组合而成：\n     $$\n     H(x) = \\text{sign} \\left( \\sum_{t=1}^{T} \\alpha_t h_t(x) \\right)\n     $$\n     （对于分类任务，通常是加权投票；对于回归任务，AdaBoost.R2 等有不同策略）\n\n- **优点:**\n\n  - 算法简单，易于实现。\n  - 分类精度高，可以提高弱分类器的性能。\n  - 无需预知弱学习器性能，只需保证性能优于随机猜测。\n\n- **缺点:**\n\n  - 对异常值和噪声数据比较敏感（因为会给误分类样本过高的权重）。\n  - 训练是串行的，难以并行处理。\n  - 主要用于二分类问题，扩展到多分类需要一些修改。\n\n#### 2.2.2 梯度提升 (Gradient Boosting Machines, GBM)\n\n- **原理:** 通过构建一系列决策树来最小化某个损失函数的**负梯度**。每一棵树不是直接预测目标变量或残差，而是预测当前模型在训练数据上的**负梯度**，然后将新树的预测结果（乘以学习率）叠加到现有模型上，沿着损失函数梯度的反方向进行优化。\n\n- **过程 (以回归为例，使用均方误差损失 $L(y, F) = \\frac{1}{2}(y-F)^2$):**\n\n  1. 初始化一个简单的模型，通常是预测使损失函数最小的常数（例如，对于 MSE 是所有样本的平均目标值） $f_0(x)$。\n\n  2. 迭代 T 次：\n     a.  对于每个样本 $i$，计算当前模型 $f_{t-1}(x_i)$ 在该样本上的损失函数的负梯度。这被称为**伪残差 (Pseudo-residuals)**。\n     $$\n     r_{it} = - \\left[ \\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)} \\right]_{F(x)=f_{t-1}(x)}\n     $$\n     对于 MSE 损失 $L(y, F) = \\frac{1}{2}(y-F)^2$，负梯度就是 $y_i - f_{t-1}(x_i)$，这恰好是残差。对于其他损失函数，负梯度是残差的一种推广。\n\n     b.  训练一棵新的决策树 $h_t(x)$ 来拟合这些伪残差 $r_{it}$。\n\n     c.  找到最佳步长 $\\gamma_t$ 来更新模型（在 GBDT 中通常简化为学习率 $\\eta$）：\n     $$\n     f_t(x) = f_{t-1}(x) + \\eta h_t(x)\n     $$\n     这里的 $\\eta$ 就是学习率 (Learning Rate)。\n\n  3. 最终模型是所有树的加权求和 (这里权重是学习率)：\n     $$\n     F(x) = f_0(x) + \\sum_{t=1}^{T} \\eta h_t(x)\n     $$\n\n- **损失函数 (Loss Function):** Gradient Boosting 可以使用各种**可微的**损失函数，例如回归中的均方误差 (MSE)、平均绝对误差 (MAE)，分类中的对数损失 (Log Loss, 即 scikit-learn 中的 'deviance')。选择合适的损失函数对模型性能至关重要。\n\n- **学习率 (Learning Rate, $\\eta$):** 是一个重要的超参数，介于 0 和 1 之间。它缩放了每棵树的贡献。较小的学习率意味着每棵树的贡献较小，需要更多棵树才能达到相同的效果，但这通常能带来更好的泛化能力和鲁棒性。这是一种**收缩 (Shrinkage)** 技术。学习率和 `n_estimators` 之间存在一个重要的权衡：较小的学习率通常需要更大的 `n_estimators` 来弥补。\n\n- **个体学习器:** 通常使用**回归树**，即使是分类问题（因为它们拟合的是伪残差或负梯度，这些是数值）。树的深度通常也比较浅 (e.g., max_depth=3-6)，以保证个体学习器是**弱学习器**，从而通过 Boosting 降低偏差。\n\n- **随机梯度提升 (Stochastic Gradient Boosting):** 通过设置 `subsample` 参数小于 1.0，在训练每棵树时随机抽取一部分样本（不放回抽样），可以进一步引入随机性，减少方差，提高模型的鲁棒性。这借鉴了 Bagging 的思想。\n\n- **早期停止 (Early Stopping):** 由于 Boosting 容易在迭代次数过多时过拟合，通常会使用一个验证集并在验证集性能不再提升时提前停止训练。这通过 `validation_fraction`, `n_iter_no_change`, `tol` 等参数来控制。\n\n- **常见变体:**\n\n  - **GBDT (Gradient Boosting Decision Tree):** 指使用决策树作为个体学习器的 Gradient Boosting。\n  - **XGBoost (Extreme Gradient Boosting):** GBDT 的优化版本，加入了正则化项（树结构和叶子节点权重）、并行处理（在特征和数据级别）、缺失值处理、剪枝策略等改进，速度和性能通常更好。\n  - **LightGBM (Light Gradient Boosting Machine):** 微软开发的 GBDT 变体，使用基于梯度的单边采样 (GOSS) 和互斥特征捆绑 (EFB) 等技术，速度非常快，适合处理大规模数据。\n  - **CatBoost:** Yandex 开发的 GBDT 变体，对类别特征有特殊处理，并采用有序提升以减少过拟合。\n\n- **优点:**\n\n  - 预测精度非常高，在许多比赛中表现优异。\n  - 可以灵活选择损失函数。\n  - 通过引入 `subsample` 和浅树可以增加鲁棒性。\n  - 早期停止是一种有效的正则化手段。\n\n- **缺点:**\n\n  - 训练过程是串行的，难以完全并行化（树之间有依赖）。\n  - 对超参数比较敏感，需要仔细调参。\n  - 容易过拟合（尤其是树的数量过多、学习率过大或树深度过深时）， Early Stopping 是必要的。\n\n**sklearn.ensemble.GradientBoostingClassifier 参数解释**\n\n| 参数/属性                  | 描述                                                         | 默认值         | 类型/选项                                        | 重要性级别                  |\n| :------------------------- | :----------------------------------------------------------- | :------------- | :----------------------------------------------- | :-------------------------- |\n| `loss`                     | 需要优化的损失函数。对于分类任务，'deviance' (即对数损失 logloss) 更常用，'exponential' 对应 AdaBoost 算法。 | 'deviance'     | {'deviance', 'exponential'}, optional            | **高**                      |\n| `learning_rate`            | **学习率** (shrinkage)。控制每个弱学习器的贡献大小。较小的值需要更多 `n_estimators`。在 `learning_rate` 和 `n_estimators` 之间存在权衡。 | 0.1            | float, optional                                  | **高**                      |\n| `n_estimators`             | **Boosting 迭代次数，即弱学习器（树）的数量。** Gradient Boosting 通常对过拟合有鲁棒性，但数量过多仍可能过拟合。一个较大的数通常意味着更好的性能，但也增加计算开销。需要配合 `learning_rate` 和早期停止进行调优。 | 100            | int, optional                                    | **高**                      |\n| `subsample`                | **用于训练基学习器的样本采样比例。** 小于 1.0 则等同于随机梯度提升 (Stochastic Gradient Boosting)。如果小于 1 则会减少方差，增加偏差，提高鲁棒性。 | 1.0            | float, optional                                  | 中                          |\n| `criterion`                | **衡量分裂质量的函数。** 这是与基学习器决策树相关的参数。`'friedman_mse'` 是一个常用的选项，它在均方误差基础上考虑了分裂点的改进。 | 'friedman_mse' | string, optional                                 | 中                          |\n| `min_samples_split`        | **分裂内部节点所需的最小样本数。** 可以是整数（绝对数量）或浮点数（比例）。 | 2              | int or float, optional                           | 中                          |\n| `min_samples_leaf`         | **叶子节点所需的最小样本数。** 可以是整数（绝对数量）或浮点数（比例）。有平滑模型的作用，特别是回归任务。 | 1              | int or float, optional                           | 中                          |\n| `min_weight_fraction_leaf` | **叶子节点所需的样本总权重的最小分数。**                     | 0.0            | float, optional                                  | 低                          |\n| `max_depth`                | **单个回归树的最大深度。** 需要进行调参来获得更好的性能。通常设置一个较小的值（例如 3-6）来构建弱学习器。 | 3              | integer, optional                                | **高**                      |\n| `min_impurity_decrease`    | **节点分裂的最小不纯度减少量。** 如果节点分裂带来的不纯度减少大于或等于该值，节点才会分裂。 | 0.0            | float, optional                                  | 中                          |\n| `min_impurity_split`       | **建树过程中早起停止的阈值。** 如果节点的不纯度大于该值会继续分裂，否则停止，成为叶子节点。已废弃，后续版本将被 `min_impurity_decrease` 参数代替。 | 1e-7           | float, optional (deprecated since 0.19)          | N/A                         |\n| `init`                     | **用来模型初始化的学习器对象或 'zero'。** 可以提供已 fit 或 predict 的对象。如果是 'zero' 则初始预测为 0。 | None           | estimator or 'zero', optional                    | 低                          |\n| `random_state`             | **随机状态/种子。** 控制自助采样 (bootstrap) 和特征选择的随机性，用于结果的可复现性。 | None           | int, RandomState instance or None, optional      | **实用**                    |\n| `max_features`             | **寻找最佳分裂时考虑的特征数量。** 控制特征子集的随机性。可以是整数、浮点数、字符串 ('auto', 'sqrt', 'log2') 或 None。'auto' 和 'sqrt' 都表示 `sqrt(n_features)`，'log2' 表示 `log2(n_features)`，None 表示 `n_features`。 | 'auto'         | int, float, string or None, optional             | 中                          |\n| `verbose`                  | **控制训练过程的输出详细程度。** 0 表示无输出，1-3 表示不同详细程度的输出。 | 0              | int, optional                                    | **实用**                    |\n| `max_leaf_nodes`           | **以最优的方式构建树，限制叶子节点的数量。** 如果是 None 则对叶子节点的数量没有限制。可以替代 `max_depth`。 | None           | int or None, optional                            | 中                          |\n| `warm_start`               | **布尔值。** 如果设置为 True，将重用上一次调用的解来学习并加入更多的学习器到集成算法中，可以用于增加已训练模型的树数量，无需从头训练。 | False          | bool, optional                                   | **实用**                    |\n| `presort`                  | **在寻找最佳分裂时是否预排序数据。** 自动模式对稠密数据进行预排序，稀疏数据不排序。 (已废弃) | 'auto'         | bool or 'auto', optional (deprecated since 0.22) | N/A                         |\n| `validation_fraction`      | **用于早期停止的验证集比例。** 如果设置了，模型会在每次迭代后在一个随机划分的验证集上评估性能。 | 0.1            | float, optional                                  | **高 (用于Early Stopping)** |\n| `n_iter_no_change`         | **在验证分数不再提高时采用 early stopping 的迭代次数。** 如果设置为整数，当连续 `n_iter_no_change` 次迭代验证分数（在 `validation_fraction` 定义的验证集上）没有超过 `tol` 定义的阈值时，则停止训练。默认 None 不考虑 early stopping。 | None           | int or None, optional                            | **高 (用于Early Stopping)** |\n| `tol`                      | **early stopping 的容差 (tolerance)。** 在 early stopping 启用时，经过 `n_iter_no_change` 步迭代的提升都没有超过 `tol` 时，则停止训练。 | 1e-4           | float, optional                                  | **高 (用于Early Stopping)** |\n| `feature_importances_`     | **[属性] 特征重要性系数。** 拟合后可用此属性查看每个特征的重要性得分。基于特征在树中分裂节点时平均带来的不纯度减少计算并归一化。 | N/A            | array of shape = `[n_features_]`                 | N/A                         |\n\n**补充说明：Early Stopping (早期停止)**\n\n在 GBDT 中，`n_estimators` 是一个非常关键的参数，迭代次数越多，模型复杂度越高，越容易过拟合。为了平衡性能和过拟合，并避免手动尝试大量 `n_estimators` 值，常常使用早期停止技术。\n\n启用早期停止需要：\n\n1. 设置 `n_iter_no_change` 为一个整数。\n2. 可选地设置 `validation_fraction` 来指定用于评估的验证集比例（如果不设置，会从训练集中自动划分）。\n3. 可选地设置 `tol` 来指定判断性能是否提高的最小阈值。\n\n当在验证集上的性能连续 `n_iter_no_change` 次迭代没有提升超过 `tol` 时，训练会自动停止，而不是跑到 `n_estimators` 设定的最大值。这是一种有效的正则化手段，也能节省训练时间。\n\n### 2.3 Bagging vs. Boosting 总结比较\n\n| 特征               | Bagging (e.g., Random Forest)                                | Boosting (e.g., AdaBoost, GBDT)                              |\n| :----------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |\n| **个体学习器关系** | 并行，无依赖，独立生成                                       | 串行，有依赖，顺序生成                                       |\n| **主要目标**       | 降低**方差 (Variance)**，提高稳定性                          | 降低**偏差 (Bias)**，提高精度                                |\n| **如何实现**       | 重新采样数据 (Bootstrap)，组合多个独立模型                   | 调整样本权重/拟合残差/负梯度，迭代训练关注错误样本/区域的模型 |\n| **个体学习器**     | 通常使用**强学习器**（如剪枝较少的深树），但在RF中通过特征随机性增加差异 | 通常使用**弱学习器**（如决策树桩或浅层树）                   |\n| **训练速度**       | 可并行，训练速度快                                           | 串行，训练速度慢（相较于 Bagging）                           |\n| **对噪声/异常值**  | 鲁棒性较好                                                   | 敏感 (尤其是 AdaBoost，GBDT 通过 Subsample 可改善)           |\n| **解释性**         | 较差                                                         | 更差                                                         |\n| **典型算法**       | Bagging Classifier/Regressor, Random Forest                  | AdaBoost, Gradient Boosting, XGBoost, LightGBM, CatBoost     |\n\n### 2.4 Scikit-learn 实现示例 (集成学习)\n\n继续使用 Iris 数据集。\n\n```python\n# 导入所需的集成模型\nfrom sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split # 如果之前没有导入和分割数据，需要运行这几行\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.datasets import load_iris\n\n# 加载数据集 (如果之前没有加载)\niris = load_iris()\nX, y = iris.data, iris.target\nfeature_names = iris.feature_names\ntarget_names = iris.target_names\n\n# 分割数据集 (如果之前没有分割)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n\nprint(\"\\n--- 集成学习模型示例 ---\")\n\n# --- 8.4.1 Bagging Classifier ---\nprint(\"\\nBagging Classifier:\")\n# BaggingClassifier 默认使用 DecisionTreeClassifier 作为基学习器\n# n_estimators: 基学习器的数量\nbagging_clf = BaggingClassifier(n_estimators=100, random_state=42, n_jobs=-1) # n_jobs=-1 使用所有CPU核心并行训练\nbagging_clf.fit(X_train, y_train)\ny_pred_bagging = bagging_clf.predict(X_test)\naccuracy_bagging = accuracy_score(y_test, y_pred_bagging)\nprint(f\"准确率: {accuracy_bagging:.4f}\")\n# print(\"分类报告:\\n\", classification_report(y_test, y_pred_bagging, target_names=target_names))\n\n# --- 8.4.2 Random Forest Classifier ---\nprint(\"\\nRandom Forest Classifier:\")\n# random_state 用于控制bootstrap采样和特征随机性\n# n_estimators: 树的数量\n# max_features: 控制特征随机性 ('sqrt', 'log2', int, float)\nrf_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\nrf_clf.fit(X_train, y_train)\ny_pred_rf = rf_clf.predict(X_test)\naccuracy_rf = accuracy_score(y_test, y_pred_rf)\nprint(f\"准确率: {accuracy_rf:.4f}\")\nprint(\"特征重要性 (Random Forest):\")\n# 使用 zip 将特征名和重要性分数对应起来打印\nfor name, importance in zip(feature_names, rf_clf.feature_importances_):\n    print(f\"  {name}: {importance:.4f}\")\n# print(\"分类报告:\\n\", classification_report(y_test, y_pred_rf, target_names=target_names))\n\n# --- 8.4.3 AdaBoost Classifier ---\nprint(\"\\nAdaBoost Classifier:\")\n# base_estimator: 基学习器 (默认是决策树桩 DecisionTreeClassifier(max_depth=1))\n# n_estimators: 弱学习器的数量\n# learning_rate: 控制每个弱学习器的贡献\nadaboost_clf = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)\nadaboost_clf.fit(X_train, y_train)\ny_pred_adaboost = adaboost_clf.predict(X_test)\naccuracy_adaboost = accuracy_score(y_test, y_pred_adaboost)\nprint(f\"准确率: {accuracy_adaboost:.4f}\")\n# print(\"分类报告:\\n\", classification_report(y_test, y_pred_adaboost, target_names=target_names))\n\n# --- 8.4.4 Gradient Boosting Classifier ---\nprint(\"\\nGradient Boosting Classifier:\")\n# n_estimators: 提升阶段的数量 (树的数量)\n# learning_rate: 控制收缩\n# max_depth: 个体回归树的深度 (通常较浅)\n# Early Stopping 参数示例：validation_fraction, n_iter_no_change, tol\ngb_clf = GradientBoostingClassifier(n_estimators=200, # 初始设置多一些树\n                                    learning_rate=0.1,\n                                    max_depth=3,\n                                    random_state=42,\n                                    subsample=0.8, # 启用随机梯度提升\n                                    validation_fraction=0.1, # 留出10%用于验证\n                                    n_iter_no_change=10, # 连续10次迭代验证分数没有提升就停止\n                                    tol=0.0001,\n                                    verbose=1 # 打印训练过程信息\n                                    )\ngb_clf.fit(X_train, y_train)\ny_pred_gb = gb_clf.predict(X_test)\naccuracy_gb = accuracy_score(y_test, y_pred_gb)\nprint(f\"准确率: {accuracy_gb:.4f}\")\n# 训练停止时的实际树数量可以通过 gb_clf.n_estimators_ 属性查看\nprint(f\"实际训练的树数量: {gb_clf.n_estimators_}\")\nprint(\"特征重要性 (Gradient Boosting):\")\n# GradientBoostingClassifier 也有 feature_importances_ 属性\nfor name, importance in zip(feature_names, gb_clf.feature_importances_):\n     print(f\"  {name}: {importance:.4f}\")\n# print(\"分类报告:\\n\", classification_report(y_test, y_pred_gb, target_names=target_names))\n```\n\n### 2.5 集成方法的调参\n\n集成方法的性能很大程度上依赖于超参数的选择。一些关键参数包括：\n\n- `n_estimators`: 集成中个体学习器的数量。数量越多通常性能越好，但计算成本也越高，并且可能导致过拟合（特别是 Boosting）。在 Boosting 中常与 `learning_rate` 和早期停止配合使用。\n- `learning_rate` (仅 Boosting): 控制每一步的贡献大小（收缩）。较小的学习率需要更多的 `n_estimators`，但通常能提高模型鲁棒性和泛化能力。\n- `max_depth` (个体树深度): 控制个体学习器的复杂度。在 Boosting 中通常设置为较小的值 (e.g., 3-6) 来构建弱学习器。在 RF 中通常设置较大或不限制，依赖特征随机性来降低相关性。\n- `max_features`: 在 RF 或设置 `max_features` 的 GBDT 中控制特征随机性。\n- `subsample` (仅 Bagging/RF/GBDT): 控制样本采样比例。小于 1.0 引入样本随机性，减少方差。\n- 从基学习器继承的参数，如 `min_samples_split`, `min_samples_leaf`, `min_impurity_decrease` 等。\n- 早期停止相关的参数 (仅 GBDT): `n_iter_no_change`, `validation_fraction`, `tol`。\n\n调参常用技术：网格搜索 (Grid Search)、随机搜索 (Random Search)、贝叶斯优化等，并结合交叉验证 (Cross-Validation) 来评估参数组合的性能。\n\n## 3. 小结\n\n决策树作为一种直观且强大的模型，是集成学习中最常用的基学习器之一。通过 Bagging 和 Boosting 这两大主流集成策略，可以有效地提升决策树模型的性能，降低过拟合（Bagging）或提高精度（Boosting）。随机森林是 Bagging 的杰出代表，通过特征随机性进一步增强了性能。Gradient Boosting (及其变体 XGBoost, LightGBM 等) 是 Boosting 方法的代表，在许多复杂任务中取得了最佳效果，通过拟合负梯度进行迭代优化，并可以通过学习率、Early Stopping 和 Subsample 等技术进一步提升性能和鲁棒性。理解这些方法的原理和它们如何结合决策树，对于解决实际问题至关重要。","tags":["python","决策树"],"categories":["机器学习"]},{"title":"决策树学习笔记","url":"/post/decision-tree.html","content":"\n# 决策树学习笔记\n\n## 1. 什么是决策树？\n\n决策树（Decision Tree）是一种基本的分类与回归方法。它是一种监督学习算法，其模型呈树形结构，可以看作是基于特征对实例进行分类或回归的过程。\n\n- **结构:**\n  - **根节点 (Root Node):** 包含样本全集。\n  - **内部节点 (Internal Node):** 代表一个特征或属性的测试。\n  - **分支 (Branch) / 边 (Edge):** 代表测试的输出（特征的某个值或范围）。\n  - **叶节点 (Leaf Node) / 终端节点 (Terminal Node):** 代表最终的决策结果（类别或数值）。\n- **目标:** 生成一棵泛化能力强，即处理未见示例能力强的决策树。\n- **决策过程:** 从根节点开始，根据实例的特征值，沿着树的分支向下移动，直到到达叶节点，该叶节点的类别或值即为预测结果。\n\n## 2. 决策树学习原理\n\n决策树学习的本质是从训练数据中归纳出一组分类规则，或者说是由训练数据集估计条件概率模型。其核心思想是 **“分而治之” (Divide and Conquer)**。\n\n学习过程是一个 **递归地选择最优特征**，并根据该特征对训练数据进行分割，使得各个子数据集有一个最好的分类的过程。\n\n### 2.1 学习步骤概览\n\n1. **开始:** 构建根节点，所有训练数据都放在根节点。\n2. **特征选择:** 选择一个最优特征，按照该特征将训练数据集分割成子集，使得各个子集在当前条件下有最好的分类。\n3. **生成子节点:** 如果某个子集已能够被基本正确分类（达到停止条件），则构建叶节点，并将这些子集分到所对应的叶节点中去。\n4. **递归:** 如果子集不能被基本正确分类，则对这些子集选择新的最优特征，继续对其进行分割，构建相应的节点。\n5. **结束:** 递归地进行步骤 2-4，直到所有训练数据子集都被基本正确分类，或者没有合适的特征为止。\n\n### 2.2 如何选择最优特征？—— 划分选择\n\n选择最优特征是决策树学习的关键。目标是选择一个特征进行划分后，各子集的“纯度” (Purity) 最高。纯度越高，意味着子集中的样本尽可能属于同一类别。\n\n常用的衡量纯度的指标有：\n\n#### a) 信息熵 (Information Entropy)\n\n熵是度量随机变量不确定性的指标。熵越大，随机变量的不确定性就越大，纯度越低。\n\n假设当前样本集合 `D` 中第 `k` 类样本所占的比例为 `p_k` (k=1, 2, ..., |Y|，|Y|是类别总数)，则 `D` 的信息熵定义为：\n$$\n\\mathrm{Ent}(D) = - \\sum_{k=1}^{|Y|} p_k \\log_2(p_k)\n$$\n\n- `Ent(D)` 的值越小，`D` 的纯度越高。\n\n#### b) 信息增益 (Information Gain) - ID3 算法\n\n信息增益表示得知特征 `A` 的信息而使得数据集 `D` 的不确定性减少的程度。选择信息增益最大的特征作为划分特征。\n\n假设用离散特征 `A` 对样本集 `D` 进行划分，`A` 有 `V` 个可能的取值 `{a¹, a², ..., aᵛ}`。若使用 `A` 来对 `D` 进行划分，则会产生 `V` 个分支节点，其中第 `v` 个分支节点包含了 `D` 中所有在特征 `A` 上取值为 `aᵛ` 的样本，记为 `Dᵛ`。\n\n我们可以计算出用特征 `A` 对 `D` 进行划分所获得的“信息增益”：\n$$\n\\text {Gain}(D, a) = \\text {Ent}(D) - \\sum_{v=1}^{V} \\frac{|D^v|}{|D|} \\text {Ent}(D^v)\n$$\n\n- `|Dᵛ| / |D|` 是分支 `v` 的权重，样本数越多的分支节点影响越大。\n- `Ent(Dᵛ)` 是分支节点 `v` 的信息熵。\n- **ID3 算法** 就是以信息增益为准则来选择划分属性的决策树算法。\n\n**缺点:** 信息增益准则对可取值数目较多的特征有所偏好（例如，如果一个特征是 ID，那么每个样本一个取值，划分出的每个子集纯度都是最高的，信息增益会很大，但这没有泛化能力）。\n\n#### c) 增益率 (Gain Ratio) - C4.5 算法\n\n为了减少信息增益对多取值特征的偏好，**C4.5 算法** 使用“增益率”来选择最优划分特征。\n\n增益率定义为：\n$$\n\\mathrm{Gain\\_ratio}(D, A) = \\frac{\\mathrm{Gain}(D, A)}{IV(A)}\n$$\n其中 `IV(A)` 称为特征 `A` 的“固有值” (Intrinsic Value)：\n$$\nIV(A) = - \\sum_{v=1}^{V} \\frac{|D^v|}{|D|} \\log_2 \\left( \\frac{|D^v|}{|D|} \\right)\n$$\n\n- 特征 `A` 的可能取值数目越多（即 `V` 越大），`IV(A)` 的值通常会越大。\n\n**注意:** 增益率准则对可取值数目较少的特征有所偏好。因此 C4.5 算法并非直接选择增益率最大的特征，而是使用一个启发式：**先从候选划分特征中找出信息增益高于平均水平的特征，再从中选择增益率最高的。**\n\n#### d) 基尼指数 (Gini Index) - CART 算法\n\n**CART (Classification and Regression Tree)** 算法使用“基尼指数”来选择划分属性。\n\n数据集 `D` 的纯度也可以用基尼值来度量：\n$$\nGini(D) = \\sum_{k=1}^{|Y|} \\sum_{k' \\neq k} p_k p_{k'} = 1 - \\sum_{k=1}^{|Y|} p_k^2\n$$\n\n- `Gini(D)` 反映了从数据集 `D` 中随机抽取两个样本，其类别标记不一致的概率。\n- `Gini(D)` 越小，数据集 `D` 的纯度越高。\n\n特征 `A` 的基尼指数定义为 (假设 `A` 是离散特征，有 `V` 个取值)：\n$$\nGini\\_index(D, A) = \\sum_{v=1}^{V} \\frac{|D^v|}{|D|} \\cdot Gini(D^v)\n$$\n\n- 选择那个使得划分后基尼指数最小的特征作为最优划分特征，即 `A_* = arg min_{A} Gini_index(D, A)`。\n\n**特点:** CART 生成的是 **二叉树**。对于连续特征，它会尝试所有可能的二分点；对于离散特征，它也会找出最优的二分组合。\n\n#### 2.2.1 连续特征的处理\n\n在决策树中，特征可以是离散的（类别型）或连续的。对于连续特征，决策树的算法需要确定一个**分割点**，即根据特征值的大小将数据划分为两部分。\n\n- 对于连续特征 \\(A\\)，先对所有样本按该特征值排序，记排序后的不同取值为 \n  $$\n  \\{v_1, v_2, \\dots, v_m\\}\n  $$\n\n- 决策树在构建过程中会选择一个合适的分割点 `t`（即 `A ≤ t`）来将数据分为两部分\n  $$\n  (v_i, v_{i+1}) \\text{之间取中点} (t = (v_i + v_{i+1})/2),\n  $$\n\n  $$\n  \\text{将数据分为} (A \\le t) \\text{和} (A > t) \\text{两部分}。\n  $$\n\n- 选择 `t` 的方法通常是通过计算划分后的纯度指标（如信息增益、增益率、基尼指数或其他标准），选出最优的 $t^*$。\n\n#### 2.2.2 线搜索 (Line Search) 过程\n\n线搜索（Line Search）是一种通过遍历所有可能的分割点来寻找最优分割点的过程。对于每个连续特征，我们会按照其特征值进行排序，然后计算每个分割点的纯度（例如信息增益或基尼指数），并选择使得纯度最大化的分割点。\n\n#### 2.2.2 二类分类中三种纯度度量的关系\n\n- **基尼指数** $Gini(p) = 2p(1-p)$\n\n  > 其中 `p` 和 `1-p` 分别是属于两个类别的样本的比例。当 `p` 或 `1-p` 趋近于 0 时，基尼指数会接近 0，说明数据集非常纯净。\n\n- **熵** $Ent(p) = -p\\log_2 p - (1-p)\\log_2(1-p)$\n\n  > 同样，当 `p` 或 `1-p` 为 0 或 1 时，熵的值接近 0，表明数据集是纯净的。\n\n- **分类误差率** $Err(p) = 1 - \\max(p,1-p)$\n\n  > 它的特点是非常直观，但对于不平衡数据（例如，一个类别占大多数）可能会给出较差的评估。\n\n熵和基尼指数都能很好地衡量不确定性，二者通常产生相似的结果。\n\n分类误差率通常不会作为选择特征的标准，因为它在纯度较高时变化较小，无法敏感地反映数据的变化。\n\n对二分类问题，三者随 $p\\in[0,1]$ 的曲线关系为\n$$\nErr(p)\\le \\frac{1}{2}Ent(p)\\le Gini(p)\\quad\\forall\\,p,\n$$\n![二分类三种纯度度量](https://s2.loli.net/2025/05/26/OLmJ9Qo5fykwA8e.png)\n\n### 2.3 停止条件\n\n递归划分过程何时停止？\n\n1. **当前节点包含的样本全属于同一类别:** 无需划分，该节点成为叶节点。\n2. **当前属性集为空，或者所有样本在所有属性上取值相同:** 无法划分，将该节点标记为叶节点，类别设定为该节点所含样本最多的类别（或根据具体问题定义）。\n3. **当前节点包含的样本集合为空:** 不能划分，标记为叶节点，类别设定为其父节点所含样本最多的类别。\n\n### 2.4 缺失值的处理\n\n在决策树学习中，处理缺失值是一个需要解决的问题。不同的算法有不同的处理方式。\n\n#### 2.4.1 在算法层面如何处理缺失值\n\n有几种常见的方法来处理缺失值：\n\n- **数据插补：** 在训练决策树之前，将缺失的值使用该特征的均值、中位数或众数进行填充。\n\n  > **注意：** scikit-learn 的决策树实现**不内置**对缺失值的处理，需要用户在训练前进行预处理（如使用 `SimpleImputer`）。\n\n- **忽略样本：** 直接忽略包含缺失值的样本。如果缺失值不多，这可能是一个简单有效的方案，但如果缺失样本较多，可能丢失大量信息。\n\n- **基于树的缺失值处理方法（某些算法支持）：** 一些决策树实现（如 C4.5）允许在划分时处理缺失值。\n\n  - **计算纯度时：** 仅使用该特征上非缺失的样本子集来计算信息增益（或其他纯度指标）。\n  - **划分样本时：** 对于在当前划分特征上有缺失值的样本，可以采用以下策略分配到子节点：\n    - 将其分配到最有可能的分支（例如，根据已知值样本在各分支的比例）。       \n    - 将其分配到多个子节点，并赋予不同的权重。例如，如果一个样本在该特征上缺失，且已知值样本根据该特征分成了 A、B 两个分支，已知值样本中 70%去了 A，30%去了 B，那么可以将这个缺失值样本以 0.7 的权重分到 A 分支，以 0.3 的权重分到 B 分支。        \n    - 将“缺失”本身视为一个独立的特征取值或分支。\n\n#### 2.4.2 如何选择划分特征（当特征有缺失值时）\n\n当考虑用一个有缺失值的特征进行划分时，传统的纯度计算方法需要调整：\n\n- **计算缺失值的概率：** 可以在计算纯度指标时，对特征的缺失值情况进行惩罚。例如，C4.5 在计算增益率时会考虑样本在当前特征上已知值的比例。\n- **调整纯度计算：** 只使用该特征上非缺失值的样本来计算纯度（如信息增益、基尼指数）。计算信息增益时，通常会乘以一个系数，这个系数等于当前节点中该特征非缺失样本的比例。\n\n### 2.5 处理过拟合 (剪枝与 Bagging)\n\n为了防止决策树 **过拟合 (Overfitting)**，即模型在训练数据上表现很好，但在新数据上表现差，需要进行剪枝。过拟合通常是因为树生长得过于复杂，学习了训练数据中过多的噪声或特性。\n\n#### a) 预剪枝 (Pre-pruning)\n\n在决策树生成过程中，对每个节点在划分前先进行估计。若当前节点的划分不能带来决策树泛化性能提升（例如，在验证集上精度下降），则停止划分并将当前节点标记为叶节点。\n\n- **优点:** 降低过拟合风险，减少训练时间和测试时间开销。\n- **缺点:** 基于“贪心”本质，可能带来欠拟合风险（有些划分暂时看可能不优，但后续划分可能显著提升性能）。\n\n常用判断条件：\n\n- 节点内样本数量小于阈值 (`min_samples_split`, `min_samples_leaf`)。\n- 树的深度达到预设值 (`max_depth`)。\n- 划分后信息增益（或其他指标）的提升小于阈值。\n- 划分后在独立的验证集上精度下降。\n\n#### b) 后剪枝 (Post-pruning)\n\n先从训练集生成一棵完整的决策树，然后自底向上地对非叶节点进行考察。若将该节点对应的子树替换为叶节点能带来决策树泛化性能提升，则将该子树替换为叶节点。\n\n- **优点:** 通常比预剪枝保留了更多分支，欠拟合风险小，泛化性能往往优于预剪枝决策树。\n- **缺点:** 训练时间开销比未剪枝和预剪枝决策树都要大得多。\n\n常用方法：\n\n- **降低错误剪枝 (Reduced Error Pruning, REP):** 使用验证集，将子树替换为叶节点后，如果验证集错误率降低或不变，则剪枝。\n- **代价复杂度剪枝 (Cost Complexity Pruning, CCP):** 定义损失函数=经验熵+正则化项（树的复杂度），通过调整正则化系数 `α` (ccp_alpha) 来权衡模型复杂度和拟合度，生成一系列树，最后通过交叉验证选择最优子树。Scikit-learn 中常用此方法。\n\n#### c) Bagging (Bootstrap Aggregating)\n\n除了传统的预剪枝和后剪枝，我们还可以使用 Bagging (Bootstrap Aggregating) 技术来处理过拟合。Bagging 是通过从原始训练集中进行有放回抽样（Bootstrap），生成多个不同的训练集，然后基于每个训练集独立地训练一棵决策树，并将它们的预测结果进行集成（例如，分类任务投票，回归任务平均）来减少过拟合风险。\n\n- **思想：** 对训练集做多次有放回抽样，训练多棵决策树，将其预测结果取平均（回归）或投票（分类）。\n- **优点：** 显著降低高方差，缓解单棵树过拟合；增强了模型的稳定性；并行化简单。\n- **缺点：**牺牲了模型的解释性（因为是多个树的集成）。\n- **常用实现：** `sklearn.ensemble.BaggingClassifier`（分类）和 `sklearn.ensemble.BaggingRegressor`（回归），以及特别针对决策树的 **随机森林（Random Forest）** (`sklearn.ensemble.RandomForestClassifier`/`Regressor`)。随机森林在 Bagging 的基础上进一步引入了特征随机性（在每个节点划分时只考虑特征的一个随机子集），进一步提升了性能和鲁棒性。。\n\n#### 2.6 二叉树和多叉树\n\n##### 2.6.1 二叉树与多叉树的区别\n\n- **二叉树**：每个节点最多有两个子节点（通常表示为左右子节点），即每个决策都只能有两个结果。CART 算法生成的树通常是二叉树。\n- **多叉树**：每个节点可以有多个子节点，表示每次决策有多个选择。ID3 和 C4.5 算法可以生成多叉树（对于离散特征，每个取值对应一个分支）。\n\n##### 2.6.2 选择二叉树还是多叉树\n\n- **二叉树** 在算法实现上通常更简单，且对计算机资源的消耗更少。许多库（包括 scikit-learn）默认或只支持二叉树。\n- **多叉树** 能处理更多的选择，但计算复杂度较高。对于离散特征，多叉划分虽然直观，但在某些情况下（如特征取值非常多）可能不够灵活。二叉树可以通过多次二分裂来模拟多叉分裂。\n\n#### 2.7 二分类和多分类\n\n##### 2.7.1 二分类\n\n决策树在二分类问题中，通过划分使得子节点的样本尽可能只属于两个类别中的一个。可以使用信息增益、增益率或基尼指数作为纯度标准。常见的二分类问题如癌症检测、垃圾邮件分类等。\n\n##### 2.7.2 多分类\n\n对于多分类问题，决策树会通过逐步划分的方式将样本集划分成多个子集。对于每个子集，决策树会重复上述过程，直到所有的样本被完全分类。可以使用 **一对一** 或 **一对多** 的方法来构建多分类树。纯度计算方法（信息熵、基尼指数等）自然地扩展到多类别情况。\n\n## 3. 决策树的优缺点\n\n### 3.1 优点\n\n- **易于理解和解释:** 可以可视化，符合人类的直观思维。\n- **数据预处理要求低:** 不需要数据归一化或标准化（但处理缺失值仍需注意）。可以同时处理数值型和类别型数据（不同算法支持度不同）。\n- **能够处理多输出问题。**\n- **计算复杂度相对较低:** 预测阶段的复杂度是 O(log₂m)，m 是样本数。\n- **可以验证模型:** 使用统计测试来验证模型的可靠性。\n- **鲁棒性:** 对于缺失值不敏感（某些算法如 C4.5 可以处理，但 scikit-learn 需要预处理）。\n\n### 3.2 缺点\n\n- **容易过拟合:** 尤其是在数据有噪声或样本量不足时，可能生成过于复杂的树。需要剪枝或集成方法来缓解。\n- **不稳定性:** 数据微小的变动可能导致生成完全不同的树。可以通过集成方法（如随机森林）改善。\n- **最优决策树学习是 NP 难问题:** 实际算法通常采用启发式方法（如贪心算法），只能得到局部最优解。\n- **可能创建有偏的树:** 如果某些类别的样本数量远多于其他类别，生成的树可能会偏向于这些数量多的类别。建议先平衡数据集。\n- **对线性关系表达能力弱:** 对于变量间存在复杂线性关系的问题，决策树可能需要很深的树才能拟合。\n\n------\n\n## 4. 使用 Scikit-learn 实现决策树 (Iris 数据集示例)\n\n我们将使用经典的 Iris (鸢尾花) 数据集来演示如何用 Python 的 Scikit-learn 库构建决策树分类器。\n\n**目标:** 根据鸢尾花的花萼长度 (Sepal Length)、花萼宽度 (Sepal Width)、花瓣长度 (Petal Length)、花瓣宽度 (Petal Width) 这四个特征来预测鸢尾花的种类 (Setosa, Versicolour, Virginica)。\n\n### 4.0 决策树在 Scikit-learn 中的主要参数、属性与方法\n\n在 Scikit-learn 中，`DecisionTreeClassifier` 和 `DecisionTreeRegressor` 类提供了多种超参数来调整决策树的构建方式。\n\n- **参数（`DecisionTreeClassifier`/`DecisionTreeRegressor`）**\n  - `criterion`：用于划分的标准。\n    分类树可选 `'gini'`（基尼指数）或 `'entropy'`（信息增益）。\n    回归树可选 `'mse'` (均方误差, 已废弃, 推荐使用 `'squared_error'`)，`'friedman_mse'` 或 `'mae'` (平均绝对误差)。\n    默认是分类树 `'gini'`，回归树 `'squared_error'`。\n  - `splitter`：划分策略。`'best'` 表示选择最好的特征进行划分（默认）。\n    `'random'` 表示随机选择部分特征后再从中选择最好的进行划分（随机森林常用）适用于样本量非常大的情况。\n  - `max_depth`: 决策树的最大深度。控制树的复杂度，避免过拟合（预剪枝）。默认 `None`，表示不限制深度。\n  - `min_samples_split`：内部节点再划分所需最小样本数。\n    较高的值有助于避免过拟合（预剪枝）。可以是整数或小数（表示比例）。默认是 2。\n  - `min_samples_leaf`：叶子节点最少样本数。\n    一个分割点只有在左右分支都满足这个最少样本数条件时，才能进行划分（预剪枝）。可以是整数或小数。默认是 1。\n  - `min_weight_fraction_leaf`：叶子节点最小的样本权重和，小于这个值会和兄弟节点一起被剪枝，默认为0不考虑权重，当较多样本有缺失值或样本分布类别偏差很大需要考虑\n  - `max_features`：每次分割考虑的最大特征数（随机森林常用）。\n    可以是整数、浮点数（比例）、`\"auto\"`/`\"sqrt\"` (等于 `sqrt(n_features)`)、`\"log2\"` (等于 `log2(n_features)`) 或 `None` (考虑所有特征)。\n  - `max_leaf_nodes`：最大叶子节点数，可以防止过拟合，默认None\n  - `min_impurity_decrease`：分裂所减小的不纯度小于等于该值才会分裂\n  - `min_impurity_split`：建树时候早停的基尼不纯度阈值，限制决策树的增长\n  - `class_weight`：类别样重，指定样本各类别的权重\n  - `ccp_alpha`：代价复杂度剪枝参数（后剪枝）。取值越大，剪枝越强。默认是 0.0 (不剪枝)。\n- **重要属性 (训练后可用)**\n  - `feature_importances_`: 一个 numpy 数组，表示每个特征的重要性评分（总和为 1）。重要性基于该特征在树中降低纯度（信息增益或基尼不纯度）的总量。\n  - `tree_`：底层的 `_tree.Tree` 对象，包含了树结构的详细信息（节点索引、左右子节点、特征索引、阈值、不纯度等）。\n  - `n_features_in_`: 训练时输入的特征数量。\n  - `classes_`: <u>分类树</u>独有，训练期间遇到的类标签数组。\n  - `n_classes_`: <u>分类树</u>独有，类别的数量。、\n  - `n_outputs_`: 模型输出的数量（对于多输出问题）。\n  - `n_node_samples_`: 每个节点中的训练样本数量数组。\n- **常用方法**\n  - `.fit(X, y)`：使用训练数据 `X` 和目标变量 `y` 训练决策树模型。\n  - `.predict(X)`：对新数据 `X` 进行预测。分类树返回类别标签，回归树返回预测值。\n  - `.predict_proba(X)`：<u>分类树</u>独有，预测每个样本属于各个类别的概率。\n  - `.score(X, y)`：返回模型的评估分数。分类树返回在 `(X, y)` 上的准确率，回归树返回 $R^2$ 分数。\n  - `apply(X)`: 返回每个样本所属的叶节点索引。\n  - `get_params([deep])`: 获取模型的超参数。\n  - `set_params(**params)`: 设置模型的超参数。\n  - `export_text(decision_tree[, …])`、将决策树导出为文本规则表示。\n  - `plot_tree(decision_tree[, …])`：将决策树可视化（需要 Matplotlib）。\n\n------\n\n### 4.1 导入所需库\n\n```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\n# 注意：Scikit-learn >= 0.20 版本需要\n# from sklearn.impute import SimpleImputer\n```\n\n### 4.2 加载和准备数据\n\n```python\n# 加载 Iris 数据集\niris = load_iris()\nX = iris.data  # 特征数据 (numpy array)\ny = iris.target # 目标标签 (numpy array)\nfeature_names = iris.feature_names # 特征名称\ntarget_names = iris.target_names   # 类别名称\n\n# （可选）处理缺失值示例 (如果数据有缺失值)\n# 例如，使用均值填充\n# imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n# X_imputed = imputer.fit_transform(X)\n# X = X_imputed # 使用填充后的数据\n\n# （可选）将数据转换为 Pandas DataFrame 以便查看\n# df = pd.DataFrame(X, columns=feature_names)\n# df['species'] = y\n# df['species_name'] = df['species'].map({0: target_names[0], 1: target_names[1], 2: target_names[2]})\n# print(df.head())\n# print(df['species_name'].value_counts())\n\n# 分割数据集为训练集和测试集\n# random_state 保证每次分割结果一致，便于复现\n# stratify=y 保证训练集和测试集中各类样本的比例与原始数据集一致 (重要!)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\nprint(f\"训练集大小: {X_train.shape[0]} samples\")\nprint(f\"测试集大小: {X_test.shape[0]} samples\")\n```\n\n### 4.3 创建和训练决策树模型\n\n```python\n# 创建决策树分类器实例\n# criterion='gini': 使用基尼指数作为划分标准 (默认)\n# criterion='entropy': 使用信息增益作为划分标准\n# max_depth: 树的最大深度 (预剪枝参数)\n# min_samples_split: 内部节点再划分所需最小样本数 (预剪枝参数)\n# min_samples_leaf: 叶子节点最少样本数 (预剪枝参数)\n# ccp_alpha: 代价复杂度剪枝的参数 (后剪枝相关)\ndt_classifier = DecisionTreeClassifier(criterion='gini', max_depth=None, random_state=42) # 先不加预剪枝\n\n# 使用训练数据训练模型\ndt_classifier.fit(X_train, y_train)\n\nprint(\"决策树模型训练完成!\")\n\n# 查看特征重要性 (属性示例)\nprint(\"\\n特征重要性:\")\nfor name, importance in zip(feature_names, dt_classifier.feature_importances_):\n    print(f\"{name}: {importance:.4f}\")\n```\n\n### 4.4 模型预测与评估\n\n```python\n# 使用训练好的模型对测试集进行预测\ny_pred = dt_classifier.predict(X_test)\n\n# 评估模型性能\n# 准确率\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"\\n模型在测试集上的准确率: {accuracy:.4f}\")\n\n# 分类报告 (包含精确率、召回率、F1分数)\nprint(\"\\n分类报告:\")\nprint(classification_report(y_test, y_pred, target_names=target_names))\n\n# 混淆矩阵\nprint(\"\\n混淆矩阵:\")\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n\n# 可视化混淆矩阵 (可选)\n# import seaborn as sns\n# plt.figure(figsize=(6, 4))\n# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n# plt.xlabel('Predicted Label')\n# plt.ylabel('True Label')\n# plt.title('Confusion Matrix')\n# plt.show()\n```\n\n### 4.5 可视化决策树\n\n理解决策树如何做出决策的一个好方法是将其可视化。\n\n#### a) 使用 `plot_tree` (需要 Matplotlib)\n\n```python\nplt.figure(figsize=(20, 10)) # 设置图形大小\nplot_tree(dt_classifier,\n          filled=True, # 填充颜色以表示类别纯度\n          feature_names=feature_names, # 显示特征名称\n          class_names=target_names, # 显示类别名称\n          rounded=True, # 节点框使用圆角\n          fontsize=10) # 字体大小\nplt.title(\"Decision Tree for Iris Classification (Gini)\")\nplt.show()\n```\n\n#### b) 使用 `export_text` 输出文本表示\n\n```python\ntree_rules = export_text(dt_classifier, feature_names=list(feature_names))\nprint(\"\\n决策树规则 (文本表示):\")\nprint(tree_rules)\n```\n\n### 4.6 探索剪枝 (示例)\n\n尝试添加预剪枝参数，例如限制最大深度。\n\n```python\n# 创建带预剪枝的决策树\ndt_classifier_pruned = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n\n# 训练\ndt_classifier_pruned.fit(X_train, y_train)\n\n# 预测\ny_pred_pruned = dt_classifier_pruned.predict(X_test)\n\n# 评估\naccuracy_pruned = accuracy_score(y_test, y_pred_pruned)\nprint(f\"\\n剪枝后 (max_depth=3) 模型准确率: {accuracy_pruned:.4f}\")\n\n# 可视化剪枝后的树\nplt.figure(figsize=(12, 6))\nplot_tree(dt_classifier_pruned, filled=True, feature_names=feature_names, class_names=target_names, rounded=True, fontsize=10)\nplt.title(\"Pruned Decision Tree (max_depth=3)\")\nplt.show()\n```\n\n剪枝后的树通常更简单，有时准确率可能会略有下降，但泛化能力可能更好（在这个简单的 Iris 数据集上可能不明显）。\n\n## 5. 决策树回归\n\n决策树不仅能用于分类问题，还能用于回归问题。**\n\n### 5.1 最小二乘回归树\n\n对于回归问题，决策树会在每个叶节点保存该节点的均值。在构建过程中，决策树将选择能够最小化节点内部 **均方误差（MSE）** 的特征和分割点作为划分标准。\n\n- **目标：** 通过递归划分，使得每个子集（节点）内的目标值（y）尽可能接近其平均值，从而最小化整体的平方误差。\n\n- **损失函数：** 用于衡量一个节点（数据集 D）的“不纯度”或方差，即节点内所有样本目标值与该节点目标值均值之间的平方误差之和。 \n  $$\n  L(D) = \\sum_{i \\in D} (y_i - \\bar{y}_D)^2\n  $$\n  其中，$y_i$ 是节点 D 中第 i 个样本的真实目标值，$\\bar{y}_D$ 是节点 D 中所有样本目标值的均值。\n\n- **划分标准：** 在选择特征和分割点时，回归树会遍历所有可能的特征和分割点，计算按该点划分后，左右子节点加权后的总均方误差（或称为平方误差的减少量）。选择使总均方误差最小的划分点。 \n  $$\n  \\min_{A, s} \\left[ \\sum_{i \\in D_1(A, s)} (y_i - \\bar{y}_{D_1})^2 + \\sum_{i \\in D_2(A, s)} (y_i - \\bar{y}_{D_2})^2 \\right]\n  $$\n  其中，$A$ 是特征，$s$ 是分割点，$D_1$ 和 $D_2$ 是划分后的两个子集，$\\bar{y}*{D_1}$ 和 $\\bar{y}*{D_2}$ 分别是子集 $D_1$ 和 $D_2$ 的目标值均值。\n\n- **实现示例：** Scikit-learn 中使用 `DecisionTreeRegressor` 类。\n\n  ```python\n  from sklearn.tree import DecisionTreeRegressor\n  from sklearn.metrics import mean_squared_error, r2_score\n  \n  # 假设 y_train_continuous 是连续的目标值\n  # reg = DecisionTreeRegressor(criterion='squared_error', max_depth=5, random_state=42)\n  # reg.fit(X_train, y_train_continuous)\n  # y_pred_reg = reg.predict(X_test)\n  \n  # 评估回归模型\n  # mse = mean_squared_error(y_test_continuous, y_pred_reg)\n  # r2 = r2_score(y_test_continuous, y_pred_reg)\n  # print(f\"\\n回归树 MSE: {mse:.4f}, R2: {r2:.4f}\")\n  \n  ```\n\n- **评估指标：** 均方误差（MSE）、均方根误差（RMSE）、$R^2$ 分数。\n\n### 5.2 分类树与回归树的区别\n\n- 目标变量类型:\n  - **分类树:** 离散型（类别标签）。\n  - **回归树:** 连续型（数值）。\n- 叶节点输出:\n  - **分类树:** 叶节点通常代表一个类别标签（该节点中样本最多的类别）或类别的概率分布。\n  - **回归树:** 叶节点代表一个预测数值，通常是该节点中所有样本目标值的均值。\n- 划分标准/损失函数:\n  - **分类树:** 使用衡量“纯度”的指标，如信息增益、增益率、基尼指数，目标是最大化纯度（最小化不纯度）。\n  - **回归树:** 使用衡量“方差”或“误差”的指标，如均方误差（MSE）或平均绝对误差（MAE），目标是最小化节点内误差。\n\n| **对比维度**          | **分类树（Classification Tree）**      | **回归树（Regression Tree）**                    |\n| --------------------- | -------------------------------------- | ------------------------------------------------ |\n| **目标变量类型**      | 离散型（类别标签）                     | 连续型（数值）                                   |\n| **叶节点输出**        | 类别标签（或类别概率分布）             | 预测数值（如均值、中位数等）                     |\n| **划分标准/损失函数** | 信息增益、增益率、基尼指数（衡量纯度） | 均方误差（MSE）、平均绝对误差（MAE）（衡量误差） |\n| **适用问题类型**      | 分类问题（如判断是否购买商品）         | 回归问题（如预测房价、温度等）                   |\n| **示例应用场景**      | 客户流失预测、垃圾邮件识别             | 房价预测、销售额预测                             |\n\n------\n\n## 6. 小结\n\n决策树是一种强大且直观的机器学习模型。理解其核心原理（信息熵、信息增益、基尼指数）、构建过程（递归划分）以及防止过拟合的方法（剪枝）至关重要。通过 Scikit-learn 等库可以方便地实现和应用决策树解决分类和回归问题。","tags":["python","决策树"],"categories":["机器学习"]},{"title":"LeetCode每日一题2025-05-27","url":"/post/divisible-and-non-divisible-sums-difference.html","content":"\n# [2894. 分类求和并作差](https://leetcode.cn/problems/divisible-and-non-divisible-sums-difference/) E\n\n给你两个正整数 `n` 和 `m` 。\n\n现定义两个整数 `num1` 和 `num2` ，如下所示：\n\n- `num1`：范围 `[1, n]` 内所有 **无法被** `m` **整除** 的整数之和。\n- `num2`：范围 `[1, n]` 内所有 **能够被** `m` **整除** 的整数之和。\n\n返回整数 `num1 - num2` 。\n\n \n\n**示例 1：**\n\n> 输入：n = 10, m = 3\n> 输出：19\n> 解释：在这个示例中：\n>\n> - 范围 [1, 10] 内无法被 3 整除的整数为 [1,2,4,5,7,8,10] ，num1 = 这些整数之和 = 37 。\n> - 范围 [1, 10] 内能够被 3 整除的整数为 [3,6,9] ，num2 = 这些整数之和 = 18 。\n> 返回 37 - 18 = 19 作为答案。\n\n**示例 2：**\n\n> 输入：n = 5, m = 6\n> 输出：15\n> 解释：在这个示例中：\n>\n> - 范围 [1, 5] 内无法被 6 整除的整数为 [1,2,3,4,5] ，num1 = 这些整数之和 =  15 。\n> - 范围 [1, 5] 内能够被 6 整除的整数为 [] ，num2 = 这些整数之和 = 0 。\n> 返回 15 - 0 = 15 作为答案。\n\n**示例 3：**\n\n> 输入：n = 5, m = 1\n> 输出：-15\n> 解释：在这个示例中：\n>\n> - 范围 [1, 5] 内无法被 1 整除的整数为 [] ，num1 = 这些整数之和 = 0 。 \n> - 范围 [1, 5] 内能够被 1 整除的整数为 [1,2,3,4,5] ，num2 = 这些整数之和 = 15 。\n> 返回 0 - 15 = -15 作为答案。\n\n \n\n**提示：**\n\n- `1 <= n, m <= 1000`\n\n## 问题分析\n\n给定两个正整数 `n` 和 `m`，我们需要计算：\n\n- `num2`：范围 `[1, n]` 内所有能够被 `m` 整除的整数之和；\n- `num1`：范围 `[1, n]` 内所有无法被 `m` 整除的整数之和；\n   然后返回 `num1 - num2`。\n\n**暴力枚举思路**\n\n最直观的做法是对 `i` 从 `1` 到 `n` 进行一次循环：\n\n- 如果 `i % m == 0`，则累加到 `num2`；\n- 否则累加到 `num1`。\n\n伪代码如下：\n\n```pseudocode\nnum1 = 0\nnum2 = 0\nfor i in 1..n:\n    if i % m == 0:\n        num2 += i\n    else:\n        num1 += i\nreturn num1 - num2\n```\n\n- **时间复杂度**：O(n)，当 n 最多到 1000 时，这个复杂度在常数范围内并不会超时，但如果 n 很大（比如上万、上百万），则循环效率下降明显。\n- **空间复杂度**：O(1)，只使用了常数个变量。\n\n由于题目给出的约束是 `1 <= n, m <= 1000`，暴力循环在实际运行中完全够用。\n\n## 算法思路\n\n**数学公式优化**\n\n1. **求 1 到 n 的自然数之和**\n   公式：\n   $$\n   S_{\\text{total}} = 1 + 2 + \\cdots + n = \\frac{n \\times (n + 1)}{2}.\n   $$\n\n2. **求 “能被 m 整除” 的那些数之和（即 num2）**\n    先求出能被 `m` 整除的最大倍数：\n   $$\n   k = \\left\\lfloor \\frac{n}{m} \\right\\rfloor,\n   $$\n   对应的正整数集合为 `{m, 2m, 3m, …, k·m}`。\n    这些数的和为：\n   $$\n   num2 = m + 2m + 3m + \\cdots + k m = m \\times (1 + 2 + \\cdots + k)      = m \\times \\frac{k \\times (k + 1)}{2}.\n   $$\n\n3. **求 “无法被 m 整除” 的数之和（即 num1）**\n    因为 `[1..n]` 中所有数的和减去能被 `m` 整除的数之和即为无法被 `m` 整除数之和：\n   $$\n   num1 = S_{\\text{total}} - num2.\n   $$\n\n4. **最终结果**\n   $$\n   result = num1 - num2 = \\bigl(S_{\\text{total}} - num2\\bigr) - num2 = S_{\\text{total}} - 2 \\times num2.\n   $$\n\n5. **计算步骤小结**\n\n   - 先算出 `S_total = n * (n + 1) / 2`\n   - 再算出 `k = n // m`\n   - 接着算出 `num2 = m * k * (k + 1) / 2`\n   - 最后 `return S_total - 2 * num2`\n\n## 时间复杂度\n\n- **时间复杂度**：$O(1)$\n\n- **空间复杂度**：$O(1)$\n\n## 代码实现\n\n```python\nclass Solution:\n    def differenceOfSums(self, n: int, m: int) -> int:\n        # 1. 计算 1 + 2 + ... + n\n        total_sum = n * (n + 1) // 2\n        \n        # 2. 计算 k = floor(n / m)，即能被 m 整除的最大倍数的个数\n        k = n // m\n        \n        # 3. 计算 num2 = m * (1 + 2 + ... + k) = m * k * (k + 1) // 2\n        num2 = m * k * (k + 1) // 2\n        \n        # 4. 计算并返回 num1 - num2 = (total_sum - num2) - num2 = total_sum - 2 * num2\n        return total_sum - 2 * num2\n\n```\n\n","tags":["Algorithm","简单","前缀和"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-26","url":"/post/largest-color-value-in-a-directed-graph.html","content":"\n# [1857. 有向图中最大颜色值](https://leetcode.cn/problems/largest-color-value-in-a-directed-graph/) H\n\n给你一个 **有向图** ，它含有 `n` 个节点和 `m` 条边。节点编号从 `0` 到 `n - 1` 。\n\n给你一个字符串 `colors` ，其中 `colors[i]` 是小写英文字母，表示图中第 `i` 个节点的 **颜色** （下标从 **0** 开始）。同时给你一个二维数组 `edges` ，其中 `edges[j] = [aⱼ, bⱼ]` 表示从节点 `aⱼ` 到节点 `bⱼ` 有一条 **有向边** 。\n\n图中一条有效 **路径** 是一个点序列 `x₁ -> x₂ -> x₃ -> ... -> xₖ` ，对于所有 `1 <= i < k` ，从 `xᵢ` 到 `xᵢ₊₁` 在图中有一条有向边。路径的 **颜色值** 是路径中 **出现次数最多** 颜色的节点数目。\n\n请你返回给定图中有效路径里面的 **最大颜色值** 。如果图中含有环，请返回 `-1` 。\n\n \n\n**示例 1：**\n\n![示例1](https://s2.loli.net/2025/05/26/GC1AlSEj4Mtq5UR.png)\n\n> 输入：colors = \"abaca\", edges = [[0,1],[0,2],[2,3],[3,4]]\n> 输出：3\n> 解释：路径 0 -> 2 -> 3 -> 4 含有 3 个颜色为 \"a\" 的节点（上图中的红色节点）。\n\n**示例 2：**\n\n![示例2](https://s2.loli.net/2025/05/26/qNg7uzB1PZxSt4o.png)\n\n> 输入：colors = \"a\", edges = [[0,0]]\n> 输出：-1\n> 解释：从 0 到 0 有一个环。\n\n\n\n**提示：**\n\n- `n == colors.length`\n- `m == edges.length`\n- `1 <= n <= 10⁵`\n- `0 <= m <= 10⁵`\n- `colors` 只含有小写英文字母。\n- `0 <= aⱼ, bⱼ < n`\n\n\n\n## 问题分析\n\n给定一个有向图，包含 $n$ 个节点和 $m$ 条边，节点编号从 $0$ 到 $n - 1$。每个节点 $i$ 有一个小写英文字母颜色 $colors[i]$。定义一条有效路径为节点序列 $x_1 \\to x_2 \\to \\dots \\to x_k$，要求对于所有 $1 \\le i < k$，存在从 $x_i$ 到 $x_{i+1}$ 的有向边。路径的“颜色值”是指在该路径中出现次数最多的颜色的节点数目。需要计算所有有效路径中最大的颜色值，如果图中含有环则返回 $-1$。\n\n- 环检测：如果图中存在环，就无法构造有效的拓扑排序，题目要求遇到环时直接返回 $-1$。\n- 最大颜色值：对于每一条有效路径，统计路径上每种颜色出现的次数，取出现次数最多的那种颜色。我们要在所有路径中找一个最大值。\n- 颜色种类有限：颜色均为小写字母，共计 26 种。因此可以为每个节点维护一个长度为 26 的数组，记录到达该节点的所有路径中，各颜色出现次数的最大值。\n\n需要解决的关键点：\n1. 如何检测有向图中的环？\n2. 如何高效地统计每个节点的“到达该节点时，各颜色出现次数的最大值”？\n3. 计算完毕后，如何得到整个图中有效路径的最大颜色值？\n\n## 算法思路\n\n1. **构建邻接表与入度数组**  \n   - 用 `adj[u]` 存储节点 $u$ 的所有出边目标节点。  \n   - 用 `indegree[v]` 记录节点 $v$ 的入度。  \n\n2. **定义 DP 状态**  \n   - 令 $dp[v][c]$ 表示：在所有能够到达节点 $v$ 的有效路径中，颜色编号为 $c$（$0$ 对应 `'a'$, …, $25$ 对应 `'z'`）的最大出现次数。  \n   - 整体维护一个二维数组 `dp`，大小为 $n \\times 26$，初始全部置 $0$。  \n\n3. **拓扑排序+DP 传播（Kahn 算法）**  \n   - 将所有 `indegree[i] == 0` 的节点入队，同时令其对应颜色索引处 $dp[i][color\\_index(i)] = 1$，因为空路径到达自己时，自己颜色出现次数至少为 $1$。  \n\n   - 维护 `visited_count = 0`，表示已经从队列中取出的节点数量；维护 `answer = 0`，表示当前全局最大的颜色值。  \n\n   - 循环直到队列为空：  \n     1. 弹出队首节点 `u`，`visited_count += 1`；  \n     2. 更新全局答案：  \n        $$answer = \\max\\bigl(answer,\\ \\max_{0 \\le c < 26} dp[u][c]\\bigr)\\,. $$  \n     3. 对于每条出边 $(u \\to v)$：  \n        - **颜色计数继承+合并**  \n          ```text\n          for c in 0..25:\n              dp[v][c] = max(dp[v][c], dp[u][c])\n          ```\n          然后单独处理节点 `v` 本身的颜色：\n          ```text\n          cidx_v = ord(colors[v]) - ord('a')\n          dp[v][cidx_v] = max(dp[v][cidx_v], dp[u][cidx_v] + 1)\n          ```\n        - 将 `indegree[v] -= 1`，若变为 0，则 `v` 入队。  \n\n   - 结束后，如果 `visited_count < n`，说明有环，返回 `-1`；否则返回 `answer`。  \n\n\n\n   - **为什么要用拓扑排序？**  \n     只有在一个无环有向图（DAG）中，才能按拓扑顺序依次保证“任意一条边的前驱节点”先处理，才能正确地将前驱的 DP 结果传递到后继节点。  \n   - **如何检测环？**  \n     Kahn 算法的特性：如果存在环，则存在至少一个节点的入度永远无法被减为 0，最终队列出队的节点总数 `visited_count` 会小于 $n$。因此，只需检验 `visited_count < n` 即可判断有环。  \n   - **为什么 DP 数组大小为 $n \\times 26$？**  \n     题目要求路径的“颜色值”是路径中出现次数最多的那种颜色。颜色种类共 26 种，以字母映射到 $0 \\ldots 25$。为了对每个节点记录“到达该节点时，每种颜色的最大出现次数”，需要 26 维空间。  \n   - **复杂度分析**  \n     - 构建邻接表与入度：$O(m)$。  \n     - 初始化 DP：将所有元素置 0 并对入度为 0 的节点赋初值，需 $O(26 \\times n)$。  \n     - 拓扑排序主循环：每个节点恰好出队一次，合计 $n$ 次；对于每个节点 $u$，要遍历其所有出边，共计 $m$ 条边。每条边需要将 $u$ 的 26 维数组合并到 $v$，需要 $O(26)$ 操作，总计 $O(26 \\times m)$。  \n     - 合并总计：  \n       $$O\\bigl(26n + 26m + n + m\\bigr) \\;=\\; O\\bigl((n + m)\\times 26\\bigr)\\;=\\; O(n + m)\\,,$$  \n       其中常数因子 26 可以视为常数。  \n   - **空间复杂度**  \n     - 邻接表：$O(n + m)$  \n     - 入度数组：$O(n)$  \n     - DP 数组：$O(26n)$  \n     - 队列：最坏 $O(n)$  \n     - 合计：$O(n + m)$  \n\n**注意：**\n\n  1. **DP 更新顺序与方式**  \n  - 在合并时，必须先将 $dp[u][c]$ 与 $dp[v][c]$ 逐维比较、取最大，然后单独把节点 `v` 自身的颜色对应的那一维加 $1$。若顺序颠倒或漏掉“+1”逻辑，会导致统计错误。  \n  2. **环检测逻辑**  \n  - 一定要统计拓扑排序中“实际出队”的节点数 `visited_count`。若 `visited_count < n`，则必须返回 `-1`，切勿返回错误的 `answer`。  \n  3. **数组越界或者字符映射错误**  \n  - 颜色字符映射到 0..25 索引时，务必使用 `ord(colors[i]) - ord('a')`，且保证 `colors` 中只含小写字母。  \n\n## 时间复杂度\n\n- 构建邻接表与入度：$O(m)$  \n- 初始化 DP：$O(26 \\times n)$  \n- 拓扑排序与 DP 传播：$O(n) + O\\bigl(m \\times 26\\bigr) = O(26m + n)$  \n- 合并后：  \n  $$T(n,m) \\;=\\; O\\bigl(26n + 26m + n + m\\bigr) \\;=\\; O\\bigl((n + m)\\times 26\\bigr) \\;=\\; O(n + m)\\,. $$\n- 空间复杂度：$O(n + m + 26n) = O(n + m)$。 \n\n## 代码分解\n\n1. **导入必要模块与类型声明**  \n   ```python\n   from collections import deque\n   from typing import List\n   ```\n\n   - `deque` 用于实现队列，支持 $O(1)$ 的入队出队操作。\n\n   - `List` 用于类型注释。\n\n2. **Solution 类与函数签名**\n\n   ```python\n   class Solution:\n       def largestPathValue(self, colors: str, edges: List[List[int]]) -> int:\n           # n: 节点数量\n           n = len(colors)\n   ```\n\n   - `colors` 是一个长度为 $n$ 的字符串，`edges` 是长度为 $m$ 的二维列表。\n\n3. **构建邻接表与入度数组**\n\n   ```python\n           adj = [[] for _ in range(n)]\n           indegree = [0] * n\n           for u, v in edges:\n               adj[u].append(v)\n               indegree[v] += 1\n   ```\n\n   - 用邻接表 `adj[u]` 存储所有从 $u$ 出发的边。\n\n   - `indegree[v]` 在遍历边时累加，表示节点 $v$ 的入度大小。\n\n4. **初始化 DP 数组**\n\n   ```python\n     dp = [[0] * 26 for _ in range(n)]\n   ```\n\n   - `dp[v][c]` 初始为 $0$。\n\n   - 后续将在“入度为 0 的节点”处将其颜色对应维度设为 $1$。\n\n5. **拓扑排序队列初始化**\n\n   ```python\n           q = deque()\n           for i in range(n):\n               if indegree[i] == 0:\n                   q.append(i)\n                   cidx = ord(colors[i]) - ord('a')\n                   dp[i][cidx] = 1\n   ```\n\n   - 所有入度为 $0$ 的节点入队，且把它们自己本身的颜色出现次数记为 $1$。\n\n6. **拓扑排序主循环与 DP 传播**\n\n   ```python\n           visited_count = 0\n           answer = 0\n   \n           while q:\n               u = q.popleft()\n               visited_count += 1\n   \n               # 更新全局最大颜色值\n               answer = max(answer, max(dp[u]))\n   \n               for v in adj[u]:\n                   # 逐维比较，取 u 的各颜色计数和 v 目前各颜色计数的最大值\n                   for c in range(26):\n                       if dp[u][c] > dp[v][c]:\n                           dp[v][c] = dp[u][c]\n   \n                   # 单独处理 v 节点自身的颜色 +1\n                   cidx_v = ord(colors[v]) - ord('a')\n                   dp[v][cidx_v] = max(dp[v][cidx_v], dp[u][cidx_v] + 1)\n   \n                   # 更新 v 的入度，若为 0，则入队\n                   indegree[v] -= 1\n                   if indegree[v] == 0:\n                       q.append(v)\n   ```\n\n   - 每次取出节点 `u`，意味着可以“确定”它的 `dp[u][*]`。\n\n   - 对于每条出边 `(u -> v)`，先将 `u` 的 26 维向量与 `v` 对应维度取最大值，再对 `v` 本身的颜色那一维做 `+1`。\n\n   - 减少 `indegree[v]`，若变为 0，将 `v` 放入队列。\n\n   - 同时实时维护全局 `answer`，取 `max(dp[u])`。\n\n7. **环检测与返回结果**\n\n   ```python\n           # 拓扑排序结束后，如果 visited_count < n，则有环\n           if visited_count < n:\n               return -1\n   \n           return answer\n   ```\n\n## 代码实现\n\n```python\nfrom collections import deque, defaultdict\nfrom typing import List\n\nclass Solution:\n    def largestPathValue(self, colors: str, edges: List[List[int]]) -> int:\n        n = len(colors)\n        # --------------------------------------------\n        # 1. 构建邻接表 + 计算每个节点的入度\n        # --------------------------------------------\n        adj = [[] for _ in range(n)]\n        indegree = [0] * n\n        for u, v in edges:\n            adj[u].append(v)\n            indegree[v] += 1\n\n        # --------------------------------------------\n        # 2. 初始化 DP 数组\n        #    dp[v][c] 表示「到达节点 v 的所有有效路径中，颜色编号 c 出现的最大次数」。\n        #    颜色编号 c = ord(colors[v]) - ord('a')\n        # --------------------------------------------\n        # 注意：dp 初始化为全 0，大多数节点在被「拓扑入队」之前是 0。但是对于最初入度为 0 的节点 u，\n        #       它自己本身就出现了一次 colors[u]，所以需要让 dp[u][ color_index(u) ] = 1。\n        dp = [ [0]*26 for _ in range(n) ]\n\n        # --------------------------------------------\n        # 3. 拓扑排序（Kahn 算法）\n        # --------------------------------------------\n        q = deque()\n        # 先将所有 indegree == 0 的节点入队\n        for i in range(n):\n            if indegree[i] == 0:\n                q.append(i)\n                cidx = ord(colors[i]) - ord('a')\n                dp[i][cidx] = 1\n\n        visited_count = 0\n        answer = 0\n\n        while q:\n            u = q.popleft()\n            visited_count += 1\n            # 在「确认节点 u」时，就可以尝试更新全局 answer\n            # 因为 dp[u][*] 已经是「到达 u 的所有路径中，各颜色出现次数的最大值」\n            answer = max(answer, max(dp[u]))  # 更新全局最大\n\n            # 对 u 的每一条出边 (u -> v)，将 u 的状态「传播」到 v\n            for v in adj[u]:\n                # 将 u 的颜色计数「分发」到 v\n                for c in range(26):\n                    # 先把 v 目前已有的 dp[v][c] 与来自 u 的 dp[u][c] 做比较，取较大者\n                    if dp[u][c] > dp[v][c]:\n                        dp[v][c] = dp[u][c]\n                # 然后再专门处理 v 自身颜色：相当于加 1\n                cidx_v = ord(colors[v]) - ord('a')\n                # “+1”只计入 v 本身的颜色出现\n                dp[v][cidx_v] = max(dp[v][cidx_v], dp[u][cidx_v] + 1)\n\n                # v 的入度减 1，如果变成 0 则入队\n                indegree[v] -= 1\n                if indegree[v] == 0:\n                    q.append(v)\n\n            # 继续下一个拓扑节点\n        # end while\n\n        # --------------------------------------------\n        # 4. 检测是否有环：如果有环，则 visited_count < n\n        # --------------------------------------------\n        if visited_count < n:\n            # 说明有某些节点没被「取出」，即存在环\n            return -1\n\n        # 如果无环，answer 已经在遍历过程中维护过\n        return answer\n\n```\n\n","tags":["Algorithm","困难","动态规划","图算法","BFS","状态建模","DAG"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-25","url":"/post/longest-palindrome-by-concatenating-two-letter-words.html","content":"\n# [2131. 连接两字母单词得到的最长回文串](https://leetcode.cn/problems/longest-palindrome-by-concatenating-two-letter-words/) M\n\n给你一个字符串数组 `words` 。`words` 中每个元素都是一个包含 **两个** 小写英文字母的单词。\n\n请你从 `words` 中选择一些元素并按 **任意顺序** 连接它们，并得到一个 **尽可能长的回文串** 。每个元素 **至多** 只能使用一次。\n\n请你返回你能得到的最长回文串的 **长度** 。如果没办法得到任何一个回文串，请你返回 `0` 。\n\n**回文串** 指的是从前往后和从后往前读一样的字符串。\n\n \n\n**示例 1：**\n\n> 输入：words = [\"lc\",\"cl\",\"gg\"]\n> 输出：6\n> 解释：一个最长的回文串为 \"lc\" + \"gg\" + \"cl\" = \"lcggcl\" ，长度为 6 。\n> \"clgglc\" 是另一个可以得到的最长回文串。\n\n**示例 2：**\n\n> 输入：words = [\"ab\",\"ty\",\"yt\",\"lc\",\"cl\",\"ab\"]\n> 输出：8\n> 解释：最长回文串是 \"ty\" + \"lc\" + \"cl\" + \"yt\" = \"tylcclyt\" ，长度为 8 。\n> \"lcyttycl\" 是另一个可以得到的最长回文串。\n\n**示例 3：**\n\n> 输入：words = [\"cc\",\"ll\",\"xx\"]\n> 输出：2\n> 解释：最长回文串是 \"cc\" ，长度为 2 。\n> \"ll\" 是另一个可以得到的最长回文串。\"xx\" 也是。\n\n \n\n**提示：**\n\n- `1 <= words.length <= 10⁵`\n- `words[i].length == 2`\n- `words[i]` 仅包含小写英文字母。\n\n\n\n## 问题分析\n给定一个包含若干长度为 2 的小写字母单词的数组 `words`。需要从中选取若干个单词，按任意顺序拼接成一个回文串（正读和反读相同），每个单词最多只能使用一次。目标是让拼接得到的回文串长度尽可能长，返回最终回文串的长度。\n\n1. **所有单词长度恒为 2**，记为 $w_1w_2$。  \n2. 回文串可以分成 **两种贡献来源**：\n   - **互为逆序的不同单词成对放在回文串两侧**，例如 “ab” 与 “ba” 各贡献 2 个字符放在左侧和右侧，共计 4。\n   - **自身即回文的单词放在中间**，例如 “gg”、“aa”，如果两两配对放在两侧，每对依旧贡献 $4$；如果剩下一个用于回文中心，则贡献 $2$。  \n3. 要保证每个单词至多使用一次，且对于自身回文的单词只能最多取一个放在“中心位置”。\n\n因此，思路是通过哈希表统计每个单词的出现次数，再针对上述两种情况进行贪心匹配。\n\n## 算法思路\n\n1. **统计单词频次**  \n   使用 `Counter`（哈希表）统计数组 `words` 中每个二字母单词的出现次数，记为 $\\text{cnt}[w]$。\n\n2. **遍历哈希表配对**  \n   对于哈希表中的每个单词 `word`，令 $c = \\text{cnt}[ \\text{word} ]$：\n   - 令 `rev = word[::-1]`，即取单词的逆序。  \n   - **情况 A：`word == rev`（自身回文）**  \n     - 将可以成对放在两侧的数量计算为 $\\left\\lfloor \\frac{c}{2} \\right\\rfloor$，每对贡献长度 $4$；更新 $\\text{cnt}[word] -= 2 \\times \\left\\lfloor \\frac{c}{2} \\right\\rfloor$。  \n     - 若此时 $\\text{cnt}[word] \\bmod 2 = 1$ 且尚未使用中心位置（用布尔变量 `used_center` 标记），则取一个放在回文中心，贡献长度 $2$，并将 `used_center = True`，同时 $\\text{cnt}[word] -= 1$。  \n   - **情况 B：`word != rev`（与逆序单词匹配）**  \n     - 若逆序单词 `rev` 也在哈希表中且 $\\text{cnt}[rev] > 0$，则可取对数 $p = \\min(\\text{cnt}[word], \\text{cnt}[rev])$，每对贡献 $4$，更新 $\\text{cnt}[word] -= p$、$\\text{cnt}[rev] -= p$。  \n\n3. **贪心原则**  \n   - 对于互为逆序的不同单词，尽量成对使用，保证两侧对称。  \n   - 对于自身回文的单词，先尽可能两两配对放在两侧，再考虑是否把剩余的一个放在中心，以获得最大长度。\n\n4. **返回结果**  \n   最终累计的 `total_length` 即为最长回文串的长度。如果无法拼出任何回文，则 `total_length` 为 0。\n\n## 时间复杂度\n- 统计频次：遍历 `words` 长度为 $n$ 的数组，$O(n)$。\n- 遍历哈希表：哈希表至多包含 $n$ 个不同二字母单词，遍历亦为 $O(n)$。  \n- 对每个单词的倒序操作由于固定长度 2，可视为常数时间 $O(1)$。  \n\n综上，整体时间复杂度为\n$$\nO(n) + O(n) = O(n).\n$$\n\n## 代码分解\n将上述思路拆解为以下几个步骤：\n1. **引入必要模块**  \n   ```python\n   from collections import Counter\n   from typing import List\n   ```\n\n2. **统计哈希表**\n\n   ```python\n   cnt = Counter(words)\n   ```\n\n3. **初始化变量**\n\n   ```python\n   total_length = 0\n   used_center = False\n   ```\n\n4. **遍历哈希表进行匹配**\n\n   ```python\n   for word, c in cnt.items():\n       if c == 0:\n           continue\n       rev = word[::-1]\n       if word == rev:\n           # 处理自身回文\n           ...\n       else:\n           # 处理与逆序单词配对\n           ...\n   ```\n\n5. **处理自身回文逻辑**\n\n   ```python\n   # pairs = c // 2\n   total_length += pairs * 4\n   cnt[word] -= pairs * 2\n   if cnt[word] > 0 and not used_center:\n       total_length += 2\n       used_center = True\n       cnt[word] -= 1\n   ```\n\n6. **处理互为逆序逻辑**\n\n   ```python\n   if rev in cnt and cnt[rev] > 0:\n       pair_count = min(cnt[word], cnt[rev])\n       total_length += pair_count * 4\n       cnt[word] -= pair_count\n       cnt[rev] -= pair_count\n   ```\n\n7. **返回累计长度**\n\n   ```python\n   return total_length\n   ```\n\n## 代码实现\n\n```python\nfrom collections import Counter\nfrom typing import List\n\nclass Solution:\n    def longestPalindrome(self, words: List[str]) -> int:\n        # 1. 统计每个单词出现次数\n        cnt = Counter(words)\n        \n        total_length = 0       # 最终回文串长度\n        used_center = False    # 是否已使用过“中心回文单词”\n        \n        # 2. 遍历哈希表进行配对\n        for word, c in cnt.items():\n            if c == 0:\n                # 如果已经被配对消耗完，直接跳过\n                continue\n            \n            rev = word[::-1]  # 单词逆序\n            \n            if word == rev:\n                # 情况 A：自身就是回文，例如 \"gg\"\n                # 先两两配对放在两侧\n                pairs = c // 2\n                total_length += pairs * 4   # 每对各占两侧 2 + 2\n                cnt[word] -= pairs * 2\n                \n                # 如果剩下一个且尚未使用中心，则放在中间\n                if cnt[word] > 0 and not used_center:\n                    total_length += 2\n                    used_center = True\n                    cnt[word] -= 1\n            else:\n                # 情况 B：与逆序单词匹配，例如 \"ab\" 与 \"ba\"\n                if rev in cnt and cnt[rev] > 0:\n                    pair_count = min(cnt[word], cnt[rev])\n                    total_length += pair_count * 4\n                    cnt[word] -= pair_count\n                    cnt[rev] -= pair_count\n        \n        # 3. 返回最终回文串长度\n        return total_length\n```","tags":["Algorithm","字符串处理","中等","回文数构造","哈希表","贪心"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-24","url":"/post/find-words-containing-character.html","content":"\n# [2942. 查找包含给定字符的单词](https://leetcode.cn/problems/find-words-containing-character/) E\n\n给你一个下标从 **0** 开始的字符串数组 `words` 和一个字符 `x` 。\n\n请你返回一个 **下标数组** ，表示下标在数组中对应的单词包含字符 `x` 。\n\n**注意** ，返回的数组可以是 **任意** 顺序。\n\n \n\n**示例 1：**\n\n> 输入：words = [\"leet\",\"code\"], x = \"e\"\n> 输出：[0,1]\n> 解释：\"e\" 在两个单词中都出现了：\"l**ee**t\" 和 \"cod**e**\" 。所以我们返回下标 0 和 1 。\n\n**示例 2：**\n\n> 输入：words = [\"abc\",\"bcd\",\"aaaa\",\"cbc\"], x = \"a\"\n> 输出：[0,2]\n> 解释：\"a\" 在 \"**a**bc\" 和 \"**aaaa**\" 中出现了，所以我们返回下标 0 和 2 。\n\n**示例 3：**\n\n> 输入：words = [\"abc\",\"bcd\",\"aaaa\",\"cbc\"], x = \"z\"\n> 输出：[]\n> 解释：\"z\" 没有在任何单词中出现。所以我们返回空数组。\n\n \n\n**提示：**\n\n- `1 <= words.length <= 50`\n- `1 <= words[i].length <= 50`\n- `x` 是一个小写英文字母。\n- `words[i]` 只包含小写英文字母。\n\n\n\n## 问题分析\n\n遍历 `words` 数组中的每个单词，检查该单词是否包含指定字符 `x`。若包含，则将对应的下标加入结果列表。\n\n## 算法思路\n\n由于 `words.length ≤ 50` 且每个 `words[i].length ≤ 50`，可直接采用最简单的暴力遍历方法：对每个单词使用 Python 的 `in` 或者遍历字符来判断是否出现 `x`。\n\n## 时间复杂度\n\n对于每个单词，检查是否包含字符需要 $O(m)$ 时间（$m$ 为该单词长度）。总共 $n$ 个单词，故整体是 $O(n \\times m)$，在最坏情况下约为 $O(50·50)=O(2500)$ \n\n空间复杂度：输出结果数组至多长度为 $n$，故为 $O(n)$\n\n## 代码分解\n\n1. 新建一个空列表 `res` 用于收集所有符合条件的下标。\n\n2. 遍历下标 `i` 从 0 到 `len(words)-1`：\n   - 令 `word = words[i]`，检查字符 `x` 是否在 `word` 中。\n     - 在 Python 中可以直接写 `if x in word:`，其底层实际上是遍历 `word` 的所有字符进行比较，复杂度为 O(m)。\n   - 如果包含，则执行 `res.append(i)`。\n\n3. 循环结束后，返回 `res`（由于题目说明“返回的数组可以是 任意 顺序”，不需要对下标排序）。\n\n## 代码实现\n\n```python\nclass Solution:\n    def findWordsContaining(self, words, x):\n        \"\"\"\n        :type words: List[str]\n        :type x: str\n        :rtype: List[int]\n        \"\"\"\n        res = []\n        for i, word in enumerate(words):\n            # 只要在 word 中找到 x，就把索引 i 加入结果\n            if x in word:\n                res.append(i)\n        return res\n```\n\n","tags":["Algorithm","暴力搜索","字符串处理","简单"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-23","url":"/post/find-the-maximum-sum-of-node-values.html","content":"\n# [3068. 最大节点价值之和](https://leetcode.cn/problems/find-the-maximum-sum-of-node-values/) H\n\n给你一棵 `n` 个节点的 **无向** 树，节点从 `0` 到 `n - 1` 编号。树以长度为 `n - 1` 下标从 **0** 开始的二维整数数组 `edges` 的形式给你，其中 `edges[i] = [ui, vi]` 表示树中节点 `ui` 和 `vi` 之间有一条边。同时给你一个 **正** 整数 `k` 和一个长度为 `n` 下标从 **0** 开始的 **非负** 整数数组 `nums` ，其中 `nums[i]` 表示节点 `i` 的 **价值** 。\n\nAlice 想 **最大化** 树中所有节点价值之和。为了实现这一目标，Alice 可以执行以下操作 **任意** 次（**包括** **0 次**）：\n\n- 选择连接节点 `u` 和 `v` 的边 `[u, v]` ，并将它们的值更新为：\n  - `nums[u] = nums[u] XOR k`\n  - `nums[v] = nums[v] XOR k`\n\n请你返回 Alice 通过执行以上操作 **任意次** 后，可以得到所有节点 **价值之和** 的 **最大值** 。\n\n \n\n**示例 1：**\n\n![示例1](https://s2.loli.net/2025/05/23/ZXGT25badJWUmPI.png)\n\n> 输入：nums = [1,2,1], k = 3, edges = [[0,1],[0,2]]\n> 输出：6\n> 解释：Alice 可以通过一次操作得到最大价值和 6 ：\n>\n> - 选择边 [0,2] 。nums[0] 和 nums[2] 都变为：1 XOR 3 = 2 ，数组 nums 变为：[1,2,1] -> [2,2,2] 。\n> 所有节点价值之和为 2 + 2 + 2 = 6 。\n> 6 是可以得到最大的价值之和。\n\n**示例 2：**\n\n![示例2](https://s2.loli.net/2025/05/23/g1nMtKG5FfvzbcV.png)\n\n> 输入：nums = [2,3], k = 7, edges = [[0,1]]\n> 输出：9\n> 解释：Alice 可以通过一次操作得到最大和 9 ：\n>\n> - 选择边 [0,1] 。nums[0] 变为：2 XOR 7 = 5 ，nums[1] 变为：3 XOR 7 = 4 ，数组 nums 变为：[2,3] -> [5,4] 。\n> 所有节点价值之和为 5 + 4 = 9 。\n> 9 是可以得到最大的价值之和。\n\n**示例 3：**\n\n![示例3](https://s2.loli.net/2025/05/23/qve83cFI4CkN2mO.png)\n\n> 输入：nums = [7,7,7,7,7,7], k = 3, edges = [[0,1],[0,2],[0,3],[0,4],[0,5]]\n> 输出：42\n> 解释：Alice 不需要执行任何操作，就可以得到最大价值之和 42 。\n\n \n\n**提示：**\n\n- `2 <= n == nums.length <= 2 * 10⁴`\n- `1 <= k <= 10⁹`\n- `0 <= nums[i] <= 10⁹`\n- `edges.length == n - 1`\n- `edges[i].length == 2`\n- `0 <= edges[i][0], edges[i][1] <= n - 1`\n- 输入保证 `edges` 构成一棵合法的树。\n\n\n\n## 问题分析\n\n给定一棵大小为 $n$ 的无向树，节点编号为 $0,1,\\dots,n-1$，以及一个正整数 $k$ 和节点价值数组 $\\text{nums}[i]$。允许的操作是：任选一条边 $[u,v]$，对其两端的节点同时做一次 $XOR$ 操作：  \n$$\n\\text{nums}[u] \\leftarrow \\text{nums}[u] \\oplus k,\\quad \\text{nums}[v] \\leftarrow \\text{nums}[v] \\oplus k.\n$$\n可以重复上述操作任意次。目标是最大化所有节点价值之和：  \n$$\n\\max\\Bigl(\\sum_{i=0}^{n-1} \\text{nums}[i]\\Bigr).\n$$\n由于树上每次操作同时影响两个相邻节点，整个过程等价于对每个节点决定“最终是否被翻转奇数次”。记节点 $i$ 的最终状态位为 $p_i\\in\\{0,1\\}$，若 $p_i=1$ 则节点 $i$ 的价值由 $\\text{nums}[i]\\mapsto \\text{nums}[i]\\oplus k$，否则保持不变。每条被选的边 $e=(u,v)$ 会让 $p_u$ 和 $p_v$ 同时翻转一次，因此如果对边 $e$ 选择了奇数次，就相当于让 $p_u$ 与 $p_v$ 最终状态异或一次。  \n- 将这些约束在整棵树上传播，实际上对于树结构，可以定义一个根节点（取 $0$ 号），并令每个节点状态由其子树的选择来决定。  \n- 记对于子节点 $v$，若整个以 $v$ 为根的子树中翻转为奇数的子边数为奇数，则子树在“奇偶”方面会有影响。需要合并所有子节点对当前节点的贡献。  \n\n故而可使用“树形 DP”解决：定义状态\n$$\ndp[u][0] = \\text{以 }u\\text{ 为根，且 }p_u = 0\\text{ 时，子树贡献最大值},\\\\\ndp[u][1] = \\text{以 }u\\text{ 为根，且 }p_u = 1\\text{ 时，子树贡献最大值}.\n$$\n在对节点 $u$ 做 DFS 递归时，遍历所有子节点 $v$，先计算其 $dp[v][0],dp[v][1]$，然后令该子树的基础贡献为\n$$\n\\mathrm{base\\_sum} = \\sum_{v\\in\\mathrm{children}(u)} dp[v][0],\n$$\n并收集每个子节点“若翻转 $v$ 的状态，相对于不翻转的增益”\n$$\n\\Delta_v = dp[v][1] - dp[v][0].\n$$\n把所有 $\\Delta_v$ 分成正数类和负数类，用 $sumP$ 表示所有 $\\Delta_v\\ge 0$ 的和，$cntP$ 表示 $\\Delta_v\\ge 0$ 的数量，$\\min P$ 表示正类中最小值，$\\max N$ 表示负类中最大值。若选择令 $u$ 的子边翻转次数总体保持“偶数”，则贡献为\n$$\n\\mathrm{contrib\\_same} = \\mathrm{base\\_sum} + sumP.\n$$\n否则（即翻转奇数次），需要从正类中去掉最小的 $\\min P$ 或者从负类中加入最大的 $\\max N$，取更优，即\n$$\n\\mathrm{contrib\\_flip} = \\max\\bigl(\\,\\mathrm{base\\_sum} + (sumP - \\min P),\\ \\mathrm{base\\_sum} + (sumP + \\max N)\\bigr).\n$$\n然后根据 $cntP\\bmod 2$ 来决定 $u$ 的子边翻转后与当前 $p_u$ 的奇偶如何匹配，依此更新 $dp[u][0]$ 与 $dp[u][1]$。最终根节点 $0$ 必须保证其 “父边不选” （即 $p_0=0$），答案即为 $dp[0][0]$。\n\n## 算法思路\n\n1. **建图与初始化**  \n   - 用邻接表 $g$ 存储树结构。  \n   - 创建二维数组 $dp[n][2]$，初始均为 $0$。\n\n2. **DFS 递归**  \n   - 对每个节点 $u$，记录其父节点 $parent$，避免回溯。  \n   - 对所有子节点 $v \\ne parent$ 递归调用 `dfs(v, u)`，获得 $dp[v][0],dp[v][1]$。  \n   - 计算子树基础贡献  \n     $$\\text{base\\_sum} = \\sum_{v} dp[v][0].$$  \n   - 列表 `deltas` 存储 $\\Delta_v = dp[v][1] - dp[v][0]$。  \n   - 按照 $\\Delta_v$ 正负分组，计算：  \n     ```pseudocode\n     sumP = ∑_{Δ_v ≥ 0} Δ_v\n     cntP = |{v | Δ_v ≥ 0}|\n     minP = min{Δ_v | Δ_v ≥ 0}  （若不存在正类则为 +∞）\n     maxN = max{Δ_v | Δ_v < 0}   （若不存在负类则为 −∞）\n     parityP = cntP mod 2\n     ```\n   - 计算两种子边翻转奇偶情况下的贡献：  \n     ```pseudocode\n     contrib_same = base_sum + sumP\n     contrib_flip = max(\n       base_sum + (sumP - minP)    if cntP > 0,\n       base_sum + (sumP + maxN)    if maxN > −∞\n     )\n     ```\n   - 若 `parityP == 0`，则子边“偶数”对应 `contrib_same`，子边“奇数”对应 `contrib_flip`；否则相反。  \n   - 最后考虑 $u$ 自身是否翻转：  \n     - 对于 $dp[u][0]$（$p_u=0$），若选择子翻转为“偶数”，则价值为 $\\mathrm{contrib_same} + \\mathrm{nums}[u]$；  \n       如果选择为“奇数”，则价值为 $\\mathrm{contrib_flip} + (\\mathrm{nums}[u]\\oplus k)$。取两者最大。  \n     - 对于 $dp[u][1]$（$p_u=1$），若子翻转为“偶数”，则价值为 $\\mathrm{contrib_same} + (\\mathrm{nums}[u]\\oplus k)$；  \n       如果为“奇数”，则为 $\\mathrm{contrib_flip} + \\mathrm{nums}[u]$。同样取最大。  \n\n3. **返回结果**  \n\n   - 在根节点 $0$ 上调用 `dfs(0,−1)`，最终 $dp[0][0]$ 即为整棵树在允许任意操作后能够获得的最大节点价值之和。\n\n## 时间复杂度\n\n- 构建邻接表花费 $O(n)$。  \n- DFS 过程对每个节点只访问一次，且对每个节点需要遍历其所有邻居并做常数时间的计算。合并子节点差值时，只做 $O(\\deg(u))$ 次更新。  \n- 整体每条边被访问两次，总共 $O(n)$。  \n- 因此总时间复杂度为 $\\displaystyle O(n)$，空间复杂度为 $O(n)$。\n\n## 代码分解\n\n1. **图的表示与初始化**  \n   ```python\n   n = len(nums)\n   g = [[] for _ in range(n)]\n   for u, v in edges:\n       g[u].append(v)\n       g[v].append(u)\n   dp = [[0, 0] for _ in range(n)]\n   ```\n2. **DFS 主逻辑函数**  \n   ```python\n   def dfs(u, parent):\n       base_sum = 0\n       deltas = []\n       for v in g[u]:\n           if v == parent: continue\n           dfs(v, u)\n           base_sum += dp[v][0]\n           deltas.append(dp[v][1] - dp[v][0])\n       if not deltas:\n           dp[u][0] = nums[u]\n           dp[u][1] = nums[u] ^ k\n           return\n       sumP, cntP = 0, 0\n       minP, maxN = float('inf'), -float('inf')\n       for d in deltas:\n           if d >= 0:\n               sumP += d\n               cntP += 1\n               minP = min(minP, d)\n           else:\n               maxN = max(maxN, d)\n       parityP = cntP % 2\n       contrib_same = base_sum + sumP\n       contrib_flip = -float('inf')\n       if cntP > 0:\n           contrib_flip = max(contrib_flip, base_sum + (sumP - minP))\n       if maxN > -float('inf'):\n           contrib_flip = max(contrib_flip, base_sum + (sumP + maxN))\n       if parityP == 0:\n           child_parity0 = contrib_same\n           child_parity1 = contrib_flip\n       else:\n           child_parity1 = contrib_same\n           child_parity0 = contrib_flip\n       cand0_even = child_parity0 + nums[u]\n       cand0_odd = child_parity1 + (nums[u] ^ k) if child_parity1 > -float('inf') else -float('inf')\n       dp[u][0] = max(cand0_even, cand0_odd)\n       cand1_even = child_parity0 + (nums[u] ^ k)\n       cand1_odd = child_parity1 + nums[u] if child_parity1 > -float('inf') else -float('inf')\n       dp[u][1] = max(cand1_even, cand1_odd)\n   ```\n3. **调用与返回**  \n   ```python\n   dfs(0, -1)\n   return dp[0][0]\n   ```\n\n## 代码实现\n\n```python\nfrom collections import defaultdict\nimport sys\nsys.setrecursionlimit(10**7)\n\nclass Solution:\n    def maximumValueSum(self, nums, k, edges):\n        n = len(nums)\n        # 构建邻接表（无向树）\n        g = [[] for _ in range(n)]\n        for u, v in edges:\n            g[u].append(v)\n            g[v].append(u)\n\n        # dp[u][0]：以 u 为根的子树，且 “u 与父节点的边不被选” 时的最大贡献\n        # dp[u][1]：以 u 为根的子树，且 “u 与父节点的边被选” 时的最大贡献\n        dp = [[0, 0] for _ in range(n)]\n\n        def dfs(u, parent):\n            # 1. 先对所有子节点递归\n            base_sum = 0   # 如果对 u 的所有子边都不选，子树的基础贡献 = sum(dp[v][0])\n            deltas = []    # 每个 v 对应的增量 Δ = dp[v][1] - dp[v][0]\n            for v in g[u]:\n                if v == parent:\n                    continue\n                dfs(v, u)\n                base_sum += dp[v][0]\n                deltas.append(dp[v][1] - dp[v][0])\n\n            # 2. 如果没有子节点，直接赋值\n            if not deltas:\n                dp[u][0] = nums[u]         # p_u = 0 时：u 取 nums[u]\n                dp[u][1] = nums[u] ^ k     # p_u = 1 时：u 取 nums[u] ^ k\n                return\n\n            # 3. 划分 deltas 为正类/负类，同时统计 sumP, cntP, minP, maxN\n            sumP = 0             # 所有 Δ >= 0 的和\n            cntP = 0             # Δ >= 0 的个数\n            minP = float('inf')  # 正类中最小的 Δ\n            maxN = -float('inf') # 负类中最大的 Δ\n            for d in deltas:\n                if d >= 0:\n                    sumP += d\n                    cntP += 1\n                    minP = min(minP, d)\n                else:\n                    maxN = max(maxN, d)\n\n            parityP = cntP % 2\n            # 当我们“保留所有正类”（不翻转奇偶）时的子树贡献：\n            contrib_same = base_sum + sumP\n            # 当我们想把“选中正类的个数”在原来奇偶上翻转一次时的子树贡献：\n            #   A. 如果 cntP > 0，则可以从正类中去掉一个 minP => 贡献 = base_sum + (sumP - minP)\n            #   B. 如果 maxN > -inf，则可以额外加一个 maxN => 贡献 = base_sum + (sumP + maxN)\n            contrib_flip = -float('inf')\n            if cntP > 0:\n                contrib_flip = max(contrib_flip, base_sum + (sumP - minP))\n            if maxN > -float('inf'):\n                contrib_flip = max(contrib_flip, base_sum + (sumP + maxN))\n\n            # 根据 cntP % 2，决定“子边被选的个数 mod 2 = 0”或“= 1”时的子树贡献\n            if parityP == 0:\n                # 当我们保留所有正类时，选中正类的个数 = cntP 为偶\n                child_contrib_parity0 = contrib_same\n                child_contrib_parity1 = contrib_flip\n            else:\n                # 当我们保留所有正类时，选中正类的个数 = cntP 为奇\n                child_contrib_parity1 = contrib_same\n                child_contrib_parity0 = contrib_flip\n\n            # 4. 根据 p_u = 0 / 1，两种情况分别计算 dp[u][0]、dp[u][1]\n            # ——————————————\n            # 情况一：p_u = 0（u 与父边不选）\n            #   如果子边选中个数 mod2 = 0: x_u = 0 => u 取 nums[u]\n            cand0_even = child_contrib_parity0 + nums[u]\n            #   如果子边选中个数 mod2 = 1: x_u = 1 => u 取 nums[u] ^ k\n            if child_contrib_parity1 > -float('inf'):\n                cand0_odd = child_contrib_parity1 + (nums[u] ^ k)\n            else:\n                cand0_odd = -float('inf')\n            dp[u][0] = max(cand0_even, cand0_odd)\n\n            # 情况二：p_u = 1（u 与父边选了）\n            #   如果子边选中个数 mod2 = 0: x_u = 1 => u 取 nums[u] ^ k\n            cand1_even = child_contrib_parity0 + (nums[u] ^ k)\n            #   如果子边选中个数 mod2 = 1: x_u = 0 => u 取 nums[u]\n            if child_contrib_parity1 > -float('inf'):\n                cand1_odd = child_contrib_parity1 + nums[u]\n            else:\n                cand1_odd = -float('inf')\n            dp[u][1] = max(cand1_even, cand1_odd)\n\n        # 从根节点 0 开始 DFS\n        dfs(0, -1)\n        # 根节点没有父边，p_0 = 0\n        return dp[0][0]\n```\n\n## 问题分析2\n\n在任意次操作条件下，每条边选一次将使其端点同时做一次 $XOR\\,k$。若我们将“最终节点 $i$ 被 $XOR\\,k$ 的次数模 2”记为状态 $p_i\\in\\{0,1\\}$，则每次对边 $(u,v)$ 的选择相当于对 $(p_u,p_v)$ 做一次异或操作。由于树的边集形成的线性系统有唯一约束：  \n$$\n\\sum_{i=0}^{n-1} p_i \\equiv 0 \\pmod 2,\n$$\n即最终被翻转奇数次的节点数必须为偶数（因为每条被选的边为两个端点各贡献一次翻转，总的翻转次数为偶数）。这样，问题就简化为：  \n> 在满足翻转节点数为偶数的约束下，决定哪些节点 $i$ 最终翻转，使得总价值  \n> $$\n> \\sum_{i=0}^{n-1} \\bigl(\\text{nums}[i] + p_i \\cdot [(\\text{nums}[i]\\oplus k) - \\text{nums}[i]]\\bigr)\n> $$\n> 最大。\n\n令每个节点 $i$ 的差值为\n$$\n\\Delta_i \\;=\\; (\\text{nums}[i]\\oplus k)\\;-\\;\\text{nums}[i].\n$$\n若我们忽略约束，则只需对所有 $\\Delta_i > 0$ 的节点都设 $p_i=1$；但由于必须保证 $\\sum_i p_i$ 为偶数，如果正差选取的数量为奇数，则需要“舍弃一个正差中最小的”或“额外加入一个负差中最大的”来翻转奇偶，取其中损失最小的一种。  \n因此，该方法不需要显式地做树形 DP，而是把所有节点看作“独立贡献”，只需一次扫描即可求得最优解。\n\n## 算法思路2\n\n1. **计算差值数组**  \n   对每个节点 $i$，计算  \n   $$\n   \\Delta_i = (\\text{nums}[i]\\oplus k) - \\text{nums}[i].\n   $$\n\n2. **求基础贡献**  \n   若不做任何操作，则所有节点价值之和为  \n   $$\n   \\mathrm{base\\_sum} \\;=\\; \\sum_{i=0}^{n-1} \\text{nums}[i].\n   $$\n\n3. **统计正负差值**  \n   遍历所有 $\\Delta_i$：  \n   - 若 $\\Delta_i \\ge 0$，累加到 $sumP$，并让 $cntP$ 自增；同时更新正类最小值 $minP$。  \n   - 否则（$\\Delta_i < 0$），更新负类最大值 $maxN$。\n\n4. **计算不翻转奇偶（偶数个正差）时的总贡献**  \n   $$\n   \\mathrm{contrib\\_same} = \\mathrm{base\\_sum} + sumP.\n   $$\n   若此时 $cntP$ 已经是偶数，则该值即为最优。\n\n5. **若 $cntP$ 为奇数，需要翻转一次正负奇偶**  \n   需要从“所有 $\\Delta_i\\ge0$ 的集合”中去掉一个最小的，也就是  \n   $$\n   \\mathrm{drop\\_minP} = \\mathrm{base\\_sum} + (sumP - minP).\n   $$\n   或者向“$\\Delta_i<0$”的集合中再添入一个最大的负值，即\n   $$\n   \\mathrm{add\\_maxN} = \\mathrm{base\\_sum} + (sumP + maxN).\n   $$\n   令最终最优为  \n   $$\n   \\max\\bigl(\\mathrm{drop\\_minP},\\ \\mathrm{add\\_maxN}\\bigr).\n   $$\n\n6. **返回结果**  \n   返回上述最优值即可。\n\n## 时间复杂度2\n\n- 计算 $\\Delta_i$ 数组需 $O(n)$。  \n- 统计正负、更新 $sumP$, $cntP$, $minP$, $maxN$ 也需一次 $O(n)$ 扫描。  \n- 整体时间复杂度为 $\\displaystyle O(n)$，空间复杂度为 $O(n)$（用于存储 $\\Delta$ 数组）。\n\n## 代码分解2\n\n1. **计算 $\\Delta_i$**  \n   ```python\n   deltas = [(num ^ k) - num for num in nums]\n   ```\n\n2. **计算基础和**  \n   ```python\n   base_sum = sum(nums)\n   ```\n\n3. **统计正负并维护最小正、最大负**  \n   ```python\n   sumP, cntP = 0, 0\n   minP = float('inf')\n   maxN = -float('inf')\n   for delta in deltas:\n       if delta >= 0:\n           sumP += delta\n           cntP += 1\n           minP = min(minP, delta)\n       else:\n           maxN = max(maxN, delta)\n   ```\n\n4. **计算 “不翻转奇偶” 时的贡献**  \n   ```python\n   contrib_same = base_sum + sumP\n   dp_root0 = contrib_same\n   ```\n\n5. **若 $cntP$ 为奇数则做调整**  \n   ```python\n   if cntP % 2 == 1:\n       drop_minP = base_sum + (sumP - minP) if cntP > 0 else -float('inf')\n       add_maxN = base_sum + (sumP + maxN) if maxN > -float('inf') else -float('inf')\n       dp_root0 = max(drop_minP, add_maxN)\n   ```\n\n6. **返回答案**  \n\n   ```python\n   return dp_root0\n   ```\n\n## 代码实现2\n\n```python\nfrom heapq import heappush, heappop\n\nclass Solution:\n    def maximumValueSum(self, nums, k, edges):\n        # —— 1. 计算每个节点 i 的 Δ_i = (nums[i] ^ k) - nums[i]\n        # 在树形 DP 里，我们把这叫做 deltas，当作 dp[v][1] - dp[v][0] 的简化版\n        deltas = [(num ^ k) - num for num in nums]\n\n        # —— 2. base_sum 对应“如果所有节点都不做任何 XOR k，那么基础贡献就是 sum(nums)”\n        base_sum = sum(nums)\n\n        # 接下来，用 sumP、cntP、minP、maxN 来合并所有 deltas\n        sumP = 0               # 树形 DP 里记录“所有 Δ >= 0 的累加”\n        cntP = 0               # 记录“Δ >= 0 的个数”\n        minP = float('inf')    # 记录“Δ >= 0 中的最小值”（如果没正数，则保持 +inf）\n        maxN = -float('inf')   # 记录“Δ < 0 中的最大值”（如果没负数，则保持 -inf）\n\n        for delta in deltas:\n            if delta >= 0:\n                sumP += delta\n                cntP += 1\n                if delta < minP:\n                    minP = delta\n            else:\n                if delta > maxN:\n                    maxN = delta\n\n        # —— 3. contrib_same 表示“不翻转正负奇偶”时的子（全）树贡献：\n        #     在树形 DP 里，就是 base_sum + sumP\n        contrib_same = base_sum + sumP\n\n        # 把它先赋给 dp_root0（对应根节点 p_0 = 0 时，且子边选数 mod2 与 cntP 原本同偶的情况）\n        dp_root0 = contrib_same\n\n        # —— 4. 如果 cntP 是奇数，就要“翻转一次正负奇偶”：\n        # 两个选项：删一个最小正(minP) 或 加一个最大负(maxN)\n        if cntP % 2 == 1:\n            # 方案 A：如果有正类，就删除 minP\n            if cntP > 0:\n                drop_minP_contrib = base_sum + (sumP - minP)\n            else:\n                drop_minP_contrib = -float('inf')\n\n            # 方案 B：如果有负类，就加上 maxN\n            if maxN > -float('inf'):\n                add_maxN_contrib = base_sum + (sumP + maxN)\n            else:\n                add_maxN_contrib = -float('inf')\n\n            # 在树形 DP 里，这两者对应“sumOdd”的两种计算方式，取更大\n            dp_root0 = max(drop_minP_contrib, add_maxN_contrib)\n\n        # —— 5. 返回最终结果 dp_root0（相当于整棵树的 dp[0][0]）\n        return dp_root0\n```\n\n| 维度           | 方法一：树形 DP                                              | 方法二：全局贪心（基于差值）                                 |\n| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| **核心思想**   | 在树上做自底向上的 DP，维护每个节点翻转与不翻转两种状态的最优值，合并子节点差值时需考虑“奇偶翻转” | 将所有节点视作“独立差值”，只需统计正差与负差的数量与极值，利用全局奇偶约束直接求解 |\n| **约束来源**   | 边选择会影响其相邻节点状态，需要在 DFS 中显式处理子树合并的“奇偶”关系 | 只需注意“被翻转节点数量必须为偶数”──一条全局约束，省去了树形结构的复杂递归 |\n| **实现难度**   | 需要写递归、合并子节点增益、维护正负差值的最小/最大值、考虑多种奇偶分支 | 只要一次扫描，代码简洁；无需建图或做 DFS                     |\n| **时间复杂度** | $O(n)$                                                       | $O(n)$                                                       |\n| **空间复杂度** | $O(n)$ （邻接表 + DP 数组）                                  | $O(n)$ （差值数组 + 常数额外变量）                           |\n| **典型场景**   | 当关注对每条边操作的奇偶传递，并扩展到“若树结构更复杂”时可推广 | 若只需考虑“翻转约束 $\\sum p_i \\equiv 0 \\pmod{2}$ ”，且树是连通无环结构时最优 |\n| **优势**       | 能处理更一般的“子树方向性”DP，逻辑清晰；适合需要扩展到变体约束的情况 | 直接高效；只用一次扫描即可；易于理解与实现                   |\n| **劣势**       | 代码复杂度高，容易出错；需要显式管理多种子情况与奇偶分支     | 只对“树”且仅含全局奇偶约束的特例适用；若约束更复杂则失效     |","tags":["Algorithm","困难","贪心","动态规划","图算法","状态建模"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-22","url":"/post/zero-array-transformation-iii.html","content":"\n# [3362. 零数组变换 III](https://leetcode.cn/problems/zero-array-transformation-iii/) M\n\n给你一个长度为 `n` 的整数数组 `nums` 和一个二维数组 `queries` ，其中 `queries[i] = [lᵢ, rᵢ]` 。\n\n每一个 `queries[i]` 表示对于 `nums` 的以下操作：\n\n- 将 `nums` 中下标在范围 `[lᵢ, rᵢ]` 之间的每一个元素 **最多** 减少 1 。\n- 坐标范围内每一个元素减少的值相互 **独立** 。\n\n**零数组** 指的是一个数组里所有元素都等于 0 。\n\n请你返回 **最多** 可以从 `queries` 中删除多少个元素，使得 `queries` 中剩下的元素仍然能将 `nums` 变为一个 **零数组** 。如果无法将 `nums` 变为一个 **零数组** ，返回 -1 。\n\n \n\n**示例 1：**\n\n> **输入：** nums = [2,0,2], queries = [[0,2],[0,2],[1,1]]\n>\n> **输出：** 1\n>\n> **解释：**\n>\n> 删除 `queries[2]` 后，`nums` 仍然可以变为零数组。\n>\n> - 对于 `queries[0]` ，将 `nums[0]` 和 `nums[2]` 减少 1 ，将 `nums[1]` 减少 0 。\n> - 对于 `queries[1]` ，将 `nums[0]` 和 `nums[2]` 减少 1 ，将 `nums[1]` 减少 0 。\n\n**示例 2：**\n\n> **输入：** nums = [1,1,1,1], queries = [[1,3],[0,2],[1,3],[1,2]]\n>\n> **输出：** 2\n>\n> **解释：**\n>\n> 可以删除 `queries[2]` 和 `queries[3]` 。\n\n**示例 3：**\n\n> **输入：** nums = [1,2,3,4], queries = [[0,3]]\n>\n> **输出：** -1\n>\n> **解释：**\n>\n> `nums` 无法通过 `queries` 变成零数组。\n\n \n\n**提示：**\n\n- `1 <= nums.length <= 10⁵`\n- `0 <= nums[i] <= 10⁵`\n- `1 <= queries.length <= 10⁵`\n- `queries[i].length == 2`\n- `0 <= lᵢ <= rᵢ < nums.length`\n\n\n\n## 问题分析\n给定一个长度为 $n$ 的整数数组 `nums` 和一个包含 $m$ 个查询的二维数组 `queries`，其中 `queries[i] = [l_i, r_i]` 表示对于 `nums` 执行一次操作：将下标在范围 $[l_i, r_i]$ 之间的每个元素最多减少 $1$（各位置减少值相互独立）。目标是从原来的 $m$ 个查询中删除尽可能多的查询，使得剩余查询仍能将 `nums` 变成全 0 的“零数组”。如果无论如何也不能变成零数组，则返回 $-1$。\n\n关键在于，“每次操作对区间内元素各自减少最多 1” 意味着，若某位置 $i$ 在剩余操作中被覆盖了 $k_i$ 次，则该位置至多减少 $k_i$，要达到最终 `nums[i] = 0`，就需要\n$$\nk_i \\;\\ge\\; \\text{nums}[i]\\,,\\quad \\forall\\,0 \\le i < n.\n$$\n此处每个查询只有两种选择：保留或删除。若保留，就会对它覆盖区间内的各个位置“增加 $1$”的覆盖次数；若删除，就相当于完全忽略它对覆盖次数的贡献。我们需要在确保对每个 $i$，剩余查询的覆盖次数 $\\sum 1\\{i \\in [l_j, r_j]\\}$ 至少等于 $\\text{nums}[i]$ 的前提下，尽量 **删除** 也就是丢弃尽量多的区间。\n\n换言之，若最少要保留 $K$ 条区间才能覆盖所有位置的需求，那么最多能删除 $m-K$ 条。若任何选择都无法满足某位置覆盖次数需求，则返回 $-1$。\n\n## 算法思路\n本文展示两种思路的实现代码，逻辑不同，但都遵循“贪心地选最需要的区间以满足每个位置的覆盖需求”这一核心原则。\n\n### 方法一：按左端点分桶 + 差分数组 + 贪心选右端最大的可用区间\n1. **按左端点分桶**  \n\n   - 事先将所有查询 `[l, r]` 按其左端点 $l$ 归类：用 `start_at[l]` 存储所有左端为 $l$ 的查询的右端 $r$。这样在扫描数组位置 $i$ 时，可以将所有新“激活”的区间（左端恰好是 $i$）一次性加入到可选集合里。\n\n2. **差分数组维护“已选区间覆盖次数”**  \n   - 用一个长度为 $n+1$ 的差分数组 $\\mathrm{diffCover}$，配合一个变量 $\\mathrm{currCover}$ 来维护“当前已保留的区间对当前位置 $i$ 的覆盖次数”。矩阵含义如下：\n     - 当我们决定保留某个区间 $[l, r]$ 时，就执行\n       $$\n       \\mathrm{diffCover}[l] \\;+=\\; 1,\\qquad \\mathrm{diffCover}[r+1] \\;-\\!=\\;1,\n       $$\n       这样在后续扫描时，位置 $p$ 所被选中区间覆盖次数 $\\mathrm{currCover}(p)$ 可以通过累加前缀和来得到。\n     - 在扫描到位置 $i$ 时，先用\n       $$\n       \\mathrm{currCover} \\;=\\; \\sum_{j=0}^{i-1} \\mathrm{diffCover}[j]\n       $$\n       （代码中累加 $\\mathrm{diffCover}[i]$ 到 $\\mathrm{currCover}$）以得到“已保留区间对 $i$ 的覆盖次数”。如果 $\\mathrm{currCover} < \\mathrm{nums}[i]$，说明还需多选区间来满足位置 $i$ 的需求。\n\n3. **维护可选区间按右端最大化**  \n   - 用 `availCount[r]` 统计当前“可选且未选”且右端恰好为 $r$ 的区间数量；用 `intervals_by_r[r]` 存储这些区间的左端 $l$。  \n   - 同时维护一个指针 `maxR`，表示当前所有可选区间中最大的右端。当我们要为当前位置 $i$ 额外“补覆盖”时，总是“贪心”地优先选取右端最大的区间（因为它能为之后尽可能多的位置提供覆盖机会），即不断从 `r = maxR` 的组里弹出一条区间 [$l_{\\text{top}},\\,\\maxR$] 来保留。  \n   - 每当保留一条 [$l_{\\text{top}},\\,\\maxR$]，我们会：\n     - `availCount[maxR] -= 1`\n     - `chosenCount += 1`（记录已选区间数）\n     - 更新差分：`diffCover[l_top] += 1`, `diffCover[maxR+1] -= 1`，并即时 `currCover += 1` 因为该区间确实覆盖了当前 $i$。\n   - 如果 `availCount[maxR]` 变为 0，则将 `maxR` 不断向左移动至下一个 `availCount[r'] > 0` 为止（且保持 $r' \\ge i$），否则就说明没有可选区间能覆盖 $i$，直接返回 $-1$。\n\n4. **逐位扫描**  \n   - 从 $i=0$ 到 $i=n-1$，先累加 `diffCover[i]` 到 `currCover`，再将左端恰好是 $i$ 的所有区间“激活”到 `availCount` 和 `intervals_by_r`，更新 `maxR`。  \n   - 如果此时 `currCover < nums[i]`，就在当前可选中右端最大的 `maxR` 里不断选区间来增加覆盖，直到 `currCover >= nums[i]` 或者发现无法满足而返回 $-1$。  \n   - 这样保证每个位置都至少被覆盖 `nums[i]` 次。扫描结束后，若没有失败，则记录已保留区间数 $K = \\mathrm{chosenCount}$，答案即 $m - K$。\n\n5. **数学公式**  \n   - 差分数组更新公式：  \n     $$\n     \\mathrm{diffCover}[l] \\;+=\\;1,\\quad \\mathrm{diffCover}[r+1]\\;-\\!=\\;1\\,.\n     $$\n   - 在扫描到位置 $i$ 时，已选区间的覆盖次数：  \n     $$\n     \\mathrm{currCover}(i) \\;=\\; \\sum_{j=0}^i \\mathrm{diffCover}[j]\\,.\n     $$\n   - 需要满足：  \n     $$\n     \\mathrm{currCover}(i) \\;\\ge\\; \\mathrm{nums}[i],\\quad \\forall\\,i.\n     $$\n\n### 方法二：按左端排序 + 最大堆 + 差分前缀\n1. **将查询按左端 $l$ 升序排序**  \n\n   - 令 `queries.sort(key=lambda x: x[0])`，并用指针 `j` 遍历所有查询。当扫描到数组位置 $i$ 时，顺便把所有 $l \\le i$ 的区间逐一推入堆中。\n\n2. **用最大堆维护“已激活的区间按右端降序”**  \n   - 在Python里，我们用 `heapq`，但由于它是最小堆，我们将右端 $r` 取负数存入堆，实际效果是“堆顶”对应最大的 $r$。  \n   - 当扫描到 $i$，先将左端 $\\le i$ 的所有区间都 `heappush(h, -r)`。\n\n3. **差分数组 `diff` 记录“当前已选区间对后续位置的累积覆盖影响”**  \n   - 初始化 `diff = [0]*(n+1)`，并维护一个前缀和 `sum_d = 0`。含义是：`sum_d = \\sum_{k=0}^{i-1} diff[k]`。\n   - 当我们保留一条区间 $[l, r]$ 时，执行：\n     $$\n     \\mathrm{diff}[\\,r+1\\,] \\;+\\!=\\; -1\\quad(\\text{因为 pos $>r$ 时覆盖计数会减少})\n     $$\n     并且在选区间时，立刻做 `sum_d -= 1` 并计入已选区间计数 `k += 1`，相当于该区间“直接覆盖了当前 $i$”，所以对 $i$ 之后的所有位置在 `sum_d` 上预先扣了 1。总之，这里将覆盖量通过一维差分转换成后缀影响。\n\n4. **遍历数组**  \n   - 对于每个 $i$，先做 `sum_d += diff[i]`。此时 `sum_d` 代表“由之前保留的区间，在当前位置及其之后还能继续贡献的覆盖次数”与当前位置应有的需求 `-nums[i]` 做对比：  \n     - 因为我们维持 `sum_d` 是负数时表示对当前位置仍需额外 $(-sum_d)$ 的“补覆盖”。\n   - 如果 `sum_d <= -nums[i]`，说明当前已有保留区间的覆盖就足够满足 `nums[i]`，不需要额外选。  \n   - 否则，就不断从堆中弹出右端最大的区间（即 `-heap[0]` 最大），若弹出区间的右端 $r` $\\ge i$，就保留它：  \n     - 执行 `diff[r+1] += 1`（意味着在位置 $r+1$ 开始，“覆盖贡献”减少 1），\n     - `sum_d -= 1`，`k += 1`。\n   - 重复弹区间直到 `sum_d <= -nums[i]` 或堆空或堆顶区间右端 $< i$（此时堆里所有剩余区间都无法覆盖当前 $i$，直接返回 $-1$）。\n   - 如果循环结束后仍然 `sum_d > -nums[i]`，说明无法达到需求，返回 $-1$。\n\n5. **答案**  \n\n   - 如果整个 $i=0..n-1$ 都顺利通过，记录保留的区间数 $K = k$，则最多能删除 $m - K$。\n\n## 时间复杂度\n- **方法一**  \n  - 构建 `start_at` 要 $O(m)$，差分数组大小 $O(n)$。  \n  - 遍历每个位置 $i$ 时：\n    - 将左端恰为 $i$ 的区间激活到 `availCount` 和 `intervals_by_r`，总共需要把 $m$ 条区间分配一次，属于 $O(m)$。\n    - 在最坏情况下，每个位置都可能进行一次或多次“选区间”操作，总共最多选 $K$ 条区间，$K \\le m$，每次更新差分和 `maxR` 都是 $O(1)$ 或者 `maxR` 左移 $O(1)$ 次的摊销。  \n  - 因此总体时间复杂度 $O(n + m)$。\n\n- **方法二**  \n  - 先对查询排序 $O(m\\log m)$。  \n  - 遍历 $0..n-1$，每步：\n    - 把左端 $\\le i$ 的查询压入堆，所有 $m$ 条均只入一次堆，总共 $O(m\\log m)$。\n    - 弹堆操作最多也是 $O(m\\log m)$。\n    - 差分数组前缀 $sum_d$ 的累加是 $O(1)$。\n  - 因此总复杂度 $O(m\\log m + n)$。若 $m$ 远大于 $n$，则主要开销在堆操作上。\n\n## 代码分解\n### 方法一\n1. **构建 `start_at` 列表**  \n   ```python\n   start_at = [[] for _ in range(n)]\n   for idx, (l, r) in enumerate(queries):\n       start_at[l].append(r)\n   ```\n\n意味着 `start_at[i]` 内存储所有左端为 $i$ 的查询的右端 `r`。\n\n1. **初始化辅助数组和变量**\n\n   ```python\n   diffCover = [0] * (n + 1)   # 差分数组\n   currCover = 0              # 前缀和，表示当前位置已有覆盖\n   chosenCount = 0            # 已保留区间数\n   availCount = [0] * n       # 右端为 r 的“可选未选”区间数量\n   intervals_by_r = [[] for _ in range(n)]  # 记录右端 r 下的各左端 l\n   maxR = n - 1               # 当前可选区间的最大右端\n   ```\n\n2. **从 i=0..n-1 扫描**\n\n   - 累加差分：`currCover += diffCover[i]`。\n\n   - 将所有 `l=i` 的区间激活：\n\n     ```python\n     for r in start_at[i]:\n         availCount[r] += 1\n         intervals_by_r[r].append(i)\n         if r > maxR: maxR = r\n     ```\n\n   - “剔除过期”并维护 `maxR >= i && availCount[maxR] > 0`。\n\n   - 若 `currCover < nums[i]`，就要补选区间：\n\n     ```python\n     while currCover < nums[i]:\n         if maxR < i: return -1\n         # 取出右端 = maxR 的一个可选区间\n         l_top = intervals_by_r[maxR].pop()\n         availCount[maxR] -= 1\n         chosenCount += 1\n         currCover += 1\n         diffCover[l_top] += 1\n         diffCover[maxR + 1] -= 1\n         if availCount[maxR] == 0:\n             # maxR 不断左移\n             while maxR >= i and (availCount[maxR] == 0):\n                 maxR -= 1\n     ```\n\n   - 若循环结束时 `currCover >= nums[i]`，位置 $i$ 满足需求，继续下一个 $i+1$。\n\n3. **返回结果**\n\n   - 如果遍历结束都没出错，最少要保留 `chosenCount` 条，最多可删除 `m - chosenCount`。否则中途返回 `-1`。\n\n### 方法二\n\n1. **排序与初始化**\n\n   ```python\n   queries.sort(key=lambda x: x[0])\n   h = []\n   diff = [0] * (len(nums) + 1)\n   q, j = len(queries), 0\n   k = sum_d = 0\n   ```\n\n   - `h` 为堆（Python 默认最小堆，用 `-r` 保存便于每次弹出最大右端）。\n   - `diff[i]` 存储差分：一旦保留区间 $[l,r]$，就对 `diff[r+1] += 1` 来表示“从 $r+1$ 开始，后缀不再被此区间覆盖”。\n   - `sum_d` 追踪前 $i$ 的差分前缀和。\n\n2. **遍历 nums**\n\n   ```python\n   for i, x in enumerate(nums):\n       sum_d += diff[i]\n       # 如果已有覆盖 sum_d <= -x，说明已满足 nums[i]\n       if sum_d <= -x:\n           continue\n       # 否则，把左端 <= i 的所有区间压堆\n       while j < q and queries[j][0] <= i:\n           heapq.heappush(h, -queries[j][1])\n           j += 1\n       # 弹堆，补选最大的右端区间\n       while sum_d > -x and h and -h[0] >= i:\n           r = -heapq.heappop(h)\n           diff[r + 1] += 1\n           sum_d -= 1\n           k += 1\n       # 若无法满足需求，则失败\n       if sum_d > -x:\n           return -1\n   return q - k\n   ```\n\n   - 对每个位置 $i$，先 `sum_d += diff[i]`。此时若 `sum_d <= -nums[i]`，说明此前已选的区间覆盖次数充足；否则进入补选。\n   - 在补选阶段，只要当前 `sum_d > -nums[i]`，且堆顶区间的右端 $r \\ge i$，就可以选取它：`sum_d -= 1` 立刻反映“当前 $i$ 被此区间覆盖”；`diff[r+1] += 1` 表示“在 $r+1$ 处去掉这条区间后续的覆盖贡献”。\n   - 若在此之后仍不能满足，则直接返回 `-1`。\n\n## 代码实现\n\n```python\nfrom typing import List\n\nclass Solution:\n    def maxRemoval(self, nums: List[int], queries: List[List[int]]) -> int:\n        n, m = len(nums), len(queries)\n        # 1. 把所有区间按左端点 l 分桶\n        #    start_at[i] 里存的，是所有左端点恰好为 i 的查询 (r)\n        start_at = [[] for _ in range(n)]\n        for idx, (l, r) in enumerate(queries):\n            start_at[l].append(r)\n\n        # 2. 差分数组 diffCover 用于维护“已选区间到当前位置 i 的覆盖次数”\n        diffCover = [0] * (n + 1)\n        currCover = 0    # 当前在 i 处，已选的区间一共覆盖了多少次\n        chosenCount = 0  # 已经保留（选中）的区间数\n\n        # 3. availCount[r] 统计：目前“可选”且尚未被选的“右端点恰好等于 r”的区间有多少条\n        availCount = [0] * n\n        # intervals_by_r[r] 存储：当区间 [l,r] 一被激活，就把它的 l push 到这里\n        intervals_by_r = [[] for _ in range(n)]\n\n        # 4. 用一个指针 maxR 来指向“当前可选区间里最大的 r”\n        maxR = n - 1\n\n        # 5. 从 i=0..n-1 依次扫描\n        for i in range(n):\n            # ——(A) 先把 diffCover[i] 累到 currCover 上\n            currCover += diffCover[i]\n\n            # ——(B) 把左端点 l = i 的区间全部“激活”\n            for r in start_at[i]:\n                availCount[r] += 1\n                intervals_by_r[r].append(i)\n                if r > maxR:\n                    maxR = r\n\n            # ——(C) 剔除过期的 r：保证 maxR ≥ i 且 availCount[maxR] > 0\n            while maxR >= i and (availCount[maxR] == 0):\n                maxR -= 1\n\n            # ——(D) 如果 currCover < nums[i]，就必须“贪心地”从 r = maxR 开始选区间补覆盖\n            while currCover < nums[i]:\n                if maxR < i:\n                    return -1\n\n                # 从 intervals_by_r[maxR] 中 pop 出一个左端 l_top\n                l_top = intervals_by_r[maxR].pop()\n                availCount[maxR] -= 1\n                chosenCount += 1\n                # 该区间覆盖了当前 i，立刻补一个 currCover\n                currCover += 1\n\n                # 差分更新：对 [l_top, maxR] 内所有位置各 +1\n                diffCover[l_top] += 1\n                if maxR + 1 < len(diffCover):\n                    diffCover[maxR + 1] -= 1\n\n                # 如果 maxR 组里已无可选区间，继续将 maxR 左移\n                while maxR >= i and (availCount[maxR] == 0):\n                    maxR -= 1\n\n            # 至此 currCover ≥ nums[i]，安全进入 i+1\n\n        # 扫完所有 i，没有失败\n        return m - chosenCount\n\n```\n\n二\n\n```python\nimport heapq\n\nclass Solution:\n    def maxRemoval(self, nums: List[int], queries: List[List[int]]) -> int:\n        # 将 queries 按左端升序排序\n        queries.sort(key=lambda x: x[0])\n        h = []  # 最大堆（用负的 r 存储）\n        diff = [0] * (len(nums) + 1)\n        q, j = len(queries), 0\n        k = sum_d = 0\n\n        for i, x in enumerate(nums):\n            # 更新前缀和\n            sum_d += diff[i]\n            # 如果已有 sum_d <= -x，则说明已满足 nums[i]，继续\n            if sum_d <= -x:\n                continue\n\n            # 将左端 <= i 的所有查询压入堆\n            while j < q and queries[j][0] <= i:\n                heapq.heappush(h, -queries[j][1])\n                j += 1\n\n            # 弹堆补选右端最大的区间，直到满足需求或堆空/无法覆盖\n            while sum_d > -x and h and -h[0] >= i:\n                r = -heapq.heappop(h)\n                # 差分更新，位置 r+1 开始对后缀去掉一个覆盖\n                diff[r + 1] += 1\n                sum_d -= 1\n                k += 1\n\n            # 如果仍然不够覆盖，返回 -1\n            if sum_d > -x:\n                return -1\n\n        # 能完成覆盖，最多删除 q - k\n        return q - k\n\n```\n\n","tags":["Algorithm","中等","数据结构","贪心","优先队列","状态建模","差分数组","区间覆盖"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-21","url":"/post/zero-array-transformation-ii.html","content":"\n# [3356. 零数组变换 II](https://leetcode.cn/problems/zero-array-transformation-ii/) M\n\n给你一个长度为 `n` 的整数数组 `nums` 和一个二维数组 `queries`，其中 `queries[i] = [lᵢ, rᵢ, valᵢ]`。\n\n每个 `queries[i]` 表示在 `nums` 上执行以下操作：\n\n- 将 `nums` 中 `[lᵢ, rᵢ]` 范围内的每个下标对应元素的值 **最多** 减少 `valᵢ`。\n- 每个下标的减少的数值可以**独立**选择。\n\n**零数组** 是指所有元素都等于 0 的数组。\n\n返回 `k` 可以取到的 **最小非负** 值，使得在 **顺序** 处理前 `k` 个查询后，`nums` 变成 **零数组**。如果不存在这样的 `k`，则返回 -1。\n\n \n\n**示例 1：**\n\n> **输入：** nums = [2,0,2], queries = [[0,2,1],[0,2,1],[1,1,3]]\n>\n> **输出：** 2\n>\n> **解释：**\n>\n> - 对于 i = 0（l = 0, r = 2, val = 1）：\n>   - 在下标 `[0, 1, 2]` 处分别减少 `[1, 0, 1]`。\n>   - 数组将变为 `[1, 0, 1]`。\n> - 对于 i = 1（l = 0, r = 2, val = 1）：\n>   - 在下标 `[0, 1, 2]` 处分别减少 `[1, 0, 1]`。\n>   - 数组将变为 `[0, 0, 0]`，这是一个零数组。因此，`k` 的最小值为 2。\n\n**示例 2：**\n\n> **输入：** nums = [4,3,2,1], queries = [[1,3,2],[0,2,1]]\n>\n> **输出：** -1\n>\n> **解释：**\n>\n> - 对于 i = 0（l = 1, r = 3, val = 2）：\n>   - 在下标 `[1, 2, 3]` 处分别减少 `[2, 2, 1]`。\n>   - 数组将变为 `[4, 1, 0, 0]`。\n> - 对于 i = 1（l = 0, r = 2, val = 1）：\n>   - 在下标 `[0, 1, 2]` 处分别减少 `[1, 1, 0]`。\n>   - 数组将变为 `[3, 0, 0, 0]`，这不是一个零数组。\n\n \n\n**提示：**\n\n- `1 <= nums.length <= 10⁵`\n- `0 <= nums[i] <= 5 * 10⁵`\n- `1 <= queries.length <= 10⁵`\n- `queries[i].length == 3`\n- `0 <= lᵢ <= rᵢ < nums.length`\n- `1 <= valᵢ <= 5`\n\n\n\n## 问题分析\n\n要找最小的 $k$ ，使得对 `nums` 执行前 $k$ 条查询后，可以将数组完全凑成“零数组”。每条查询 $[l_i,\\,r_i,\\,v_i]$ 表示在区间 $[l_i,r_i]$ 内，各下标位置最多各自减少 $v_i$，每个位置可以独立选减少多少。\n\n我们定义一个“**剩余需求**”数组 $\\mathrm{rem}[i]$，它表示下标 iii 要变成 0，还需要从查询里“累计扣除”多少。\n 初始时 $\\mathrm{rem}[i] = \\texttt{nums}[i]$。随着我们“依次”处理第 1 条、第 2 条、…、第 $k$ 条查询，每执行一条查询，就要把它对区间 $[l,r]$ 内的 $\\mathrm{rem}$ 统一**“减去”** $v$（注意：如果该条查询本身要求的 $v$ 大于 $\\mathrm{rem}[i]$，其实“最多”减 $v$ 的含义对应我们在代码里直接减；因为之后我们会在 $\\mathrm{rem}[i] \\le 0$ 时“收集答案”并且把它标记为不再参与后续运算——详见下文）。\n\n当且仅当某个位置 $i$ 经历了若干次涵盖它的查询以后，$\\mathrm{rem}[i]$ 的值变得 $\\le 0$，就说明“对下标 $i$ 而言，它已经完全被扣成 0 了”。我们记录下最先使得 $\\mathrm{rem}[i]$ “跨到 $\\le 0$”的那条查询的编号 $idx$，记为 $\\mathrm{ans}[i] = idx$。如果直到所有 $m$ 条查询都跑完，它仍未被扣到 $\\le 0$，则 $\\mathrm{ans}[i]=+\\infty$ （或用 $-1$ 表示“永远扣不成 0”）。\n\n最后，只要所有下标都能在某个时刻“跨到 $\\le0$”，那么整个数组才能凑成零。令\n$$\nK = \\max_{0 \\le i < n}\\; \\mathrm{ans}[i]\\,.\n$$\n如果 $K \\le m$，则答案就是 $K$；否则（存在某个位置从未走到 $\\le0$），答案返回 $-1$。\n\n## 算法思路\n\n**区间减与“找最小非正下标”**\n\n**“给 $\\mathrm{rem}[\\,]$ 做一次 $[l,r]$ 区间统一减 $v$”**\n\n**“询问当前整个数组 $\\mathrm{rem}[\\,]$ 的最小值，检查它是否 $\\le 0$；如果是，把那个位置取出来，记录答案，并把它从后续运算中剔除。”**\n\n要想在**每执行一条查询**之后，快速做到“把 $\\mathrm{rem}[l \\ldots r]$ 整个区间都减掉 $v$”，并能检查是否有位置跨到 $\\leq 0$，最常用的办法就是**线段树（带懒标记）的“区间减一次，区间查询最小值”**。具体思路如下：\n\n我们把 $\\mathrm{rem}[]$ 维护在一棵线段树上，线段树的每个节点记录该区间当前的最小 rem 值（即 minv），同时支持“区间减去 $v$”的**懒标记**（节点上加一个 `lazy` 值表示要向下传递的减量）。\n\n我们还需要一个额外操作：**“如果整个区间的最小值 $\\leq 0$，就找出一个下标 $i$，使得 $\\mathrm{rem}[i] \\leq 0$。”**\n\n由于线段树根节点存储了全区间（$0..n-1$）的最小值，即 $\\text{tree}[1].\\text{minv}$，只要 $\\text{tree}[1].\\text{minv} \\leq 0$，就说明至少有一个叶子节点 $i$ 满足 $\\mathrm{rem}[i] \\leq 0$。\n\n此时我们可以从根节点向下递归：\n\n- 如果左子节点的 minv $\\leq 0$，就优先进入左子树，否则进入右子树。\n\n- 不断递归，直到定位到某个叶节点 $i$，它的 `minv` $\\leq 0$，这就是当前“最小 `rem` $\\leq 0$”对应的下标。\n\n找到 $i$ 之后，我们将线段树中 $\\mathrm{rem}[i]$ 设为一个很大的正数（比如 $+\\infty$，实际代码里用足够大的常数 $\\text{INF}=10^{18}$）。这样，相当于把 $i$ 从后续所有区间减法操作中移除，该下标不再参与后面的判 $\\leq 0$ 检查。\n\n只要“线段树根节点 `minv` $\\leq 0$”，就不断进行“找 $i$，将 $\\mathrm{rem}[i]$ 置 $+\\infty$，并记录 $\\text{ans}[i]=\\text{当前查询编号}$”操作；循环直到根节点最小值 $>0$，然后进入下一条查询。\n\n## 时间复杂度\n\n1. 线段树建树 $O(n)$。\n\n2. 先把 $\\mathrm{nums}[i]=0$ 的那些下标提取一次，总共操作次数最多 $n$ 次“找 $\\le 0$ + 单点置 $\\mathrm{INF}$”，每次 $O(\\log n)$，合计 $O(n \\log n)$。\n3. 针对 $m$ 条查询，每条：\n   1. 区间减一次 $O(\\log n)$。\n   2. 紧接着最多有若干个新下标跨到 $\\mathrm{rem} \\le 0$，反复做“找 $i$ + 置 $\\mathrm{INF}$” 若干次。\n      - 每个下标 $i$ 只会从 $\\mathrm{rem}>0$ 变到 $\\mathrm{rem}\\le 0$ 一次，因此**所有**“找 $i$ 并置 $\\mathrm{INF}$”操作总共不会超过 $n$ 次，每次 $O(\\log n)$。\n4. 所以总复杂度为：\n   - 建树 $O(n)$\n   - 查找与置 $\\mathrm{INF}$ 总共 $O(n \\log n)$\n   - 区间减 $m$ 次 $O(m \\log n)$\n   - 最终为 $O((n+m)\\log n)$\n\n- 空间复杂度 $O(n)$，主要用于 $\\mathrm{rem}$、$\\mathrm{ans}$ 以及线段树节点（最多约 $4n$）。\n\n## 代码分解\n\n1. **初始化**\n\n- 读入 $n = \\mathrm{len(nums)}$，$m = \\mathrm{len(queries)}$。\n\n- 用一个数组 $\\mathrm{rem}$，大小 $n$，令 $\\mathrm{rem}[i] = \\mathrm{nums}[i]$。\n\n- 用一个大小为 $n$ 的答案数组 $\\mathrm{ans}$，全部初始化成 $\\mathrm{INF}$（或者 $m+1$，表示“还没被扣到 $\\le 0$”）。\n\n- 提前把所有 $i$ 且 $\\mathrm{rem}[i] = 0$ 的下标视作“在第 $0$ 条查询就能扣到 $\\le 0$”：\n\n  - 构建一棵线段树，把每个叶子节点的初始值设成 $\\mathrm{rem}[i]$。\n\n  - 线段树内置“最小值”信息，建完之后如果根节点 $\\mathrm{minv} == 0$，就说明某些下标初始就 $\\mathrm{rem}=0$。我们要**在第 $0$ 步**（即不执行任何查询）就把它们提取：\n\n    ```python\n    while tree_root.minv ≤ 0:\n        i = query_index_of_some_leaf_with_minv≤0()\n        ans[i] = 0\n        update_leaf(i, +INF)   # 把 rem[i] 设为 +INF，等于“干掉它”\n    ```\n\n  - 这样，所有初始 $\\mathrm{nums}[i]=0$ 的位置就有了 $\\mathrm{ans}[i]=0$。\n\n2. **按查询编号 $1..m$ 依次处理**\n\n  对于当前处理到第 $idx$（1-based）的查询 $\\mathrm{queries}[idx-1] = [l, r, v]$，执行：\n\n  - 在线段树上对区间 $[l, r]$ 做“整体再减 $v$” （用懒标记方式）。\n\n  - 更新完毕后，检查线段树的根节点 $\\mathrm{minv}$ 是否 $\\le 0$：\n\n    - 如果 $\\mathrm{minv} > 0$，说明这时候没有任何下标的 $\\mathrm{rem} \\le 0$，直接跳到下一条查询（$idx += 1$）。\n\n    - 否则，反复循环：\n\n      ```python\n      while tree_root.minv ≤ 0:\n          i = 找到某个叶子下标 i，使得 rem[i] ≤ 0\n          ans[i] = idx\n          update_leaf(i, +INF)   # 将该位置从后续考虑中剔除\n      ```\n\n    - 上述循环结束代表此时所有还在树里的“rem”都已 $> 0$，可以处理下一条查询。\n\n3. **遍历结束后，计算最终答案**\n\n  - 对 $\\mathrm{ans}[i]$ 做一次遍历：如果有下标 $i$ 永远都没被扣到 $\\le 0$（即 $\\mathrm{ans}[i]$ 保持初始的 $\\mathrm{INF}$），说明它不可能凑成零，直接返回 $-1$。\n  - 否则，答案 $K = \\max_{0 \\le i < n} \\mathrm{ans}[i]$。返回此 $K$。\n\n4. 我们需要实现一个支持以下操作的线段树（0-based）：\n\n  5. **建树（build）**：把初始数组 $\\mathrm{rem}[]$ 的值装进去，构建出“每个区间的最小值”。\n  6. **区间减 $(ql, qr, v)$**：在 $[ql, qr]$ 这段，所有 $\\mathrm{rem}[i]$ 都要再减去 $v$。\n     - 通过在节点打“懒标记 $\\mathrm{lz}[node] += v$”让该节点下所有值都“虚拟地”减 $v$，并在需要时把懒标记下传给左右子节点。\n  7. **询问全局最小 (query_min())**：直接从根节点读出 $\\mathrm{tree}[1].\\mathrm{minv}$。\n  8. **找某个满足 $\\mathrm{rem}[i]\\leq 0$ 的下标 $i$**：\n     - 如果当前根节点的 $\\mathrm{minv} > 0$，说明没有任何 $\\le 0$ 的叶子，直接返回“无”。\n     - 否则从根节点开始，若左子节点的 $\\mathrm{minv} \\leq 0$ 就往左子树走；否则往右子树。直到到叶子，拿到具体下标 $i$。\n  9. **把一个下标 $i$“标记为已完成”**：在叶子层将 $\\mathrm{rem}[i]$ 直接置 $\\mathrm{INF}$（足够大的正数），然后向上拉一次更新父节点的最小值。这样后续它就不会再被判 $\\le 0$。\n\n由于 $n\\le 10^{5}$，线段树最多需要 $4n$ 个节点。所有操作的单次复杂度都是 $O(\\log n)$。\n\n## 代码实现\n\n**初始化时把 $\\mathrm{nums}[i]=0$ 的下标提前提取**\n\n- 一开始建树完毕后，就把所有 $\\mathrm{rem}[i] == 0$ 的下标（也就是原始 $\\mathrm{nums}[i]$ 已经是 $0$）用“查询编号 $0$”直接记录在 $\\mathrm{ans}[i]$，然后在树里把 $\\mathrm{rem}[i]$ 设为 $\\mathrm{INF}$（等价于把它从后续所有区间操作和“再查 $\\le 0$”中干掉）。\n- 这样做的好处是：如果某个位置原本就是 $0$，就不需要等待任何真正的查询，它的答案就是 $0$。\n\n**每条查询后“区间整体再减 $v$”**\n\n- 使用线段树带懒标记的区间减操作 $\\mathrm{range\\_sub}(1, 0, n-1, l, r, v)$，单次复杂度 $O(\\log n)$。\n- 更新完毕以后，只需要检查树根的最小值 $\\mathrm{query\\_global\\_min}()$ 是否 $\\le 0$。\n  - 如果 $> 0$，说明目前没有新的下标变得 $\\mathrm{rem} \\le 0$，直接进入下一条查询。\n  - 否则，循环“找一个 $\\le 0$ 的叶子” $i_0 = \\mathrm{find\\_any\\_nonpos}(1, 0, n-1)$，把它的 $\\mathrm{ans}[i_0]$ 设为当前查询编号 $idx$，再在树里把 $\\mathrm{rem}[i_0]=\\mathrm{INF}$，并向上更新维护最小值。循环直到树根最小值 $> 0$。\n\n**最后的答案 $K$**\n\n- 只要所有 $i$ 都在某个时刻跨到 $\\mathrm{rem}[i] \\le 0$，它们的 $\\mathrm{ans}[i]$ 就是一个落在 $[0..m]$ 的整数。此时答案 $K = \\max_i \\mathrm{ans}[i]$。\n- 如果有某个 $\\mathrm{ans}[i]$ 始终保持 $\\mathrm{INF}$，说明它从来没被扣到 $\\le 0$，返回 $-1$。\n\n```python\nclass SegmentTree:\n    def __init__(self, arr: list):\n        self.n = len(arr)\n        self.minv = [0] * (4 * self.n)\n        self.lazy = [0] * (4 * self.n)\n        self.INF = 10**18\n\n        def build(node, l, r):\n            if l == r:\n                self.minv[node] = arr[l]\n            else:\n                mid = (l + r) // 2\n                build(node * 2, l, mid)\n                build(node * 2 + 1, mid + 1, r)\n                self.minv[node] = min(self.minv[node * 2], self.minv[node * 2 + 1])\n\n        build(1, 0, self.n - 1)\n\n    def _apply_lazy(self, node, delta):\n        self.minv[node] -= delta\n        self.lazy[node] += delta\n\n    def _push_down(self, node):\n        if self.lazy[node] != 0:\n            delta = self.lazy[node]\n            self._apply_lazy(node * 2, delta)\n            self._apply_lazy(node * 2 + 1, delta)\n            self.lazy[node] = 0\n\n    def _push_up(self, node):\n        self.minv[node] = min(self.minv[node * 2], self.minv[node * 2 + 1])\n\n    def range_sub(self, node, l, r, ql, qr, v):\n        if ql <= l and r <= qr:\n            self._apply_lazy(node, v)\n            return\n\n        self._push_down(node)\n        mid = (l + r) // 2\n        if qr <= mid:\n            self.range_sub(node * 2, l, mid, ql, qr, v)\n        elif ql > mid:\n            self.range_sub(node * 2 + 1, mid + 1, r, ql, qr, v)\n        else:\n            self.range_sub(node * 2, l, mid, ql, qr, v)\n            self.range_sub(node * 2 + 1, mid + 1, r, ql, qr, v)\n\n        self._push_up(node)\n\n    def query_global_min(self):\n        return self.minv[1]\n\n    def find_any_nonpos(self, node, l, r):\n        if self.minv[node] > 0:\n            return -1\n        if l == r:\n            return l\n\n        self._push_down(node)\n        mid = (l + r) // 2\n        if self.minv[node * 2] <= 0:\n            return self.find_any_nonpos(node * 2, l, mid)\n        else:\n            return self.find_any_nonpos(node * 2 + 1, mid + 1, r)\n\n    def set_inf(self, node, l, r, idx):\n        if l == r:\n            self.minv[node] = self.INF\n            return\n\n        self._push_down(node)\n        mid = (l + r) // 2\n        if idx <= mid:\n            self.set_inf(node * 2, l, mid, idx)\n        else:\n            self.set_inf(node * 2 + 1, mid + 1, r, idx)\n\n        self._push_up(node)\n\n\nclass Solution:\n    def minZeroArray(self, nums, queries):\n        n = len(nums)\n        m = len(queries)\n        rem = nums[:]\n        INF = 10**18\n        ans = [INF] * n\n        st = SegmentTree(rem)\n\n        # 处理原本就为0的下标\n        while True:\n            if st.query_global_min() > 0:\n                break\n            i0 = st.find_any_nonpos(1, 0, n - 1)\n            if i0 == -1:\n                break\n            ans[i0] = 0\n            st.set_inf(1, 0, n - 1, i0)\n\n        # 依次处理每条查询\n        for idx in range(1, m + 1):\n            l, r, v = queries[idx - 1]\n            st.range_sub(1, 0, n - 1, l, r, v)\n            while True:\n                if st.query_global_min() > 0:\n                    break\n                i0 = st.find_any_nonpos(1, 0, n - 1)\n                if i0 == -1:\n                    break\n                if ans[i0] == INF:\n                    ans[i0] = idx\n                st.set_inf(1, 0, n - 1, i0)\n\n        # 检查是否全部 <= 0\n        final_ans = 0\n        for i in range(n):\n            if ans[i] == INF:\n                return -1\n            final_ans = max(final_ans, ans[i])\n        return final_ans\n```\n\n## 算法思路2\n\n1. **差分+验证模型**\n\n   - 对于某个固定的 k（只考虑前 k 条查询），要判断是否能把 nums 完全减为 0，需要检查每个位置 i 在这 k 条查询中，允许的“最大累计减量”之和是否 $\\geq nums[i]$。\n\n   - 原因：每个查询在覆盖区间 [l, r] 内，对位置 i 可以最多减去 v；若该位置被多条查询覆盖，那么这些查询各自能提供的“最大减量额度”加起来，就形成了“可用的整体减量上限”。只有当前 k 条查询对位置 i 的“减量额度之和” $\\geq$ nums[i]，才能让它有机会被减到 0。\n\n   - 判定条件转化为：\n\n      > 定义数组 $cap[i] = \\sum_{j=0}^{k-1,\\ l_j \\leq i \\leq r_j} v_j$。\n      > 如果对所有 i 都有 cap[i] $\\geq$ nums[i]，则这 k 条查询可以通过合理分配将 nums 全部扣为 0。否则不能。\n\n2. 计算 cap[]——**差分+前缀和**\n\n   - 维护一个长度为 n+1 的差分数组 diff，初始化全为 0。\n\n   - 对于查询 [l, r, v]（下标从 0 开始），做：\n     ```pseudocode\n     diff[l] += v\n     diff[r+1] -= v\n     ```\n   - 所有前 k 条查询都更新后，对 diff 做一次前缀和，在线性时间 $O(n)$ 内得到每个位置 i 的 cap[i]。\n   - 最后只需检验：对每个 i，cap[i] $\\geq$ nums[i] 吗？\n\n3. **二分查找**\n\n   - 如果对于某个 k₀ 满足“前 k₀ 条查询可以凑出零数组”，则对于任何 $k \\geq k_0$，cap[i] 只会更大，所以“可行性”是单调的。\n   - 可在 [0, m] 区间二分，找第一个可行的 k。若整个区间都不可，返回 -1。\n\n4. 实现思路\n\n   - 定义函数 check(k)：判断前 k 条查询能否凑成零数组\n     a. 初始化长度为 n+1 的 diff 数组，全 0。\n     b. 对于 j=0..k-1，每条 $[l_j, r_j, v_j]$：执行 $diff[l_j] += v_j$，$diff[r_j+1] -= v_j$。\n     c. 对 diff 做前缀和，得到 cap 数组长度为 n：cap[i] = 能够提供给位置 i 的累计减量额度。\n     d. 遍历 i=0..n-1，如果 cap[i] < nums[i]，直接返回 False；否则全部通过返回 True。\n\n   - 在主函数，对 k 在 [0, m] 做二分：\n\n     ```pseudocode\n     a. lo = 0, hi = m, answer = m+1。\n     b. while lo $\\leq$ hi：\n         mid = (lo+hi)//2\n         if check(mid)：answer = mid; hi = mid-1\n         else：lo = mid+1\n     c. 最终如果 answer $$\\leq$$ m 则返回 answer，否则返回 -1。\n     ```\n\n   - 允许 k = 0 进入 check(0)：没有任何查询时，只有当 nums 全为 0 才判通过。\n\n**时间复杂度**\n\n- 一次 check(k)：$O(n + k)$。\n- 二分最多调用 $O(\\log m)$ 次。\n- 总复杂度：$O((n+m)\\log m)$。\n\n**空间复杂度**\n\n- 差分数组 diff 长度 n+1，cap 长度 n，以及 zerolithx 变量，$O(n)$。\n\n```python\nfrom typing import List\n\nclass Solution:\n    def minZeroArray(self, nums: List[int], queries: List[List[int]]) -> int:\n        n = len(nums)\n        m = len(queries)\n        \n        # 检查函数：检查前 k 条查询能否把 nums 减为零数组\n        def check(k: int) -> bool:\n            # 差分数组，长度 n+1，初始全 0\n            diff = [0] * (n + 1)\n            \n            # 如果 k > 0，则把前 k 条查询都叠加到 diff 上\n            for idx in range(k):\n                l, r, v = queries[idx]\n                diff[l] += v\n                if r + 1 < n:\n                    diff[r + 1] -= v\n            \n            # 前缀和得到 cap[i]，并随即验证 cap[i] 是否 >= nums[i]\n            running = 0\n            for i in range(n):\n                running += diff[i]\n                # cap[i] = running\n                if running < nums[i]:\n                    return False\n            return True\n        \n        # 在 k ∈ [0, m] 上二分，寻找最小的 k 使 check(k) 为 True\n        lo, hi = 0, m\n        answer = m + 1\n        while lo <= hi:\n            mid = (lo + hi) // 2\n            if check(mid):\n                answer = mid\n                hi = mid - 1\n            else:\n                lo = mid + 1\n        \n        return answer if answer <= m else -1\n\n```\n\n## 算法思路3\n\n我们需要求出最小的 $k$，使得“前 $k$ 条查询”能够**同时**满足\n$$\n\\forall\\,0 \\le i < n,\\quad \\sum_{\\substack{0 \\le j < k \\\\ l_j \\le i \\le r_j}} v_j \\;\\; \\ge\\; nums[i].\n$$\n如果把\n$$\n\\text{cap}[i](k) \\;=\\; \\sum_{\\substack{0 \\le j < k \\\\ l_j \\le i \\le r_j}} v_j\n$$\n看作“在下标 $i$ 处，前 $k$ 条查询最多能提供的扣减总量”，那么题目要求找最小 $k$ 使得$\\text{cap}[i](k) \\ge nums[i],\\,\\forall i$。\n这本质上等同于：对每个 $i$，我们单独去看“最早满足 $\\text{cap}[i](k) \\ge nums[i]$ 的那个 $k_i$”；答案就是\n$$\nk = \\max_{0 \\le i < n} k_i\n$$\n（如果某个位置永远加不够，那整个答案就是 $-1$。）\n\n- **贪心地求出每个 $k_i$ 的思路**\n\n  - 把下标 $i$ 从 $0$ 到 $n-1$ 依次“排队”，\n\n  - 维护一个“差分数组” `cnt[0..n]`，它可以让我们以 $O(1)$ 的方式“把新的一条查询 $[a, b, v]$ 加入到以后所有下标的可用额度里”：\n\n    - `cnt[a] += v; cnt[b+1] -= v`，\n    - 然后每推进一个下标 $i$ 时，只要做 `s += cnt[i]`，就能得到“前面已经加入到差分结构的那些查询，在位置 $i$ 处的总叠加额度”。\n\n  - 于是，如果当前 `s < nums[i]`（说明已经加到差分里的查询还不够把 `nums[i]` 扣成 0），我们就**继续**把第 $j$ 条、第 $j+1$ 条……查询“投进来”——也就是执行\n\n    ```python\n    cnt[a_j] += v_j\n    cnt[b_j + 1] -= v_j\n    ```\n\n  在差分里给它记号，然后如果这条新加的查询确实覆盖到了位置 $i$（`if a_j <= i <= b_j`），就 `s += v_j`，因为此时“对 $i$”就立刻生效——把 `s` 补 $v_j$。\n\n  - 只要 `s` 还小于 `nums[i]`，就再把下一条查询“投进来”，直到$s \\ge nums[i]$ 或者$j == m$（查完所有查询）为止。\n    - 如果 $s < nums[i]$ 而 $j == m$，说明“所有查询投完”都还是凑不够$nums[i]$，直接 `return -1`。\n    - 否则在“退出 while”后，必然有 $s \\ge nums[i]$，说明此时我们已经用了 $j$ 条查询第一个时刻让 $i$ 处达标。把这个“时刻”记下来，对更大的 $i$ 来说，我们不会再减 $j$，因为我们要保证所有小于当前 $i$ 的下标也都满足。在前面迭代过的所有 $i' < i$ 都已经被保证：它们的 “累计额度” $\\le$ “我们此刻用的 $j$ 条查询的额度”，自然它们也都能凑够。\n  - 最终结束所有 $i$ 后，$j$ 就是满足每个位置的需求（$\\text{cap}[i] \\ge nums[i]$）的 **最小** 查询数。\n    - 若有任何一个 iii 走到一半就发现 $j$ 用光、又$s < nums[i]$，就 `return -1`。\n    - 反之，最后返回的 $j$ 恰好等同于 $\\max_i k_i$。\n\n\n\n**时间复杂度**\n\n- 外层 `for i in range(n)` 总共循环 `n` 次。\n- 内部的 `while j < m and s < nums[i]`：\n  - 每次循环体都会做一次 `j += 1`，因此 `j` 最多从 0 增加到 `m`，循环体总共进不超过 `m` 次。\n  - 换句话说，所有 `i` 累积在一起，`j` 只会单调增长，从 0 到最多 `m`，绝不会回退或重复。\n- 差分 `cnt[a] += c; cnt[b+1] -= c;` 是 $O(1)$ 操作。\n- 每进 `for i` 一次，都先做 `s += cnt[i]`，也是 $O(1)$。\n- 其余判断、下标范围判断、加法、比较都只是常数操作。\n\n因此，总体的执行步骤：\n\n1. 外层走 `n` 步（`i = 0 … n-1`）。\n2. 内层的 `j` 累计至多走 `m` 步（从 `j=0` 一直加到不满足条件为止）。\n\n没有任何嵌套导致 `m` 与 `n` 相乘，只是把这两段“线性扫描”交织在一起，最终耗时正好 $O(n + m)$。\n\n\n\n**代码实现**\n\n- `n = len(nums)`，`m = len(queries)`。\n\n- `cnt` 是一个长度为 `n+1` 的「差分数组」，用于在 $O(1)$ 时间内模拟对任意区间 $[a,b]$ 做一次 “所有下标各自减去 c” 的操作。\n\n  - 当我们想对 $[a, b]$ 区间整体去掉 “最多减 c” 这一额度时，就写\n\n    ```python\n    cnt[a] += c\n    cnt[b+1] -= c\n    ```\n\n  - 然后在遍历到下标 `i` 时，保留一个滚动变量 `s`，先做 `s += cnt[i]`，此时 `s` 就相当于 “下标 i 处所有已加入（也就是 `j` 之前的）查询对 i 的累积可用额度之和”。\n\n- `s`： 表示“当前下标 `i` 被所有已用查询（前 `j` 条）覆盖时累计能减去的总量”。\n\n- `j`：代表「已经把 `queries[0], queries[1], …, queries[j-1]` 这 `j` 条查询全部用到差分 `cnt` 里了」。\n\n从 `i=0` 开始，遍历每个位置 `i`，保证在走到下标 `i` 时，`s`（累积能减的额度）足以满足 `nums[i]`。如果 `s < nums[i]`，就再从 `queries[j]` 开始把第 `j` 条、第 `j+1` 条……不断「添加到差分」直到让 `s >= nums[i]` 或者查询用完为止。一旦 `s < nums[i]` 并且 `j == m`（没有更多查询可加），就无法把 `nums[i]` 扣到 0，直接 `return -1`。如果所有 `i` 都能满足过，那么用到的查询数就是 `j`，返回它。\n\n```python\nclass Solution:\n    def minZeroArray(self, nums: List[int], queries: List[List[int]]) -> int:\n        n, m = len(nums), len(queries)\n        cnt = [0] * (n + 1)   # 差分数组，长度 n+1\n        s = 0                 # 当前在下标 i 处的“累计已减”总量\n        j = 0                 # 已经用了多少条查询\n\n        for i in range(n):\n            # 1) 先把差分 cnt[i] 累加到 s，得到“到下标 i 时，所有已用查询对 i 的累积贡献”：\n            s += cnt[i]\n\n            # 2) 如果到目前位置 i，s < nums[i]，说明“还不够把 nums[i] 扣成 0”\n            #    那就从 queries[j] 开始，依次把第 j 条查询加进来，直到 s >= nums[i] 或 j 用完为止\n            while j < m and s < nums[i]:\n                a, b, c = queries[j]\n                # 把 queries[j] 对区间 [a, b] 的“最多减 c”转化成差分:\n                cnt[a] += c\n                cnt[b + 1] -= c\n                # 如果 i 恰好被 [a,b] 覆盖，那么要立刻把 s += c，因为在下标 i 处，这条查询就生效了\n                if a <= i <= b:\n                    s += c\n                j += 1\n\n            # 3) 退出 while 以后，要么 s >= nums[i]，说明“前 j 条查询对 i 的累计贡献至少 nums[i]”，可以把 nums[i] 扣到0；\n            #    要么 j == m 且 s < nums[i]，说明所有查询都用完了，i 处还是扣不够，直接返回 -1\n            if s < nums[i]:\n                return -1\n\n        # 4) 如果走到这里，说明对所有 0 ≤ i < n，都有 “前 j 条查询能把 nums[i] 扣成 0”。\n        #    此时 j 就是最小 k，使得处理前 k 条查询后，nums 全部变成零数组。\n        return j\n\n```\n\n**差分数组 cnt + 滚动和 s**\n\n- 当我们刚进入循环、到达 `i` 时，用 `s += cnt[i]` 把“这一格的前缀差分”补上。\n- 这样 `s` 始终表示“所有已经加进 `cnt` 的查询，对 `i` 这个位置在累计能减的总量”——与我们要的 $\\text{cap}[i]$ 一一对应。\n\n**while j<m and s<nums[i] 里“如果 a≤i≤b 就 s += c”**\n\n- 这一步很重要：我们先在差分里做了 `cnt[a]+=c; cnt[b+1]-=c`，这保证了“从下标 `a` 开始”到“下标 `b` 结束”每个位置最终前缀和会多 `c`。\n- 但是此时指针还在 `i` 上，如果 `a ≤ i ≤ b`，说明这个新加的区间 **立刻影响** 到了位置 `i`，所以 `s` 要马上加上那份 `c`。\n- 如果 `i < a` 或者 `i > b`，新加的区间对 `i` 还不生效（会在后面 `i` 推到 `a` 时再生效，具体表现为执行到 `i=a` 后的 `s += cnt[a]` 就扣上去了）。\n\n**一旦 s < nums[i] 且 j==m，直接返回 -1**\n\n- 因为此时所有 `m` 条查询都加入到差分里，可是走到 `i` 时却依旧 `s < nums[i]`，说明在 **所有查询** 覆盖的累积额度下，`nums[i]` 也凑不成 0，后面没办法了。\n\n**最小性保证：贪心不会跳过更优解**\n\n- 你需要最小的 `j`，使得每个位置的“累积额度”都足够。如果在某个 `i` 上，`s < nums[i]`，你就一定要把 `queries[j]` 拿出来打一把，才能继续往前走——否则你根本没法保证这个 `i` 处的需求被满足。\n- 你无法“跳过”某条查询，因为如果你不把它算在内，`s` 不可能「突然」跳到够用。\n- 另一方面，一旦满足了 `i`，你也不会再撤回以前的查询——因为如果你撤回，就可能会让更小的下标变得不满足。但要想让 **所有** 下标都凑够，只能向右“多用”查询或者“用到恰好满足”为止。\n- 因此你在 “遇到 `i` 还不够就把查询往里扔” 这一步上，实际上是严格按下标顺序寻找每个 `i` 的最早 “凑够它的那条查询编号”。这样遍历完所有 `i`，得到的 `j` 恰好就是最大的那一个“把 `i` 扣成 0 的查询编号”；也就是等同于 $\\max_i k_i$。","tags":["Algorithm","中等","数据结构","双指针","二分查找","贪心","前缀和","线段树"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-20","url":"/post/zero-array-transformation-i.html","content":"\n# [3355. 零数组变换 I](https://leetcode.cn/problems/zero-array-transformation-i/) M\n\n给定一个长度为 `n` 的整数数组 `nums` 和一个二维数组 `queries`，其中 `queries[i] = [li, ri]`。\n\n对于每个查询 `queries[i]`：\n\n- 在 `nums` 的下标范围 `[li, ri]` 内选择一个下标 子集。\n- 将选中的每个下标对应的元素值减 1。\n\n**零数组** 是指所有元素都等于 0 的数组。\n\n如果在按顺序处理所有查询后，可以将 `nums` 转换为 **零数组** ，则返回 `true`，否则返回 `false`。\n\n \n\n**示例 1：**\n\n> **输入：** nums = [1,0,1], queries = [[0,2]]\n>\n> **输出：** true\n>\n> **解释：**\n>\n> - 对于 i = 0：\n>   - 选择下标子集 `[0, 2]` 并将这些下标处的值减 1。\n>   - 数组将变为 `[0, 0, 0]`，这是一个零数组。\n\n**示例 2：**\n\n> **输入：** nums = [4,3,2,1], queries = [[1,3],[0,2]]\n>\n> **输出：** false\n>\n> **解释：**\n>\n> - 对于 i = 0：\n>   - 选择下标子集 `[1, 2, 3]` 并将这些下标处的值减 1。\n>   - 数组将变为 `[4, 2, 1, 0]`。\n> - 对于 i = 1：\n>   - 选择下标子集 `[0, 1, 2]` 并将这些下标处的值减 1。\n>   - 数组将变为 `[3, 1, 0, 0]`，这不是一个零数组。\n\n \n\n**提示：**\n\n- `1 <= nums.length <= 10⁵`\n- `0 <= nums[i] <= 10⁵`\n- `1 <= queries.length <= 10⁵`\n- `queries[i].length == 2`\n- `0 <= lᵢ <= rᵢ < nums.length`\n\n\n\n## 问题分析\n\n给定长度为 *n* 的整数数组 `nums` 和 *m* 个查询 `queries[i] = [l_i, r_i]`。对于每个查询，我们可以在区间 `[l_i, r_i]` 内任意选取一些下标，将这些位置对应的元素减 1。要在“按顺序”处理完所有 *m* 个查询之后，将原始数组 `nums` 变成“零数组”（即所有元素都恰好被减为 0），需要满足：\n\n> 对于每个位置 `j`，它最终被减去的次数必须恰好等于 `nums[j]`。\n>  而每次查询只能在它指定的区间内对某个位置减 1，并且每个查询对同一个位置最多减 1 次。\n\n## 算法思路\n\n设 `cover[j]` 表示有多少个查询区间 `[l_i, r_i]` 覆盖位置 `j`。\n\n如果 `cover[j] < nums[j]`，那么位置 `j` 即使在所有能覆盖它的查询中都“选中”它去减 1，最大也只能被减 `cover[j]` 次，仍然无法将 `nums[j]` 减到 0，直接返回 `false`。\n\n如果对每个 `j` 都满足 `cover[j] >= nums[j]`，理论上我们可以在所有覆盖 `j` 的查询中选取任意 `nums[j]` 次去对 `j` 减 1。由于不同位置的选择互不干扰（每次查询可以对区间内任意多个下标同时减 1，没有上限），只要每个位置都有足够的“机会”被减，就能找到一种方案使得最终所有位置正好被减到 0。\n\n考虑“按顺序”执行查询的限制：即使我们在前面的查询选择了“跳过”某些位置，只要剩下“未来的查询”依然足够覆盖剩余需要减的次数字段，就没问题。实际上，只需满足总体上 `cover[j] >= nums[j]` 即可，因为可以把对于每个 `j` 的 `nums[j]` 次减操作安排在它被覆盖的最后 `nums[j]` 个查询上。\n\n1. 先用一个差分数组（长度 `n+1`）来累积每个查询对各下标的覆盖次数：\n\n   ```pseudocode\n   diff = new int[n+1];\n   对于每个 query = [l, r]:\n       diff[l] += 1;\n       diff[r+1] -= 1;    // 若 r+1 越界则跳过\n   再对 diff 做前缀和，得到 cover[0…n-1]。\n   ```\n\n2. 这样就能在 $O(n + m)$ 的时间内算出 `cover[j]` = 该下标被多少查询覆盖。\n3. 遍历 `j=0…n-1`，若发现 `cover[j] < nums[j]`，立即返回 `false`。\n4. 如果所有 `j` 都通过检查，则返回 `true`。\n\n## 时间复杂度\n\n- 差分数组初始化及累计： $O(m)$\n- 计算前缀和： $O(n)$\n- 最终逐位检查： $O(n)$\n   整体为 $O(n + m)$，空间复杂度 $O(n)$（存储 diff/cover）。\n- 使用了长度为 `n+1` 的差分数组 `diff`，以及长度为 `n` 的覆盖次数数组 `cover`，总计 $O(n)$ 额外空间。\n\n## 代码分解\n\n1. 差分数组 `diff` 在索引 `l` 处 +1、在 `r+1` 处 −1，最终对 `diff` 做前缀和就相当于：每个查询在 `[l, r]` 区间内为 `cover[j]` 累加了 1。\n2. 得到的 `cover[j]` 就是“有多少个查询区间覆盖位置 j”。\n3. 对于位置 `j` 来说，如果总共被覆盖的次数少于它当前需要减的次数 `nums[j]`，无论怎么选都不够，将来无法把它减到 0；否则只要“用掉”它需要的 `nums[j]` 次就行。\n4. 由于不同下标在同一次查询中是否选取互不干扰（每次查询可以对区间里任意子集进行减操作），所以只用全局判断 `cover[j] >= nums[j]` 即可。\n\n## 代码实现\n\n```python\nclass Solution:\n    def isZeroArray(self, nums: list[int], queries: list[list[int]]) -> bool:\n        n = len(nums)\n        m = len(queries)\n\n        # 1. 构造差分数组 diff，长度为 n+1，初始全 0\n        diff = [0] * (n + 1)\n        for (l, r) in queries:\n            diff[l] += 1\n            if r + 1 < n:\n                diff[r + 1] -= 1\n\n        # 2. 用 diff 计算前缀和，得到 cover[j]\n        cover = [0] * n\n        curr = 0\n        for j in range(n):\n            curr += diff[j]\n            cover[j] = curr\n\n        # 3. 检查每个位置 j：如果被查询覆盖的次数 < nums[j]，则不可能\n        for j in range(n):\n            if cover[j] < nums[j]:\n                return False\n\n        # 4. 全部通过，说明可以分配减操作，返回 True\n        return True\n\n```\n\n","tags":["Algorithm","中等","数据结构","贪心","前缀和"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-19","url":"/post/type-of-triangle.html","content":"\n# [3024. 三角形类型](https://leetcode.cn/problems/type-of-triangle/) E\n\n给你一个下标从 **0** 开始长度为 `3` 的整数数组 `nums` ，需要用它们来构造三角形。\n\n- 如果一个三角形的所有边长度相等，那么这个三角形称为 **equilateral** 。\n- 如果一个三角形恰好有两条边长度相等，那么这个三角形称为 **isosceles** 。\n- 如果一个三角形三条边的长度互不相同，那么这个三角形称为 **scalene** 。\n\n如果这个数组无法构成一个三角形，请你返回字符串 `\"none\"` ，否则返回一个字符串表示这个三角形的类型。\n\n \n\n**示例 1：**\n\n> 输入：nums = [3,3,3]\n> 输出：\"equilateral\"\n> 解释：由于三条边长度相等，所以可以构成一个等边三角形，返回 \"equilateral\" 。\n\n**示例 2：**\n\n> 输入：nums = [3,4,5]\n> 输出：\"scalene\"\n> 解释：\n> nums[0] + nums[1] = 3 + 4 = 7 ，大于 nums[2] = 5 。\n> nums[0] + nums[2] = 3 + 5 = 8 ，大于 nums[1] = 4 。\n> nums[1] + nums[2] = 4 + 5 = 9 ，大于 nums[0] = 3 。\n> 由于任意两边之和都大于第三边，所以可以构成一个三角形，因为三条边的长度互不相等，所以返回 \"scalene\"。\n\n**提示：**\n\n- `nums.length == 3`\n- `1 <= nums[i] <= 100`\n\n\n\n## 问题分析\n\n给定三个正整数边长 `nums[0], nums[1], nums[2]`，判断它们能否构成三角形。如果不能，返回 `\"none\"`；如果可以，再根据三边相等情况返回对应类型：\n\n- 三条边相等 → `equilateral`\n- 正好两条边相等 → `isosceles`\n- 三条边互不相等 → `scalene`\n\n## 算法思路\n\n首先，对这三个边长进行排序（标签：排序），记为 `a ≤ b ≤ c`。排序不仅能让后续判断更清晰，也方便验证三角形的必要且充分条件，只需要判断 `a + b > c` 即可。\n\n如果 `a + b ≤ c`，则无法构成三角形，直接返回 `\"none\"`。\n\n否则，根据 `a, b, c` 三者是否相等做分类：\n\n- 如果 `a == c`，说明三条边都相等，返回 `\"equilateral\"`。\n- 否则如果 `a == b` 或 `b == c`，则恰有两条相等，返回 `\"isosceles\"`。\n- 否则三条边互不相等，返回 `\"scalene\"`。\n\n## 时间复杂度\n\n- 对 `nums` 长度为 3 的数组排序，时间复杂度为 $O(N \\log n)$（可以认为是常数级操作）。其余比较操作也是 $O(1)$。因此整体时间复杂度为 $O(1)$。\n\n- 空间复杂度也为 $O(1)$，只使用了常数级的额外变量。\n\n## 代码分解\n\n**排序**：对 `[x, y, z]` 三个数进行排序，得到 `a ≤ b ≤ c`。排序的本质是为了简化三角形最基本的判定：只需判断最小的两个数之和是否大于最大的数即可。此时不必反复考虑全部三种两边之和情况，因为：\n$$\na + b > c \\iff   \\begin{cases}     a + b > c, \\\\     a + c > b \\text{(总是成立，因为 } c \\ge b\\text{)},\\\\     b + c > a \\text{(总是成立，因为 } c \\ge a\\text{)}.   \\end{cases}\n$$\n若 `a + b ≤ c`，直接返回 `\"none\"`。\n\n否则，继续比较 `a, b, c`：\n\n- 若 `a == c`，三个元素全等 → `equilateral`。\n- 若 `a == b` 或 `b == c`，则恰好两边相等 → `isosceles`。\n- 否则 → `scalene`。\n\n## 代码实现\n\n```python\nclass Solution:\n    def triangleType(self, nums: list[int]) -> str:\n        # 1. 排序：a <= b <= c\n        nums.sort()\n        a, b, c = nums[0], nums[1], nums[2]\n\n        # 2. 三角形的必要且充分条件：最短两边之和要大于最长边\n        if a + b <= c:\n            return \"none\"\n\n        # 3. 根据相等情况分类\n        if a == c:\n            # a == b == c\n            return \"equilateral\"\n        if a == b or b == c:\n            # 恰有两条边相等\n            return \"isosceles\"\n        # 三条边互不相等\n        return \"scalene\"\n\n```\n\n因为输入规模固定且极小，性能开销几乎忽略不计；若后续需要对大量三元组进行批量判定，也可以把这段逻辑放到循环或向量化环境中（如 NumPy）来做批量处理，但基本思路一致。\n\n若需要校验输入是否全是正整数，也可在最前面加一步验证，比如 `if min(nums) < 1: return \"none\"`，但题目已保证 `1 <= nums[i] <= 100`，故此处略去。","tags":["Algorithm","简单","排序"],"categories":["算法"]},{"title":"Python 与数据清洗","url":"/post/data-cleaning.html","content":"\n# Python 与数据清洗\n\n## 1. 数据清洗的重要性\n\n在机器学习项目中，**数据清洗**是至关重要的第一步。它指的是识别并修正数据集中的错误、不一致性、不准确性或缺失部分，以保证数据的质量和适用性。高质量的数据是构建可靠机器学习模型的基石。如果输入到模型中的数据存在缺陷，即使是最先进的算法也无法产生有意义的结果。这正如一句谚语所说：“垃圾进，垃圾出”。\n\n不良的数据质量可能导致：\n- 模型训练不准确  \n- 预测结果不可靠  \n- 最终损害整个项目的价值与可用性  \n\n因此，投入时间和精力进行彻底的数据清洗，是项目成功的先决条件。\n\n### 1.1 “脏数据”的常见来源\n\n- **人为错误**  \n  - 拼写错误  \n  - 数值录入失误  \n- **测量设备故障或精度限制**  \n  - 传感器数据偏差  \n  - 仪器读数不稳定  \n- **数据记录不完整**  \n  - 用户注册时未填写某些字段  \n  - 采集过程丢失数据  \n- **多源数据格式不一致**  \n  - 日期格式（如 `YYYY-MM-DD` vs `DD/MM/YYYY`）  \n  - 单位表示差异（如米 vs 英尺）  \n\n---\n\n## 2. 处理缺失值\n\n缺失值是指在数据集中某些观测的特定特征没有记录或无法获取的情况。理解缺失值的类型对于选择合适的处理方法至关重要。\n\n### 2.1 缺失值的类型\n\n1. **完全随机缺失（MCAR，Missing Completely At Random）**  \n   - 数据缺失的概率与其他任何观测或特征都无关。  \n   - 例如：实验室设备偶然故障导致部分测量结果丢失。\n\n2. **随机缺失（MAR，Missing At Random）**  \n   - 数据缺失的概率可能与某些已观测到的特征有关，但与缺失值本身无关。  \n   - 例如：收入高的人倾向于不填写“家庭收入”字段，但缺失并不依赖于收入数值本身。\n\n3. **非随机缺失（MNAR，Missing Not At Random）**  \n   - 数据缺失的概率与缺失值本身有关。  \n   - 例如：抑郁症患者可能因为症状严重而不愿意填写精神健康调查。\n\n### 2.2 处理缺失值的主要方法\n\n> **Tip:** 选择何种方法，要综合考虑数据量、缺失比例及其分布机制。\n\n#### 2.2.1 删除（Deletion）\n\n1. **行删除**  \n   - 删除包含任何缺失值的整行。  \n   - 优点：简单易行；  \n   - 缺点：可能丢失大量信息，尤其在缺失比例较高时容易引入偏差。  \n   - 适用场景：数据集很大且缺失值非常少时。\n\n   ```python\n   import pandas as pd\n   \n   # 读取示例 DataFrame\n   df = pd.DataFrame({\n       'A': [1, 2, None, 4],\n       'B': [5, None, 7, 8],\n       'C': ['a', 'b', 'c', None]\n   })\n   \n   # 删除任何含有缺失值的行\n   df_drop_rows = df.dropna()\n   print(df_drop_rows)\n   ```\n\n1. **列删除**\n\n   - 删除缺失值比例超过某个阈值的列。\n   - 优点：避免模型被缺失信息大规模干扰；\n   - 缺点：可能丢失重要特征，需要谨慎判断。\n   - 适用场景：某个特征缺失比例过高且无法合理填充时。\n\n   ```python\n   # 假设阈值为 50%\n   threshold = 0.5\n   df_drop_cols = df.dropna(axis=1, thresh=int((1 - threshold) * len(df)))\n   print(df_drop_cols)\n   ```\n\n#### 2.2.2 填充（Imputation）\n\n1. **统计填充**\n\n   - **均值填充**：用该特征的平均值替换缺失值。\n\n     ```python\n     df_mean = df.copy()\n     df_mean['A'] = df_mean['A'].fillna(df_mean['A'].mean())\n     print(df_mean)\n     ```\n\n   - **中位数填充**：用该特征的中位数替换缺失值，对异常值更鲁棒。\n\n     ```python\n     df_median = df.copy()\n     df_median['A'] = df_median['A'].fillna(df_median['A'].median())\n     print(df_median)\n     ```\n\n   - **众数填充**：常用于类别型特征，用最频繁出现的值替换缺失值。\n\n     ```python\n     df_mode = df.copy()\n     mode_value = df_mode['C'].mode()[0]\n     df_mode['C'] = df_mode['C'].fillna(mode_value)\n     print(df_mode)\n     ```\n\n2. **基于模型的填充**\n\n   - 使用回归、KNN 等模型，根据其他特征预测缺失值。\n   - 优点：能够捕捉各变量之间的关系，更准确；\n   - 缺点：实现复杂、计算成本高。\n\n   ```python\n   from sklearn.impute import KNNImputer\n   \n   imputer = KNNImputer(n_neighbors=3)\n   df_knn = pd.DataFrame(imputer.fit_transform(df[['A', 'B']]), columns=['A', 'B'])\n   print(df_knn)\n   ```\n\n3. **创建缺失值指示器（Missing Indicator）**\n\n   - 不直接填充缺失值，而是生成一个二元特征，标记原始位置是否缺失。\n   - 优点：保留了“缺失”本身的信息，有时缺失就是一个信号；\n   - 缺点：增加数据维度。\n\n   ```python\n   df_indicator = df.copy()\n   \n   # 创建指示器列，1 表示原始值缺失，0 表示不缺失\n   df_indicator['A_missing'] = df_indicator['A'].isnull().astype(int)\n   df_indicator['B_missing'] = df_indicator['B'].isnull().astype(int)\n   \n   # 对缺失值进行填充（这里以均值为例）\n   df_indicator['A'] = df_indicator['A'].fillna(df_indicator['A'].mean())\n   df_indicator['B'] = df_indicator['B'].fillna(df_indicator['B'].mean())\n   \n   print(df_indicator)\n   ```\n\n### 2.3 小结\n\n- 没有“万能方法”，要根据数据缺失类型和业务场景选择合适策略。\n- 如果缺失不随机，简单的统计填充会扭曲数据分布；\n- 理解缺失背后的原因，才能做出明智的处理决定。\n\n**表 1: 处理缺失值的常用技术**\n\n| **技术**       | **描述**                     | **优点**                       | **缺点**                   | **典型应用场景**                 |\n| -------------- | ---------------------------- | ------------------------------ | -------------------------- | -------------------------------- |\n| 行删除         | 删除包含任何缺失值的行       | 简单易行                       | 可能丢失宝贵信息，引入偏差 | 数据集很大且缺失值很少           |\n| 列删除         | 删除包含大量缺失值的列       | 可以避免模型被缺失值干扰       | 可能丢失重要特征           | 某特征缺失值过多，难以合理填充   |\n| 均值填充       | 使用特征的平均值填充缺失值   | 简单快速                       | 降低方差，对异常值敏感     | 缺失值较少，数据分布近似正态     |\n| 中位数填充     | 使用特征的中位数填充缺失值   | 对异常值不敏感                 | 可能改变原始数据分布       | 数据存在较多异常值               |\n| 众数填充       | 使用特征的众数填充缺失值     | 适用于类别型特征               | 可能引入偏差               | 类别型特征存在缺失值             |\n| 基于模型的填充 | 使用统计模型预测缺失值       | 可以捕捉变量间关系，填充更准确 | 实现复杂，计算成本高       | 缺失值模式复杂，需要更精确的填充 |\n| 缺失值指示器   | 创建一个二元特征标记缺失情况 | 保留缺失信息                   | 增加数据维度               | 缺失本身可能包含有用信息         |\n\n## 3. 处理异常值\n\n异常值指的是与其他观测值显著不同的数据点。它们可能源于测量误差、录入错误，也可能是真实世界中罕见事件的反映。异常值会对模型产生扰动，扭曲分布、降低性能，甚至导致错误结论。\n\n### 3.1 检测异常值的方法\n\n#### 3.1.1 可视化方法\n\n1. **箱线图（Box Plot）**\n\n   - 显示数据的四分位数（Q1、Q2、Q3）和四分位距（IQR）。\n   - 将超出 `Q1 - 1.5·IQR` 或 `Q3 + 1.5·IQR` 的点视为潜在异常值。\n\n   ```python\n   import matplotlib.pyplot as plt\n   \n   plt.boxplot(df['A'].dropna())\n   plt.title(\"Boxplot of A\")\n   plt.show()\n   ```\n\n2. **散点图（Scatter Plot）**\n\n   - 适用于双变量数据，直观发现与其他点显著分离的观测。\n\n   ```python\n   plt.scatter(df['A'], df['B'])\n   plt.xlabel(\"A\")\n   plt.ylabel(\"B\")\n   plt.title(\"Scatter Plot of A vs B\")\n   plt.show()\n   ```\n\n3. **直方图（Histogram）**\n\n   - 显示数据分布，可观察尾部是否有孤立的条柱。\n\n   ```python\n   plt.hist(df['A'].dropna(), bins=10)\n   plt.xlabel(\"A\")\n   plt.ylabel(\"Frequency\")\n   plt.title(\"Histogram of A\")\n   plt.show()\n   ```\n\n#### 3.1.2 统计方法\n\n1. **Z-分数（Z-Score）**\n\n   - 计算每个数据点与均值的距离，以标准差为单位。\n   - 通常 |Z| > 3 的值被认为是异常。\n\n   ```python\n   import numpy as np\n   \n   mean_A = df['A'].mean()\n   std_A = df['A'].std()\n   df['A_zscore'] = (df['A'] - mean_A) / std_A\n   \n   # 标记异常值\n   outliers_z = df[np.abs(df['A_zscore']) > 3]\n   print(outliers_z)\n   ```\n\n2. **IQR 方法**\n\n   - 基于箱线图思想，将落在 `Q1 - 1.5·IQR` 或 `Q3 + 1.5·IQR` 之外的值视为异常。\n\n   ```python\n   Q1 = df['A'].quantile(0.25)\n   Q3 = df['A'].quantile(0.75)\n   IQR = Q3 - Q1\n   \n   lower_bound = Q1 - 1.5 * IQR\n   upper_bound = Q3 + 1.5 * IQR\n   \n   outliers_iqr = df[(df['A'] < lower_bound) | (df['A'] > upper_bound)]\n   print(outliers_iqr)\n   ```\n\n3. **Isolation Forest**（孤立森林）\n\n   - 基于树的集成方法，通过不断随机切分特征空间来“隔离”异常值。\n   - 适用于高维数据，检测复杂模式的异常。\n\n   ```python\n   from sklearn.ensemble import IsolationForest\n   \n   iso = IsolationForest(contamination=0.1, random_state=42)\n   df_nonull = df[['A', 'B']].dropna()\n   iso.fit(df_nonull)\n   \n   df_nonull['anomaly_score'] = iso.decision_function(df_nonull)\n   df_nonull['anomaly_flag'] = iso.predict(df_nonull)  # -1 为异常，1 为正常\n   \n   print(df_nonull[df_nonull['anomaly_flag'] == -1])\n   ```\n\n### 3.2 处理异常值的策略\n\n1. **删除**\n\n   - 直接移除被识别的异常点。\n   - 适用于确认是数据输入错误或设备误差时，需谨慎避免丢失真实但极端的观测。\n\n   ```pseudocode\n   df_clean = df[~((df['A'] < lower_bound) | (df['A'] > upper_bound))]\n   ```\n\n2. **转换**\n\n   - 使用 **对数转换**、**截尾（Winsorizing）** 等方法，减小极端值影响。\n   - 例如，对数转换：`A_log = np.log(df['A'])`，适用于正值且偏态分布的数据。\n\n   ```pseudocode\n   df['A_log'] = np.log(df['A'].replace(0, np.nan).dropna())\n   ```\n\n3. **填充**\n\n   - 用更合理的边界值或均值、中位数替换异常值。\n\n   ```pseudocode\n   df['A_clipped'] = df['A'].clip(lower=lower_bound, upper=upper_bound)\n   ```\n\n4. **保留**\n\n   - 不做处理，将异常值视为潜在信号。\n   - 常见于 **异常检测**、**欺诈识别** 等场景。\n\n**表 2: 检测和处理异常值的常用技术**\n\n| **技术** | **描述**                                     | **优点**                 | **缺点**                       | **典型应用场景**                 |\n| -------- | -------------------------------------------- | ------------------------ | ------------------------------ | -------------------------------- |\n| 箱线图   | 可视化数据的分布和潜在异常值                 | 直观易懂                 | 对高维数据不适用               | 初步探索性数据分析               |\n| Z-分数   | 衡量数据点距离均值的标准差个数               | 易于计算                 | 对数据分布有要求，对异常值敏感 | 数据分布近似正态                 |\n| IQR方法  | 基于四分位数间距识别异常值                   | 对异常值不敏感           | 可能遗漏极端异常值             | 数据存在异常值                   |\n| 孤立森林 | 基于树的集成方法，通过隔离异常值进行检测     | 适用于高维数据，性能较好 | 参数调整可能复杂               | 复杂数据集的异常值检测           |\n| 删除     | 移除被识别为异常值的数据点                   | 简单直接                 | 可能丢失信息                   | 明显的错误数据或噪声             |\n| 转换     | 使用数学函数（如对数）调整数据分布           | 降低极端值的影响         | 可能改变数据的原始含义         | 数据偏态分布                     |\n| 填充     | 用其他值（如均值、中位数或边界值）替换异常值 | 保留数据量               | 可能引入偏差                   | 异常值数量不多，且有合理的替换值 |\n| 保留     | 不对异常值进行处理                           | 避免丢失潜在重要信息     | 异常值可能影响模型性能         | 异常值可能代表重要事件或模式     |\n\n## 4. 数据转换技术\n\n数据转换是将原始数据转换为更适合模型处理的格式或分布。合理的转换能够提升模型性能与稳定性。\n\n### 4.1 缩放与归一化\n\n1. **最小–最大缩放（Min–Max Scaling）**\n\n   - 将数值线性映射到 `[0, 1]` 区间：\n     $$\n     x_{\\text{scaled}} = \\frac{x - x_{\\text{min}}}{x_{\\text{max}} - x_{\\text{min}}}\n     $$\n\n   - 优点：直观；\n\n   - 缺点：对异常值敏感。\n\n   ```python\n   from sklearn.preprocessing import MinMaxScaler\n   \n   scaler = MinMaxScaler()\n   df_scaled = scaler.fit_transform(df[['A', 'B']].dropna())\n   print(df_scaled[:5])\n   ```\n\n2. **标准化（Standardization，Z-Score Scaling）**\n\n   - 转换为均值为 0、标准差为 1 的分布：\n     $$\n     x_{\\text{standardized}} = \\frac{x - \\mu}{\\sigma}\n     $$\n\n   - 对异常值相对鲁棒一些，但对极端值仍有影响。\n\n   ```python\n   from sklearn.preprocessing import StandardScaler\n   \n   std_scaler = StandardScaler()\n   df_standard = std_scaler.fit_transform(df[['A', 'B']].dropna())\n   print(df_standard[:5])\n   ```\n\n3. **鲁棒缩放（Robust Scaling）**\n\n   - 基于中位数和四分位数进行缩放，对异常值更不敏感。\n\n   ```\n   from sklearn.preprocessing import RobustScaler\n   \n   robust_scaler = RobustScaler()\n   df_robust = robust_scaler.fit_transform(df[['A', 'B']].dropna())\n   print(df_robust[:5])**鲁棒缩放**是一种对异常值不太敏感的缩放方法，例如scikit-learn中的`RobustScaler`，它基于数据的百分位数进行缩放。\n   ```\n\n### 4.2 非线性转换\n\n1. **对数转换（Log Transformation）**\n\n   - 用于处理偏态分布，将大值压缩。\n   - 仅适用于正值数据。\n\n   ```pseudocode\n   df['A_log'] = np.log(df['A'].replace(0, np.nan)).dropna()\n   ```\n\n2. **幂转换（Power Transformation，如 Box–Cox、Yeo–Johnson）**\n\n   - 更通用的方法，常用于稳定方差、使数据更接近正态分布。\n\n   ```python\n   from sklearn.preprocessing import PowerTransformer\n   \n   pt = PowerTransformer(method='yeo-johnson')\n   df_power = pt.fit_transform(df[['A', 'B']].dropna())\n   print(df_power[:5])\n   ```\n\n### 4.3 类别型变量编码\n\n1. **独热编码（One-Hot Encoding）**\n\n   - 对于机器学习模型，类别型变量通常需要转换为数值形式。**独热编码**是一种常用的方法，它为每个类别创建一个新的二元特征，如果某个观测属于该类别，则该特征的值为1，否则为0。\n   - 为每个类别生成一个二元特征。\n   - 适用于无序类别变量，但会增加维度。\n\n   ```python\n   df_cat = pd.DataFrame({'color': ['red', 'blue', 'green', 'blue', None]})\n   df_cat_onehot = pd.get_dummies(df_cat['color'], dummy_na=True)\n   print(df_cat_onehot)\n   ```\n\n2. **标签编码（Label Encoding）**\n\n   - **标签编码**将每个类别分配一个唯一的整数。\n   - 将类别变量映射为整数。\n   - 适用于有序类别，可能会引入无意义的顺序关系。\n\n   ```python\n   from sklearn.preprocessing import LabelEncoder\n   \n   le = LabelEncoder()\n   df_cat['color_encoded'] = le.fit_transform(df_cat['color'].astype(str))\n   print(df_cat)\n   ```\n\n### 4.4 选择合适的转换方法\n\n- **基于距离的算法**（如 KNN、K-Means）：对特征尺度敏感，通常需要缩放\n  因为基于距离的算法依赖于特征之间的距离计算，尺度较大的特征可能会在距离计算中占据主导地位，即使它们的重要性并非更高。缩放可以确保所有特征对距离计算的贡献更加均衡。\n- **树模型**（如 决策树、随机森林）：对尺度不敏感，但对异常值和分布可能敏感。\n  树模型基于单个特征内部值的顺序进行决策，因此对整体尺度不敏感\n\n## Python实现示例\n\nPandas的`isnull()`和`sum()`方法来检查缺失值，使用`fillna()`方法进行填充，使用`dropna()`方法删除缺失值。\n可以使用Matplotlib和Seaborn库进行可视化以检测异常值，并使用NumPy进行统计计算。\n可以使用`sklearn.preprocessing`模块中的各种类进行数据缩放、归一化和编码。\n\n一个简单的数据清洗工作流程包括以下步骤：\n\n首先，加载数据并使用Pandas进行初步的探索性分析，例如查看数据的基本统计信息和缺失值情况。\n然后，根据数据的特性和业务需求，选择合适的缺失值处理方法，并使用Pandas或scikit-learn进行填充或删除。\n接下来，可以使用可视化方法和统计方法检测异常值，并根据情况选择删除、转换或保留。\n最后，根据所选的机器学习算法的要求，对数据进行缩放、归一化或编码等转换。\n\n下面展示一个端到端的数据清洗示例，包含：加载数据、检查/处理缺失值、检测/处理异常值、数据转换。\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.ensemble import IsolationForest\n\n# 1. 加载示例数据\ndf = pd.DataFrame({\n    'age': [25, 30, np.nan, 22, 40, 120, 28],\n    'income': [50000, 60000, 55000, np.nan, 65000, 70000, 58000],\n    'gender': ['M', 'F', 'F', 'M', np.nan, 'M', 'F']\n})\n\n# 2. 初步探索\nprint(\"缺失值情况：\")\nprint(df.isnull().sum())\n\n# 3. 处理缺失值\n# 3.1 对数值特征使用均值填充\nnum_cols = ['age', 'income']\nimp_mean = SimpleImputer(strategy='mean')\ndf[num_cols] = imp_mean.fit_transform(df[num_cols])\n\n# 3.2 对类别特征使用众数填充\nimp_mode = SimpleImputer(strategy='most_frequent')\ndf[['gender']] = imp_mode.fit_transform(df[['gender']])\n\nprint(\"\\n填充后数据：\")\nprint(df)\n\n# 4. 检测异常值（Isolation Forest）\niso = IsolationForest(contamination=0.15, random_state=42)\ndf[['age', 'income']] = df[['age', 'income']].astype(float)\niso.fit(df[['age', 'income']])\ndf['anomaly_flag'] = iso.predict(df[['age', 'income']])  # -1 异常，1 正常\n\nprint(\"\\n异常检测结果：\")\nprint(df[df['anomaly_flag'] == -1])\n\n# 5. 处理异常值（这里以删除为例）\ndf_clean = df[df['anomaly_flag'] == 1].drop(columns=['anomaly_flag'])\nprint(\"\\n删除异常值后的数据：\")\nprint(df_clean)\n\n# 6. 数据转换\n# 6.1 连续特征标准化\nscaler = StandardScaler()\ndf_clean[['age', 'income']] = scaler.fit_transform(df_clean[['age', 'income']])\n\n# 6.2 类别特征独热编码\nencoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\ngender_encoded = encoder.fit_transform(df_clean[['gender']])\ndf_gender = pd.DataFrame(gender_encoded, columns=encoder.get_feature_names_out(['gender']))\n\n# 合并特征\ndf_final = pd.concat([df_clean.drop(columns=['gender']).reset_index(drop=True),\n                      df_gender.reset_index(drop=True)], axis=1)\n\nprint(\"\\n最终处理后数据：\")\nprint(df_final)\n```\n\n> **注释解读：**\n>\n> 1. 使用 `SimpleImputer` 分别对数值特征（均值）和类别特征（众数）进行填充。\n> 2. `IsolationForest` 标记异常值，并将异常样本剔除。\n> 3. 对数值特征进行标准化、类别特征进行独热编码，得到最终可用于建模的数据集。\n\n## 总结\n\n- **数据清洗**是机器学习流程中的核心步骤，良好的数据清洗能显著提升模型质量与稳定性。\n- 针对 **缺失值** 要区分 MCAR、MAR、MNAR，不盲目删除或填充。\n- 对 **异常值** 的处理需结合业务背景，可能选择删除、转换、填充或保留。\n- **数据转换**（缩放、编码）应根据所用算法特点进行选择。\n- 在 Python 中，Pandas、NumPy、Scikit-learn 等库提供了便捷的接口，能够高效地完成各类数据清洗操作。","tags":["python","数据操作"],"categories":["数据分析"]},{"title":"Pandas操作方式笔记","url":"/post/pandas.html","content":"\n# Pandas 操作方式笔记\n\n## 1. Pandas 简介\n\nPandas 是一个在 Python 编程语言中广泛使用的数据操作和分析的开源库。它建立在另一个基础库 NumPy 之上，NumPy 主要用于数值计算。Pandas 的出现极大地简化了使用 Python 进行数据清洗、转换和分析的过程，提供了高性能且易于使用的数据结构和数据分析工具。在当前数据科学和机器学习的工作流程中，Pandas 扮演着至关重要的角色。\n\nPandas 依赖于 NumPy，这意味着理解一些基本的 NumPy 概念对于优化 Pandas 的操作非常有益，尤其是在处理大型数据集时。例如，NumPy 的数组操作和广播规则直接影响着 Pandas 的性能。因此，在掌握 Pandas 的基础知识后，进一步探索 NumPy 将有助于用户编写更高效的 Pandas 代码。\n\n此外，Pandas 在数据科学领域被广泛采用，这使得精通 Pandas 成为任何希望在 Python 中处理数据的人的一项非常有价值的技能。无论是进行学术研究、商业分析还是开发机器学习模型，Pandas 都是一个不可或缺的工具。因此，学习 Pandas 的长期收益是显著的，它将为用户打开数据相关职业发展的大门。\n\n相较于标准的 Python 数据结构（如列表和字典），使用 Pandas 进行数据分析具有显著的优势。Pandas 提供了表格数据的表示方式，即 DataFrame，它类似于电子表格和数据库中的表结构。这种结构使得数据的组织和理解更加直观。此外，Pandas 具有带标签的轴（行和列），这使得数据的访问更加方便和有意义。\n\nPandas 提供了强大且灵活的数据操作功能，包括数据过滤、排序、合并等。它还内置了处理缺失数据的功能，并提供了数据对齐和整合的工具。更重要的是，Pandas 可以与其他 Python 库（如 NumPy、Matplotlib 和 Scikit-learn）无缝集成，形成一个强大的数据分析生态系统。最后，Pandas 在处理大型数据集时也表现出高效性，这使得它成为处理各种规模数据的理想选择。\n\nPandas DataFrame 中带标签的轴相比于 NumPy 数组或列表的列表仅使用数字索引，极大地提高了数据的可读性和操作性。对于初学者来说，使用有意义的列名和行索引进行复杂的数据操作会更加直观，减少出错的可能性。传统的 Python 数据结构通常依赖于位置索引，当数据集变得复杂时，这种方式可能会显得笨拙。而 Pandas 的标签索引允许用户通过名称引用数据，从而提高了代码的清晰度和可维护性。\n\nPandas 与其他数据科学库的无缝集成创建了一个强大的端到端数据分析工作流程。从数据加载和清洗到可视化和模型构建，Pandas 都可以作为核心组件。例如，Pandas 可以轻松地将数据传递给 Matplotlib 进行绘图，或传递给 Scikit-learn 进行机器学习模型的训练。这种集成性突显了 Pandas 在更广泛的 Python 数据科学领域中的核心地位。\n\n## 2. Pandas 数据结构：Series 和 DataFrame\n\nPandas 中最核心的两个数据结构是 Series 和 DataFrame。理解这两种数据结构是掌握 Pandas 的关键。\n\n### **Series 介绍**\n\nSeries 是一种一维的带标签的数组，它可以存储任何数据类型（整数、字符串、浮点数、Python 对象等）。可以将 Series 想象成电子表格中的一列，或者一个带标签的列表。\n\n一个 Series 由两个主要部分组成：**索引（Index）** 和 **值（Values）**。索引是数据的标签，可以是整数、字符串或任何其他可哈希的 Python 对象。如果创建 Series 时没有明确指定索引，Pandas 会自动创建一个默认的整数索引，从 0 开始递增。值是 Series 中存储的实际数据。\n\n与普通的 Python 列表不同，Series 拥有显式的索引。这种显式的索引使得数据的访问和对齐更加有意义。尤其是在处理时间序列数据或具有内在标签的数据时，Series 的优势更加明显。例如，在一个存储产品价格的 Series 中，可以使用产品名称作为索引，这样就可以直接通过产品名称来查找其价格，而不需要记住它在列表中的位置。\n\n### **DataFrame 介绍**\n\nDataFrame 是一种二维的带标签的数据结构，可以看作是由多个 Series 组成的表格。DataFrame 的每一列可以是不同的数据类型。它是 Pandas 中最核心的数据结构，用于表示表格数据。\n\nDataFrame 由三个主要部分组成：**索引（Index）**、**列（Columns）** 和 **值（Values）**。索引是行的标签，类似于 Series 中的索引。列是数据的标签，每一列都可以看作是一个 Series。值是实际的数据，以表格的形式排列在行和列中。\n\n可以将 DataFrame 类比为一个电子表格或一个 SQL 数据库中的表。它提供了一种非常直观的方式来组织和处理结构化数据。例如，在一个存储学生信息的 DataFrame 中，每一行可能代表一个学生，而每一列可能代表学生的姓名、年龄、成绩等信息。\n\nDataFrame 能够容纳不同数据类型的列，这与 NumPy 数组通常要求所有元素具有相同类型形成了鲜明的对比。现实世界中的数据往往包含各种不同的类型，例如数值型的测量数据、类别型的标签以及日期时间信息。Pandas DataFrame 的这种灵活性使其非常适合表示和处理各种真实世界的数据集。\n\n此外，Pandas 中一个非常重要的概念是按照索引和列标签对齐数据。这简化了涉及多个 Series 或 DataFrame 的操作。当对两个 Pandas 对象进行操作时（例如，将两个 DataFrame 相加），Pandas 会自动根据它们的行和列标签对齐数据。即使这些对象的初始顺序不同或存在缺失的标签，这种自动对齐也能确保操作在对应的数据点上执行，从而避免了常见的错误，并使得数据操作更加健壮。\n\n## 3. 创建 Series 和 DataFrame\n\nPandas 提供了多种灵活的方法来创建 Series 和 DataFrame 对象。了解这些方法对于开始使用 Pandas 至关重要。\n\n### **创建 Series**\n\n- **从列表创建：** 可以使用 Python 列表来创建一个 Series。Pandas 会自动为列表中的每个元素分配一个从 0 开始的整数索引。\n\n  ```python\n  import pandas as pd\n  data = \n  s = pd.Series(data)\n  print(s)\n  ```\n\n  输出结果会显示每个值及其对应的默认整数索引。\n\n- **从 NumPy 数组创建：** 也可以从 NumPy 数组创建 Series。数据会直接从 NumPy 数组转移到 Series 中。\n\n  ```python\n  import numpy as np\n  arr = np.array()\n  s = pd.Series(arr)\n  print(s)\n  ```\n\n  与从列表创建类似，Pandas 会为数组中的每个元素分配一个默认的整数索引。\n\n- **从字典创建：** 从 Python 字典创建 Series 是一种非常强大的方式。字典的键会成为 Series 的索引标签，而字典的值会成为 Series 的值。\n\n  ```python\n  data = {'Alice': 10, 'Bob': 20, 'Charlie': 30}\n  s = pd.Series(data)\n  print(s)\n  ```\n\n  在这种情况下，Series 的索引将是 'Alice', 'Bob', 'Charlie'，对应的值分别是 10, 20, 30。这种方式非常适合表示带有明确标签的数据。\n\n- **指定索引：** 在从列表或 NumPy 数组创建 Series 时，可以显式地指定索引。\n\n  ```python\n  data = \n  index =\n  s = pd.Series(data, index=index)\n  print(s)\n  ```\n\n  通过 `index` 参数，我们可以自定义 Series 的索引标签。\n\n从字典创建 Series 是一种表示带有内在含义标签的数据的强大方法，例如将产品名称映射到价格。字典本身就存储着键值对，当转换为 Pandas Series 时，这些键会直接转化为有意义的索引标签，使得数据更具描述性。例如，一个字典 `{'apple': 2.5, 'banana': 1.0, 'orange': 1.5}` 转换为 Series 后，可以直接通过产品名称（如 'apple'）来访问其价格（2.5）。\n\n### **创建 DataFrame**\n\n- **从字典列表创建：** 可以使用包含字典的列表来创建 DataFrame。列表中的每个字典代表 DataFrame 中的一行，字典的键会成为列名。\n\n  ```python\n  data =\n  df = pd.DataFrame(data)\n  print(df)\n  ```\n\n  DataFrame 将会包含 'name' 和 'age' 两列，每一行对应列表中的一个字典。\n\n- **从列表的字典或 NumPy 数组的字典创建：** 可以使用字典来创建 DataFrame，其中字典的每个键代表一个列名，而对应的值是一个列表或 NumPy 数组，包含该列的数据。需要确保所有列表或数组的长度相同。\n\n  ```python\n  data = {'name':, 'age': }\n  df = pd.DataFrame(data)\n  print(df)\n  ```\n\n  这里，'name' 列对应一个包含姓名的列表，'age' 列对应一个包含年龄的列表。\n\n- **从 Series 的字典创建：** 还可以使用字典来创建 DataFrame，其中字典的每个键代表一个列名，而对应的值是一个 Series。DataFrame 的索引将与 Series 的索引对齐。\n\n  ```python\n  s1 = pd.Series(, index=['a', 'b', 'c'])\n  s2 = pd.Series(, index=['a', 'b', 'd'])\n  data = {'col1': s1, 'col2': s2}\n  df = pd.DataFrame(data)\n  print(df)\n  ```\n\n  在这个例子中，`s1` 和 `s2` 的索引略有不同。Pandas 会根据索引进行对齐，对于 `s2` 中没有 'c' 索引，以及 `s1` 中没有 'd' 索引的地方，会填充缺失值（NaN）。\n\n- **从 NumPy 数组创建：** 可以从一个二维 NumPy 数组创建 DataFrame。可以指定列名。\n\n  ```python\n  arr = np.array([, , ])\n  columns =\n  df = pd.DataFrame(arr, columns=columns)\n  print(df)\n  ```\n\n  这里，NumPy 数组的数据被放入 DataFrame 中，并使用指定的列名 'A', 'B', 'C'。\n\n- **从另一个 Series 或 DataFrame 创建：** 可以通过复制或修改现有的 Series 或 DataFrame 来创建新的 DataFrame。\n\n  ```python\n  s = pd.Series()\n  df1 = pd.DataFrame(s)\n  print(df1)\n  \n  df2 = df.DataFrame({'col1': , 'col2': })\n  df3 = pd.DataFrame(df2) # 复制 df2\n  print(df3)\n  ```\n\n  这些方法提供了创建 DataFrame 的多种途径，可以根据不同的数据来源和结构选择最合适的方法。\n\n从 Series 的字典创建 DataFrame 提供了处理具有潜在不同索引的数据的灵活性，因为 Pandas 会自动对齐这些索引，并在必要时填充缺失值。当使用不同来源的数据创建 DataFrame 时，各个 Series 可能具有不同的索引标签。Pandas 在将这些 Series 合并为 DataFrame 的列时，会根据它们的索引进行对齐。如果某个 Series 在 DataFrame 的索引中缺少某个标签，Pandas 会在该位置填充 `NaN`（Not a Number），表示缺失值。这种自动对齐的功能对于整合来自不同来源、可能存在不一致标签的数据非常有用。\n\n创建 DataFrame 的各种方法能够适应不同的数据输入格式，这使得 Pandas 在处理来自各种来源的数据时非常通用。无论数据是以记录列表的形式存在，还是以命名列的集合，或者是一个原始的数值数组，Pandas 都提供了便捷的方式将其导入到 DataFrame 中，而 DataFrame 是进行后续分析的核心数据结构。\n\n### **创建 Series 和 DataFrame 的方法小结**\n\n| **方法**                       | **数据来源**                  | **描述**                                                     | **示例代码片段**                                           |\n| ------------------------------ | ----------------------------- | ------------------------------------------------------------ | ---------------------------------------------------------- |\n| `pd.Series(data)`              | 列表，NumPy 数组              | 从列表或 NumPy 数组创建 Series，自动生成整数索引。           | `pd.Series()`                                              |\n| `pd.Series(data, index=index)` | 列表，NumPy 数组              | 从列表或 NumPy 数组创建 Series，并指定索引。                 | `pd.Series(, index=['a', 'b', 'c'])`                       |\n| `pd.Series(data)`              | 字典                          | 从字典创建 Series，字典的键成为索引，值成为 Series 的值。    | `pd.Series({'a': 1, 'b': 2})`                              |\n| `pd.DataFrame(data)`           | 字典列表                      | 从字典列表创建 DataFrame，每个字典代表一行，键成为列名。     | `pd.DataFrame([{'a': 1, 'b': 2}, {'a': 3, 'b': 4}])`       |\n| `pd.DataFrame(data)`           | 字典（列表或 NumPy 数组的值） | 从字典创建 DataFrame，每个键代表一列名，值是列表或 NumPy 数组。 | `pd.DataFrame({'col1': , 'col2': })`                       |\n| `pd.DataFrame(data)`           | 字典（Series 的值）           | 从字典创建 DataFrame，每个键代表一列名，值是 Series，DataFrame 的索引与 Series 的索引对齐。 | `pd.DataFrame({'col1': pd.Series(), 'col2': pd.Series()})` |\n| `pd.DataFrame(data)`           | 二维 NumPy 数组               | 从二维 NumPy 数组创建 DataFrame，可以指定列名。              | `pd.DataFrame(np.array([, ]), columns=)`                   |\n| `pd.DataFrame(series)`         | Series                        | 从一个 Series 创建 DataFrame，Series 成为 DataFrame 的一列。 | `pd.DataFrame(pd.Series())`                                |\n| `pd.DataFrame(dataframe)`      | DataFrame                     | 复制现有的 DataFrame。                                       | `pd.DataFrame(existing_df)`                                |\n\n## 4. 索引和选择数据\n\n一旦创建了 Series 或 DataFrame，接下来的重要步骤就是如何访问和选择其中的数据。Pandas 提供了多种灵活的方式来实现这一点。\n\n### **Series 的索引和选择**\n\n对于 Series，可以使用索引标签或位置进行数据访问。\n\n- **使用标签索引：** 如果 Series 有明确的标签索引，可以直接使用这些标签来访问数据。\n\n  ```python\n  s = pd.Series(, index=)\n  print(s['A'])  # 输出 10\n  print(s[['A', 'C']]) # 输出包含索引 'A' 和 'C' 的 Series\n  ```\n\n- **使用位置索引：** 即使 Series 有标签索引，仍然可以使用整数位置索引（从 0 开始）来访问数据，类似于 Python 列表。\n\n  ```python\n  print(s)   # 输出 10\n  print(s[]) # 输出包含位置 0 和 2 的 Series\n  ```\n\n- **切片：** 可以使用标签或位置进行切片操作来选择 Series 的一部分。\n\n  ```python\n  print(s) # 使用标签切片，注意包含结束标签 'B'\n  print(s[0:2])   # 使用位置切片，不包含结束位置 2\n  ```\n\n- **布尔索引：** 可以使用布尔条件来选择满足条件的元素。\n\n  ```python\n  s = pd.Series()\n  print(s[s > 20]) # 输出值大于 20 的元素\n  ```\n\n### **DataFrame 的索引和选择**\n\nDataFrame 的数据选择更加复杂，因为它是二维结构。主要有以下几种方法：\n\n- **选择列：** 可以像访问字典的键一样，使用列名来选择 DataFrame 的单个列，返回一个 Series。\n\n  ```python\n  data = {'name':, 'age': }\n  df = pd.DataFrame(data)\n  print(df['name']) # 输出 'name' 列的 Series\n  ```\n\n  也可以使用属性访问的方式选择列（当列名是有效的 Python 标识符时）。\n\n  ```python\n  print(df.name) # 与 df['name'] 等效\n  ```\n\n  要选择多个列，可以使用包含列名的列表。\n\n  ```python\n  print(df[['name', 'age']]) # 输出包含 'name' 和 'age' 列的 DataFrame\n  ```\n\n- **选择行：** 选择行主要使用 `.loc` 和 `.iloc` 索引器。\n\n  - **.loc：** 基于标签进行索引。可以使用行索引标签选择单行或多行。\n\n    ```python\n    df = pd.DataFrame(data, index=['row1', 'row2', 'row3'])\n    print(df.loc['row1'])       # 输出标签为 'row1' 的行，以 Series 形式\n    print(df.loc[['row1', 'row3']]) # 输出标签为 'row1' 和 'row3' 的行，以 DataFrame 形式\n    ```\n\n    也可以使用标签进行切片。\n\n    ```python\n    print(df.loc['row1':'row2']) # 选择标签从 'row1' 到 'row2' 的行（包含 'row2'）\n    ```\n\n  - **.iloc：** 基于整数位置进行索引。可以使用整数位置选择单行或多行。\n\n    ```python\n    print(df.iloc)        # 输出第一行（位置索引为 0），以 Series 形式\n    print(df.iloc[])     # 输出第一行和第三行，以 DataFrame 形式\n    ```\n\n    也可以使用整数位置进行切片。\n\n    ```python\n    print(df.iloc[0:2])      # 选择位置索引从 0 到 1 的行（不包含 2）\n    ```\n\n- **选择特定单元格：** 可以结合行和列的选择来访问 DataFrame 中的特定单元格。\n\n  - 使用 `.loc`：先指定行标签，再指定列标签。\n\n    ```python\n    print(df.loc['row1', 'name']) # 输出标签为 'row1' 的行的 'name' 列的值\n    print(df.loc[['row1', 'row2'], ['name', 'age']]) # 选择指定行和列的子集\n    ```\n\n  - 使用 `.iloc`：先指定行位置，再指定列位置。\n\n    ```python\n    print(df.iloc)      # 输出第一行第一列的值\n    print(df.iloc[, ]) # 选择指定位置的行和列的子集\n    ```\n\n- **布尔索引：** 可以使用列的条件来选择满足条件的行。\n\n  ```python\n  print(df[df['age'] > 25]) # 输出 'age' 列中值大于 25 的所有行\n  ```\n\n  可以组合多个条件，使用 `&` (and) 和 `|` (or) 运算符。\n\n  ```python\n  print(df[(df['age'] > 25) & (df['name']!= 'Bob')])\n  ```\n\n理解不同的索引和选择方法是有效使用 Pandas 进行数据分析的关键。`.loc` 基于标签，更易于理解数据的含义，而 `.iloc` 基于位置，更类似于传统的数组索引。在实际应用中，根据具体的需求选择合适的方法。\n\n## 5. 数据操作\n\nPandas 提供了丰富的功能来操作 Series 和 DataFrame 中的数据，包括过滤、排序、添加或删除列、以及应用函数等。\n\n### **过滤数据**\n\n在前面的索引和选择部分已经介绍过布尔索引，这是过滤 DataFrame 中数据的常用方法。通过创建一个布尔 Series，根据条件判断每一行是否保留。\n\n```python\ndata = {'name':, 'age': , 'city':}\ndf = pd.DataFrame(data)\n\n# 选择年龄大于 25 的行\nolder_than_25 = df[df['age'] > 25]\nprint(older_than_25)\n\n# 选择城市为 'New York' 或 'Paris' 的行\nin_ny_or_paris = df[df['city'].isin(['New York', 'Paris'])]\nprint(in_ny_or_paris)\n```\n\n### **排序数据**\n\n可以使用 `.sort_values()` 方法根据一个或多个列的值对 DataFrame 进行排序。对于 Series，可以使用 `.sort_values()` 方法按值排序，或使用 `.sort_index()` 方法按索引排序。\n\n```python\n# 按 'age' 列升序排序\nsorted_by_age = df.sort_values(by='age')\nprint(sorted_by_age)\n\n# 按 'age' 列降序排序\nsorted_by_age_desc = df.sort_values(by='age', ascending=False)\nprint(sorted_by_age_desc)\n\n# 按多个列排序，先按 'age' 升序，再按 'name' 升序\nsorted_by_age_name = df.sort_values(by=['age', 'name'])\nprint(sorted_by_age_name)\n\ns = pd.Series(, index=['c', 'a', 'd', 'e', 'b'])\n# 按值排序\nsorted_series_values = s.sort_values()\nprint(sorted_series_values)\n\n# 按索引排序\nsorted_series_index = s.sort_index()\nprint(sorted_series_index)\n```\n\n### **添加或删除列**\n\n- **添加新列：** 可以像操作字典一样，直接为 DataFrame 添加新的列。\n\n  ```python\n  df['salary'] = \n  print(df)\n  \n  # 基于现有列计算新列\n  df['age_plus_5'] = df['age'] + 5\n  print(df)\n  ```\n\n- **删除列：** 可以使用 `.drop()` 方法删除列。需要指定 `axis=1` 来表示删除的是列。\n\n  ```python\n  df_dropped_salary = df.drop('salary', axis=1)\n  print(df_dropped_salary)\n  \n  # 删除多个列\n  columns_to_drop = ['age_plus_5', 'city']\n  df_dropped_multiple = df.drop(columns_to_drop, axis=1)\n  print(df_dropped_multiple)\n  ```\n\n### **应用函数**\n\nPandas 提供了将函数应用于 Series 或 DataFrame 的强大功能，包括 `.apply()`, `.map()` 和 `.applymap()` 方法。\n\n- **.apply()：** 可以应用于 Series 的每个值或 DataFrame 的每一行或每一列。\n\n  ```python\n  def square(x):\n      return x * x\n  \n  s = pd.Series()\n  squared_series = s.apply(square)\n  print(squared_series)\n  \n  # 应用于 DataFrame 的列\n  df_sum_age = df[['age']].apply(sum)\n  print(df_sum_age)\n  \n  # 应用于 DataFrame 的行\n  def describe_row(row):\n      return f\"{row['name']} is {row['age']} years old and lives in {row['city']}.\"\n  \n  row_descriptions = df.apply(describe_row, axis=1)\n  print(row_descriptions)\n  ```\n\n- **.map()：** 主要用于 Series，将函数或字典映射应用于 Series 的每个元素。\n\n  ```python\n  city_map = {'New York': 'NY', 'London': 'LDN', 'Paris': 'PR', 'Tokyo': 'TK'}\n  df['city_code'] = df['city'].map(city_map)\n  print(df)\n  ```\n\n- **.applymap()：** 只能应用于 DataFrame，将函数应用于 DataFrame 的每个元素。\n\n  ```python\n  df_numeric = df[['age', 'salary']]\n  def add_100(x):\n      return x + 100\n  \n  df_added = df_numeric.applymap(add_100)\n  print(df_added)\n  ```\n\n这些数据操作功能使得 Pandas 成为处理和转换数据的强大工具。通过灵活地组合这些操作，可以完成复杂的数据清洗和准备任务。\n\n## 6. 基本数据分析\n\nPandas 不仅用于数据操作，还提供了进行基本数据分析的功能，例如统计计算、聚合和分组等。\n\n### **统计计算**\n\nPandas Series 和 DataFrame 提供了许多内置的统计方法，用于快速计算数据的描述性统计信息。\n\n- **常用统计方法：**\n\n  - `.count()`：计算非缺失值的数量。\n  - `.sum()`：计算总和。\n  - `.mean()`：计算均值。\n  - `.median()`：计算中位数。\n  - `.min()`：计算最小值。\n  - `.max()`：计算最大值。\n  - `.std()`：计算标准差。\n  - `.describe()`：生成包含计数、均值、标准差、最小值、四分位数和最大值的描述性统计信息。\n\n  ```python\n  s = pd.Series([1, 2, 3, 4, 5, np.nan])\n  print(s.count())   # 输出 5\n  print(s.sum())     # 输出 15.0\n  print(s.mean())    # 输出 3.0\n  print(s.median())  # 输出 3.0\n  print(s.describe()) # 输出 Series 的描述性统计信息\n  \n  data = {'col1': [1, 2, 3, np.nan], 'col2': }\n  df = pd.DataFrame(data)\n  print(df.mean())   # 输出每列的均值\n  print(df.describe()) # 输出 DataFrame 的描述性统计信息\n  ```\n\n### **聚合**\n\n聚合操作是指将多个值汇总为一个值的过程。Pandas 提供了 `.agg()` 方法来执行各种聚合操作。\n\n```python\nprint(df.agg(['sum', 'mean', 'max'])) # 对 DataFrame 的每一列应用多个聚合函数\n\nprint(df.agg({'col1': ['sum', 'min'], 'col2': ['mean', 'max']})) # 对不同的列应用不同的聚合函数\n```\n\n### **分组**\n\n分组是指根据一个或多个列的值将数据分成不同的组，然后对每个组应用聚合或其他操作。Pandas 使用 `.groupby()` 方法来实现分组操作。\n\n```python\ndata = {'team':,\n        'player': ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7'],\n        'points': }\ndf = pd.DataFrame(data)\n\n# 按 'team' 列分组，并计算每个组的平均 points\ngrouped_by_team = df.groupby('team')['points'].mean()\nprint(grouped_by_team)\n\n# 按 'team' 列分组，并计算每个组的 points 的总和和最大值\ngrouped_agg = df.groupby('team')['points'].agg(['sum', 'max'])\nprint(grouped_agg)\n\n# 按多个列分组\ngrouped_multiple = df.groupby(['team', 'player'])['points'].sum()\nprint(grouped_multiple)\n```\n\n分组操作是数据分析中非常重要的技术，可以帮助我们理解数据中不同类别之间的差异和关系。\n\n## 7. 处理缺失数据\n\n在实际数据分析中，经常会遇到缺失数据。Pandas 使用 `NaN`（Not a Number）来表示浮点数和非浮点数组中的缺失值。Python 本身也有一个 `None` 值，Pandas 在某些情况下也会将其视为缺失值。\n\n### **检测缺失数据**\n\n可以使用 `.isnull()` 和 `.notnull()` 方法来检测 DataFrame 或 Series 中的缺失值。这两个方法会返回一个布尔型的 DataFrame 或 Series，指示每个值是否为缺失值。\n\n```python\ndata = {'col1': [1, 2, np.nan, 4], 'col2': [np.nan, 6, 7, 8]}\ndf = pd.DataFrame(data)\n\nprint(df.isnull())\nprint(df.notnull())\n```\n\n可以使用 `.sum()` 方法结合 `.isnull()` 或 `.notnull()` 来统计每列或每行的缺失值数量。\n\n```python\nprint(df.isnull().sum()) # 统计每列的缺失值数量\nprint(df.isnull().sum(axis=1)) # 统计每行的缺失值数量\n```\n\n### **处理缺失数据的方法**\n\nPandas 提供了几种处理缺失数据的方法：\n\n- **删除缺失值：** 可以使用 `.dropna()` 方法删除包含缺失值的行或列。\n\n  ```python\n  # 删除包含任何缺失值的行\n  df_dropped_rows = df.dropna()\n  print(df_dropped_rows)\n  \n  # 删除包含任何缺失值的列\n  df_dropped_cols = df.dropna(axis=1)\n  print(df_dropped_cols)\n  \n  # 删除所有值都缺失的行\n  df_dropped_all_na_rows = df.dropna(how='all')\n  print(df_dropped_all_na_rows)\n  \n  # 删除至少有两个非缺失值的行\n  df_dropped_thresh_rows = df.dropna(thresh=2)\n  print(df_dropped_thresh_rows)\n  ```\n\n- **填充缺失值：** 可以使用 `.fillna()` 方法用指定的值或方法填充缺失值。\n\n  ```python\n  # 用 0 填充所有缺失值\n  df_filled_zero = df.fillna(0)\n  print(df_filled_zero)\n  \n  # 用列的均值填充缺失值\n  df_filled_mean = df.fillna(df.mean())\n  print(df_filled_mean)\n  \n  # 使用前一个有效值填充（向前填充）\n  df_filled_ffill = df.fillna(method='ffill')\n  print(df_filled_ffill)\n  \n  # 使用后一个有效值填充（向后填充）\n  df_filled_bfill = df.fillna(method='bfill')\n  print(df_filled_bfill)\n  ```\n\n选择哪种方法处理缺失数据取决于具体的数据和分析需求。删除缺失值可能会导致数据丢失，而填充缺失值则需要选择合适的填充策略，避免引入偏差。\n\n## 8. 合并和连接 DataFrame\n\nPandas 提供了将多个 DataFrame 合并或连接在一起的功能，类似于 SQL 中的 JOIN 操作。主要使用 `pd.merge()` 和 `pd.concat()` 函数。\n\n### **pd.merge()**\n\n`pd.merge()` 函数用于基于一个或多个共同的列将两个 DataFrame 连接起来。\n\n```python\ndf1 = pd.DataFrame({'key':, 'value': })\ndf2 = pd.DataFrame({'key':, 'value2': })\n\n# 内连接：只保留两个 DataFrame 中 'key' 列都存在的行\nmerged_inner = pd.merge(df1, df2, on='key')\nprint(merged_inner)\n\n# 左连接：保留左边的 DataFrame 的所有行，右边的 DataFrame 中匹配的行。如果右边没有匹配，则填充 NaN。\nmerged_left = pd.merge(df1, df2, on='key', how='left')\nprint(merged_left)\n\n# 右连接：保留右边的 DataFrame 的所有行，左边的 DataFrame 中匹配的行。如果左边没有匹配，则填充 NaN。\nmerged_right = pd.merge(df1, df2, on='key', how='right')\nprint(merged_right)\n\n# 外连接：保留两个 DataFrame 的所有行。如果某个键在一个 DataFrame 中不存在，则填充 NaN。\nmerged_outer = pd.merge(df1, df2, on='key', how='outer')\nprint(merged_outer)\n\n# 基于多个列进行连接\ndf3 = pd.DataFrame({'key1':, 'key2': ['X', 'Y', 'Z', 'W'], 'value': })\ndf4 = pd.DataFrame({'key1':, 'key2': ['Y', 'W', 'V', 'U'], 'value2': })\nmerged_multi_key = pd.merge(df3, df4, on=['key1', 'key2'])\nprint(merged_multi_key)\n```\n\n### **pd.concat()**\n\n`pd.concat()` 函数用于沿着指定的轴将多个 Series 或 DataFrame 拼接在一起。\n\n```python\ns1 = pd.Series()\ns2 = pd.Series()\nconcatenated_series = pd.concat([s1, s2])\nprint(concatenated_series)\n\ndf5 = pd.DataFrame({'col1': , 'col2': })\ndf6 = pd.DataFrame({'col1': , 'col2': })\nconcatenated_df_rows = pd.concat([df5, df6]) # 默认按行拼接 (axis=0)\nprint(concatenated_df_rows)\n\nconcatenated_df_cols = pd.concat([df5, df6], axis=1) # 按列拼接\nprint(concatenated_df_cols)\n\n# 使用 keys 参数为拼接后的 DataFrame 添加一个额外的层级索引\nconcatenated_keys = pd.concat([df5, df6], keys=['first', 'second'])\nprint(concatenated_keys)\n```\n\n合并和连接操作是整合来自不同数据源的数据的关键步骤，使得我们可以进行更全面的分析。\n\n## 9. 输入与输出\n\nPandas 提供了方便的方法来读取和写入各种格式的文件，例如 CSV、Excel、SQL 数据库等。\n\n### **读取文件**\n\n- **CSV 文件：** 使用 `pd.read_csv()` 函数读取 CSV 文件。\n\n  ```python\n  # df = pd.read_csv('your_file.csv')\n  # 可以指定分隔符、编码等参数\n  # df = pd.read_csv('your_file.csv', sep=',', encoding='utf-8')\n  ```\n\n- **Excel 文件：** 使用 `pd.read_excel()` 函数读取 Excel 文件。\n\n  ```python\n  # df = pd.read_excel('your_file.xlsx')\n  # 可以指定 sheet 名称或索引\n  # df = pd.read_excel('your_file.xlsx', sheet_name='Sheet1')\n  ```\n\n- **其他格式：** Pandas 还支持读取 JSON (`pd.read_json()`)、HTML (`pd.read_html()`)、SQL 数据库 (`pd.read_sql()`) 等多种格式的文件。\n\n### **写入文件**\n\n- **CSV 文件：** 使用 `.to_csv()` 方法将 DataFrame 写入 CSV 文件。\n\n  ```python\n  # df.to_csv('output.csv')\n  # 可以设置是否包含索引、分隔符等参数\n  # df.to_csv('output.csv', index=False, sep=';')\n  ```\n\n- **Excel 文件：** 使用 `.to_excel()` 方法将 DataFrame 写入 Excel 文件。\n\n  ```python\n  # df.to_excel('output.xlsx')\n  # 可以设置 sheet 名称、是否包含索引等参数\n  # df.to_excel('output.xlsx', sheet_name='Sheet2', index=False)\n  ```\n\n- **其他格式：** 类似地，Pandas 也提供了将 DataFrame 写入 JSON (`.to_json()`)、HTML (`.to_html()`)、SQL 数据库 (`.to_sql()`) 等格式的方法。\n\n输入输出功能使得 Pandas 能够方便地与外部数据进行交互，是数据分析流程中不可或缺的一环。\n\n## 10. 总结\n\nPandas 是 Python 中用于数据操作和分析的核心库。本指南介绍了 Pandas 的基本概念，包括其核心数据结构 Series 和 DataFrame，以及如何创建、索引、选择、操作、分析、处理缺失数据、合并连接数据以及进行文件输入输出。掌握这些基本操作是使用 Pandas 进行更高级数据分析的基础。\n\n对于 Python 初学者来说，Pandas 提供了一种强大且直观的方式来处理和理解数据。通过不断地练习和应用，可以更深入地掌握 Pandas 的各种功能，并将其应用于实际的数据分析项目中。建议在掌握本指南中的内容后，进一步探索 Pandas 的高级特性，例如时间序列分析、更复杂的数据聚合和转换等，以提升数据分析的能力。","tags":["python","数据操作"],"categories":["数据分析"]},{"title":"NumPy操作方式笔记","url":"/post/numpy.html","content":"\n# NumPy操作方式笔记\n\nNumPy，全称为 Numerical Python，是Python语言中用于科学计算的基础库之一。它为Python提供了强大的多维数组和矩阵的支持，以及一套用于在这些数组上执行高性能计算的数学函数集合。NumPy的核心在于其引入的 `ndarray` 对象，这是一个可以存储同类型数据（如数字）的多维数组结构，为处理大型数据集提供了内存效率极高的存储和操作方式。与Python内置的列表不同，NumPy数组中的所有元素都必须是相同的数据类型，这一特性使得NumPy能够实现更快的运算速度。实际上，NumPy的许多操作都是通过优化过的C语言代码实现的，这使得其在处理数值计算任务时，性能远超使用标准Python列表和循环的实现方式。此外，NumPy还具备广播（broadcasting）功能，允许不同形状的数组之间进行运算，而无需显式地进行循环操作。这种设计极大地简化了代码，并提升了处理大规模数据的效率。\n\n## NumPy的重要性与优势\n\nNumPy之所以在科学计算领域如此重要，原因在于其多方面的优势：\n\n* **提升运算速度**：它能够显著提升数学运算的速度，尤其是在处理包含大量数字的数组时，其效率远高于标准的Python实现。\n* **简化数据处理**：NumPy简化了对大型数值列表（即数组）的处理，避免了编写复杂的循环结构。\n* **丰富的函数库**：NumPy还提供了丰富的、可以直接使用的函数，用于执行统计分析、线性代数运算以及生成随机数等任务。\n* **科学计算库的基础**：更重要的是，NumPy是许多其他重要的科学计算库（如Pandas、SciPy、TensorFlow和scikit-learn）的基础。这些库在数据分析、高级科学计算和机器学习等领域发挥着关键作用，它们都依赖于NumPy数组作为其核心数据结构。\n* **高效的内存管理**：最后，与Python列表相比，NumPy在存储和管理大量数据时，占用的内存更少，效率更高，这对于处理庞大的数据集至关重要。\n\n## NumPy的应用领域\n\n由于其强大的功能和高效的性能，NumPy被广泛应用于各种领域：\n\n* **数据分析**：NumPy可以用于创建、筛选和操作以数组形式存在的数据，并执行诸如计算均值和标准差等各种操作。\n* **机器学习与人工智能**：流行的工具如TensorFlow和PyTorch都使用NumPy来管理输入数据、处理模型参数和输出值。\n* **数组操作**：NumPy还提供了强大的数组操作功能，包括创建、调整大小、切片、索引、堆叠、分割和组合数组。\n* **金融与经济**：NumPy被用于财务分析，包括投资组合优化、风险评估、时间序列分析和统计建模。\n* **图像与信号处理**：NumPy能够帮助处理和分析图像和信号数据。\n* **数据可视化**：虽然NumPy本身不直接创建可视化图表，但它与Matplotlib和Seaborn等库紧密集成，可以从数值数据生成各种图表。\n\nNumPy的这些应用表明，无论是在基础的数据处理还是在复杂的算法实现中，它都扮演着至关重要的角色。\n\n## NumPy的安装与导入\n\n要开始使用NumPy，首先需要在Python环境中安装它。这可以通过Python的包管理器pip轻松完成，只需在命令行中运行：\n```bash\npip install numpy\n```\n\n这个命令会自动从Python的包索引中下载并安装NumPy及其依赖项。\n\n安装完成后，在Python代码中需要导入NumPy库才能使用其功能。按照惯例，我们通常会使用别名 `np` 来导入NumPy，即使用语句：\n\n```python\nimport numpy as np\n```\n\n这样做的好处是，在后续的代码中，我们可以通过 `np` 这个更简洁的名称来引用NumPy的函数和对象，这提高了代码的可读性，并且是Python科学计算社区广泛采用的一种标准做法。这种一致性使得不同开发者编写的代码更容易被理解和协作。\n\n## NumPy的核心：ndarray对象\n\nNumPy的核心是其多维数组对象，即 `ndarray`。理解 `ndarray` 的核心属性对于有效地使用NumPy至关重要。\n\n- **同质性**：NumPy数组是同质的，这意味着数组中的所有元素都必须是相同的数据类型。这与Python列表可以包含不同类型的元素形成了鲜明的对比。同质性是NumPy实现高效数值计算的关键，因为它允许NumPy在内存中以连续的方式存储数据，并针对特定的数据类型进行优化。\n- **多维性**：NumPy数组可以是多维的。一维数组类似于Python中的列表，可以看作是向量。二维数组则更像是一个表格或矩阵，具有行和列。NumPy还支持更高维度的数组，例如三维数组可以想象成由多个二维数组堆叠而成，更高维度的数组在处理更复杂的数据结构时非常有用，通常被称为张量。\n\n### ndarray的核心属性\n\n- **形状 (shape)**：描述数组结构的一个重要属性，它是一个由整数组成的元组，每个整数表示数组在相应维度上的大小。例如，对于一个二维数组，其形状表示为 `(行数, 列数)`。理解数组的形状对于进行需要兼容数组尺寸的操作（如算术运算和矩阵乘法）至关重要。\n- **数据类型 (dtype)**：指定了数组中元素的数据类型。NumPy支持多种数据类型，包括整数（如 `int64`）、浮点数（如 `float64`）、复数（如 `complex32`）等。在创建数组时，如果没有显式指定数据类型，NumPy通常会根据输入数据的类型进行推断，默认的数据类型通常是 `float64`。用户也可以在创建数组时通过 `dtype` 参数显式地指定所需的数据类型，这有助于更好地管理内存使用和控制计算精度。\n- 其他基本属性： \n  - `ndim`: 数组的维度（轴）的数量。\n  - `size`: 数组中元素的总数。\n  - `itemsize`: 数组中每个元素占用的字节数。\n  - `data`: 一个缓冲区，包含了数组中实际的元素数据，但通常不直接使用。\n- **可变性**：与Python列表类似，NumPy数组是可变的，这意味着在数组创建后，可以修改其元素的值。\n\n这些属性共同构成了对NumPy数组的基本理解，为后续学习更复杂的操作打下了基础。\n\n## 创建NumPy数组\n\n创建NumPy数组有多种方法。\n\n- **从Python序列创建**：一种常见的方法是使用 `np.array()` 函数，该函数可以从常规的Python列表或元组创建NumPy数组。`np.array()` 会尝试根据序列中元素的类型推断出结果数组的数据类型。例如，如果传入的列表包含整数，则创建的数组将是整数类型的；如果包含浮点数，则数组将是浮点数类型的。对于多维数组，可以传入由列表组成的列表（或元组组成的元组），NumPy会将其转换为相应的多维数组结构。需要注意的是，在调用 `np.array()` 时，应该将要转换的序列作为一个单独的参数传入，而不是将序列中的元素作为多个独立的参数传入，否则会导致类型错误。\n- **使用专门函数创建具有特定初始值的数组**：\n  - `np.zeros(shape, dtype=float, order='C')`: 创建一个指定形状和数据类型的数组，并用零填充所有元素。例如，`np.zeros((3, 4))` 将创建一个 3 行 4 列的二维数组，所有元素都初始化为 `0.0`。\n  - `np.ones(shape, dtype=None, order='C')`: 创建一个用 1 填充的数组。例如，`np.ones((2, 3, 4), dtype=np.int16)` 将创建一个 2x3x4 的三维数组，所有元素都初始化为整数 `1`。\n  - `np.empty(shape, dtype=float, order='C')`: 创建一个指定形状和数据类型的数组，但不会对其进行初始化，数组中的初始值是内存中已有的任意数据。使用 `np.empty()` 的优势在于速度可能比 `np.zeros()` 或 `np.ones()` 快，因为它不需要进行初始化，但这也意味着在使用之前必须确保数组的所有元素都被赋予了有意义的值。\n- **创建数值序列**：\n  - `np.arange([start,] stop[, step,], dtype=None, *, like=None)`: 类似于Python内置的 `range()` 函数，但返回的是一个NumPy数组。`np.arange()` 可以接受浮点数参数，例如 `np.arange(0, 2, 0.3)` 将生成 `[0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8]`。然而，当使用浮点数步长时，由于浮点数精度的限制，可能无法准确预测生成的元素数量。\n  - `np.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0)`: 通常建议使用此函数来创建指定数量的在给定间隔内均匀分布的数值。`np.linspace()` 接收起始值、结束值以及期望生成的元素数量作为参数，例如 `np.linspace(0, 2, 9)` 将生成 9 个从 0 到 2（包含 2）均匀分布的数值。\n\n这些函数为创建各种类型的NumPy数组提供了灵活的方式。\n\n## NumPy数组的基本操作\n\nNumPy在数组上执行基本操作时，通常是**逐元素 (element-wise)**进行的。这意味着当对两个形状相同的数组进行算术运算时（例如加法、减法、乘法、除法、乘方和取模），运算会对应地应用到数组中的每个元素，并产生一个新的包含结果的数组。 例如，如果 `a = np.array([20, 30, 40, 50])` 且 `b = np.arange(4)`，那么 `a - b` 将得到 `array([20, 29, 38, 47])`，而 `b**2` 将得到 `array([0, 1, 4, 9])`。 同样，标量与数组之间的运算也会被广播到数组的每个元素上，例如 `10 * np.sin(a)` 会先计算数组 `a` 中每个元素的正弦值，然后将结果乘以 10。这种逐元素的操作方式使得对整个数据集进行数学运算变得简洁高效，无需编写显式的循环。\n\n### 通用函数 (ufuncs)\n\nNumPy为这些基本的算术运算提供了相应的**通用函数 (universal functions，简称 ufuncs)**。例如：\n\n- `np.add()` 对应于加法 (`+`)\n- `np.subtract()` 对应于减法 (`-`)\n- `np.multiply()` 对应于乘法 (`*`)\n- `np.divide()` 对应于除法 (`/`)\n- `np.power()` 对应于乘方 (`**`)\n- `np.mod()` 对应于取模 (`%`)\n\n这些 ufuncs 不仅执行逐元素操作，而且通常经过高度优化，能够提供比标准Python操作更高的性能。它们是NumPy向量化操作的基础，直接在NumPy数组的内存缓冲区上操作，避免了为每个元素调用Python函数的开销。\n\n### 其他数学函数\n\n除了基本的算术运算，NumPy还提供了大量的通用数学函数，这些函数同样以逐元素的方式应用于数组。这包括：\n\n- **三角函数**: 如 `np.sin()` (正弦)、`np.cos()` (余弦)、`np.tan()` (正切)、`np.arcsin()` (反正弦)等。\n- **指数和对数函数**: 如 `np.exp()` (指数)、`np.log()` (自然对数)、`np.log10()` (以 10 为底的对数)等。\n- **舍入函数**: 如 `np.round()` (四舍五入)、`np.floor()` (向下取整)、`np.ceil()` (向上取整)等。\n- **绝对值函数**: `np.abs()`。\n\nNumPy的文档中包含了完整的数学函数列表，这些函数极大地扩展了在NumPy数组上进行复杂数值计算的能力。\n\n## NumPy数组的索引和切片\n\n### 单个元素访问\n\n访问NumPy数组中的单个元素与Python列表类似，都是通过索引来实现的，索引从 0 开始。\n\n- **一维数组**: 可以直接使用方括号内的索引来访问元素，例如 `a[0]` 将访问数组 `a` 的第一个元素。\n- **多维数组**: 可以使用逗号分隔的索引元组来访问特定位置的元素，每个索引对应数组的一个维度。例如，对于一个二维数组 `a`，`a[1, 3]` 将访问第二行（索引为 1）第四列（索引为 3）的元素。\n- **负索引**: NumPy还支持负索引，可以从数组的末尾开始计数，例如 `a[-1]` 将访问数组的最后一个元素。\n\n这种灵活的索引方式使得可以方便地访问数组中的特定元素。\n\n### 切片 (Slicing)\n\n除了访问单个元素，NumPy还提供了强大的切片（slicing）功能，用于提取数组的子数组。切片使用 `[start:stop:step]` 这样的表示法，其中 `start` 是切片的起始索引（包含），`stop` 是结束索引（不包含），`step` 是步长。\n\n- 如果没有指定 `start`，则默认为 0。\n- 如果没有指定 `stop`，则默认为数组的长度。\n- 如果没有指定 `step`，则默认为 1。\n\n一个重要的特性是，NumPy的切片操作创建的是原始数组的**视图 (view)**，而不是数据的副本。这意味着对切片进行修改会直接影响到原始数组。这种行为可以提高效率，避免不必要的数据复制，但需要注意，如果需要一个独立的副本，应该使用 `.copy()` 方法。\n\n对于多维数组，切片可以应用于每个维度，通过逗号分隔每个维度的切片规格。例如：\n\n- `a[0:2, :]` 选择数组 `a` 的前两行（所有列）。\n- `a[:, 1:4]` 选择所有行的第 2 到第 4 列（不包括第 4 列）。\n- `a[1, :]` 选择第二行的所有元素。\n- `a[:, 2]` 选择第三列的所有元素。\n\n### 高级索引\n\nNumPy还支持更高级的索引方式。\n\n- **布尔数组索引 (Boolean array indexing / Masking)**：通过创建一个与原始数组形状相同的布尔数组作为索引，可以根据布尔数组中 `True` 值对应的位置来选择原始数组中的元素。例如，`a[a > 5]` 将选择数组 `a` 中所有大于 5 的元素。布尔索引是根据条件过滤数据的强大工具。\n- **整数数组索引 (Integer array indexing / Fancy indexing)**：通过传递一个包含整数索引的NumPy数组作为索引，可以选择原始数组中特定位置的元素。这允许以非连续的方式选择元素，甚至可以重复选择相同的元素。例如，`a[[0, 2, 4]]` 将选择数组 `a` 中索引为 0、2 和 4 的元素。对于二维数组，可以传递两个整数数组，分别表示要选择的元素的行索引和列索引。例如，`a[[0, 1, 2], [0, 1, 0]]` 将选择位于 `(0, 0)`、`(1, 1)` 和 `(2, 0)` 的元素。与基本的切片不同，整数数组索引**总是返回原始数据的一个副本**。\n\n## NumPy数组的形状操作\n\nNumPy提供了多种方法来改变数组的形状而不改变其数据内容。\n\n- **ndarray.reshape(new_shape, order='C')**: 将数组重塑为指定的形状，`new_shape` 参数是一个表示新形状的元组。重要的是，重塑后的数组必须包含与原始数组相同数量的元素。如果可能，`reshape()` 会返回原始数组的一个视图，否则会返回一个副本。例如，如果 `a` 是一个包含 12 个元素的一维数组，`a.reshape((3, 4))` 将其转换为一个 3 行 4 列的二维数组。\n- **数组的扁平化 (Flattening)**：是将多维数组转换为一维数组的过程。\n  - `ndarray.flatten(order='C')`: 返回一个原始数组的副本，并将其展平为一维数组。\n  - `ndarray.ravel(order='C')`: 也执行相同的操作，但它会尝试返回原始数组的视图，只有在必要时才会返回副本，因此在可能的情况下，`ravel()` 通常比 `flatten()` 更节省内存。 例如，对于一个多维数组 `a`，`a.flatten()` 和 `a.ravel()` 都会得到一个包含相同元素的一维数组。\n- **转置 (Transposing)**：是另一种常见的数组形状操作。对于二维数组（矩阵），转置会交换其行和列。在NumPy中，可以使用 `ndarray.T` 属性来获取数组的转置视图，或者使用 `np.transpose(a, axes=None)` 函数，该函数返回一个转置后的数组。通过 `axes` 参数，可以指定更复杂的轴交换顺序。例如，对于一个数组 `a`，`a.T` 或 `np.transpose(a)` 将返回其转置。转置在线性代数中非常重要，例如在进行矩阵乘法时，可能需要先对矩阵进行转置。\n\n这些形状操作为处理和组织NumPy数组中的数据提供了灵活性。\n\n## NumPy的线性代数运算\n\nNumPy还为线性代数运算提供了强大的支持。\n\n- **点积 (Dot product)**：可以使用 `np.dot(a, b)` 函数来计算两个数组的点积。\n  - 如果 `a` 和 `b` 都是一维数组，`np.dot()` 返回向量的内积。\n  - 如果它们都是二维数组，则执行矩阵乘法（在较新的NumPy版本中，推荐使用 `np.matmul()` 或 `a @ b` 进行矩阵乘法）。\n  - 对于更高维度的数组，点积的计算方式更为复杂，涉及到最后一个轴的求和乘积。 点积是线性代数中的基本运算，广泛应用于物理学和机器学习等领域。\n- **矩阵乘法 (Matrix multiplication)**：可以使用 `np.matmul(a, b)` 或 `a @ b` 来执行。对于二维数组，这是标准的矩阵乘法。需要注意的是，进行矩阵乘法时，第一个矩阵的列数必须等于第二个矩阵的行数。\n- **逐元素乘法 (Element-wise multiplication)**：可以使用 `np.multiply(a, b)` 或简单的 `a * b` 来实现，它将两个形状相同的数组中对应位置的元素相乘。这与矩阵乘法是不同的。\n\n### `linalg` 模块\n\nNumPy的 `linalg` 模块还包含许多其他有用的线性代数函数，例如：\n\n- `np.linalg.solve(a, b)`: 求解线性方程组 $Ax = b$。\n- `np.linalg.inv(a)`: 计算矩阵的逆。\n- `np.linalg.eig(a)`: 计算方阵的特征值和特征向量。\n- `np.linalg.det(a)`: 计算矩阵的行列式。\n- `np.linalg.norm(x)`: 计算矩阵或向量的范数。\n\n这些函数构成了进行高级数值计算和解决复杂数学问题的基础。\n\n## NumPy的随机数生成\n\nNumPy还提供了强大的随机数生成功能，这些功能在模拟、机器学习等领域非常有用。\n\n- `np.random.rand(d0, d1,..., dn)`: 创建一个指定形状的数组，并用从均匀分布（区间 `[0, 1)`）中抽取的随机浮点数填充。例如，`np.random.rand(5)` 将创建一个包含 5 个随机数的 1D 数组，而 `np.random.rand(2, 3)` 将创建一个 2x3 的随机数数组。\n- `np.random.randn(d0, d1,..., dn)`: 类似，但它从标准正态分布（均值为 0，方差为 1）中抽取随机数。\n- `np.random.randint(low, high=None, size=None, dtype=int)`: 返回在指定范围内（从 `low`（包含）到 `high`（不包含））的随机整数，形状由 `size` 参数指定。如果只提供一个参数，则返回 0 到该参数之间的随机整数。例如，`np.random.randint(10, size=5)` 将创建一个包含 5 个 0 到 9 之间随机整数的数组。\n\n对于更新的NumPy代码（版本 1.17 及更高版本），推荐使用 `np.random.default_rng()` 创建一个随机数生成器对象，该对象提供了更结构化的方式来生成来自各种分布的随机数，例如：\n\n```python\nrng = np.random.default_rng()\nrandom_array = rng.random((3, 2)) # 使用 random 而非 rand\nrandom_integers = rng.integers(0, 10, size=5)\n```\n\n这种方式提供了更好的控制和更广泛的分布选择。\n\n## NumPy数组的复制与视图\n\n在使用NumPy数组时，理解**复制 (copy)**数组和创建**视图 (view)**之间的区别非常重要。\n\n- **赋值操作 (b = a)**: 并不会创建数组 `a` 的一个新副本，而是使 `b` 成为对 `a` 所指向的同一数组对象的另一个引用。这意味着，如果修改 `b` 中的元素，`a` 中的相应元素也会被修改。\n- **切片操作 (b = a[0:5])**: 通常会创建原始数组的一个视图。视图本质上是原始数组数据的一个窗口，它本身不存储任何数据，而是引用原始数组的一部分。因此，通过视图对数组进行的修改可能会影响到原始数组。\n- **.copy() 方法 (b = a.copy())**: 如果需要创建数组及其数据的完全独立副本，应该使用 `.copy()` 方法。在这种情况下，对 `b` 的修改不会影响到 `a`。\n\n理解这种行为对于避免在程序中出现意外的副作用至关重要。\n\n## NumPy数组的保存与加载\n\nNumPy还提供了方便的方法来将数组数据保存到磁盘以及从磁盘加载数组数据。\n\n- `np.save('filename.npy', array)`: 将单个NumPy数组以二进制格式保存到扩展名为 `.npy` 的文件中。\n- `np.load('filename.npy')`: 将保存的数组从 `.npy` 文件加载回来。\n- `np.savetxt('filename.txt', array)`: 将数组保存到文本文件中。\n- `np.loadtxt('filename.txt')`: 从文本文件中加载数组。\n- `np.genfromtxt('data.txt', delimiter=',')`: 可以从文本文件加载数据，并且更灵活，可以处理缺失值和不同的数据类型。\n\n这些功能使得NumPy能够有效地处理大型数据集，这些数据集可能无法一次性加载到内存中。\n\n## 总结\n\nNumPy作为Python科学计算的核心库，为处理多维数组和执行数值计算提供了强大且高效的工具。通过理解NumPy数组的特性、掌握创建数组的多种方式、熟悉基本的逐元素操作和数学函数、灵活运用索引和切片技术、以及了解数组形状的变换和基本的线性代数运算，Python初学者可以为后续更深入的数据分析、机器学习和科学研究打下坚实的基础。理解复制和视图的区别以及学会保存和加载数组数据，将有助于更有效地管理和处理实际应用中的数据。NumPy的高效性和广泛的功能使其成为Python科学计算生态系统中不可或缺的一部分。\n\n## NumPy数组创建函数比较表\n\n| 函数名称      | 描述                               | 主要参数                                                     | 用途示例                                                 |\n| ------------- | ---------------------------------- | ------------------------------------------------------------ | -------------------------------------------------------- |\n| `np.array`    | 从列表、元组或其他序列创建数组     | `object` (要转换的序列), `dtype` (数据类型), `copy` (是否复制) | `np.array([1,2,3])`, `np.array([[1,2], [3,4]])`          |\n| `np.zeros`    | 创建一个用零填充的数组             | `shape` (数组形状), `dtype` (数据类型)                       | `np.zeros((2, 3))`, `np.zeros(5, dtype=int)`             |\n| `np.ones`     | 创建一个用一填充的数组             | `shape` (数组形状), `dtype` (数据类型)                       | `np.ones((3, 2))`, `np.ones((2, 2), dtype=float)`        |\n| `np.empty`    | 创建一个未初始化的数组             | `shape` (数组形状), `dtype` (数据类型)                       | `np.empty((2, 2))`, `np.empty(3, dtype=complex)`         |\n| `np.arange`   | 在给定范围内创建均匀间隔的值的数组 | `start` (起始值), `stop` (结束值), `step` (步长), `dtype` (数据类型) | `np.arange(0, 10, 2)`, `np.arange(5)`                    |\n| `np.linspace` | 在指定间隔内创建均匀间隔的数字序列 | `start` (起始值), `stop` (结束值), `num` (元素数量), `dtype` (数据类型) | `np.linspace(0, 1, 5)`, `np.linspace(0, np.pi, 10)`      |\n| `np.full`     | 创建一个用指定值填充的数组         | `shape` (数组形状), `fill_value` (填充值), `dtype` (数据类型) | `np.full((2, 2), 7)`, `np.full(5, 'test', dtype=object)` |\n| `np.eye`      | 创建一个单位矩阵                   | `N` (行数), `M` (列数，可选), `k` (对角线索引), `dtype` (数据类型) | `np.eye(3)`, `np.eye(4, M=5, k=1)`                       |\n| `np.diag`     | 提取对角线或创建对角数组           | `v` (对角线元素), `k` (对角线索引)                           | `np.diag([1,2,3])`, `np.diag(np.array([[1,2], [3,4]]))`  |\n\n## 基本算术通用函数比较表\n\n| 运算符 | 等效通用函数  | 描述               |\n| ------ | ------------- | ------------------ |\n| `+`    | `np.add`      | 逐元素相加         |\n| `-`    | `np.subtract` | 逐元素相减         |\n| `*`    | `np.multiply` | 逐元素相乘         |\n| `/`    | `np.divide`   | 逐元素相除         |\n| `**`   | `np.power`    | 逐元素乘方         |\n| `%`    | `np.mod`      | 逐元素取模（余数） |\n\n## 数组扁平化方法比较表\n\n| 方法        | 返回值         | 内存效率 | 对原始数组的影响 | 适用场景                           |\n| ----------- | -------------- | -------- | ---------------- | ---------------------------------- |\n| `flatten()` | 原始数组的副本 | 较低     | 不影响           | 需要一个原始数组的独立副本时       |\n| `ravel()`   | 原始数组的视图 | 较高     | 可能影响         | 当不需要副本且希望尽可能节省内存时 |","tags":["python","数据操作"],"categories":["数据分析"]},{"title":"LeetCode每日一题2025-05-18","url":"/post/count-equal-and-divisible-pairs.html","content":"\n# [1931. 用三种不同颜色为网格涂色](https://leetcode.cn/problems/painting-a-grid-with-three-different-colors/) H\n\n给你两个整数 `m` 和 `n` 。构造一个 `m x n` 的网格，其中每个单元格最开始是白色。请你用 **红、绿、蓝** 三种颜色为每个单元格涂色。所有单元格都需要被涂色。\n\n涂色方案需要满足：**不存在相邻两个单元格颜色相同的情况** 。返回网格涂色的方法数。因为答案可能非常大， 返回 **对** `10⁹ + 7` **取余** 的结果。\n\n \n\n**示例 1：**\n\n![colorthegrid](https://s2.loli.net/2025/05/18/mDHT6orlxOePg3M.png)\n\n> 输入：m = 1, n = 1\n> 输出：3\n> 解释：如上图所示，存在三种可能的涂色方案。\n\n**示例 2：**\n\n![copy-of-colorthegrid](https://s2.loli.net/2025/05/18/J82rswYUVe1yCz3.png)\n\n> 输入：m = 1, n = 2\n> 输出：6\n> 解释：如上图所示，存在六种可能的涂色方案。\n\n**示例 3：**\n\n> 输入：m = 5, n = 5\n> 输出：580986\n\n \n\n**提示：**\n\n- `1 <= m <= 5`\n- `1 <= n <= 1000`\n\n\n\n## 问题分析\n\n给定 m×n 的网格（1 ≤ m ≤ 5，1 ≤ n ≤ 1000），每个格子都要用三种颜色之一（红/绿/蓝）上色，且要求 **无两相邻格子颜色相同**。邻接关系包括水平方向（左右）和垂直方向（上下）。\n\n由于 m 较小（至多 5），可以把“同一列的 m 个格子”看作一个整体状态。对于一列内部，必须保证上下相邻的颜色不同；对于两列之间，必须保证同一行的两个格子颜色不同。\n\n## 算法思路\n\n### 1. 合法列状态数\n\n- 对于一列，逐格向下涂色：\n  - 第一行格子有 3 种颜色可选；\n  - 之后每增加一格，颜色只能是剩下的 2 种（不能与上一格相同）；\n- 因此一列共有 $3 \\times 2^{,m-1}$ 种合法的“列颜色方案”。\n- 当 m=5 时，合法状态数 $=3×2^4=48$；当 m=1 时，合法状态数 $=3$；依此类推。\n\n我们可以把每个“列方案”用长度为 m 的元组（或一个整数掩码）来表示。例如：若 m=3，用 (0,1,2) 表示第一行红、第二行绿、第三行蓝。然后预先枚举出全部合法的列状态列表 `states`。\n\n### 2. 列与列之间的兼容性\n\n- 若列 A 和列 B 在同一行颜色相同，则它们不能相邻摆放。\n\n- 因此，对所有合法状态对 $(s_i, s_j)$ ，检查：\n  $$\n  \\forall\\,0\\le r<m:\\; s_i[r] \\ne s_j[r].\n  $$\n\n- 枚举时可得到一个邻接列表（邻接矩阵／邻接表）`compat[i]` 记录状态 i 能与哪些状态 j 配对。\n\n### 3. 动态规划\n\n定义 $\\text{dp}[c][i]$ 为第 $c$ 列选择状态 $i$ 时的方案总数。\n\n- 初始化 $c=1$ 时：对于任意合法状态 $i$，$\\text{dp}[1][i]=1$。\n\n- 状态转移（$2\\le c\\le n$）：\n  $$\n  \\text{dp}[c][j]   = \\sum_{\\substack{i=0\\\\ i\\,\\text{与}\\,j\\,\\text{兼容}}}^{S-1} \\text{dp}[c-1][i].\n  $$\n\n- 最终答案 $=\\sum_{i=0}^{S-1}\\text{dp}[n][i] \\bmod (10^9+7)$。\n\n- 其中 $S=3\\times2^{m-1}$ 是合法列状态数。\n\n## 时间复杂度\n\n- **预处理列状态**：枚举每个长度为 m 的染色情况，共 $3^m$ 种，筛选出 $S=3\\times2^{m-1}$ 个合法；时间约 $O(3^m \\times m)$，当 m≤5 时常数小（最多 3^5=243）；\n- **预处理兼容矩阵**：两两枚举 $S\\times S$ 对，检查 m 行是否同色；时间 $O(S^2 \\times m)$，当 m=5 时 $S=48$，约 48^2×5≈11520 步；\n- **动态规划**：共 n 列，每列从上一列的兼容状态中累加，时间 $O(n \\times S_{\\mathrm{avg\\_neighbors}})$。最坏的邻居数约 $S$，则 $O(nS^2)$。\n  - 当 m=5, S=48, S^2≈2304, n≤1000 时，总步数 ≈2.3×10^6，完全可行。\n- **空间**：若保存整个 dp 表，为 $O(nS)$；也可以用滚动数组仅保留上一列，总空间 $O(S)$。\n\n若 n 更大（例如 n 接近 10⁹ ），可以把兼容关系矩阵看作 $S×S$ 的转移矩阵，用矩阵快速幂将 $n$ 次转移压缩为 $O(S^3\\log n)$。在本题 n≤1000 的规模下，直接DP已足够高效。\n\n经测试，时间复杂度为$O(M * 2^M * N)$\n\n## 代码分解\n\n1. 用整数 0/1/2 表示三种颜色；\n2. 枚举所有合法的“列状态”，存入 `states`；\n3. 构造每对状态是否兼容的布尔矩阵 `compatible`；\n4. 用一维滚动数组实现 DP，依次累加；\n5. 返回最终总和。\n\n## 代码实现\n\n**DFS 枚举合法单列**\n\n- 用 `dfs_build(0, -1)` 从 row=0 开始，`prev_color=-1` 表示第一行可任意选择 0/1/2；\n- 每往下一行，只要不与上一行 (`prev_color`) 相等即可；\n- 递归深度为 m，结束时将当前路径 `tuple(path)` 加入 `states`。\n- 最终 `states` 列表长度应 $3\\times2^{m-1}$。\n\n**兼容性检查**\n\n- `compatible[i][j]` 表示第 i 种列状态能否在左侧，第 j 种列状态能否在右侧；\n- 遍历 `states[i]` 与 `states[j]` 每一行，若有任何一行相同，则标记不兼容。\n- 时间复杂度 $O(S^2 \\times m)$，当 m=5, S=48 时约 48^2×5≈11520 步。\n\n**动态规划**\n\n- 定义 `dp_prev[i]` 为“上一列选状态 i 时的方案数”；初始时 第一列“任意状态”都记为 1；\n- 对于第 col(≥2) 列，枚举 `j` 作为当前列状态，累加所有 `i`（上一列）满足 `compatible[i][j]` 的 `dp_prev[i]`；\n- 用 `%MOD` 保证不溢出；更新完一列后，用滚动数组交换指针（`dp_prev, dp_cur = dp_cur, [0]*S`）。\n\n**合并答案**\n\n- 第 n 列计算完毕后，所有 `dp_prev[i]` 即为“第 n 列状态为 i” 的方案数，直接求和取模。\n\n```python\nclass Solution:\n    MOD = 10**9 + 7\n\n    def colorTheGrid(self, m: int, n: int) -> int:\n        # 1. 枚举所有合法的列状态\n        #    用整数列表表示，如 [0, 1, 2, 0, ...]，其中 0/1/2 代表三种颜色。\n        states = []\n        def dfs_build(col, prev_color):\n            \"\"\"\n            通过深度优先搜索构建单列的所有合法方案。\n            col: 当前处理到哪一行（0-based）\n            prev_color: 上一行的颜色（若为 -1 则表示第一行）\n            path: 当前已选颜色列表\n            \"\"\"\n            if col == m:\n                # 到达第 m 行，保存当前路径\n                states.append(tuple(path))\n                return\n            for color in (0, 1, 2):\n                if color != prev_color:\n                    path.append(color)\n                    dfs_build(col + 1, color)\n                    path.pop()\n\n        path = []\n        dfs_build(0, -1)\n        S = len(states)  # 合法状态总数，应=3 * 2^(m-1)\n\n        # 2. 构造兼容性矩阵：若两列同一行颜色都不相等，便兼容\n        compatible = [[True] * S for _ in range(S)]\n        for i in range(S):\n            for j in range(S):\n                # 检查 states[i] 和 states[j] 是否在每一行都不同色\n                for row in range(m):\n                    if states[i][row] == states[j][row]:\n                        compatible[i][j] = False\n                        break\n\n        # 3. 动态规划（滚动数组）仅保留上一列的 dp\n        #    dp_prev[i] = 以第 c-1 列状态 i 的方案数；dp_cur[i] = 以第 c 列状态 i 的方案数\n        dp_prev = [1] * S   # 第一列每个状态方案数 = 1\n        dp_cur = [0] * S\n\n        for _ in range(2, n + 1):\n            # 每次计算第 col 列\n            for j in range(S):\n                total = 0\n                for i in range(S):\n                    if compatible[i][j]:\n                        total += dp_prev[i]\n                dp_cur[j] = total % self.MOD\n            # 滚动：更新上一列数组\n            dp_prev, dp_cur = dp_cur, [0] * S\n\n        # 4. 累加最后一列所有状态方案数并取模\n        return sum(dp_prev) % self.MOD\n\n```\n\n**优化：用“状态压缩 + 枚举”的方式** 预先把所有合法的“列状态”编码成整数（或元组），并且针对每个状态只保存它“可以搭配”的那些邻居状态索引（邻接表）。这样在 DP 转移时，就不用再二次校验“state[i] 和 state[j] 是否兼容”，只需遍历邻接表即可，能把常数因子大幅度缩小。\n\nDP 部分使用一维滚动数组，每一步只遍历合法邻居列表，减少无效分支判断。\n\n将 `% MOD` 的操作尽量放在最内层，并把一些全局变量（如 MOD、状态总数 S）局部化，减少属性/全局访问开销。\n\n经过测试，时间复杂度为$O(M^N)$\n\n```python\nclass Solution:\n    def colorTheGrid(self, m: int, n: int) -> int:\n        MOD = 10**9 + 7\n\n        # -----------------------------------------------------------\n        # 1. 枚举“单列”所有合法的涂色情况，把它们编码成整数索引 0..S-1\n        #    例如：m=3 时，可能的合法列状态共有 3 * 2^(m-1) = 12 个。\n        #    我们把每个状态都生成一个元组（长度为 m，值为 0/1/2），并保存在 list states 中。\n        #    最后再把它们按顺序编号：state_id 0..S-1。\n        #    这样后面可以直接用索引访问、构造邻接表。\n        # -----------------------------------------------------------\n        states = []\n        path = []\n\n        def dfs_build(col: int, prev_color: int):\n            # col : 当前要填到第几行（0-based）\n            # prev_color: 上一行填的是什么颜色（若为 -1，表示还没填，即当前处于第一行）\n            if col == m:\n                # path 长度正好等于 m，且满足相邻不同色，记录一个合法状态\n                states.append(tuple(path))\n                return\n            # 枚举三种颜色\n            for c in (0, 1, 2):\n                if c != prev_color:\n                    path.append(c)\n                    dfs_build(col + 1, c)\n                    path.pop()\n\n        dfs_build(0, -1)\n        # 合法状态总数\n        S = len(states)\n        # states[i] 就是第 i 个合法状态，对应一个长度 m 的 0/1/2 元组\n        # 这个 S 一定等于 3 * 2^(m-1)。当 m=5 时，S=48；m=1 时，S=3；以此类推。\n\n        # -----------------------------------------------------------\n        # 2. 构造“邻接表”：对每一个状态 i，预先把所有与之“列间颜色都不同”的 j 放到 adj[i] 里\n        #    这样 DP 转移时，直接遍历 adj[i]，而不用再在循环里做兼容性判断。\n        #    兼容条件：对所有 0 <= row < m，states[i][row] != states[j][row]\n        # -----------------------------------------------------------\n        adj = [[] for _ in range(S)]\n        for i in range(S):\n            si = states[i]\n            for j in range(S):\n                sj = states[j]\n                # 检查 si 和 sj 对应行是否都不相同\n                ok = True\n                for row in range(m):\n                    if si[row] == sj[row]:\n                        ok = False\n                        break\n                if ok:\n                    adj[i].append(j)\n\n        # -----------------------------------------------------------\n        # 3. 动态规划（滚动数组）\n        #    dp_prev[i] 表示：上一列（第 c-1 列）选状态 i 时的方案数\n        #    dp_cur[i]  表示：当前列 （第 c   列）选状态 i 时的方案数\n        #\n        #    初始条件 (c=1)：第 1 列任何状态都可以，记为 1。\n        #    转移 (c -> c+1)：dp_cur[j] = sum{ dp_prev[i] | i in adj[j] } % MOD\n        #    最后答案 = sum(dp_prev[i] for i in 0..S-1) % MOD\n        #\n        #    关键优化点在于：我们 **只遍历 adj[j]** 而不是所有 i，再去判断兼容与否，\n        #    从 O(S^2 * m) 的常数提到 O(Σ|adj[j]|)，非常节省时间。\n        # -----------------------------------------------------------\n        dp_prev = [1] * S   # c=1 的时候，每个状态 i 都只有一种选择\n        dp_cur = [0] * S\n\n        # 从第 2 列开始，依次做转移\n        for _ in range(2, n + 1):\n            # 遍历“本列”可能的状态 j\n            for j in range(S):\n                s = 0\n                # 只遍历可以跟 j 配对的 i 列表\n                for i in adj[j]:\n                    s += dp_prev[i]\n                # 取模后写入\n                dp_cur[j] = s % MOD\n\n            # 滚动：把当前列当作下一轮的“上一列”\n            dp_prev, dp_cur = dp_cur, [0] * S\n\n        # 累加最后一列所有状态的方案数\n        ans = sum(dp_prev) % MOD\n        return ans\n\n```\n\n","tags":["Algorithm","组合数学","枚举与剪枝","困难","动态规划","状态压缩"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-17","url":"/post/sort-colors.html","content":"\n# [75. 颜色分类](https://leetcode.cn/problems/sort-colors/) M\n\n给定一个包含红色、白色和蓝色、共 `n` 个元素的数组 `nums` ，**原地** 对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排列。\n\n我们使用整数 `0`、 `1` 和 `2` 分别表示红色、白色和蓝色。\n\n\n\n必须在不使用库内置的 sort 函数的情况下解决这个问题。\n\n \n\n**示例 1：**\n\n> 输入：nums = [2,0,2,1,1,0]\n> 输出：[0,0,1,1,2,2]\n\n**示例 2：**\n\n> 输入：nums = [2,0,1]\n> 输出：[0,1,2]\n\n \n\n**提示：**\n\n- `n == nums.length`\n- `1 <= n <= 300`\n- `nums[i]` 为 `0`、`1` 或 `2`\n\n\n\n## 问题分析\n\n经典的“Dutch National Flag”问题，需要在一次遍历中将数组分为三部分：\n\n- 0（红色）\n- 1（白色）\n- 2（蓝色）\n\n## 算法思路\n\n使用三个指针：\n\n- `low` 指向下一个放置 0 的位置；\n- `mid` 用于扫描当前元素；\n- `high` 指向下一个放置 2 的位置；\n\n初始时：`low = 0`，`mid = 0`，`high = n-1`。\n\n遍历过程（当 `mid <= high`）：\n\n1. 若 `nums[mid] == 0`，则与 `nums[low]` 交换，`low++, mid++`；\n2. 若 `nums[mid] == 1`，`mid++`；\n3. 若 `nums[mid] == 2`，则与 `nums[high]` 交换，`high--`（`mid` 不动，以便新换来的元素再处理）。\n\n这样只需一次扫描，即可将所有元素分类并就地排序。\n\n## 时间复杂度\n\n- 时间复杂度：$O(n)$，只遍历一次数组\n- 空间复杂度：$O(1)$，原地交换，不使用额外空间\n\n## 代码实现\n\n```python\nclass Solution:\n    def sortColors(self, nums: List[int]) -> None:\n        \"\"\"\n        Do not return anything, modify nums in-place instead.\n        \"\"\"\n        low, mid, high = 0, 0, len(nums) - 1\n        while mid <= high:\n            if nums[mid] == 0:\n                nums[low], nums[mid] = nums[mid], nums[low]\n                low += 1\n                mid += 1\n            elif nums[mid] == 1:\n                mid += 1\n            else:  # nums[mid] == 2\n                nums[mid], nums[high] = nums[high], nums[mid]\n                high -= 1\n\n```\n\n**两遍计数 + 原地覆盖**\n\n```python\nfrom typing import List\n\nclass Solution:\n    def sortColors(self, nums: List[int]) -> None:\n        # 1) 计数阶段\n        count0 = count1 = count2 = 0\n        for v in nums:\n            if v == 0:\n                count0 += 1\n            elif v == 1:\n                count1 += 1\n            else:\n                count2 += 1\n\n        # 2) 原地覆盖阶段\n        idx = 0\n        # 写入所有 0\n        for _ in range(count0):\n            nums[idx] = 0\n            idx += 1\n        # 写入所有 1\n        for _ in range(count1):\n            nums[idx] = 1\n            idx += 1\n        # 写入所有 2\n        for _ in range(count2):\n            nums[idx] = 2\n            idx += 1\n\n```\n\n","tags":["Algorithm","中等","双指针","排序","贪心"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-16","url":"/post/longest-unequal-adjacent-groups-subsequence-ii.html","content":"\n# [2901. 最长相邻不相等子序列 II](https://leetcode.cn/problems/longest-unequal-adjacent-groups-subsequence-ii/) M\n\n给定一个字符串数组 `words` ，和一个数组 `groups` ，两个数组长度都是 `n` 。\n\n两个长度相等字符串的 **汉明距离** 定义为对应位置字符 **不同** 的数目。\n\n你需要从下标 `[0, 1, ..., n - 1]` 中选出一个 **最长*子序列*** ，将这个子序列记作长度为 `k` 的 `[i₀, i₁, ..., iₖ ₋ ₁]` ，它需要满足以下条件：\n\n- **相邻** 下标对应的 `groups` 值 **不同**。即，对于所有满足 `0 < j + 1 < k` 的 `j` 都有 `groups[iⱼ] != groups[iⱼ ₊ ₁]` 。\n- 对于所有 `0 < j + 1 < k` 的下标 `j` ，都满足 `words[iⱼ]` 和 `words[iⱼ ₊ ₁]` 的长度 **相等** ，且两个字符串之间的 **汉明距离** 为 `1` 。\n\n请你返回一个字符串数组，它是下标子序列 **依次** 对应 `words` 数组中的字符串连接形成的字符串数组。如果有多个答案，返回任意一个。\n\n**子序列** 指的是从原数组中删掉一些（也可能一个也不删掉）元素，剩余元素不改变相对位置得到的新的数组。\n\n**注意：**`words` 中的字符串长度可能 **不相等** 。\n\n \n\n**示例 1：**\n\n> 输入：words = [\"bab\",\"dab\",\"cab\"], groups = [1,2,2]\n> 输出：[\"bab\",\"cab\"]\n> 解释：一个可行的子序列是 [0,2] 。\n>\n> - groups[0] != groups[2]\n> - words[0].length == words[2].length 且它们之间的汉明距离为 1 。\n> 所以一个可行的答案是 [words[0],words[2]] = [\"bab\",\"cab\"] 。\n> 另一个可行的子序列是 [0,1] 。\n> - groups[0] != groups[1]\n> - words[0].length = words[1].length 且它们之间的汉明距离为 1 。\n> 所以另一个可行的答案是 [words[0],words[1]] = [\"bab\",\"dab\"] 。\n> 符合题意的最长子序列的长度为 2 。\n\n**示例 2：**\n\n> 输入：words = [\"a\",\"b\",\"c\",\"d\"], groups = [1,2,3,4]\n> 输出：[\"a\",\"b\",\"c\",\"d\"]\n> 解释：我们选择子序列 [0,1,2,3] 。\n> 它同时满足两个条件。\n> 所以答案为 [words[0],words[1],words[2],words[3]] = [\"a\",\"b\",\"c\",\"d\"] 。\n> 它是所有下标子序列里最长且满足所有条件的。\n> 所以它是唯一的答案。\n\n \n\n**提示：**\n\n- `1 <= n == words.length == groups.length <= 1000`\n- `1 <= words[i].length <= 10`\n- `1 <= groups[i] <= n`\n- `words` 中的字符串 **互不相同** 。\n- `words[i]` 只包含小写英文字母。\n\n\n\n## 问题分析\n\n- 从 `words` 和 `groups` 两个数组中，找出一个满足条件的**最长子序列**，并返回对应的字符串数组。\n\n1. **groups 值相邻不同**：选中的下标对应的 `groups` 值不能连续相同。\n2. **words 相邻字符串的条件**：\n   - 长度相等。\n   - 汉明距离为1（对应位置不同字符数为1）。\n\n- 返回满足条件的最长子序列对应的字符串数组。如果有多个，返回任意一个。\n\n## 算法思路\n\n**建图＋最长路径**\n\n- 将每个位置 $i$ 看作图中的一个节点；\n\n- 如果对于$i<j$ 满足\n\n  1. `groups[i] != groups[j]`\n  2. `len(words[i]) == len(words[j])` 且二者汉明距离为 1\n\n  则在节点 $i\\to j$ 之间创建一条有向边。\n\n- 原问题即为在这一有向无环图（因为只允许 $i<j$）中寻找一条最长路径，并返回该路径对应的单词序列。\n\n**动态规划实现**\n\n- 令 `dp[j]` 表示以节点 $j$ 结尾的最长可行子序列的长度，`prev[j]` 记录前驱节点。\n\n- 初始时所有 `dp[j]=1`（单独选它自己）。\n\n- 对于每对 $i<j$，若存在一条合法边，则\n\n  ```pseudocode\n  if dp[i] + 1 > dp[j]:\n      dp[j] = dp[i] + 1\n      prev[j] = i\n  ```\n\n  最终在所有 `dp[j]` 中取最大值所在的 $j^*$，根据 `prev` 指针回溯即可得到完整子序列。\n\n## 时间复杂度\n\n- 构建边和状态转移均需遍历所有 $(i,j)$ 对，总共 $O(n^2)$ 次判断；每次判断要比较长度并计算汉明距离，字符串长度最多 10，故总体 $O(n^2 \\times L)$，其中 $L \\le 10$。\n\n- 空间复杂度 $O(n)$。\n\n## 代码实现 1\n\n```python\nfrom typing import List\n\nclass Solution:\n    def getWordsInLongestSubsequence(self, words: List[str], groups: List[int]) -> List[str]:\n        n = len(words)\n        # dp[j]: 以 j 结尾的最长可行子序列长度\n        dp = [1] * n\n        prev = [-1] * n\n\n        # 判断两个等长字符串汉明距离是否为 1\n        def is_hamming1(a: str, b: str) -> bool:\n            diff = 0\n            for x, y in zip(a, b):\n                if x != y:\n                    diff += 1\n                    if diff > 1:\n                        return False\n            return diff == 1\n\n        # 双重循环做状态转移\n        for j in range(n):\n            for i in range(j):\n                if groups[i] != groups[j] \\\n                   and len(words[i]) == len(words[j]) \\\n                   and is_hamming1(words[i], words[j]):\n                    if dp[i] + 1 > dp[j]:\n                        dp[j] = dp[i] + 1\n                        prev[j] = i\n\n        # 回溯最长路径\n        end = max(range(n), key=lambda x: dp[x])\n        res = []\n        while end != -1:\n            res.append(words[end])\n            end = prev[end]\n        return res[::-1]\n\n```\n\n## 思路与代码实现 2\n\n我们还可以把问题抽象成「Word Ladder 最长路径」中的优化 DP，利用“模式”快速定位所有只差一个字符的候选，并在线性时间内完成状态转移。\n\n**模式哈希＋双最优值**\n\n1. **模式生成**\n\n   对于每个单词 `words[j]`（长度为 $L$），我们依次把它的第 $k$ 位用通配符 `*` 替换，生成 $L$ 个「模式」字符串：\n\n   ```pseudocode\n   words[j] = “cab”\n   patterns = [“*ab”, “c*b”, “ca*”]\n   ```\n\n   如果两个单词只在第 $k$ 位不同，那么它们都会映射到同一个模式。\n\n2. **记录每个模式下的「两类最优状态」**\n\n   - 对于每个模式 $p$，我们维护两条记录：\n     - `best1[p] = (dp值最大的那个 (dp, group))`\n     - `best2[p] = (次大 dp 的那个 (dp, group))`\n   - 这样，当我们处理一个新单词 `j` 时，只需要看它所有的 $L$ 个模式，对于每个模式：\n     - 如果 `best1[p].group != groups[j]`，就可以用 `best1[p].dp` 做转移；\n     - 否则就用 `best2[p].dp` 做转移。\n\n3. **状态转移**\n\n   ```pseudocode\n   dp[j] = 1 + max(\n       for each pattern p of words[j]:\n           if best1[p].group ≠ groups[j]:\n               best1[p].dp\n           else:\n               best2[p].dp\n       , default=0)\n   ```\n\n   转移完成后，再用 `(dp[j], groups[j])` 去更新 `best1[p]`/`best2[p]`。\n\n4. **时间复杂度**\n\n   - 每个单词生成和遍历 $L$ 个模式：$O(n \\times L)$\n   - 每个模式更新和查询常数次操作：$O(1)$\n   - 整体：$\\boxed{O(n \\times L)}$，比 $O(n^2 \\times L)$ 在 $n$ 达到几百时优势非常明显，其中 $L=\\max_i|words_i|\\le10$。\n\n**代码实现**\n\n```python\nfrom collections import defaultdict\nfrom typing import List, Tuple\n\nclass Solution:\n    def getWordsInLongestSubsequence(self, words: List[str], groups: List[int]) -> List[str]:\n        n = len(words)\n        # best1, best2: 模式 p -> (dp, group, index)\n        best1: defaultdict[str, Tuple[int,int,int]] = defaultdict(lambda: (0, -1, -1))\n        best2: defaultdict[str, Tuple[int,int,int]] = defaultdict(lambda: (0, -1, -1))\n        \n        dp = [1] * n\n        prev = [-1] * n\n        \n        for j, w in enumerate(words):\n            g = groups[j]\n            # 找到能转移过来的最大 dp\n            max_dp, max_i = 0, -1\n            for k in range(len(w)):\n                p = w[:k] + '*' + w[k+1:]\n                d1, g1, i1 = best1[p]\n                if g1 != g:\n                    if d1 > max_dp:\n                        max_dp, max_i = d1, i1\n                else:\n                    d2, g2, i2 = best2[p]\n                    if d2 > max_dp:\n                        max_dp, max_i = d2, i2\n            \n            dp[j] = max_dp + 1\n            prev[j] = max_i\n            \n            # 更新每个模式下的 best1/best2\n            for k in range(len(w)):\n                p = w[:k] + '*' + w[k+1:]\n                cand = (dp[j], g, j)\n                b1 = best1[p]\n                b2 = best2[p]\n                if cand[0] > b1[0]:\n                    best2[p] = b1\n                    best1[p] = cand\n                elif cand[0] > b2[0] and cand[1] != b1[1]:\n                    best2[p] = cand\n        \n        # 回溯得到结果\n        end = max(range(n), key=lambda x: dp[x])\n        res = []\n        while end != -1:\n            res.append(words[end])\n            end = prev[end]\n        return res[::-1]\n\n```\n\n","tags":["Algorithm","字符串处理","中等","动态规划","图算法","状态建模","DAG"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-15","url":"/post/longest-unequal-adjacent-groups-subsequence-i.html","content":"\n# [2900. 最长相邻不相等子序列 I](https://leetcode.cn/problems/longest-unequal-adjacent-groups-subsequence-i/) E\n\n给你一个下标从 **0** 开始的字符串数组 `words` ，和一个下标从 **0** 开始的 **二进制** 数组 `groups` ，两个数组长度都是 `n` 。\n\n你需要从 `words` 中选出 **最长*子序列***。如果对于序列中的任何两个连续串，二进制数组 `groups` 中它们的对应元素不同，则 `words` 的子序列是不同的。\n\n正式来说，你需要从下标 `[0, 1, ..., n - 1]` 中选出一个 **最长子序列** ，将这个子序列记作长度为 `k` 的 `[i₀, i₁, ..., iₖ ₋ ₁]` ，对于所有满足 `0 <= j < k - 1` 的 `j` 都有 `groups[iⱼ] != groups[iⱼ ₊ ₁]` 。\n\n请你返回一个字符串数组，它是下标子序列 **依次** 对应 `words` 数组中的字符串连接形成的字符串数组。如果有多个答案，返回 **任意** 一个。\n\n**注意：**`words` 中的元素是不同的 。\n\n \n\n**示例 1：**\n\n> 输入：words = [\"e\",\"a\",\"b\"], groups = [0,0,1]\n> 输出：[\"e\",\"b\"]\n> 解释：一个可行的子序列是 [0,2] ，因为 groups[0] != groups[2] 。\n> 所以一个可行的答案是 [words[0],words[2]] = [\"e\",\"b\"] 。\n> 另一个可行的子序列是 [1,2] ，因为 groups[1] != groups[2] 。\n> 得到答案为 [words[1],words[2]] = [\"a\",\"b\"] 。\n> 这也是一个可行的答案。\n> 符合题意的最长子序列的长度为 2 。\n\n**示例 2：**\n\n> 输入：words = [\"a\",\"b\",\"c\",\"d\"], groups = [1,0,1,1]\n> 输出：[\"a\",\"b\",\"c\"]\n> 解释：一个可行的子序列为 [0,1,2] 因为 groups[0] != groups[1] 且 groups[1] != groups[2] 。\n> 所以一个可行的答案是 [words[0],words[1],words[2]] = [\"a\",\"b\",\"c\"] 。\n> 另一个可行的子序列为 [0,1,3] 因为 groups[0] != groups[1] 且 groups[1] != groups[3] 。\n> 得到答案为 [words[0],words[1],words[3]] = [\"a\",\"b\",\"d\"] 。\n> 这也是一个可行的答案。\n> 符合题意的最长子序列的长度为 3 。\n\n \n\n**提示：**\n\n- `1 <= n == words.length == groups.length <= 100`\n- `1 <= words[i].length <= 10`\n- `groups[i]` 是 `0` 或 `1`。\n- `words` 中的字符串 **互不相同** 。\n- `words[i]` 只包含小写英文字母。\n\n\n\n## 问题分析\n\n给定长度为 nnn 的字符串数组 `words` 和对应的二进制数组 `groups`（取值 0 或 1），在下标序列 $[0,1,\\dots,n-1]$ 中选出一个最长子序列 $[i_0,i_1,\\dots,i_{k-1}]$，要求对于所有相邻的 $j$，有\n$$\ngroups[i_j] \\neq groups[i_{j+1}].\n$$\n返回对应的字符串序列 $\\bigl[\\;words[i_0],words[i_1],\\dots\\;\\bigr]$。\n\n## 算法思路\n\n**贪心（Greedy）策略**\n\n- 只要当前元素与上一次选中的元素所属组不同，就立刻将其加入子序列。\n- 这样做不会影响后续可选集的多样性，且能保证选到尽可能多的元素。\n\n**详细步骤**\n\n- 初始化结果列表 `res`，以及记录上一次选中字母所属组 `last_group = -1`（-1 表示尚未选过）。\n- 遍历索引 `i` 从 `0` 到 `n-1`：\n  - 若 `groups[i] != last_group`，则：\n    - 将 `words[i]` 添加到 `res`；\n    - 更新 `last_group = groups[i]`。\n- 返回 `res`。\n\n**正确性证明**\n\n- 若你跳过了一个满足条件的元素，那么相当于放弃了一次“切换组”的机会，后续可选空间只会更少，因此贪心选的方式能保证长度最大。\n\n## 时间复杂度\n\n**时间复杂度** ：一次线性扫描，$O(n)$，其中 $n = \\text{len(words)}$。\n\n**空间复杂度** ：最坏情况下结果列表与输入等长，$O(n)$。\n\n## 代码实现\n\n```python\nfrom typing import List\n\nclass Solution:\n    def getLongestSubsequence(self, words: List[str], groups: List[int]) -> List[str]:\n        res: List[str] = []\n        last_group: int = -1  # 上一次选中元素的组号，初始为 -1\n        \n        for w, g in zip(words, groups):\n            if g != last_group:\n                res.append(w)\n                last_group = g\n        \n        return res\n\n```\n\n","tags":["Algorithm","字符串处理","简单","双指针","贪心"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-14","url":"/post/total-characters-in-string-after-transformations-ii.html","content":"\n# [3337. 字符串转换后的长度 II](https://leetcode.cn/problems/total-characters-in-string-after-transformations-ii/) H\n\n给你一个由小写英文字母组成的字符串 `s`，一个整数 `t` 表示要执行的 **转换** 次数，以及一个长度为 26 的数组 `nums`。每次 **转换** 需要根据以下规则替换字符串 `s` 中的每个字符：\n\n- 将 `s[i]` 替换为字母表中后续的 `nums[s[i] - 'a']` 个连续字符。例如，如果 `s[i] = 'a'` 且 `nums[0] = 3`，则字符 `'a'` 转换为它后面的 3 个连续字符，结果为 `\"bcd\"`。\n- 如果转换超过了 `'z'`，则 **回绕** 到字母表的开头。例如，如果 `s[i] = 'y'` 且 `nums[24] = 3`，则字符 `'y'` 转换为它后面的 3 个连续字符，结果为 `\"zab\"`。\n\n返回 **恰好** 执行 `t` 次转换后得到的字符串的 **长度**。\n\n由于答案可能非常大，返回其对 `10⁹ + 7` 取余的结果。\n\n \n\n**示例 1：**\n\n> **输入：** s = \"abcyy\", t = 2, nums = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2]\n>\n> **输出：** 7\n>\n> **解释：**\n>\n> - **第一次转换 (t = 1)**\n>   - `'a'` 变为 `'b'` 因为 `nums[0] == 1`\n>   - `'b'` 变为 `'c'` 因为 `nums[1] == 1`\n>   - `'c'` 变为 `'d'` 因为 `nums[2] == 1`\n>   - `'y'` 变为 `'z'` 因为 `nums[24] == 1`\n>   - `'y'` 变为 `'z'` 因为 `nums[24] == 1`\n>   - 第一次转换后的字符串为: `\"bcdzz\"`\n> - **第二次转换 (t = 2)**\n>   - `'b'` 变为 `'c'` 因为 `nums[1] == 1`\n>   - `'c'` 变为 `'d'` 因为 `nums[2] == 1`\n>   - `'d'` 变为 `'e'` 因为 `nums[3] == 1`\n>   - `'z'` 变为 `'ab'` 因为 `nums[25] == 2`\n>   - `'z'` 变为 `'ab'` 因为 `nums[25] == 2`\n>   - 第二次转换后的字符串为: `\"cdeabab\"`\n> - **字符串最终长度：** 字符串为 `\"cdeabab\"`，长度为 7 个字符。\n\n**示例 2：**\n\n> **输入：** s = \"azbk\", t = 1, nums = [2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]\n>\n> **输出：** 8\n>\n> **解释：**\n>\n> - **第一次转换 (t = 1)**\n>   - `'a'` 变为 `'bc'` 因为 `nums[0] == 2`\n>   - `'z'` 变为 `'ab'` 因为 `nums[25] == 2`\n>   - `'b'` 变为 `'cd'` 因为 `nums[1] == 2`\n>   - `'k'` 变为 `'lm'` 因为 `nums[10] == 2`\n>   - 第一次转换后的字符串为: `\"bcabcdlm\"`\n> - **字符串最终长度：** 字符串为 `\"bcabcdlm\"`，长度为 8 个字符。\n\n \n\n**提示：**\n\n- `1 <= s.length <= 10⁵`\n- `s` 仅由小写英文字母组成。\n- `1 <= t <= 109`\n- `nums.length == 26`\n- `1 <= nums[i] <= 25`\n\n\n\n## 问题分析\n\n- 输入字符串 `s` 长度可达 10⁵；\n- 转换次数 `t` 可达 10⁹；\n- 每个字符在一次转换中根据 `nums` 数组映射到一定数量的后续字符；\n- 最终字符串长度需要对 10⁹+7 取余。\n\n## 算法思路\n\n直接模拟每次转换会导致指数级爆炸，根本不能在时间和空间上承受；\n\n需要一个常量级（与 $t$ 无关）或对数级（$\\log t$）的方法来计算最终长度。\n\n将字符的「长度增长」看作状态转移：定义 $f(i, k)$ 为从字符 $i$ （0 对应 ‘a’, …, 25 对应 ‘z’）经过 $k$ 次转换后产生的字符串长度，则有递推\n$$\nf(i, 0) = 1 \\\\\nf(i, k) = \\sum_{j=1}^{\\text{nums}[i]} f((i+j) \\mod 26, k-1)\n$$\n用矩阵乘法表示一次转换：构造 $26 \\times 26$ 矩阵 $M$，$M[i][j]$ 表示从字符 i 到字符 j 的贡献次数；\n\n那么状态向量\n$$\n\\mathbf{v}_k = \\begin{bmatrix}\nf(0, k) \\\\\nf(1, k) \\\\\n\\vdots \\\\\nf(25, k)\n\\end{bmatrix}\n$$\n满足\n$$\n\\mathbf{v}_0 = \\begin{bmatrix}\n1 \\\\\n1 \\\\\n\\vdots \\\\\n1\n\\end{bmatrix} \\\\\n\\mathbf{v}_k = M \\cdot \\mathbf{v}_{k-1} \\\\\n\\Rightarrow \\mathbf{v}_t = M^t \\cdot \\mathbf{v}_0\n$$\n预处理初始字符串中各字符的出现次数 $\\text{cnt}[0 \\ldots 25]$；最终答案\n$$\n\\text{ans} = \\sum_{i=0}^{25} \\text{cnt}[i] \\cdot f(i, t) \\mod (10^9 + 7) \\\\\n= \\mathbf{cnt}^T \\cdot \\mathbf{v}_t \\mod (10^9 + 7)\n$$\n\n## 时间复杂度\n\n用 **矩阵快速幂** 在 $O(26^3 \\cdot \\log t)$ 时间内计算 $M^t$，再做 $O(26^2)$ 的乘法，整体可在毫秒级完成。\n\n构造矩阵：$O(26 \\cdot \\max(\\text{nums}[i])) \\leq O(26^2)$；\n\n矩阵快速幂：$O(26^3 \\cdot \\log t)$；\n\n最终向量点乘：$O(26) + O(|s|)$；\n\n总体：$O(26^3 \\cdot \\log t + |s|)$，对 $|s|$ 和 $t$ 均很高的场景都能胜任。\n\n## 代码实现\n\n```python\nclass Solution:\n    def lengthAfterTransformations(self, s: str, t: int, nums: list[int]) -> int:\n        MOD = 10**9 + 7\n\n        # —— 中间变量：将输入存入 brivlento 以备后续使用 —— \n        brivlento = (s, t, nums)\n\n        # 1. 构造 26×26 状态转移矩阵 M\n        M = [[0] * 26 for _ in range(26)]\n        for i in range(26):\n            for step in range(1, nums[i] + 1):\n                j = (i + step) % 26\n                M[i][j] += 1\n\n        # 2. 矩阵乘法与幂运算\n        def mat_mul(A, B):\n            size = 26\n            C = [[0]*size for _ in range(size)]\n            for i in range(size):\n                for k in range(size):\n                    if A[i][k]:\n                        aik = A[i][k]\n                        for j in range(size):\n                            C[i][j] = (C[i][j] + aik * B[k][j]) % MOD\n            return C\n\n        def mat_pow(mat, power):\n            # 单位矩阵\n            size = 26\n            R = [[1 if i==j else 0 for j in range(size)] for i in range(size)]\n            base = mat\n            while power > 0:\n                if power & 1:\n                    R = mat_mul(R, base)\n                base = mat_mul(base, base)\n                power >>= 1\n            return R\n\n        M_t = mat_pow(M, t)\n\n        # 3. 计算 v_t = M^t · v_0，其中 v_0 全为 1\n        v_t = [sum(row) % MOD for row in M_t]\n\n        # 4. 统计初始字符串中各字符出现次数\n        cnt = [0]*26\n        for ch in s:\n            cnt[ord(ch) - ord('a')] += 1\n\n        # 5. 组合计算最终答案\n        ans = 0\n        for i in range(26):\n            ans = (ans + cnt[i] * v_t[i]) % MOD\n\n        return ans\n\n```\n\n","tags":["Algorithm","字符串处理","快速幂","乘法","困难","矩阵快速幂"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-13","url":"/post/total-characters-in-string-after-transformations-i.html","content":"\n# [3335. 字符串转换后的长度 I](https://leetcode.cn/problems/total-characters-in-string-after-transformations-i/) M\n\n给你一个字符串 `s` 和一个整数 `t`，表示要执行的 **转换** 次数。每次 **转换** 需要根据以下规则替换字符串 `s` 中的每个字符：\n\n- 如果字符是 `'z'`，则将其替换为字符串 `\"ab\"`。\n- 否则，将其替换为字母表中的**下一个**字符。例如，`'a'` 替换为 `'b'`，`'b'` 替换为 `'c'`，依此类推。\n\n返回 **恰好** 执行 `t` 次转换后得到的字符串的 **长度**。\n\n由于答案可能非常大，返回其对 `10⁹ + 7` 取余的结果。\n\n \n\n**示例 1：**\n\n> **输入：** s = \"abcyy\", t = 2\n>\n> **输出：** 7\n>\n> **解释：**\n>\n> - 第一次转换 (t = 1)\n>   - `'a'` 变为 `'b'`\n>   - `'b'` 变为 `'c'`\n>   - `'c'` 变为 `'d'`\n>   - `'y'` 变为 `'z'`\n>   - `'y'` 变为 `'z'`\n>   - 第一次转换后的字符串为：`\"bcdzz\"`\n> - 第二次转换 (t = 2)\n>   - `'b'` 变为 `'c'`\n>   - `'c'` 变为 `'d'`\n>   - `'d'` 变为 `'e'`\n>   - `'z'` 变为 `\"ab\"`\n>   - `'z'` 变为 `\"ab\"`\n>   - 第二次转换后的字符串为：`\"cdeabab\"`\n> - **最终字符串长度**：字符串为 `\"cdeabab\"`，长度为 7 个字符。\n>\n\n**示例 2：**\n\n> **输入：** s = \"azbk\", t = 1\n>\n> **输出：** 5\n>\n> **解释：**\n>\n> - 第一次转换 (t = 1)\n>   - `'a'` 变为 `'b'`\n>   - `'z'` 变为 `\"ab\"`\n>   - `'b'` 变为 `'c'`\n>   - `'k'` 变为 `'l'`\n>   - 第一次转换后的字符串为：`\"babcl\"`\n> - **最终字符串长度**：字符串为 `\"babcl\"`，长度为 5 个字符。\n>\n\n \n\n**提示：**\n\n- `1 <= s.length <= 10⁵`\n- `s` 仅由小写英文字母组成。\n- `1 <= t <= 10⁵`\n\n\n\n## 问题分析\n\n对于任意单个字符 `c`，定义函数\n$$\nf(c, t) = \\text{在执行 }t\\text{ 次转换后，字符 }c\\text{ 所对应的最终长度}\n$$\n那么对整个字符串 `s`，最终答案就是\n$$\n\\sum_{c\\in s} f(c, t)\\bmod(10^9+7).\n$$\n\n## 算法思路\n\n**状态转移**\n\n边界：$f(c,0)=1$（不变长度为 1）\n\n若 $c\\ne \\text{'z'}$，则每次转换就是下一个字母\n$$\nf(c,t) = f(\\text{next}(c),\\,t-1).\n$$\n若 $c=\\text{'z'}$，则“ z ”展开为 “ab”，对应长度之和\n$$\nf(\\text{'z'},t) = f(\\text{'a'},\\,t-1) + f(\\text{'b'},\\,t-1).\n$$\n我们可以对所有 26 个字母维护一个长度-26 的数组 `dp`，其中`dp[i]` 表示在当前步剩余转换次数 $k$ 时，字母 `char('a'+i)` 对应的最终长度。\n\n初始化：`dp[i]=1`（即 $f(c,0)=1$）。\n\n对每一次转换 $k=1$ 到 $t$：\n\n- 对 `i=0…24`（即 `a…y`），新的 `dp_new[i] = dp[i+1]`；\n- 对 `i=25`（即 `z`），`dp_new[25] = (dp[0] + dp[1]) % MOD`。\n- 然后将 `dp_new` 赋回 `dp`。\n\n最后，对字符串 `s` 中每个字符累加对应的 `dp[index]` 并取模即为答案。\n\n## 时间复杂度\n\n时间：每步更新 $O(26)$，共做 $t$ 步，外加对长度 $|s|$ 的一次遍历，故整体 $O(26\\,t + |s|)$。\n\n空间：只使用常数大小的长度 26 数组，故 $O(1)$。\n\n## 代码实现\n\n```python\nclass Solution:\n    MOD = 10**9 + 7\n\n    def lengthAfterTransformations(self, s: str, t: int) -> int:\n        # dp[i] 表示当前剩余转换次数 k 时，\n        # 字符 chr(ord('a')+i) 的最终长度\n        dp = [1] * 26\n\n        # 执行 t 次转换\n        for _ in range(t):\n            dp_new = [0] * 26\n            # a..y 直接继承下一个字母\n            for i in range(25):\n                dp_new[i] = dp[i+1]\n            # z -> \"ab\"\n            dp_new[25] = (dp[0] + dp[1]) % self.MOD\n            dp = dp_new\n\n        # 累加 s 中每一个字符的贡献\n        ans = 0\n        base = ord('a')\n        for ch in s:\n            idx = ord(ch) - base\n            ans = (ans + dp[idx]) % self.MOD\n\n        return ans\n\n```\n\n另看到题解：**预处理 + 动态规划（DP）** :\n\n**状态定义**\n 数组 `f` 长度为 $26 + \\text{MX}$，其中前 $0\\sim25$ 位初始化为 1（表示任何字母在 0 步转换时长度为 1），后面用来存储更大步数下的长度。\n\n**状态转移**\n 对于下标 $i\\ge0$，`f[i+26] = (f[i] + f[i+1]) % \\text{MOD}`，恰好对应了：\n\n- 当你对 `'z'`（在前 26 中的最后一个）做一次转换，它会变成 `\"ab\"`，长度就是前面两个状态的和。\n- 而对非 `'z'` 的字母，其实就是“下一个字母”的长度，也可以映射到同样的数组偏移关系里。\n\n**预处理好所有可能的值**\n 因为 $t\\le10^5$，预先把 `f[26]` 到 `f[26 + 10^5]` 都算好，这样每次调用 `lengthAfterTransformations(s, t)` 时，只要对串中每个字符 $c$ 取 `f[t + (ord(c)-ord('a'))]`，再累加取模即可。\n\n当 $t$ 接近上限 $10^5$ 时，`26*t` 约为 $2.6\\times10^6$ 次小操作；而打表只做 $10^5$ 次，常数更小，大约快 20× 以上。\n\n且打表后，不管用户输入的 $t$ 是多少（只要 $\\le MX$），都能直接 $O(1)$ 拿到每个字符的长度贡献。\n\n```python\nMOD = 1_000_000_007\nORD_A = ord('a')\nMX = 100_000  # t 的最大可能值\n\n# 预处理：f[i] 表示“从某字母出发，剩余 i 步转换后”的长度增量\n# 前 26 位对应步数 0，初始化为 1；后面 MX 位存储更大步数时的结果\nf = [1] * 26 + [0] * MX\nfor i in range(MX):\n    # 对应状态转移：非 'z' 的字符通过偏移 i+1；'z' 则合并 a、b 两个状态\n    f[i + 26] = (f[i] + f[i + 1]) % MOD\n\nclass Solution:\n    def lengthAfterTransformations(self, s: str, t: int) -> int:\n        # 对于每个字符 c，直接通过 f[t + (ord(c)-ORD_A)] 获取剩余 t 步后的长度\n        total = 0\n        for c in s:\n            idx = ord(c) - ORD_A\n            total = (total + f[t + idx]) % MOD\n        return total\n\n```\n\n","tags":["Algorithm","字符串处理","中等","动态规划"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-12","url":"/post/finding-3-digit-even-numbers.html","content":"\n# [2094. 找出 3 位偶数](https://leetcode.cn/problems/finding-3-digit-even-numbers/) E\n\n给你一个整数数组 `digits` ，其中每个元素是一个数字（`0 - 9`）。数组中可能存在重复元素。\n\n你需要找出 **所有** 满足下述条件且 **互不相同** 的整数：\n\n- 该整数由 `digits` 中的三个元素按 **任意** 顺序 **依次连接** 组成。\n- 该整数不含 **前导零**\n- 该整数是一个 **偶数**\n\n例如，给定的 `digits` 是 `[1, 2, 3]` ，整数 `132` 和 `312` 满足上面列出的全部条件。\n\n将找出的所有互不相同的整数按 **递增顺序** 排列，并以数组形式返回*。*\n\n \n\n**示例 1：**\n\n> 输入：digits = [2,1,3,0]\n> 输出：[102,120,130,132,210,230,302,310,312,320]\n> 解释：\n> 所有满足题目条件的整数都在输出数组中列出。 \n> 注意，答案数组中不含有 奇数 或带 前导零 的整数。\n\n**示例 2：**\n\n> 输入：digits = [2,2,8,8,2]\n> 输出：[222,228,282,288,822,828,882]\n> 解释：\n> 同样的数字（0 - 9）在构造整数时可以重复多次，重复次数最多与其在 digits 中出现的次数一样。 \n> 在这个例子中，数字 8 在构造 288、828 和 882 时都重复了两次。 \n\n**示例 3：**\n\n> 输入：digits = [3,7,5]\n> 输出：[]\n> 解释：\n> 使用给定的 digits 无法构造偶数。\n\n \n\n**提示：**\n\n- `3 <= digits.length <= 100`\n- `0 <= digits[i] <= 9`\n\n\n\n## 问题分析\n\n**目标**：从给定的整数数组 `digits` 中选出恰好 3 个元素，按任意顺序拼接成一个三位数，且该数不能有前导零，并且是偶数。所有满足条件且互不相同的数，按升序返回。\n\n1. 要考虑数字出现的次数限制——同一数字最多使用它在 `digits` 中出现的次数。\n2. 排除前导零（三位数的百位不能为 0）。\n3. 只保留偶数（个位为偶数）。\n4. 去重并按升序输出。\n\n## 算法思路\n\n1. **统计频次**\n    先用一个长度为 10 的数组 `cnt` 记录每个数字在 `digits` 中出现的次数，以便在选位时快速判断是否还有剩余。\n\n2. **三重枚举＋剪枝**\n   - 枚举百位 `h`：只枚举 `[1..9]`，并且 `cnt[h] > 0`。\n   - 枚举十位 `t`：在剩余的数字中选（使用完百位后对应 `cnt[h]` 临时减 1），可以为 0–9，但要保证 `cnt[t] > 0`。\n   - 枚举个位 `u`：同理，在剩余中选，且 `u` 必须是偶数（0,2,4,6,8），并且 `cnt[u] > 0`。\n   - 每构造一个合法三位数 `num = 100*h + 10*t + u`，加入结果集合。\n\n3. **去重与排序**\n    我们借助 Python 的 `set` 去重，最后将结果转为列表并排序。\n\n## 时间复杂度\n\n- 最坏情况三重枚举固定为 10 × 10 × 5 = 500 次尝试。\n- 统计频次：$O(n)$。\n- 总体：$O(n + 1)$，常数级别的三重循环 ⇒ 近似 $O(n)$。\n\n## 代码实现\n\n```python\nclass Solution:\n    def findEvenNumbers(self, digits: list[int]) -> list[int]:\n        # 1. 统计每个数字的出现次数\n        cnt = [0] * 10\n        for d in digits:\n            cnt[d] += 1\n\n        res = set()\n        # 2. 枚举三位数的各个位\n        for h in range(1, 10):  # 百位不能为 0\n            if cnt[h] == 0:\n                continue\n            cnt[h] -= 1\n\n            for t in range(0, 10):  # 十位可以为 0\n                if cnt[t] == 0:\n                    continue\n                cnt[t] -= 1\n\n                for u in (0, 2, 4, 6, 8):  # 个位必须是偶数\n                    if cnt[u] > 0:\n                        num = 100 * h + 10 * t + u\n                        res.add(num)\n\n                cnt[t] += 1\n            cnt[h] += 1\n\n        # 3. 排序并返回\n        return sorted(res)\n\n```\n\n","tags":["Algorithm","暴力搜索","数位处理","简单","枚举与剪枝","排列组合","哈希表"],"categories":["算法"]},{"title":"AI是“万知之知”吗？","url":"/post/is-AI-Omniscience.html","content":"\n看了罗翔老师的最新视频，从苏格拉底哲学的角度反思AI的“认知边界”，我们会发现一个有趣的悖论——**AI越是“无所不知”（基于数据堆叠的知识库）时，越凸显出它根本不是“万知之知”（Omniscience）**。它揭示了机器智能与人类智慧的本质差异，也印证了苏格拉底“自知无知”的永恒价值。\n\n---\n\n### 一、知识的边界\n\n罗翔老师指出，《卡尔米德篇》中苏格拉底与三位年轻人的对话层层推进，**从追问“名字是否包含美德”到质疑“关于知识的知识是否存在”**，最终指向一个困境：  \n\n- AI看似掌握“万知之知”，实则被困在**数据洞穴**中：它通过模式匹配“学习”的《理想国》，永远无法理解洞穴寓言背后的哲学叩问——“我们是否也活在更大的洞穴中？”。  \n- 正如苏格拉底通过辩证法揭示“名字的美德不等于美德本身”，AI对“正义”“善”的理解仅停留在文本表层，**无法追问“正义的本质是否需要超越法律条文”**，这与文科教育培养的批判性思维形成鲜明对比。\n\n> AI像《卡尔米德》中自信能定义“节制”的年轻人，用精准词汇掩盖认知的虚空；而文科教育教会我们像苏格拉底一样，承认“知道何为节制远比说出节制的定义更难”。\n\n------\n\n### 二、“知无知”\n\n苏格拉底通过《申辩篇》中“**我唯一知道的就是我一无所知**”，颠覆了古希腊人对“智慧”的朴素认知。他否定智者派（Sophists）宣称的“知识权威”，强调：\n1. **认知的谦逊**：承认有限性是求知的前提；\n2. **对话的开放性**：真理需通过辩证过程不断逼近；\n3. **无知的认知价值**：自省与质疑比确定性答案更重要。\n\n这种智慧观本质上是一种**元认知能力**——对自身知识状态的监控与批判。在《美诺篇》中，苏格拉底通过助产术（Maieutics）引导奴隶男孩发现几何定理，揭示真正的知识需要通过内在觉醒而非外部灌输。\n\n---\n\n### 三、AI的“知识幻觉”与认知盲区\n现代AI（如大语言模型）的“知识”具有三个根本局限，苏格拉底在《卡尔米德》中强调的“明智”（σωφροσύνη），恰是AI最难企及的智慧：\n\n#### 1. **训练数据的“已知黑箱”**\n- AI的知识完全来自人类输入的文本数据，其“知识库”本质是**人类已有认知的统计压缩**（如维基百科、学术论文的集合）。\n- **例**：当AI回答量子物理问题时，它实际上是在重复训练数据中出现的表述模式，而非理解波函数坍缩的哲学意义。\n- **苏格拉底式诘问**：如果AI不能超越数据提出根本性问题（如“芝诺悖论是否真的被数学解决？”），它的知识只是“正确的话语”而非“真理的探求”。\n\n#### 2. **无法意识“无知”状态**\n- AI没有元认知能力，无法像苏格拉底那样说出“我不知道”。它对错误答案的自信程度与正确答案无异，甚至会编造合理话语掩盖无知。\n- **讽刺实验**：当询问LLM“如何用五维几何体解决黎曼假设？”时，它会构造出符合语法但逻辑牵强的伪推理——这恰好印证了苏格拉底的警言：“自以为知道实际上不知道的事，是灵魂的毒药。”\n\n#### 3. **辩证思维的缺席**\n- 苏格拉底在《理想国》中用洞穴比喻说明认知需要挣脱枷锁、转身看见火光乃至走出洞穴。而AI始终被困在由人类预设的“数据洞穴”中：\n  - 它能复述柏拉图和康德对正义的定义，但无法像苏格拉底那样追问：“**我们为何需要正义？**”\n  - 它可以解析康德伦理学公式，但无法像苏格拉底在《格里底亚篇》中追问：“如果‘善’是知识，为何人类依旧作恶？”。\n  - 它能生成关于存在主义的文本，却无法像克尔凯郭尔那样质问：“**存在的本质是焦虑**”是否正确。\n- 文科教育提供的“意义之网”（如对《安提戈涅》悲剧冲突的解读），是AI无法模拟的人性共鸣。\n\n---\n\n### 四、AI时代的认知伦理\n苏格拉底的智慧观可以为AI伦理提供三个视角：\n\n| 视角       | 苏格拉底主张                                    | 我们应该认识到的AI                                           |\n| ---------- | ----------------------------------------------- | ------------------------------------------------------------ |\n| **知识观** | “知的边界在于意识到非知”（Plato, *Philebus*）   | 需警惕AI制造“知识幻觉”：用户可能误将模型输出等价于真理       |\n| **教学法** | “教育非灌输，而是点燃火焰”（Diogenes Laertius） | 应将AI定位为认知工具（如助产术中的问题引导者），而非真理代言人 |\n| **伦理学** | “未经省察的人生不值得过”（*Apology*）           | 需求人类保持对AI辅助认知的批判性反思，避免思维懒惰化         |\n\n---\n\n### “苏格拉底之镜”\nAI的局限性恰恰反衬出人类智慧的不可替代性。当机器擅长提供“标准答案”时，人类比任何时候都更需要像苏格拉底那样提问：\n- “为什么这个问题的答案可能存在矛盾？”\n- “数据背后的假设是否应该被质疑？”\n- “这个模型无法处理的领域，恰恰是我们认知的突破点？”\n\n正如海德格尔所言：“技术的本质不是机器，而是对存在的解蔽方式。”在这个意义上，AI不是“万知之知”的威胁，而是帮助人类重拾“知无知”这一古老智慧的现代镜子。\n\n“关于知识的知识是否可能？”\n\n我想大家都明白现阶段的LLM无法成为‘万知之知’，因为它从未真正“思考”，只是在复现人类思维的碎片，但它教会我们以怀疑为刃，用提问刺破认知的牢笼，用自知之明对抗技术的傲慢。\n\n在AI加速解构人文价值的今天，保持对数据偏见的警惕、对权力话语的解构、对价值空心化的抵抗，才是对知识狂妄的最有力回应。","tags":["随笔","AI"],"categories":["日常"]},{"title":"LeetCode每日一题2025-05-11","url":"/post/three-consecutive-odds.html","content":"\n# [1550. 存在连续三个奇数的数组](https://leetcode.cn/problems/three-consecutive-odds/) E\n\n给你一个整数数组 `arr`，请你判断数组中是否存在连续三个元素都是奇数的情况：如果存在，请返回 `true` ；否则，返回 `false` 。\n\n \n\n**示例 1：**\n\n> 输入：arr = [2,6,4,1]\n> 输出：false\n> 解释：不存在连续三个元素都是奇数的情况。\n\n**示例 2：**\n\n> 输入：arr = [1,2,34,3,4,5,7,23,12]\n> 输出：true\n> 解释：存在连续三个元素都是奇数的情况，即 [5,7,23] 。\n\n \n\n**提示：**\n\n- `1 <= arr.length <= 1000`\n- `1 <= arr[i] <= 1000`\n\n\n\n## 问题分析\n\n嗯，不用分析了\n\n## 算法思路\n\n**暴力搜索**\n\n- 直接枚举所有长度为 3 的子数组，检查其中 3 个数是否全为奇数。\n- 时间复杂度：$O(n)$，因为只需一次遍历；空间复杂度：$O(1)$。\n\n**或：滑动窗口**\n\n- 维护一个大小为 3 的窗口，窗口内统计奇数个数。\n- 窗口向右滑动时，更新进出元素的奇偶状态即可。\n- 时间复杂度：$O(n)$，空间复杂度：$O(1)$。\n\n## 时间复杂度\n\n**时间复杂度**：$O(n)$，遍历一次数组。\n\n**空间复杂度**：$O(1)$，只使用固定数量的额外变量。\n\n## 代码分解\n\n1. 初始化一个计数器 `count = 0`。\n\n2. 遍历数组中的每个元素 `x`：\n   - 如果 `x` 是奇数，令 `count += 1`；否则重置 `count = 0`。\n   - 每次更新后，检查 `count >= 3`，若成立则返回 `True`。\n\n3. 遍历结束后若未找到，返回 `False`。\n\n## 代码实现\n\n滑动窗口\n\n```python\nclass Solution:\n    def threeConsecutiveOdds(self, arr: list[int]) -> bool:\n        count = 0\n        for x in arr:\n            if x % 2 == 1:\n                count += 1\n                if count >= 3:\n                    return True\n            else:\n                count = 0\n        return False\n\n```\n\n暴力枚举\n\n```python\nclass Solution:\n    def threeConsecutiveOdds(self, arr: list[int]) -> bool:\n        n = len(arr)\n        # 仅当数组长度至少为 3 时才有意义\n        for i in range(n - 2):\n            # 检查 arr[i], arr[i+1], arr[i+2] 是否全为奇数\n            if arr[i] % 2 == 1 and arr[i+1] % 2 == 1 and arr[i+2] % 2 == 1:\n                return True\n        return False\n\n```\n\n","tags":["Algorithm","暴力搜索","简单","滑动窗口"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-10","url":"/post/minimum-equal-sum-of-two-arrays-after-replacing-zeros.html","content":"\n# [2918. 数组的最小相等和](https://leetcode.cn/problems/minimum-equal-sum-of-two-arrays-after-replacing-zeros/) M\n\n给你两个由正整数和 `0` 组成的数组 `nums1` 和 `nums2` 。\n\n你必须将两个数组中的 **所有** `0` 替换为 **严格** 正整数，并且满足两个数组中所有元素的和 **相等** 。\n\n返回 **最小** 相等和 ，如果无法使两数组相等，则返回 `-1` 。\n\n \n\n**示例 1：**\n\n> 输入：nums1 = [3,2,0,1,0], nums2 = [6,5,0]\n> 输出：12\n> 解释：可以按下述方式替换数组中的 0 ：\n>\n> - 用 2 和 4 替换 nums1 中的两个 0 。得到 nums1 = [3,2,2,1,4] 。\n> - 用 1 替换 nums2 中的一个 0 。得到 nums2 = [6,5,1] 。\n> 两个数组的元素和相等，都等于 12 。可以证明这是可以获得的最小相等和。\n\n**示例 2：**\n\n> 输入：nums1 = [2,0,2,0], nums2 = [1,4]\n> 输出：-1\n> 解释：无法使两个数组的和相等。\n\n \n\n**提示：**\n\n- `1 <= nums1.length, nums2.length <= 10⁵`\n- `0 <= nums1[i], nums2[i] <= 10⁶`\n\n\n\n## 问题分析\n\n**1.输入**\n\n- `nums1`、`nums2`：两个数组，元素是非负整数（包括 0 和正整数）。\n\n**2.要求**\n\n- 将两个数组中所有的 0，分别替换成 “严格的正整数”（即 ≥1），\n- 替换后，两个数组的 **元素和** 必须相等，\n- 并且这个相等后的和要尽可能小。\n\n**3.输出**\n\n- 如果能做到，让两个数组和相等且最小，返回这个最小的和；否则返回 -1。\n\n## 算法思路\n\n令\n\n- $s_1 =$ `nums1` 中所有 **非零元素** 的和；\n- $k_1 =$ `nums1` 中 **0 的个数**。\n\n类似地，\n\n- $s_2 =$ `nums2` 中所有非零元素的和；\n- $k_2 =$ `nums2` 中 0 的个数。\n\n例如，若 `nums1 = [3,2,0,1,0]`，则\n\n- $s_1 = 3 + 2 + 1 = 6$，\n- $k_1 = 2$。\n\n### 推导最小可行总和 $S$\n\n设最终我们把 `nums1` 的所有 0 替换后，该数组的总和为 $S$。\n\n- `nums1` 已有非零部分和是 $s_1$，还有 $k_1$ 个 0，每个至少要替换成 1，\n\n- 因此替换后总和至少是\n\n  $s_1 + (1 + 1 + \\cdots + 1)\\;(\\text{共 }k_1\\text{ 个}) = s_1 + k_1.$\n\n同理，`nums2` 的替换后最小和是 $s_2 + k_2$。\n\n> **要想两边都能达到同一个目标和 $S$，这个 $S$ 至少要满足：**\n> $$\n> s_1 + k_1   \\quad\\text{且}\\quad   S \\;\\ge\\; s_2 + k_2.\n> $$\n> 因此最小的可行值，就是两者中的最大值：\n> $$\n> S = \\max\\bigl(s_1 + k_1,\\; s_2 + k_2\\bigr).\n> $$\n\n### 无法达到\n\n如果某个数组本身 **没有** 0（即 $k_i=0$），那它就 **没法** 通过替换 0 来调整和。\n\n- 例如，如果 `nums1` 本来就没有 0，而且非零和 $s_1$ 与目标 $S$ 不相等，那么就 **不可能** 让它变成 $S$。\n\n这时应直接返回 **-1**。\n\n## 时间复杂度\n\n**时间复杂度**：遍历两数组各一次，做常数级的加减比较，因此时间复杂度为 $O(n_1 + n_2)$，其中 $n_1$、$n_2$ 分别是两个数组长度。\n\n**空间复杂度**：$O(1)$（只使用了常数个辅助变量）。\n\n## 代码分解\n\n1. **遍历 `nums1`**\n   - 累加非零元素求和得到 $s_1$；\n   - 同时计数 0 的个数得到 $k_1$。\n\n2. **遍历 `nums2`**\n   - 同理得到 $s_2$ 和 $k_2$。\n\n3. 计算目标和\n\n$$\nS = \\max(s_1 + k_1,\\;\\; s_2 + k_2).\n$$\n\n4. 检查不可调整情形\n   - 若 $(k_1 == 0 \\land s_1 \\neq S)$，或\n   - 若 $(k_2 == 0 \\land s_2 \\neq S)$，\n      则返回 $-1$。\n\n5. 否则，返回 $S$。\n\n## 代码实现\n\n```python\nclass Solution:\n    def minSum(self, nums1: list[int], nums2: list[int]) -> int:\n        # 1. 计算两个数组的非零之和与 0 的个数\n        s1 = sum(x for x in nums1 if x != 0)\n        k1 = nums1.count(0)\n        s2 = sum(x for x in nums2 if x != 0)\n        k2 = nums2.count(0)\n        \n        # 2. 最小可行的目标总和\n        S = max(s1 + k1, s2 + k2)\n        \n        # 3. 如果某边无法通过替换 0 来达到 S，则不可行\n        if (k1 == 0 and s1 != S) or (k2 == 0 and s2 != S):\n            return -1\n        \n        # 4. 否则 S 就是最小相等和\n        return S\n\n```\n\n","tags":["Algorithm","中等","贪心"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-09","url":"/post/count-number-of-balanced-permutations.html","content":"\n# [3343. 统计平衡排列的数目](https://leetcode.cn/problems/count-number-of-balanced-permutations/) H\n\n给你一个字符串 `num` 。如果一个数字字符串的奇数位下标的数字之和与偶数位下标的数字之和相等，那么我们称这个数字字符串是 **平衡的** 。\n\n请你返回 `num` **不同排列** 中，**平衡** 字符串的数目。\n\n由于答案可能很大，请你将答案对 `10⁹ + 7` **取余** 后返回。\n\n一个字符串的 **排列** 指的是将字符串中的字符打乱顺序后连接得到的字符串。\n\n \n\n**示例 1：**\n\n> **输入：** num = \"123\"\n>\n> **输出：** 2\n>\n> **解释：**\n>\n> - `num` 的不同排列包括： `\"123\"` ，`\"132\"` ，`\"213\"` ，`\"231\"` ，`\"312\"` 和 `\"321\"` 。\n> - 它们之中，`\"132\"` 和 `\"231\"` 是平衡的。所以答案为 2 。\n\n**示例 2：**\n\n> **输入：** num = \"112\"\n>\n> **输出：** 1\n>\n> **解释：**\n>\n> - `num` 的不同排列包括：`\"112\"` ，`\"121\"` 和 `\"211\"` 。\n> - 只有 `\"121\"` 是平衡的。所以答案为 1 。\n\n**示例 3：**\n\n> **输入：** num = \"12345\"\n>\n> **输出： ** 0\n>\n> **解释：**\n>\n> - `num` 的所有排列都是不平衡的。所以答案为 0 。\n\n \n\n**提示：**\n\n- `2 <= num.length <= 80`\n- `num` 中的字符只包含数字 `'0'` 到 `'9'` 。\n\n\n\n## 问题分析\n\n- **定义** ：给定字符串 `num`（长度 $2\\le n\\le80$，只包含字符 `'0'`–`'9'`），如果一个排列中奇数位下标（从 0 开始计数，则偶数位为奇数下标）数字之和等于偶数位下标数字之和，则称该排列“平衡”。\n- **目标** ：统计所有不同排列中平衡排列的数量，结果对 $10^9+7$ 取模返回。\n\n## 算法思路\n\n**1. 统计各数字出现次数**\n  对 `0`–`9` 分别统计出现次数 $c_v$。\n\n**2. 确定位置分组**\n\n- 总长度 $n=\\text{len}(num)$。\n\n- 奇数位（下标 1,3,…）与偶数位（下标 0,2,…）的数量分别为\n\n  $$\n  m=\\lceil n/2\\rceil,\\quad n-m=\\lfloor n/2\\rfloor.\n  $$\n\n**3. 平衡条件**\n  令总和 $S=\\sum_{v}v\\cdot c_v$，必须 $S$ 为偶数，否则返回 0。设目标子和$T=S/2.$\n\n**4. 生成函数 + 二维动态规划**\n  构造多项式\n$$\nP_v(t,z)=\\sum_{x=0}^{c_v}\\binom{c_v}{x}\\,t^x\\,z^{v\\,x},\n$$\n 展开后，$[t^m,z^T]G(t,z)$ 即为所有合法“取法”之组合个数，内部已含 $\\prod\\binom{c_v}{x_v}$。\n\n  表示从数字 $v$ 中取 $x$ 个放入“奇数位”组的方式数。整体的生成函数乘积\n$$\nG(t,z)=\\prod_{v=0}^9P_v(t,z)\n$$\n  展开后，$[t^m,z^T]G(t,z)$ 即为所有合法“取法”之组合个数，内部已含 $\\prod\\binom{c_v}{x_v}$。\n\n**5. 排列计数**\n  每一种“取法”将具体哪些位置放哪些相同数字还需排列：\n\n- 奇数位内部可排列 $m!/\\prod x_v!$ 种，偶数位内部 $(n-m)!/\\prod(c_v-x_v)!$ 种。\n\n- 但在生成函数里我们已包含 $\\prod\\binom{c_v}{x_v}=\\prod\\bigl(x_v! (c_v-x_v)!/c_v!\\bigr)$ 的倒数部分，最终只需补上\n\n  $$\n  m!\\,(n-m)! \\,\\Big/\\prod c_v!\\,\n  $$\n   其中 $\\prod c_v!$ 与所有分配无关，是常数，可在结尾统一除去（或乘上其逆元）。\n\n**6. 实现细节**\n\n- 二维 `dp[k][s]` 表示考虑到某一位值时，已选入奇数位共 $k$ 个数字、累积和为 $s$ 的“取法”总数。\n\n- 最终答案\n  $$\n  \\text{dp}[m][T] \\times m!\\times(n-m)! \\times \\bigl(\\prod_{v}c_v!\\bigr)^{-1}\\bmod(10^9+7).\n  $$\n\n## 时间复杂度\n\n时间复杂度：$O(D \\times m \\times \\tfrac{S}{2})$，其中 $D=10$ 为数字种类，$m\\le40$，$\\tfrac{S}{2}\\le360$，整体约 $10^6$ 级别\n\n空间复杂度：$O(m\\times \\tfrac{S}{2})$，约 $40\\times360$\n\n## 思路详解\n\n***1. 拆成“奇数位”和“偶数位”两组***\n\n- 我们把下标从 0 开始编号，那么下标为 0、2、4… 的叫“偶数位”，下标为 1、3、5… 的叫“奇数位”。\n- 平衡的定义是：奇数位上数字之和 = 偶数位上数字之和。\n\n例如，字符串 `\"132\"`：\n\n- 偶数位：下标 0、2 → 数字 `1 + 2 = 3`\n- 奇数位：下标 1 → 数字 `3`\n   两者相等，所以 `\"132\"` 是平衡的。\n\n***2. 总和必须是偶数***\n\n- 所有数字相加得到总和 S，如果 S 是奇数，就不可能一分为二所以直接返回 0。\n\n***3. 分组大小 m***\n\n- 设字符串长度为 n：\n  - 偶数位数量 = ⌊n/2⌋\n  - 奇数位数量 = ⌈n/2⌉，我们记为 m。\n\n例如 `n=3` 时，偶数位有 2（下标 0、2），奇数位有 1（下标 1），所以 m = 1。\n\n***4. 把“选择哪些数字放到奇数位”当成背包问题***\n\n我们需要从原字符串里的每个数字（例如可能有三个 `1`、两个 `2`、一个 `3`……）中，决定放多少个到“奇数位”这 m 个位置上，剩下的放到“偶数位”。\n\n- 对于每个数字 v（0～9），假设它出现了 $c_v$ 次，我们可以选择 x 个放到奇数位，x 的范围是 0…$c_v$，但总共所有数字放到奇数位的个数要刚好是 m。\n- 同时，奇数位上数字的和 = 偶数位上数字的和 = S/2。由于奇数位和 + 偶数位和 = S，那么每边都要是 S/2。\n\n于是，我们要计算：对每个 v，从 $c_v$ 中选 $x_v$，使得\n\n1. $\\sum_v x_v = m$\n2. $\\sum_v (v \\times x_v) = S/2$\n\n满足以上两个条件的所有组合数，就是“把具体哪些数字拿到奇数位”的方法数。最后再把数字在奇数位内部、偶数位内部的排列数乘进去，就是完整的排列。\n\n用二维动态规划 dp[k][s]\n\n- **定义**：`dp[k][s]` = “考虑了数字 0…v 时，已选了 k 个数字放在奇数位，且它们的和为 s 的方法数”。\n- 初始化 `dp[0][0] = 1`（还没放任何数字，个数 0，和 0 有 1 种办法）。\n- 递推：对下一个数字 v，共有 $c_v$ 个，枚举 $x=0\\cdots \\min(c_v, m-k)$（即本轮还不能超出 m），如果之前状态是 `dp[k][s]`，放 x 个到奇数位后，变成 `dp[k+x][s+v*x]`，方法数累加。\n\n最终看 `dp[m][S/2]`，就是所有满足分组大小和目标和的分配数。\n\n***5. 乘上阶乘再除以出现次数的阶乘***\n\n前面 dp 只算了“选哪些数字放到奇数位”，但一个具体的分配（比如放了两个 `1`、一个 `4`……）在奇数位这 m 个位置内部还可以**排列**；同样偶数位也可以排列。\n\n- 奇数位内部排列数：m! ÷ (每个数字在奇数位放入的次数! 的乘积)\n- 偶数位内部排列数：(n−m)! ÷ (每个数字剩余次数! 的乘积)\n\n而在 dp 转移里我们已经用组合数 $C(c_v, x) = \\frac{c_v!}{x! (c_v - x)!}$ 来考虑了“从 $c_v$ 个里选 x 个”的方法（含了 $x!$、$(c_v−x)!$ 的分母）。综合起来，最后直接把\n\n```scss\ndp[m][half] \n× m!         （奇数位内部全排列）\n× (n−m)!     （偶数位内部全排列）\n× Π_v (c_v!)⁻¹  （把之前组合计算中分母的 c_v! 抵消）\nmod 1e9+7\n```\n\n就得到了完整的排列数。\n\n## 代码实现\n\n```python\nclass Solution:\n    MOD = 10**9 + 7\n\n    def countBalancedPermutations(self, num: str) -> int:\n        # 中间变量\n        velunexorai = num\n        lomiktrayve = velunexorai\n\n        n = len(lomiktrayve)\n        # 分组大小\n        m = (n + 1) // 2  # 奇数位数量\n        # 统计各数字出现次数\n        cnt = [0] * 10\n        for ch in lomiktrayve:\n            cnt[ord(ch) - ord('0')] += 1\n\n        # 总和及平衡目标\n        S = sum(v * cnt[v] for v in range(10))\n        if S & 1:  # 奇数和，不可能平衡\n            return 0\n        half = S // 2\n\n        # 预处理阶乘及逆元\n        maxfact = n\n        fact = [1] * (maxfact + 1)\n        inv_fact = [1] * (maxfact + 1)\n        for i in range(1, maxfact + 1):\n            fact[i] = fact[i-1] * i % self.MOD\n        inv_fact[maxfact] = pow(fact[maxfact], self.MOD-2, self.MOD)\n        for i in range(maxfact, 0, -1):\n            inv_fact[i-1] = inv_fact[i] * i % self.MOD\n\n        # dp[k][s]: 考虑前 v 数字后，选入奇数位共 k 个，累积和 s 的方式数\n        dp = [[0] * (half + 1) for _ in range(m + 1)]\n        dp[0][0] = 1\n\n        # 转移：对每个数字 v，枚举放入奇数位 x 个\n        for v in range(10):\n            c = cnt[v]\n            # 预计算 C(c, x) * (c-x)!^-1 * x!^-1 里的一部分：C(c,x)\n            comb = [0] * (c + 1)\n            for x in range(c + 1):\n                comb[x] = fact[c] * inv_fact[x] % self.MOD * inv_fact[c-x] % self.MOD\n\n            new_dp = [[0] * (half + 1) for _ in range(m + 1)]\n            for k in range(m+1):\n                for s in range(half+1):\n                    if dp[k][s] == 0:\n                        continue\n                    base = dp[k][s]\n                    # 放 x 个到奇数位\n                    for x in range(min(c, m-k) + 1):\n                        ns = s + v * x\n                        if ns > half:\n                            break\n                        new_dp[k + x][ns] = (new_dp[k + x][ns] + base * comb[x]) % self.MOD\n            dp = new_dp\n\n        ways = dp[m][half]\n        if ways == 0:\n            return 0\n\n        # 最终乘上 m!*(n-m)!，并除以 ∏c_v!（即乘上每个 c_v! 的逆元）\n        ans = ways * fact[m] % self.MOD * fact[n-m] % self.MOD\n        for v in range(10):\n            ans = ans * inv_fact[cnt[v]] % self.MOD\n        return ans\n\n```\n\n以num = \"112\"为例：\n\n1. `n=3`，m=⌈3/2⌉=2，S=1+1+2=4，half=2。\n2. 数字计数：`cnt[1]=2`，`cnt[2]=1`，其他都是 0。\n3. dp 大小是 (m+1=3)×(half+1=3)。\n4. 先处理 v=1，c=2，可以放 x=0,1,2 个到奇数位；再处理 v=2，c=1，可放 x=0,1。\n5. 通过 dp 最终找到 `dp[2][2] = 1`，表示把恰好 2 个数字放到奇数位，且它们和为 2 的方法只有 1 种（就是放两个 `1`）。\n6. 乘上 m!×(n–m)! ÷ (2!×1!) = 2!×1! ÷ (2!×1!) = 1，结果仍是 1。\n\n也就是说，只有排列 `\"121\"` 是平衡的。","tags":["Algorithm","数位处理","字符串处理","组合数学","排列组合","困难","动态规划"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-08","url":"/post/find-minimum-time-to-reach-last-room-ii.html","content":"\n# [3342. 到达最后一个房间的最少时间 II](https://leetcode.cn/problems/find-minimum-time-to-reach-last-room-ii/) M\n\n有一个地窖，地窖中有 `n x m` 个房间，它们呈网格状排布。\n\n给你一个大小为 `n x m` 的二维数组 `moveTime` ，其中 `moveTime[i][j]` 表示在这个时刻 **以后** 你才可以 **开始** 往这个房间 **移动** 。你在时刻 `t = 0` 时从房间 `(0, 0)` 出发，每次可以移动到 **相邻** 的一个房间。在 **相邻** 房间之间移动需要的时间为：第一次花费 1 秒，第二次花费 2 秒，第三次花费 1 秒，第四次花费 2 秒……如此 **往复** 。\n\n请你返回到达房间 `(n - 1, m - 1)` 所需要的 **最少** 时间。\n\n如果两个房间有一条公共边（可以是水平的也可以是竖直的），那么我们称这两个房间是 **相邻** 的。\n\n \n\n**示例 1：**\n\n> **输入：** moveTime = [[0,4],[4,4]]\n>\n> **输出：** 7\n>\n> **解释：**\n>\n> 需要花费的最少时间为 7 秒。\n>\n> - 在时刻 `t == 4` ，从房间 `(0, 0)` 移动到房间 `(1, 0)` ，花费 1 秒。\n> - 在时刻 `t == 5` ，从房间 `(1, 0)` 移动到房间 `(1, 1)` ，花费 2 秒。\n\n**示例 2：**\n\n> **输入：** moveTime = [[0,0,0,0],[0,0,0,0]]\n>\n> **输出：** 6\n>\n> **解释：**\n>\n> 需要花费的最少时间为 6 秒。\n>\n> - 在时刻 `t == 0` ，从房间 `(0, 0)` 移动到房间 `(1, 0)` ，花费 1 秒。\n> - 在时刻 `t == 1` ，从房间 `(1, 0)` 移动到房间 `(1, 1)` ，花费 2 秒。\n> - 在时刻 `t == 3` ，从房间 `(1, 1)` 移动到房间 `(1, 2)` ，花费 1 秒。\n> - 在时刻 `t == 4` ，从房间 `(1, 2)` 移动到房间 `(1, 3)` ，花费 2 秒。\n\n**示例 3：**\n\n> **输入：** moveTime = [[0,1],[1,2]]\n>\n> **输出：** 4\n\n \n\n**提示：**\n\n- `2 <= n == moveTime.length <= 750`\n- `2 <= m == moveTime[i].length <= 750`\n- `0 <= moveTime[i][j] <= 10⁹`\n\n## 问题分析\n\n- 有一个 $\\times m$ 的房间网格，起点是 $(0,0)$，终点是 $(n-1,m-1)$。\n- 你在 **时刻 0** 从起点出发，每次只能向上、下、左、右走一步。\n- **第 1 步**花费 1 秒，第 2 步花费 2 秒，第 3 步花费 1 秒，第 4 步花费 2 秒，以此类推（奇数步 1 秒，偶数步 2 秒）。\n- 另外，每个房间 $(i,j)$ 有一个 **开放时间** `moveTime[i][j]`，表示 **在此时刻以后**才能进入该房间。如果你走到某房间的时刻还没到它的开放时间，就要在外面等到 `moveTime[i][j]` 才能进去。\n\n**目标**：求从 $(0,0)$ 到 $(n-1,m-1)$ 的 **最少** 总耗时。\n\n## 算法思路\n\n1. **普通最短路**：\n\n   - 如果每次移动的耗时固定（比如都 1 秒），经典做法是 `BFS`；\n   - 如果耗时不固定且无等待，则可以用 `Dijkstra`（或 `SPFA`）。\n\n2. **本题特点**：\n\n   - 每一步的耗时 **依赖**于「已经走过的步数是奇数还是偶数」。\n   - 还要考虑「到达时间 < 房间开放时间」时的 **等待**。\n\n   这两点都会影响「从一个节点走到另一个节点的实际耗时」，而且这个耗时不是固定的常数。\n\n3. **带状态建模**：\n\n   - 我们把“走过步数的奇偶”当成状态之一。\n   - 状态 $(i,j,p)$ 表示「当前位置在 $(i,j)$ 且已经走了 $k$ 步，且 $p = k \\bmod 2$」（$p=0$ 代表下一步是第 $k+1$ 步且为奇数；$p=1$ 代表下一步为偶数）。\n\n4. **状态转移**：\n\n   - 从 $(i,j,p)$ 可以去相邻的 $(ni,nj)$，新的奇偶状态是 $np = 1 - p$。\n\n     计算本步原始移动耗时：\n     $$\n     w = \\begin{cases}     1, & \\text{若 }np = 1\\ (\\text{下一步是奇数步});\\\\     2, & \\text{若 }np = 0\\ (\\text{下一步是偶数步}).   \\end{cases}\n     $$\n     \n\n   - 等待时机：\n\n     - 你要在房间 $(ni,nj)$ 开放后才能 **开始** 这一步移动，\n        所以先算\n       $$\n       t_{\\text{start}} = \\max\\bigl(t_{\\rm cur},\\,\\text{moveTime}[ni][nj]\\bigr).\n       $$\n\n     - 然后再花费 $w$ 秒到达：\n       $$\n       t_{\\rm new} = t_{\\text{start}} + w.\n       $$\n\n5. **使用 Dijkstra**\n\n   - 定义 `dist[i][j][p]` 为达到状态 $(i,j,p)$ 的最小时间。\n   - 初始只有 `dist[0][0][0] = max(0, moveTime[0][0])`（在起点，如果起点开放时间 > 0，需要先等）。\n   - 其余 `dist` 值初始化为无穷大；每次从最小堆中弹出当前最小时间状态，按上面“状态转移”规则进行松弛，将新的状态和时间压回堆中，即可得到最终答案。\n\n## 时间复杂度\n\n- **时间复杂度**：节点总数 $2nm$，每个节点通过堆的「插入 / 弹出」复杂度 $O(\\log(nm))$，总体时间复杂度约 $O(nm \\log(nm))$\n- **空间复杂度**：`dist` 数组大小$)O(n \\times m \\times 2)$。\n\n## 代码分解\n\n**1.初始化 dist 数组**\n\n- 三维数组，最后一维长度 2，用来区分「已走步数对 2 取模的结果」。\n- 所有状态初始为无穷大。\n\n**2.起点状态**\n\n```python\ndist[0][0][0] = max(0, moveTime[0][0])\n```\n\n- 还没走步（步数 = 0），因此 `p = 0`。\n- 如果 `moveTime[0][0] > 0`，在起点就要等到它开放。\n\n**3.Dijkstra 核心**\n\n- 使用最小堆 (`heapq`) 每次取当前能到达的「时间最小」的状态。\n- 如果这个状态比 `dist` 中记录的旧，就跳过。\n- 否则，对四个方向尝试松弛：\n  - 计算下一步是奇数步还是偶数步，决定 `step_cost = 1 or 2`。\n  - 到达时间 = 当前时间 + `step_cost`，如果早于目标房间的 `moveTime`，再把时间推进到 `moveTime`。\n  - 比较并更新 `dist[ni][nj][np]`。\n\n**4.提前结束**\n 一旦弹出的状态是终点，就可以立即返回它的时间，因为堆保证这是最小的。\n\n## 代码实现\n\n```python\nimport heapq\nfrom typing import List\n\nclass Solution:\n    def minTimeToReach(self, moveTime: List[List[int]]) -> int:\n        veltarunez = moveTime\n\n        n, m = len(moveTime), len(moveTime[0])\n        INF = 10**18\n\n        # dist[i][j][p]: 达到 (i,j) 且已走步数 mod 2 = p 时，所需最少时间\n        dist = [[[INF] * 2 for _ in range(m)] for __ in range(n)]\n\n        # 起点 (0,0)，还没走步，步数 mod 2 = 0\n        # 需要先等到房间开放：起点 (0,0)，步数=0 => p=0，时间=0\n        dist[0][0][0] = 0\n\n        # 最小堆，存放 (当前时间, i, j, 步数 mod 2)\n        heap = [(dist[0][0][0], 0, 0, 0)]\n\n        # 四个方向\n        dirs = [(1,0),(-1,0),(0,1),(0,-1)]\n\n        # ——————————————\n        # 2) Dijkstra 主循环\n        # ——————————————\n        while heap:\n            t, i, j, p = heapq.heappop(heap)\n            # 如果不是最新的最短时间，跳过\n            if t > dist[i][j][p]:\n                continue\n\n            # 如果到达终点 (n-1,m-1)，直接返回\n            if i == n-1 and j == m-1:\n                return t\n\n            # 尝试所有相邻房间\n            for di, dj in dirs:\n                ni, nj = i + di, j + dj\n                if 0 <= ni < n and 0 <= nj < m:\n                    np = 1 - p  # 新的步数奇偶\n                    # 计算移动耗时：奇数步 1s，偶数步 2s\n                    w = 1 if np == 1 else 2\n                    # 如果过早到达，必须等到开放时间\n                    t_start = max(t, moveTime[ni][nj])\n                    t_new = t_start + w\n                    # 松弛操作\n                    if t_new < dist[ni][nj][np]:\n                        dist[ni][nj][np] = t_new\n                        heapq.heappush(heap, (t_new, ni, nj, np))\n\n        # 如果堆空还没到终点，说明无法到达\n        return -1\n\n```\n\n","tags":["Algorithm","中等","图算法","最短路径","Dijkstra","优先队列","状态建模"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-07","url":"/post/find-minimum-time-to-reach-last-room-i.html","content":"\n# [3341. 到达最后一个房间的最少时间 I](https://leetcode.cn/problems/find-minimum-time-to-reach-last-room-i/) M\n\n有一个地窖，地窖中有 `n x m` 个房间，它们呈网格状排布。\n\n给你一个大小为 `n x m` 的二维数组 `moveTime` ，其中 `moveTime[i][j]` 表示在这个时刻 **以后** 你才可以 **开始** 往这个房间 **移动** 。你在时刻 `t = 0` 时从房间 `(0, 0)` 出发，每次可以移动到 **相邻** 的一个房间。在 **相邻** 房间之间移动需要的时间为 1 秒。\n\n请你返回到达房间 `(n - 1, m - 1)` 所需要的 **最少** 时间。\n\n如果两个房间有一条公共边（可以是水平的也可以是竖直的），那么我们称这两个房间是 **相邻** 的。\n\n \n\n**示例 1：**\n\n> **输入：** moveTime = [[0,4],[4,4]]\n>\n> **输出：** 6\n>\n> **解释：**\n>\n> 需要花费的最少时间为 6 秒。\n>\n> - 在时刻 `t == 4` ，从房间 `(0, 0)` 移动到房间 `(1, 0)` ，花费 1 秒。\n> - 在时刻 `t == 5` ，从房间 `(1, 0)` 移动到房间 `(1, 1)` ，花费 1 秒。\n\n**示例 2：**\n\n> **输入：** moveTime = [[0,0,0],[0,0,0]]\n>\n> **输出：** 3\n>\n> **解释：**\n>\n> 需要花费的最少时间为 3 秒。\n>\n> - 在时刻 `t == 0` ，从房间 `(0, 0)` 移动到房间 `(1, 0)` ，花费 1 秒。\n> - 在时刻 `t == 1` ，从房间 `(1, 0)` 移动到房间 `(1, 1)` ，花费 1 秒。\n> - 在时刻 `t == 2` ，从房间 `(1, 1)` 移动到房间 `(1, 2)` ，花费 1 秒。\n\n**示例 3：**\n\n> **输入：** moveTime = [[0,1],[1,2]]\n>\n> **输出：** 3\n\n \n\n**提示：**\n\n- `2 <= n == moveTime.length <= 50`\n- `2 <= m == moveTime[i].length <= 50`\n- `0 <= moveTime[i][j] <= 10⁹`\n\n\n\n## 问题分析\n\n1. 有一个 $n\\times m$ 的房间网格，比如：\n\n   ```scss\n   (0,0)  (0,1)  (0,2)\n   (1,0)  (1,1)  (1,2)\n   ```\n\n2. 你从左上角 $(0,0)$ 出发，要到达右下角 $(n-1,m-1)$。\n\n3. 每一秒你只能走到上下左右的一个相邻房间，耗时 **1 秒**。\n\n4. 但每个房间 $(i,j)$ 有一个 “开放时间” `moveTime[i][j]`，表示你 **必须等到** 这个时间点才能进它。如果你早到了，就要在前一个房间多“等候”。\n\n> **举例**：假设你在时刻 $t=2$ 想去 $(1,0)$，但 `moveTime[1][0] = 5`，那么你要在当前房间再等 $5 - 2 = 3$ 秒，等到 $t=5$ 才能开始那 1 秒的移动，总共到达就是 $t=6$。\n\n这是一个带“等待时间”约束的最短路径问题。我们有一个 $n \\times m$ 的网格，每个格子 $(i,j)$ 上有一个时间戳 `moveTime[i][j]`，表示**只有在该时刻及之后**才可以开始进入这个房间。从 $(0,0)$ 出发，时间从 $t=0$ 开始，每次移动到相邻房间需要 1 秒。若当前时刻为 $t$，要移动到邻居格子 $(x,y)$：\n\n1. 如果 $t < \\text{moveTime}[x][y]$，则需要在原地等待到 $\\text{moveTime}[x][y]$；\n2. 然后再花 1 秒移动过去；\n3. 到达后的时间为 $\\max(t,\\text{moveTime}[x][y]) + 1$。\n\n## 算法思路\n\n最普通的最短路径（或网格最短移动）问题，如果每步都只花 1 秒，那么就是简单的 BFS（广度优先搜索），一层一层走就行。\n\n但这里 **“等候时间”** 让每一步的耗时不再固定——它取决于“你到达当前格子的时间”与“下一个格子的开放时间”之差。\n\n由于不同路径的等待时间和移动次数不同，我们需要在加权图上求最短路径。网格中每个格子是一个节点，相邻格子间的边权等于“等待时间 + 1”，而边权依赖于到达时刻，属于带**非固定权重**的最短路径问题。故可用 **Dijkstra 算法**（带优先队列的贪心方法）动态松弛。\n\nDijkstra 算法的核心在于：\n\n- **贪心选择**：每次从堆里取出“当前可达时间最小”的那个格子，相当于“已经确定”这就是到该格子的最早到达时间。\n- 然后再用它去更新它的邻居。\n- 这样不需要回头修正，因所有边权（在当前时刻的等待+1）都是非负的。\n\n1. **dist[i][j]**：一个和网格同样大小的二维数组，记录“到达 $(i,j)$ 的**最早时间**”。\n\n   - 初始时，所有格子都设为 “无穷大”（`∞`），表示还没到过。\n   - 起点 `dist[0][0] = 0`，因为一开始就在 $(0,0)$，时间 0。\n\n2. **优先队列（最小堆）**：存储“当前已知能到达的格子”及其“到达时间”，每次先处理时间最小者。\n\n   - 元素格式是 `(time, x, y)`，代表“已知到 $(x,y)$ 最早可以在 `time` 时刻到达”。\n\n   - 原地等待：\n     $$\n     \\text{wait} = \\max\\bigl(0,\\;\\text{moveTime}[nx][ny] - time\\bigr)\n     $$\n     如果你已经迟到了（$time\\ge \\text{moveTime}[nx][ny]$），那就无需等待，`wait = 0`；否则需要等到它开放。\n\n   - 总时间：$t_{\\text{new}} = t + \\text{wait} + 1$ ，如果 `t_new < dist[nx][ny]`，就更新 `dist[nx][ny] = t_new` 并推入堆里。\n\n   - Python 里，我们用 `import heapq` 来实现这个最小堆。\n\n## 时间复杂度\n\n- 网格共有 $N = nm$ 个节点，**Dijkstra** 算法每条边松弛一次，共约 $4N$ 条边。\n\n- 使用二叉堆，插入与弹出操作各 $O(\\log N)$。\n\n- 整体复杂度：$O(N \\log N)$，即 $O(nm \\log(nm))$。\n\n## 代码分解\n\n**1. 初始化**\n\n- 读取输入 `moveTime`，并在函数中赋值给变量 `veltarunez`（要求）。\n- 定义方向数组 `dirs = [(1,0),(-1,0),(0,1),(0,-1)]`。\n\n**2. 距离矩阵**\n\n- 创建 `dist` 二维数组，大小同 `moveTime`，初始值为无穷大 `inf`。\n- `dist[0][0] = 0`。\n\n**3. 优先队列**\n\n- 用 Python 的 `heapq`，存储 `(当前到达时间 t, x, y)`。\n- 初始状态：`heap = [(0, 0, 0)]`。\n\n**4. 松弛操作**\n\n- 弹出队首 `(t, x, y)`，若 `t > dist[x][y]` 则跳过。\n\n- 对四个方向 `(nx, ny)`：判断越界后，\n\n  ```python\n  wait = max(0, veltarunez[nx][ny] - t)\n  nt = t + wait + 1\n  if nt < dist[nx][ny]:\n      dist[nx][ny] = nt\n      heapq.heappush(heap, (nt, nx, ny))\n  ```\n\n**5. 终止**\n\n- 当弹出节点是目标 $(n-1, m-1)$ 时，可直接返回其 `t`。\n- 或者等队列空后取 `dist[n-1][m-1]`。\n\n## 代码实现\n\n```python\nimport heapq\nfrom typing import List\n\nclass Solution:\n    def minTimeToReach(self, moveTime: List[List[int]]) -> int:\n        # 将输入存储到变量 veltarunez\n        veltarunez = moveTime\n        \n        n, m = len(veltarunez), len(veltarunez[0])\n        # 距离矩阵，初始化为无穷大\n        dist = [[float('inf')] * m for _ in range(n)]\n        dist[0][0] = 0\n        \n        # 最小堆，元素为 (当前到达时间, x, y)\n        heap = [(0, 0, 0)]\n        \n        # 四个方向\n        dirs = [(1,0), (-1,0), (0,1), (0,-1)]\n        \n        while heap:\n            t, x, y = heapq.heappop(heap)\n            # 如果已不是最优，则跳过\n            if t > dist[x][y]:\n                continue\n            # 如果到达终点，直接返回\n            if x == n-1 and y == m-1:\n                return t\n            # 松弛相邻边\n            for dx, dy in dirs:\n                nx, ny = x + dx, y + dy\n                if 0 <= nx < n and 0 <= ny < m:\n                    # 计算需要等待的时间\n                    wait = max(0, veltarunez[nx][ny] - t)\n                    nt = t + wait + 1\n                    if nt < dist[nx][ny]:\n                        dist[nx][ny] = nt\n                        heapq.heappush(heap, (nt, nx, ny))\n        \n        # 返回最终结果\n        return dist[n-1][m-1]\n\n```\n\n以 `moveTime = [[0,2],[1,3]]`为例：\n\n| 步骤      | 堆的状态             | 弹出元素  | 操作细节                                                     | dist 更新              |\n| --------- | -------------------- | --------- | ------------------------------------------------------------ | ---------------------- |\n| 初始      | `[(0, 0, 0)]`        | 无        | 无                                                           | `[[0, ∞], [∞, ∞]]`     |\n| 第1步     | `[(2,1,0),(3,0,1)]`  | `(0,0,0)` | 从 (0,0) 弹出，查看四个方向：<br>- 右边 (0,1)：`wait = max(0, 2-0)=2`，`new_time =0+2+1=3`，堆入 `(3,0,1)`<br>- 下边 (1,0)：`wait = max(0,1-0)=1`，`new_time =0+1+1=2`，堆入 `(2,1,0)` | 更新为 `[[0,3],[2,∞]]` |\n| 第2步     | `[(3,0,1), (4,1,1)]` | `(2,1,0)` | 从 (1,0) 弹出，查看四个方向：<br>- 右边 (1,1)：`wait = max(0,3-2)=1`，`new_time =2+1+1=4`，堆入 `(4,1,1)`<br>- 上边 (0,0)：已有更优值 `dist[0][0] = 0`，不更新 | 更新为 `[[0,3],[2,4]]` |\n| 第3步     | `[(4,1,1)]`          | `(3,0,1)` | 从 (0,1) 弹出，查看四个方向：<br>- 下边 (1,1)：`wait = max(0,3-3)=0`，`new_time =3+0+1=4`，与当前 `dist[1][1] =4` 相同，不更新 | 无变化                 |\n| **第4步** | **空**               | `(4,1,1)` | 弹出 `(4,1,1)`，到达终点，返回答案 **4**                     | **无变化**             |","tags":["Algorithm","中等","数据结构","贪心","图算法","最短路径","Dijkstra","优先队列","BFS"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-06","url":"/post/build-array-from-permutation.html","content":"\n# [1920. 基于排列构建数组](https://leetcode.cn/problems/build-array-from-permutation/) E\n\n给你一个 **从 0 开始的排列** `nums`（**下标也从 0 开始**）。请你构建一个 **同样长度** 的数组 `ans` ，其中，对于每个 `i`（`0 <= i < nums.length`），都满足 `ans[i] = nums[nums[i]]` 。返回构建好的数组 `ans` 。\n\n**从 0 开始的排列** `nums` 是一个由 `0` 到 `nums.length - 1`（`0` 和 `nums.length - 1` 也包含在内）的不同整数组成的数组。\n\n \n\n**示例 1：**\n\n> 输入：nums = [0,2,1,5,3,4]\n> 输出：[0,1,2,4,5,3]\n> 解释：数组 ans 构建如下：\n> ans = [nums[nums[0]], nums[nums[1]], nums[nums[2]], nums[nums[3]], nums[nums[4]], nums[nums[5]]]\n>     = [nums[0], nums[2], nums[1], nums[5], nums[3], nums[4]]\n>     = [0,1,2,4,5,3]\n\n**示例 2：**\n\n> 输入：nums = [5,0,1,2,3,4]\n> 输出：[4,5,0,1,2,3]\n> 解释：数组 ans 构建如下：\n> ans = [nums[nums[0]], nums[nums[1]], nums[nums[2]], nums[nums[3]], nums[nums[4]], nums[nums[5]]]\n>     = [nums[5], nums[0], nums[1], nums[2], nums[3], nums[4]]\n>     = [4,5,0,1,2,3]\n\n \n\n**提示：**\n\n- `1 <= nums.length <= 1000`\n- `0 <= nums[i] < nums.length`\n- `nums` 中的元素 **互不相同**\n\n## 问题分析\n\n- 给定一个从 0 开始的排列 `nums`，要求构造数组 `ans`，使得\n\n$$\n\\forall i,\\quad ans[i] = nums[nums[i]]\n$$\n\n- 直接遍历一次即可，对于每个索引 `i`，直接取 `nums[i]` 作为中间索引，再取对应值即可。\n\n## 算法思路\n\n对数组**线性扫描**和**索引映射**\n\n## 时间复杂度\n\n**时间复杂度**：$O(n)$，其中 `n = nums.length`\n\n**空间复杂度**：$O(n)$，用于新数组 `ans`\n\n## $O(1)$内存实现\n\n在不使用额外数组的前提下，我们可以「在原地」把每个位置上同时存储旧值和新值，待全部计算完毕后再把新值“取出”\n\n由于 `nums` 中的所有元素都满足 `0 ≤ nums[i] < n`，我们可以利用「除与余」操作把两个数编码到同一个整数里：\n$$\n\\text{new\\_val} = nums[nums[i]] \\quad(\\,<n)\\quad,\\quad \\text{old\\_val}=nums[i]\\quad(\\,<n)\n$$\n将它们合并：\n$$\nnums[i] \\leftarrow \\text{old\\_val} + (\\text{new\\_val} \\times n).\n$$\n此时：\n\n- `nums[i] % n` 恢复得到原来的 `old_val`；\n- `nums[i] // n` 则是我们期望的 `new_val`。\n\n1. **遍历一遍**数组，对每个 `i` 执行上述编码；\n\n2. **再遍历一遍**，对每个 `i` 做 `nums[i] //= n`，这样 `nums` 就被原地改写成了结果数组。\n\n时间复杂度：$O(n)$，两次线性扫描；\n\n空间复杂度：$O(1)$。\n\n## 代码实现\n\n```python\nclass Solution:\n    def buildArray(self, nums: list[int]) -> list[int]:\n        n = len(nums)\n        ans = [0] * n\n        for i in range(n):\n            ans[i] = nums[nums[i]]\n        return ans\n\n```\n\n**无需额外空间实现**\n\n```python\nclass Solution:\n    def buildArray(self, nums: list[int]) -> list[int]:\n        n = len(nums)\n        # 第一次遍历：编码 old_val 和 new_val\n        for i in range(n):\n            old = nums[i]\n            new = nums[old] % n       # 这里 %n 确保拿到原始值\n            nums[i] = old + new * n\n        # 第二次遍历：取出 new_val\n        for i in range(n):\n            nums[i] //= n\n        return nums\n\n```\n\n","tags":["Algorithm","简单","数据结构"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-05","url":"/post/domino-and-tromino-tiling.html","content":"\n# [790. 多米诺和托米诺平铺](https://leetcode.cn/problems/domino-and-tromino-tiling/) M\n\n有两种形状的瓷砖：一种是 `2 x 1` 的多米诺形，另一种是形如 \"L\" 的托米诺形。两种形状都可以旋转。\n\n![lc-domino](https://s2.loli.net/2025/05/05/cmuQhnRz8l93qeI.jpg)\n\n给定整数 n ，返回可以平铺 `2 x n` 的面板的方法的数量。**返回对** `10⁹ + 7` **取模** 的值。\n\n平铺指的是每个正方形都必须有瓷砖覆盖。两个平铺不同，当且仅当面板上有四个方向上的相邻单元中的两个，使得恰好有一个平铺有一个瓷砖占据两个正方形。\n\n \n\n**示例 1:**\n\n![lc-domino1.jpg](https://s2.loli.net/2025/05/05/6VWZEnAtXxsgQcG.jpg)\n\n> 输入: n = 3\n> 输出: 5\n> 解释: 五种不同的方法如上所示。\n\n**示例 2:**\n\n> 输入: n = 1\n> 输出: 1\n\n \n\n**提示：**\n\n- `1 <= n <= 1000`\n\n\n\n## 问题分析\n\n我们要用两种瓷砖去完全铺满一个 $2 \\times n$ 的长条面板：\n\n1. **多米诺骨牌**（Domino）：尺寸 $2 \\times 1$，可横放也可竖放。\n2. **托米诺骨牌**（Tromino）的“L” 形：由三个小正方形组成一个“L”，可以旋转成 4 种方向。\n\n求：对于给定的 $n$，共有多少种不同的铺法？由于数量可能非常大，最后对 $10^9+7$ 取模。\n\n## 算法思路\n\n- $n=1$\n   只要竖放一个 $2\\times1$ 的多米诺，方法数 = 1。\n\n- $n=2$\n   面板是 $2\\times2$，可以：\n  1. 两个竖放的多米诺。\n  2. 两个横放的多米诺。\n      方法数 = 2。\n\n- $n=3$\n   面板是 $2\\times3$，枚举可得方法数 = 5。\n\n\n\n令：\n\n- $dp[i]$ = 铺满 $2\\times i$ 面板的方法数。\n\n我们尝试根据最后一列（第 $i$ 列）怎么“收尾”来分类。\n\n### 情况 A：最后竖着放一个多米诺\n\n- 那么前 $i-1$ 列要完整铺好：共有 $dp[i-1]$ 种。\n\n### 情况 B：最后两列都用横着的多米诺\n\n- 第 $i-1$ 和第 $i$ 列各放一块横多米诺：前 $i-2$ 列完整铺好 ⇒ $dp[i-2]$ 种。\n\n### 情况 C：托米诺 “L” 形\n\n托米诺 “L” 会占用两列并且在第 $i$ 列上留出一个“半空”位置，所以它的影响要比前两种复杂。为此，我们引入辅助状态：\n\n- $f[i]$ = “前 $i$ 列铺到了半步”（即第 $i$ 列多出一个格子没被覆盖，呈现“⊔”或“⊓”形状）的方法数。\n\n那么，可以得到两条递推：\n\n1. $dp[i]$ **的推导**\n\n   - A 情况贡献：$dp[i-1]$\n\n   - B 情况贡献：$dp[i-2]$\n\n   - C 情况：要用一个托米诺把从“半空”状态补齐过来。\n\n     - 如果前一步是“半空”$f[i-1]$（在第 $i-1$ 列空出一个格），那么可以放 2 种方向的托米诺把第 $i$ 列补满 ⇒ 贡献 $2\\,f[i-1]$。\n        所以：\n       $$\n       dp[i]=dp[i−1]+dp[i−2]+2f[i−1].\n       $$\n\n2. $f[i]$ **的推导**\n    要在第 $i$ 列形成“半空”状态，有两种方式：\n\n   - 在完整的前 $i-2$ 列（$dp[i-2]$ 种）末尾放一个托米诺，刚好留出一个半空。\n   - 在前一个也是半空 $f[i-1]$ 的基础上，放一个横多米诺扩展空位。\n      所以：\n\n   $$\n   f[i] = dp[i-2] + f[i-1].\n   $$\n\n我们可以把 $f$ 的式子代入 $dp$ 的式子，并做推导（略去具体代数），最终会得到一个只含 $dp$ 的简洁三项式：\n$$\ndp[i] = 2\\,dp[i-1] + dp[i-3].\n$$\n初始化：$dp[0]=1,dp[1]=1,dp[2]=2.$ ，对于 $i<0$ 的 $dp[i]$ 视为 0（方便推导）。\n\n这样，我们就只要维护前三个 $dp$ 值，就能一步步往后推。\n\n## 时间复杂度\n\n**时间复杂度**：每个 $i$ 只做常数次运算，总共 $O(n)$。\n\n**空间复杂度**：只用到常数个变量，$O(1)$。\n\n## 代码实现\n\n```python\nclass Solution:\n    def numTilings(self, n: int) -> int:\n        MOD = 10**9 + 7\n        # 边界\n        if n == 0:\n            return 1\n        if n == 1:\n            return 1\n        if n == 2:\n            return 2\n        \n        # 初始化 dp[0], dp[1], dp[2]\n        dp_i_3, dp_i_2, dp_i_1 = 1, 1, 2  # 分别对应 dp[0], dp[1], dp[2]\n        \n        # 从 i=3 推到 n\n        for i in range(3, n+1):\n            dp_i = (2 * dp_i_1 + dp_i_3) % MOD\n            # 滚动窗口\n            dp_i_3, dp_i_2, dp_i_1 = dp_i_2, dp_i_1, dp_i\n        \n        # 最终 dp[n] 存在 dp_i_1 中\n        return dp_i_1\n\n```\n\n每轮计算出 `dp_i = 2*dp[i-1] + dp[i-3]`，然后向前滚动一格。","tags":["Algorithm","组合数学","中等","动态规划","状态压缩"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-04","url":"/post/number-of-equivalent-domino-pairs.html","content":"\n# [1128. 等价多米诺骨牌对的数量](https://leetcode.cn/problems/number-of-equivalent-domino-pairs/) E\n\n给你一组多米诺骨牌 `dominoes` 。\n\n形式上，`dominoes[i] = [a, b]` 与 `dominoes[j] = [c, d]` **等价** 当且仅当 (`a == c` 且 `b == d`) 或者 (`a == d` 且 `b == c`) 。即一张骨牌可以通过旋转 `0` 度或 `180` 度得到另一张多米诺骨牌。\n\n在 `0 <= i < j < dominoes.length` 的前提下，找出满足 `dominoes[i]` 和 `dominoes[j]` 等价的骨牌对 `(i, j)` 的数量。\n\n \n\n**示例 1：**\n\n```\n输入：dominoes = [[1,2],[2,1],[3,4],[5,6]]\n输出：1\n```\n\n**示例 2：**\n\n```\n输入：dominoes = [[1,2],[1,2],[1,1],[1,2],[2,2]]\n输出：3\n```\n\n \n\n**提示：**\n\n- `1 <= dominoes.length <= 4 * 10⁴`\n- `dominoes[i].length == 2`\n- `1 <= dominoes[i][j] <= 9`\n\n\n\n## 问题分析\n\n- 给你一个多米诺骨牌列表 `dominoes`，每个骨牌是一个长度为 2 的数组 `[a, b]`。\n- 如果两张骨牌旋转后能完全一致，就称它们等价。\n- 例如 `[1,2]` 与 `[2,1]` 等价。我们要统计所有满足等价关系的骨牌对 `(i, j)` $(i < j)$ 的总数。\n\n## 算法思路\n\n1. **规范化（标准化）表示**\n   - 每张骨牌 `[a, b]`，将它变成有序对 `(min(a,b), max(a,b))`。\n   - 这样无论原来是 `[1,2]` 还是 `[2,1]`，都统一映射为为 `(1,2)`。\n\n2. **哈希表计数**\n   - 用一个字典（或 Python 的 `Counter`）记录每种“规范化后”的骨牌出现了多少次。\n   - 键（key）就是那个二元组，值（value）就是出现次数。\n\n3. **组合数学计算对数**\n\n   - 如果某种骨牌规范后出现了 $k$ 次，那么这 $k$ 张骨牌两两之间都能组成等价对，共有组合数\n     $$\n     \\binom{k}{2} \\;=\\;\\frac{k\\times (k-1)}{2}\n     $$\n\n   - 把所有不同骨牌规范的组合数累加，就是答案。\n\n## 时间复杂度\n\n- **时间复杂度**：遍历一次骨牌列表 $O(n)$，再遍历一次哈希表（最坏也是 $O(n)$），总体 $O(n)$。\n- **空间复杂度**：哈希表存储规范后骨牌的计数，最坏情况键值对有 $O(n)$ 个。\n\n## 代码分解\n\n1. 初始化计数字典\n\n   ```python\n   from collections import Counter\n   count = Counter()\n   ```\n\n2. 标准化并计数\n\n   ```python\n   for a, b in dominoes:\n       key = (a, b) if a <= b else (b, a) # 保证顺序\n       count[key] += 1\n   ```\n\n3. 组合数学求配对数\n\n   ```\n   for k in count.values():\n       if k > 1:\n           result += k*(k-1)//2\n   ```\n\n   $\\binom{k}{2}$ 的计算公式直接用整数运算实现\n\n## 代码实现\n\n```python\nclass Solution:\n    def numEquivDominoPairs(self, dominoes: list[list[int]]) -> int:\n        # 1. 用 Counter 创建一个空的哈希表\n        count = Counter()\n        \n        # 2. 遍历每一张骨牌\n        for a, b in dominoes:\n            # 2.1 规范化：用元组(key)表示，保证先小后大\n            if a <= b:\n                key = (a, b)\n            else:\n                key = (b, a)\n            # 2.2 对该 key 的出现次数 +1\n            count[key] += 1\n        \n        # 3. 统计所有规范对的组合数之和\n        result = 0\n        # 3.1 对哈希表中每一种规范对\n        for k in count.values():\n            # 只有 k>=2 时才会有配对\n            if k > 1:\n                # 组合数 C(k,2) = k*(k-1)//2\n                result += k * (k - 1) // 2\n        \n        # 4. 返回结果\n        return result\n\n```\n以 `[[1,2], [2,1], [3,4], [5,6]]` 为例：\n\n| 原始骨牌 | 规范化后 | 累计到哈希表中   |\n| -------- | -------- | ---------------- |\n| [1,2]    | (1,2)    | count[(1,2)] = 1 |\n| [2,1]    | (1,2)    | count[(1,2)] = 2 |\n| [3,4]    | (3,4)    | count[(3,4)] = 1 |\n| [5,6]    | (5,6)    | count[(5,6)] = 1 |\n\n最终哈希表 `count` 为：\n\n```pseudocode\n{\n  (1,2): 2,\n  (3,4): 1,\n  (5,6): 1\n}\n```\n\n接下来计算组合数：\n\n- 对 `(1,2)`，出现次数 $k=2$，组合数 $\\binom{2}{2} = 1$\n- `(3,4)` 与 `(5,6)` 都只出现过 1 次，不会贡献配对（因为 $\\binom{1}{2}=0$ ）\n\n所以总对数 = 1。","tags":["Algorithm","简单","组合数学","哈希表"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-03","url":"/post/minimum-domino-rotations-for-equal-row.html","content":"\n# [1007. 行相等的最少多米诺旋转](https://leetcode.cn/problems/minimum-domino-rotations-for-equal-row/) M\n\n在一排多米诺骨牌中，`tops[i]` 和 `bottoms[i]` 分别代表第 `i` 个多米诺骨牌的上半部分和下半部分。（一个多米诺是两个从 1 到 6 的数字同列平铺形成的 —— 该平铺的每一半上都有一个数字。）\n\n我们可以旋转第 `i` 张多米诺，使得 `tops[i]` 和 `bottoms[i]` 的值交换。\n\n返回能使 `tops` 中所有值或者 `bottoms` 中所有值都相同的最小旋转次数。\n\n如果无法做到，返回 `-1`.\n\n \n\n**示例 1：**\n\n![示例](https://s2.loli.net/2025/05/03/LcKUAD3wXMYTgsi.png)\n\n> 输入：tops = [2,1,2,4,2,2], bottoms = [5,2,6,2,3,2]\n> 输出：2\n> 解释： \n> 图一表示：在我们旋转之前， tops 和 bottoms 给出的多米诺牌。 \n> 如果我们旋转第二个和第四个多米诺骨牌，我们可以使上面一行中的每个值都等于 2，如图所示。 \n\n**示例 2：**\n\n> 输入：tops = [3,5,1,2,3], bottoms = [3,6,3,3,4]\n> 输出：-1\n> 解释： 在这种情况下，不可能旋转多米诺牌使一行的值相等。\n\n \n\n**提示：**\n\n- `2 <= tops.length <= 2 * 10⁴`\n- `bottoms.length == tops.length`\n- `1 <= tops[i], bottoms[i] <= 6`\n\n\n\n## 问题分析\n\n给定两条长度相同的数组 `tops` 和 `bottoms`，表示一排多米诺骨牌的上下数字。你可以对任意一张牌做“旋转”操作（即上下数字交换位置）。目标是让 **整条“上行”** 或 **整条“下行”** 的数字都相同，求所需的最少旋转次数；如果做不到，则返回 -1。\n\n## 算法思路\n\n假设最终我们要把上行全部变成某个数字 `x`。那么对于第 1 张牌，它转前在上行是 `tops[0]`，转后可能是拿下面的 `bottoms[0]` 过来。\n\n- 如果最终目标行全是 `x`，第 1 张牌要么原本上面就是 `x`（即 `tops[0] == x`），要么通过旋转后上面成为 `bottoms[0] == x`。\n- 因此，唯一可能的候选 `x` 就是 `{ tops[0], bottoms[0] }` 两个值之一。\n- 其它任何值作为目标，都不可能同时兼顾第 1 张牌。\n\n## 时间复杂度\n\n**时间复杂度**：$O(n)$，其中 $n$ 是多米诺数量。至多对两个候选各做一次「线性遍历」。\n\n**空间复杂度**：$O(1)$，只用了常数级额外变量（两个计数器和一个候选集合）。\n\n## 代码分解\n\n1. **确定候选目标值**\n    只可能让最终整行相同的值是第一张牌上或下的数字，记为 `x1 = tops[0]`、`x2 = bottoms[0]`。\n\n2. **对每个候选值 x，遍历整排牌**\n   - 用两个计数器 `rot_top` 和 `rot_bot` 分别记录：\n     - `rot_top`：若想让 **上行tops** 全部变为 `x`，需要旋转的次数；\n     - `rot_bot`：若想让 **下行bottoms** 全部变为 `x`，需要旋转的次数。\n   - 遍历索引 `i`，对每一张牌：\n     - 若 `tops[i]≠x` 且 `bottoms[i]≠x`，说明这张牌无论如何（原地或旋转）都无法在上行或下行出现 `x`，立即返回不可行（记为无穷大，最后结果取最小会被过滤）。\n     - 否则：\n       - **想让上行变成 x**：如果 `tops[i]≠x`，则必须旋转这一张，令 `rot_top++`。\n       - **想让下行变成 x**：如果 `bottoms[i]≠x`，则必须旋转这一张，令 `rot_bot++`。\n\n3. **取两条方案中的最小值**\n   - 对候选 `x1`、`x2` 分别计算后（要么把上行全换成 `x`，需要 `rot_top` 次旋转；\n     要么把下行全换成 `x`，需要 `rot_bot` 次旋转），\n   - 答案为其中较小的旋转次数；\n   - 若都是无穷大，则返回 `-1`。\n4. **小结**\n   1. 从 `{ tops[0], bottoms[0] }` 中拿到至多两个候选 `x`。\n   2. 对每个候选值调用上面“检查并计数”逻辑，得到一个旋转次数（或“无解”标记）。\n   3. 在这两个结果中取最小，若都是“无解”，则返回 -1，否则返回该最小值。\n\n## 代码实现\n\n```python\nfrom typing import List\n\nclass Solution:\n    def minDominoRotations(self, tops: List[int], bottoms: List[int]) -> int:\n        # 内部函数：给定目标 x，返回让上行或下行全为 x 的最少旋转次数\n        # 如果无解，则返回 float('inf')\n        def check(x: int) -> int:\n            rot_top = 0   # 让 tops 全为 x，需要的旋转次数\n            rot_bot = 0   # 让 bottoms 全为 x，需要的旋转次数\n\n            for t, b in zip(tops, bottoms):\n                # 如果这张牌两面都不是 x，就不可能通过任何旋转获得 x\n                if t != x and b != x:\n                    return float('inf')  # 无解\n\n                # 若上面不是 x，则必须旋转一次\n                if t != x:\n                    rot_top += 1\n                # 若下面不是 x，则必须旋转一次\n                if b != x:\n                    rot_bot += 1\n\n            # 返回两种方案的较小旋转次数\n            return min(rot_top, rot_bot)\n\n        # 仅需检查前第一张牌的两个面\n        candidates = {tops[0], bottoms[0]}\n        ans = float('inf')\n\n        # 分别试每个候选值\n        for x in candidates:\n            ans = min(ans, check(x))\n\n        # 若仍是无穷，说明两个候选都无解\n        return -1 if ans == float('inf') else ans\n\n```\n\n以 `tops = [2,1,2,4,2,2]`，`bottoms = [5,2,6,2,3,2]` 为例：\n\n- 候选集合：`{ 2, 5 }`\n\n试 `x = 2`\n\n| i    | tops[i] | bottoms[i] | tops[i]==2? | bottoms[i]==2? | rot_top 增量 | rot_bot 增量 |\n| ---- | ------- | ---------- | ----------- | -------------- | ------------ | ------------ |\n| 0    | 2       | 5          | 是          | 否             | 0            | 1            |\n| 1    | 1       | 2          | 否          | 是             | 1            | 0            |\n| 2    | 2       | 6          | 是          | 否             | 0            | 1            |\n| 3    | 4       | 2          | 否          | 是             | 1            | 0            |\n| 4    | 2       | 3          | 是          | 否             | 0            | 1            |\n| 5    | 2       | 2          | 是          | 是             | 0            | 0            |\n|      |         |            |             | **合计**       | **2**        | **3**        |\n\n试 `x = 5`\n\n检查到 `tops[1]=1` 且 `bottoms[1]=2` 都不是 5，立即判定无解（记作 ∞）。\n\n最终在 `{2, ∞}` 中取最小，就是 2。","tags":["Algorithm","中等","枚举与剪枝","贪心"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-02","url":"/post/push-dominoes.html","content":"\n# [838. 推多米诺](https://leetcode.cn/problems/push-dominoes/) M\n\n`n` 张多米诺骨牌排成一行，将每张多米诺骨牌垂直竖立。在开始时，同时把一些多米诺骨牌向左或向右推。\n\n每过一秒，倒向左边的多米诺骨牌会推动其左侧相邻的多米诺骨牌。同样地，倒向右边的多米诺骨牌也会推动竖立在其右侧的相邻多米诺骨牌。\n\n如果一张垂直竖立的多米诺骨牌的两侧同时有多米诺骨牌倒下时，由于受力平衡， 该骨牌仍然保持不变。\n\n就这个问题而言，我们会认为一张正在倒下的多米诺骨牌不会对其它正在倒下或已经倒下的多米诺骨牌施加额外的力。\n\n给你一个字符串 `dominoes` 表示这一行多米诺骨牌的初始状态，其中：\n\n- `dominoes[i] = 'L'`，表示第 `i` 张多米诺骨牌被推向左侧，\n- `dominoes[i] = 'R'`，表示第 `i` 张多米诺骨牌被推向右侧，\n- `dominoes[i] = '.'`，表示没有推动第 `i` 张多米诺骨牌。\n\n返回表示最终状态的字符串。\n\n \n\n**示例 1：**\n\n> 输入：dominoes = \"RR.L\"\n> 输出：\"RR.L\"\n> 解释：第一张多米诺骨牌没有给第二张施加额外的力。\n\n**示例 2：**\n\n![示例 2](https://s2.loli.net/2025/05/02/1rHAOVNqpifQEnD.png)\n\n> 输入：dominoes = \".L.R...LR..L..\"\n> 输出：\"LL.RR.LLRRLL..\"\n\n \n\n**提示：**\n\n- `n == dominoes.length`\n- 1 `<= n <=` $10^5$\n- `dominoes[i]` 为 `'L'`、`'R'` 或 `'.'`\n\n## 问题分析\n\n有n张多米诺骨牌排成一行。\n\n- 当推动一些骨牌向左或向右后，每秒倒向左边的骨牌会推倒其左侧相邻骨牌，\n- 倒向右边的骨牌会推倒其右侧相邻骨牌。\n- 如果竖立骨牌的左右两侧同时有骨牌倒下，则它保持竖立。\n\n求最后的骨牌倒向状态。\n\n## 算法思路\n\n### 1. 加入哨兵（Sentinel）\n\n- 我们在原串 `dominoes` 的最左端加入一个虚拟的 `'L'`，下标记为 `0`；\n- 在最右端加入一个虚拟的 `'R'`，下标记为 `n+1`。\n- 原字符串字符对应到新数组 `s` 的位置是 `1` 到 `n`。\n\n这样做的好处是：无论最左或最右一侧最初如何受力，都能统一用同一套逻辑处理，无需额外分支。\n\n> 原：   .  L  .  R  . . .  L  R  . .  L  . .\n> 索引： 1  2  3  4  5 6 7  8  9 10 11 12 13 14\n> s：   [L] .  L  .  R  . . .  L  R  . .  L  . . [R]\n> 索引：  0   1  2  3  4  5 6 7  8  9 10 11 12 13 14 15\n\n- `prev` 和 `prevChar` 初始为 `0`、`'L'`，对应哨兵左侧。\n- 我们的目标是，每当遇到一个非点字符（`'L'` 或 `'R'`）时，就处理上一次非点到当前之间的区间。\n\n### 2. 区间类型与对应填充策略\n\n设当前指针 `i`（范围 `1…n+1`）指向一个非点字符 `currChar = s[i]`，上一次非点在 `prev`、字符为 `prevChar`。区间 `(prev, i)`（不含端点）即是待处理段。共有三种情况：\n\n| prevChar | currChar | 说明                                                         | 区间填充方式                                                 |\n| -------- | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| L        | R        | 左侧向左，右侧向右——中间没人受力                             | 保持全部 `.` 不变                                            |\n| L        | L        | 两侧都向左——向左的力传导                                     | 整段填充为 `L`                                               |\n| R        | R        | 两侧都向右——向右的力传导                                     | 整段填充为 `R`                                               |\n| R        | L        | 左右相向——中间骨牌两端受力，向中央倒；中间正中如果恰好在平衡点，则不倒 | 从两端向中间：左半段填 `R`，右半段填 `L`；如果区间长度为奇数，中点保留 `.` |\n\n特别地，`R...L` 的中点保持直立是因为左右对等力量平衡。\n\n## 时间复杂度\n\n$O(n)$ ：一次从 `1` 扫描到 `n+1`，区间内填充合计仅做每个位置不超过一次写操作\n\n空间复杂度：$O(n)$，使用大小为 `n+2` 的辅助字符数组。\n\n## 代码分解\n\n1. **线性扫描 + 两个指针**\n    我们在字符串两端分别加上虚拟的多米诺骨牌，以简化边界处理：\n   - 在最左端加一个假想的 `L`（下标 `-1`），\n   - 在最右端加一个假想的 `R`（下标 `n`）。\n\n2. **记录上一次非点状态的位置和方向**\n   - 用 `prev` 存储上一个非点（`'L'` 或 `'R'`）的下标，\n   - 用 `prevChar` 存储对应的字符。\n\n3. **遍历**\n   - 当遇到下一个非点字符 `currChar`（下标 `i`）时，考察区间 `(prev, i)`：\n     - 如果 `prevChar == currChar`，则这一段内所有骨牌都倒向同一方向；\n     - 如果 `prevChar=='R'` 且 `currChar=='L'`，则中间部分向两端倒：左半段倒 `R`，右半段倒 `L`；\n     - 如果 `prevChar=='L'` 且 `currChar=='R'`，中间保持直立不动。\n     - 更新 `prev = i, prevChar = currChar`，继续扫描。\n\n## 代码实现\n\n```python\nclass Solution:\n    def pushDominoes(self, dominoes: str) -> str:\n        n = len(dominoes)\n        # 在头尾各加一个哨兵，简化边界\n        s = ['L'] + list(dominoes) + ['R']\n        prev = 0\n        prevChar = 'L'\n        \n        for i in range(1, n + 2):\n            currChar = s[i]\n            if currChar == '.':\n                continue\n            \n            # 区间 (prev, i)\n            if prevChar == currChar:\n                # 同向全填充\n                for k in range(prev + 1, i):\n                    s[k] = currChar\n            elif prevChar == 'R' and currChar == 'L':\n                # 两侧相向，中间向两端\n                left, right = prev + 1, i - 1\n                while left < right:\n                    s[left] = 'R'\n                    s[right] = 'L'\n                    left += 1\n                    right -= 1\n                # 如果 left == right，保持 '.'（平衡力）\n            # 如果是 L...R，保持不变\n            \n            prev = i\n            prevChar = currChar\n        \n        # 拼回原始长度\n        return ''.join(s[1:-1])\n\n```\n\n以 `\".L.R...LR..L..\"` 为例（原长 14），在数组 `s` 上的区间索引是 `1…14`，我们实际扫描到 `i=15` 才遇到最后的 `'R'` 哨兵。\n\n| 索引 i      | s[i] 内容 | 操作及说明                                                   | 更新后 prev 值 | 更新后 prevChar |\n| ----------- | --------- | ------------------------------------------------------------ | -------------- | --------------- |\n| 初始化      | \\-        | `s = ['L', '.', 'L', '.', 'R', '.', '.', '.', 'L', 'R', '.', '.', 'L', '.', '.', 'R']`，`prev = 0`，`prevChar = 'L'` | 0              | L               |\n| i=1         | .         | 跳过                                                         | 0              | L               |\n| i=2         | L         | 区间 `(0, 2)`，只有下标 1，`prevChar = 'L'`，`currChar = 'L'`，属于 `L...L` → 将 `s[1]` 填为 `L` | 2              | L               |\n| i=3         | .         | 跳过                                                         | 2              | L               |\n| i=4         | R         | 区间 `(2,4)`，下标 3，`prevChar = 'L'`，`currChar = 'R'`，属于 `L...R` → 保持 `s[3]='.'` | 4              | R               |\n| i=5 - i=8   | 全为 .    | 跳过                                                         | 4              | R               |\n| i=9         | L         | 区间 `(4,9)`，下标 5,6,7,8，`prevChar = 'R'`，`currChar = 'L'`，属于 `R...L`，长度 4，左右对称 → `s[5] = R`，`s[8] = L`；`s[6] = R`，`s[7] = L` | 9              | L               |\n| i=10        | R         | 区间 `(9,10)`，只有 `s[9.5?]` 无点 → 跳过。更新 `prev = 10`，`prevChar = 'R'` | 10             | R               |\n| i=11 - i=12 | .         | 跳过                                                         | 10             | R               |\n| i=13        | L         | 区间 `(10,13)`，下标 11,12，`R...L`，长度 2 → `s[11] = R`，`s[12] = L` | 13             | L               |\n| i=14        | .         | 跳过                                                         | 13             | L               |\n| i=15        | R         | 区间 `(13,15)`，下标 14，`L...R` → 保持 `'.'`                | 15             | R               |\n\n最终去掉两端哨兵，拼回结果就是 `\"LL.RR.LLRRLL..\"`","tags":["Algorithm","字符串处理","中等","双指针","贪心"],"categories":["算法"]},{"title":"LeetCode每日一题2025-05-01","url":"/post/maximum-number-of-tasks-you-can-assign.html","content":"\n# [2071. 你可以安排的最多任务数目](https://leetcode.cn/problems/maximum-number-of-tasks-you-can-assign/) H\n\n给你 `n` 个任务和 `m` 个工人。每个任务需要一定的力量值才能完成，需要的力量值保存在下标从 **0** 开始的整数数组 `tasks` 中，第 `i` 个任务需要 `tasks[i]` 的力量才能完成。每个工人的力量值保存在下标从 **0** 开始的整数数组 `workers` 中，第 `j` 个工人的力量值为 `workers[j]` 。每个工人只能完成 **一个** 任务，且力量值需要 **大于等于** 该任务的力量要求值（即 `workers[j] >= tasks[i]` ）。\n\n除此以外，你还有 `pills` 个神奇药丸，可以给 **一个工人的力量值** 增加 `strength` 。你可以决定给哪些工人使用药丸，但每个工人 **最多** 只能使用 **一片** 药丸。\n\n给你下标从 **0** 开始的整数数组`tasks` 和 `workers` 以及两个整数 `pills` 和 `strength` ，请你返回 **最多** 有多少个任务可以被完成。\n\n \n\n**示例 1：**\n\n> 输入：tasks = [3,2,1], workers = [0,3,3], pills = 1, strength = 1\n> 输出：3\n> 解释：\n> 我们可以按照如下方案安排药丸：\n>\n> - 给 0 号工人药丸。\n> - 0 号工人完成任务 2（0 + 1 >= 1）\n> - 1 号工人完成任务 1（3 >= 2）\n> - 2 号工人完成任务 0（3 >= 3）\n\n**示例 2：**\n\n> 输入：tasks = [5,4], workers = [0,0,0], pills = 1, strength = 5\n> 输出：1\n> 解释：\n> 我们可以按照如下方案安排药丸：\n>\n> - 给 0 号工人药丸。\n> - 0 号工人完成任务 0（0 + 5 >= 5）\n\n**示例 3：**\n\n> 输入：tasks = [10,15,30], workers = [0,10,10,10,10], pills = 3, strength = 10\n> 输出：2\n> 解释：\n> 我们可以按照如下方案安排药丸：\n>\n> - 给 0 号和 1 号工人药丸。\n> - 0 号工人完成任务 0（0 + 10 >= 10）\n> - 1 号工人完成任务 1（10 + 10 >= 15）\n\n**示例 4：**\n\n> 输入：tasks = [5,9,8,5,9], workers = [1,6,4,2,6], pills = 1, strength = 5\n> 输出：3\n> 解释：\n> 我们可以按照如下方案安排药丸：\n>\n> - 给 2 号工人药丸。\n> - 1 号工人完成任务 0（6 >= 5）\n> - 2 号工人完成任务 2（4 + 5 >= 8）\n> - 4 号工人完成任务 3（6 >= 5）\n\n \n\n**提示：**\n\n- `n == tasks.length`\n- `m == workers.length`\n- 1 `<= n, m <=` $5 * 10^4$\n- `0 <= pills <= m`\n- 0 `<= tasks[i], workers[j], strength <=` $10^9$\n\n## 问题分析\n\n- **任务**：有 $n$ 个任务，任务力量需求数组为 `tasks`；有 $m$ 名工人，力量数组为 `workers`。\n\n- **药丸**：你有 `pills` 颗药，每颗可以让一个工人的力量增加 `strength`，且每个工人最多只能吃一颗。\n\n- **目标**：在最优分配下，最多能完成多少个任务。\n\n## 算法思路\n\n1. **排序**\n   - 将 `tasks` 从小到大排序，编号后更容易按难度取子区间；\n   - 将 `workers` 从小到大排序，方便挑最强和二分查找。\n2. **二分答案** $k$\n   - 答案 $k$ 最多不会超过 $\\min(n, m)$。\n   - 我们在区间 $[0, \\min(n,m)]$ 上二分查找最大的可行 $k$。\n3. **可行性验证 `can_do(k)`**\n   - **取子集**：对尝试完成的前 $k$ 个最小任务 `tasks[0..k-1]`，对应后 $k$ 个最强工人 `workers[m-k..m-1]`。\n   - **维护有序容器**：把这 $k$ 名工人放入一个支持「删最大」「按需求二分查找最小满足」操作的有序结构（如 Python `bisect`+`list` 或者 `sortedcontainers.SortedList`）。\n   - **从 hardest 到 easiest**：为了节省药丸，我们先处理需求最高的任务。对每个任务 $t$：\n     - 如果容器中**最大力量** $\\ge t$，直接分配该工人（弹出最大），不消耗药丸。\n     - 否则，需要用药：找容器中**最小的**工人 $w$ 满足 $w + strength \\ge t$（用二分查找找第一个 $\\ge t - strength$），若找不到或药丸已用完，则失败；否则分配、药丸减一。\n   - 如果所有 $k$ 个任务都能分配完，`can_do(k)=True`，如果在分配过程中药丸数超过 `pills`，或找不到可用工人，则 `can_do(k)` 返回 False。\n\n## 时间复杂度\n\n1. **时间复杂度**\n\n   - 排序：$O(n\\log n + m\\log m)$\n\n   - 二分：$O(\\log \\min(n,m))$ 次可行性验证\n\n   - 每次验证：最多 $k$ 次删除/查找，每次 $O(\\log k)$，所以 $O(k\\log k)$\n\n   - **总计**：\n     $$\n     O\\bigl((n+m)\\log(n+m)\\;+\\;\\log\\min(n,m)\\times\\min(n,m)\\log m\\bigr).\n     $$\n\n2. **空间复杂度** : 排序原地排序外，额外使用 `O(m)` 存储可用工人列表。\n\n## 代码分解\n\n先解决最难的任务，这样能保证弱工人和药丸优先用于最“吃力”的配对，若连最难的都配不上，`k` 肯定不可行。\n\n使用 `sortedcontainers.SortedList`，支持 `sl.pop(-1)`、`sl.bisect_left()`、`sl.pop(idx)` 都是 $O(\\log k)$\n\n用「上取整」的 mid 方案：\n\n```python\nlo, hi = 0, min(n, m)\nwhile lo < hi:\n    mid = (lo + hi + 1) // 2\n    if can_do(mid):\n        lo = mid\n    else:\n        hi = mid - 1\nreturn lo\n\n```\n\n## 代码实现\n\n```python\nfrom sortedcontainers import SortedList\nfrom bisect import bisect_left\n\nclass Solution:\n    def maxTaskAssign(self, tasks, workers, pills, strength):\n        tasks.sort()\n        workers.sort()\n\n        def can_do(k):\n            # 取最强 k 工人，放入可排序列表\n            avail = SortedList(workers[-k:])\n            pills_left = pills\n            # 从最难任务到最简单\n            for t in reversed(tasks[:k]):\n                # 如果最强工人够力\n                if avail and avail[-1] >= t:\n                    avail.pop(-1)\n                else:\n                    # 用药分配\n                    if pills_left == 0:\n                        return False\n                    # 找最弱且加药后能胜任的工人,需要 w >= t - strength\n                    need = t - strength\n                    idx = avail.bisect_left(need)\n                    if idx == len(avail):\n                        return False\n                    # 分配并消耗\n                    avail.pop(idx)\n                    pills_left -= 1\n            return True\n        # 二分最大 k\n        lo, hi = 0, min(len(tasks), len(workers))\n        while lo < hi:\n            mid = (lo + hi + 1) // 2\n            if can_do(mid):\n                lo = mid\n            else:\n                hi = mid - 1\n        return lo\n\n```\n\n以`tasks = [3,2,1],` `workers = [0,3,3]`, `pills = 1, strength = 1`为例：\n\n| 二分过程         | 任务子集 | 工人子集 | 药丸使用情况 | 分配过程                                                     | 结果判断                                  |\n| ---------------- | -------- | -------- | ------------ | ------------------------------------------------------------ | ----------------------------------------- |\n| 初始状态(排序后) | \\[1,2,3] | \\[0,3,3] | 1            | -                                                            | -                                         |\n| 尝试 mid=2       | \\[1,2]   | \\[0,3,3] | 1            | 1. 较大任务 2 分配给最大工人 3 ≥ 2 → 不用药，弹出 3。<br>2. 任务 1 分配给最大工人 3 ≥ 1 → 不用药，弹出 3。 | 成功 → `can_do(2)=True`，二分上界提升到 2 |\n| 尝试 mid=3       | \\[1,2,3] | \\[0,3,3] | 1            | 1. 任务 3 分配给最大工人 3 ≥ 3 → 不用药，弹出 3，剩 `[0,3]`。<br>2. 任务 2 分配给最大工人 3 ≥ 2 → 不用药，弹出 3，剩 `[0]`。<br>3. 任务 1 分配给唯一工人 0 < 1 → 需要用药，查找最小 $w\\ge 1-1=0$，找到 0，用药后分配成功。 | 成功 → `can_do(3)=True`，最终答案 3       |","tags":["Algorithm","困难","二分查找","排序","贪心","有序集合"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-30","url":"/post/find-numbers-with-even-number-of-digits.html","content":"\n\n\n# [1295. 统计位数为偶数的数字](https://leetcode.cn/problems/find-numbers-with-even-number-of-digits/) E\n\n给你一个整数数组 `nums`，请你返回其中包含 **偶数** 个数位的数字的个数。\n\n \n\n**示例 1：**\n\n> 输入：nums = [12,345,2,6,7896]\n> 输出：2\n> 解释：\n> 12 是 2 位数字（位数为偶数） \n> 345 是 3 位数字（位数为奇数）\n> 2 是 1 位数字（位数为奇数） \n> 6 是 1 位数字 位数为奇数） \n> 7896 是 4 位数字（位数为偶数）\n> 因此只有 12 和 7896 是位数为偶数的数字\n\n**示例 2：**\n\n> 输入：nums = [555,901,482,1771]\n> 输出：1 \n> 解释： \n> 只有 1771 是位数为偶数的数字。\n\n \n\n**提示：**\n\n- `1 <= nums.length <= 500`\n- 1 `<= nums[i] <=` $10^5$\n\n\n\n## 算法思路\n\n1. **遍历**：对输入数组 `nums` 中的每个数字 `num` 进行遍历（共 `n` 个）。\n2. **计数位数**：\n   - 方法 A（数学方式）：不断除以 10 直至 `num` 为 0，统计除法次数。\n   - 方法 B（字符串方式）：将 `num` 转为字符串 `s = str(num)`，直接用 `len(s)` 获取位数。\n3. **判断奇偶**：如果位数 `digit_count % 2 == 0`，则计数器加 1。\n4. **返回结果**：遍历结束后输出计数器的值。\n\n## 时间复杂度\n\n方法 A：对每个数做除法操作，平均每个数的位数为 `d`（$d = O(\\log_{10}(num))$），总体为 $O(n·d)$。\n\n方法 B：字符串转换和长度计算也约为 $O(n·d)$。 由于 `num[i] ≤` $10^5$，`d ≤ 6`，故可视为 **线性** $O(n)$。\n\n空间复杂度：$O(1)$（忽略输出和输入空间）。\n\n## 代码实现\n\n```python\nfrom typing import List\n\nclass Solution:\n    def findNumbers(self, nums: List[int]) -> int:\n        count = 0\n        for num in nums:\n            # 方法 B：字符串方式统计位数\n            if len(str(num)) % 2 == 0:\n                count += 1\n        return count\n\n```\n\n","tags":["Algorithm","暴力搜索","数位处理","简单"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-29","url":"/post/count-subarrays-where-max-element-appears-at-least-k-times.html","content":"\n# [2962. 统计最大元素出现至少 K 次的子数组](https://leetcode.cn/problems/count-subarrays-where-max-element-appears-at-least-k-times/) M\n\n给你一个整数数组 `nums` 和一个 **正整数** `k` 。\n\n请你统计有多少满足 「 `nums` 中的 **最大** 元素」至少出现 `k` 次的子数组，并返回满足这一条件的子数组的数目。\n\n子数组是数组中的一个连续元素序列。\n\n \n\n**示例 1：**\n\n> 输入：nums = [1,3,2,3,3], k = 2\n> 输出：6\n> 解释：包含元素 3 至少 2 次的子数组为：[1,3,2,3]、[1,3,2,3,3]、[3,2,3]、[3,2,3,3]、[2,3,3] 和 [3,3] 。\n\n**示例 2：**\n\n> 输入：nums = [1,4,2,1], k = 3\n> 输出：0\n> 解释：没有子数组包含元素 4 至少 3 次。\n\n \n\n**提示：**\n\n- 1 `<= nums.length <=` $10^5$\n- 1 `<= nums[i] <=` $10^6$\n- 1 `<= k <=` $10^5$\n\n\n\n## 问题分析\n\n给定一个长度为 `n` 的整数数组 `nums` 和正整数 `k`，我们需要统计满足“子数组中数组 `nums` 的**最大元素**至少出现 `k` 次”的所有**连续子数组**的个数。\n\n- **全局最大值**：数组中所有元素的最大值，记作 `M = max(nums)`。\n- **子数组**：数组中任意一段连续的元素序列。\n- **目标**：统计所有子数组中，元素 `M` 出现次数 ≥ `k` 的子数组个数。\n\n直接枚举所有子数组会有 $O(n^2)$ 个，无法在 `n ≤` $10^5$ 的规模下通过。因此，需要一个 $O(n)$ 或 $O(n \\log n)$ 的方法。\n\n## 算法思路\n\n1. **全局最大值定位**：首先在数组 `nums` 中找到最大的元素 `M = max(nums)`。\n2. **子数组计数思路**：我们要统计所有包含元素 `M` 至少出现 `k` 次的连续子数组。\n3. **滑动窗口＋双指针**：统计“包含 M 出现次数 < k 的子数组数目”，记为 `cnt_less`。\n   - 用双指针 `left, right` 扩展窗口，维护窗口中 `M` 的出现次数 `count_M`。\n   - 每次将 `right` 向右移动，若 `nums[right] == M` 则 `count_M += 1`。\n   - 当 `count_M >= k` 时，窗口不再满足“<k”条件，需要移动 `left` 且在移动时相应地更新 `count_M`，直到 `count_M < k`。\n   - 对于每一个 `right`，当前满足 `< k` 的最长窗口长度是 `right - left + 1`，将其累加到 `cnt_less`。\n4. **总子数组数目**：$\\text {total}= \\frac{n(n+1)}2\\text.$\n5. **答案**：$\\text{answer} = \\text{total} - \\text{cnt\\_less}$，即所有子数组减去不满足条件的那些。\n\n## 时间复杂度\n\n**时间复杂度**：$O(n)$，`left` 和 `right` 指针各最多移动 $n$ 次。\n\n**空间复杂度**：$O(1)$，只使用常数级的额外变量。\n\n## 代码分解\n\n1. **找最大值** ：`M = max(nums)`\n\n2. **初始化**\n\n   ```python\n   n = len(nums)\n   left = 0\n   count_M = 0\n   cnt_less = 0\n   ```\n\n3. **滑动窗口循环**\n\n   ```python\n   for right in range(n):\n       if nums[right] == M:\n           count_M += 1\n       # 收缩左端，直到 count_M < k\n       while count_M >= k:\n           if nums[left] == M:\n               count_M -= 1\n           left += 1\n       # 累加以 right 结尾的不满足子数组数\n       cnt_less += (right - left + 1)\n   ```\n\n4. **计算并返回结果**\n\n   ```python\n   total = n * (n + 1) // 2\n   return total - cnt_less\n   ```\n\n## 代码实现\n\n```python\nclass Solution:\n    def countSubarrays(self, nums: List[int], k: int) -> int:\n        n = len(nums)\n        # 1. 找到全局最大值 M\n        M = max(nums)\n        # 2. 统计出现次数 < k 的子数组数（滑动窗口）\n        left = 0\n        count_M = 0   # 窗口中 M 的出现次数\n        cnt_less = 0  # 子数组中 M 出现次数 < k 的数量\n        # 3. 滑动窗口遍历所有可能的右端点\n        for right in range(n):\n            # 扩张窗口：若新加入元素是 M，则计数器 +1\n            if nums[right] == M:\n                count_M += 1\n            # 当窗口中 M 出现次数 >= k 时，收缩 left\n            while count_M >= k:\n                if nums[left] == M:\n                    count_M -= 1\n                left += 1\n            # 此时窗口 [left..right] 都是 < k，子数组数量 = 窗口长度\n            # 以 right 结尾的所有子数组的起点可以是 left, left+1, …, right\n            cnt_less += (right - left + 1)\n        # 4. 计算总子数组数并取差\n        total = n * (n + 1) // 2\n        return total - cnt_less\n\n```\n\n- 输入：`nums = [1,3,2,3,3]`, `k = 2`\n  - 全局最大值 `M = 3`\n  - 统计 `<2` 次的子数组数 `cnt_less = 15 - 6 = 9` （总子数组 15 个，满足条件 6 个）\n  - 返回 `15 - 9 = 6`，与题目示例一致。\n\n- 输入：`nums = [1,4,2,1]`, `k = 3`\n  - `M = 4`，在任何子数组中最多出现 1 次，均 <3\n  - `cnt_less = total = 10`，所以返回 `10 - 10 = 0`。","tags":["Algorithm","中等","滑动窗口","双指针","前缀和"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-28","url":"/post/count-subarrays-with-score-less-than-k.html","content":"\n# [2302. 统计得分小于 K 的子数组数目](https://leetcode.cn/problems/count-subarrays-with-score-less-than-k/) H\n\n一个数组的 **分数** 定义为数组之和 **乘以** 数组的长度。\n\n- 比方说，`[1, 2, 3, 4, 5]` 的分数为 `(1 + 2 + 3 + 4 + 5) * 5 = 75` 。\n\n给你一个正整数数组 `nums` 和一个整数 `k` ，请你返回 `nums` 中分数 **严格小于** `k` 的 **非空整数子数组数目**。\n\n**子数组** 是数组中的一个连续元素序列。\n\n \n\n**示例 1：**\n\n> 输入：nums = [2,1,4,3,5], k = 10\n> 输出：6\n> 解释：\n> 有 6 个子数组的分数小于 10 ：\n>\n> - [2] 分数为 2 * 1 = 2 。\n> - [1] 分数为 1 * 1 = 1 。\n> - [4] 分数为 4 * 1 = 4 。\n> - [3] 分数为 3 * 1 = 3 。 \n> - [5] 分数为 5 * 1 = 5 。\n> - [2,1] 分数为 (2 + 1) * 2 = 6 。\n> 注意，子数组 [1,4] 和 [4,3,5] 不符合要求，因为它们的分数分别为 10 和 36，但我们要求子数组的分数严格小于 10 。\n\n**示例 2：**\n\n> 输入：nums = [1,1,1], k = 5\n> 输出：5\n> 解释：\n> 除了 [1,1,1] 以外每个子数组分数都小于 5 。\n> [1,1,1] 分数为 (1 + 1 + 1) * 3 = 9 ，大于 5 。\n> 所以总共有 5 个子数组得分小于 5 。\n\n \n\n**提示：**\n\n- 1 `<= nums.length <=` $10^5$\n- 1 `<= nums[i] <=` $10^5$\n- 1 `<= k <=` $10^{15}$\n\n\n\n## 问题分析\n\n1. **分数 monotonic 性质**\n   对于正整数数组，子数组向右扩展会同时增加「和」与「长度」，因此分数\n   $$\n   \\text{score}(l, r) = \\left( \\sum_{i=l}^{r} \\text{nums}[i] \\right) \\times (r - l + 1)\n   $$\n   随着 $l$ 不变而 $r$ 增大时单调递增；同理，对于固定的右端点 $r$ ，若从左端点 $l$ 开始的子数组已满足 $\\left( \\sum_{i=l}^{r} \\text{nums}[i] \\right) \\times (r - l + 1)<k$，那么从任意 $l' > l$ 开始到 $r$ 的子数组也必然满足该不等式，当 $l$ 增大（窗口缩小）时，分数单调递减。\n\n2. **利用双指针维护合法区间**\n\n   - 用指针 `l`、`r` 表示当前窗口 $[l..r]$。\n   - 保证窗口内任何子数组（以任意左端点 $\\ge l$ 出发、以 $r$ 结尾）的分数都严格小于 $k$。\n   - 随着 `r` 从左向右遍历，将 `nums[r]` 加入当前窗口的累加和 `window_sum`。\n   - 若此时 `window_sum * (r-l+1) ≥ k`，则不断收缩左端 `l++`（并从 `window_sum` 中减去 `nums[l]`），直到重新满足 `< k`。\n\n3. **计数方式**\n    对于每个右端点 $r$，一旦窗口调到了最大合法大小 $[l..r]$，那么所有起点在 $l, l+1, \\dots, r$ 的子数组都合法，共有 $r - l + 1$ 个。\n\n## 算法思路\n\n1. 初始化：`l = 0, window_sum = 0, ans = 0`\n\n2. 遍历 `r` 从 `0` 到 `n-1`：\n\n   - `window_sum += nums[r]`\n\n   - 当 `window_sum * (r - l + 1) ≥ k` 时：\n\n     ```python\n     while l <= r and window_sum * (r - l + 1) >= k:\n         window_sum -= nums[l]\n         l += 1\n     ```\n\n   - 此时 `[l..r]` 中所有子数组都合法，其数量为 `r - l + 1`，加到 `ans`。.\n\n3. 遍历结束，返回 `ans`。\n\n## 时间复杂度\n\n**时间复杂度**：指针 `r` 从左向右遍历一遍：$O(n)$；`l` 最多也只会从 $0$ 移动到 $n-1$：$O(n)$；合计 $O(n)$。\n\n**空间复杂度**：只使用了若干常数变量，$O(1)$。\n\n## 代码分解\n\n```pseudocode\n初始化\n  l = 0            # 窗口左端\n  window_sum = 0   # 窗口 [l..r] 的元素和\n  ans = 0          # 累计答案\n\n遍历 r 从 0 到 n-1：\n  1. 将 nums[r] 加入窗口和\n     window_sum += nums[r]\n\n  2. 如果窗口分数 >= k，则移动 l 收缩：\n     while l ≤ r 且 window_sum * (r - l + 1) ≥ k:\n         window_sum -= nums[l]\n         l += 1\n     # 结束后，[l..r] 窗口恢复到「所有子数组分数 < k」状态\n\n  3. 以 r 为右端点的合法子数组有 (r - l + 1) 个，累加到 ans\n     ans += (r - l + 1)\n\n返回 ans\n\n```\n\n## 代码实现\n\n```python\nfrom typing import List\n\nclass Solution:\n    def countSubarrays(self, nums: List[int], k: int) -> int:\n        \"\"\"\n        返回 nums 中所有分数 < k 的非空子数组数量。\n        分数定义为 子数组之和 * 子数组长度。\n        \"\"\"\n        n = len(nums)\n        l = 0\n        window_sum = 0\n        ans = 0\n        \n        for r in range(n):\n            window_sum += nums[r]\n            # 收缩左端，直到窗口合法\n            while l <= r and window_sum * (r - l + 1) >= k:\n                window_sum -= nums[l]\n                l += 1\n            # 以 r 为右端点的所有子数组数\n            ans += (r - l + 1)\n        \n        return ans\n\n```\n\n以 `nums = [2,1,4,3,5]`, `k = 10` 为例：\n\n| 步骤 | r    | 加入 nums[r] | window_sum | l    | 检查 & 收缩                                                  | 合法子数组数 r−l+1r-l+1r−l+1 | 累计 ans |\n| ---- | ---- | ------------ | ---------- | ---- | ------------------------------------------------------------ | ---------------------------- | -------- |\n| 初始 | —    | —            | 0          | 0    | —                                                            | —                            | 0        |\n| 1    | 0    | +2 → 2       | 2          | 0    | $2*1<10$✓                                                    | 0–0：1 个                    | 1        |\n| 2    | 1    | +1 → 3       | 3          | 0    | $3*2<10$✓                                                    | 0–1：2 个                    | 3        |\n| 3    | 2    | +4 → 7       | 7          | 0    | $7*3=21\\ge 10\\times$ → 收缩 <br />– remove 2 → sum=5, l=1 <br />$5*2=10\\ge 10\\times$ → 收缩 <br />– remove 1 → sum=4, l=2 | 2–2：1 个                    | 4        |\n| 4    | 3    | +3 → 7       | 7          | 2    | $7*2=14\\ge 10\\times$ → 收缩 <br />– remove 4 → sum=3, l=3 <br />$3*1=3 < 10\\times$✓ | 3–3：1 个                    | 5        |\n| 5    | 4    | +5 → 8       | 8          | 3    | $8*2=16\\ge 10\\times$ → 收缩 <br />– remove 3 → sum=5, l=4 <br />$5*1=5 < 10$✓ | 4–4：1 个                    | 6        |","tags":["Algorithm","困难","滑动窗口","双指针","前缀和"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-27","url":"/post/count-subarrays-of-length-three-with-a-condition.html","content":"\n# [3392. 统计符合条件长度为 3 的子数组数目](https://leetcode.cn/problems/count-subarrays-of-length-three-with-a-condition/) E\n\n给你一个整数数组 `nums` ，请你返回长度为 3 的 子数组 的数量，满足第一个数和第三个数的和恰好为第二个数的一半。\n\n**子数组** 指的是一个数组中连续 **非空** 的元素序列。\n\n \n\n**示例 1：**\n\n> **输入：** nums = [1,2,1,4,1]\n>\n> **输出：** 1\n>\n> **解释：**\n>\n> 只有子数组 `[1,4,1]` 包含 3 个元素且第一个和第三个数字之和是中间数字的一半。number.\n\n**示例 2：**\n\n> **输入：** nums = [1,1,1]\n>\n> **输出： ** 0\n>\n> **解释：**\n>\n> `[1,1,1]` 是唯一长度为 3 的子数组，但第一个数和第三个数的和不是第二个数的一半。\n\n \n\n**提示：**\n\n- `3 <= nums.length <= 100`\n- `-100 <= nums[i] <= 100`\n\n## 问题分析\n\n**输入**：长度为 $n$ 的整数数组 `nums`，满足 $3 \\le n \\le 100$，元素取值 $[-100,100]$。\n\n**目标**：统计所有长度恰好为 3 的**连续子数组** $[a,b,c]$，使得\n$$\na+c=\\frac{b}{2}\\quad\\Longleftrightarrow\\quad2(a+c)=b.\n$$\n因为子数组长度固定且很小（仅 3），子数组个数仅 $n-2$，可线性枚举，每个子数组只涉及 3 个元素，检查条件恒为常数时间。\n\n## 算法思路\n\n1. **初始化**\n\n   - 计数器 `ans = 0`。\n\n2. **遍历“中间位置”**\n\n   - 令指针 $i$ 从 1 到 $n-2$（包含），那么第 $i$ 个元素就是子数组的中间元素 $b = \\text{nums}[i]$。\n\n   - 子数组的首尾分别是：\n     $$\n     a = \\text{nums}[i-1],\\quad c = \\text{nums}[i+1].\n     $$\n\n3. **判断并累加**\n\n   - 检查条件：\n     $$\n     2 \\times (a + c) == b.\n     $$\n\n   - 如果成立，`ans += 1`。\n\n4. **返回结果**\n\n   - 遍历结束后，`ans` 即为满足条件的子数组数量。\n\n## 时间复杂度\n\n**时间复杂度**：\n\n- 暴力枚举每个窗口需要 $O(n)$ 次检查，其中 $n = \\text{len}(nums)$，每次检查 $O(1)$，只需一次线性遍历，整体 $O(n)$。\n\n**空间复杂度**：\n\n- 仅使用常数级额外变量计数，$O(1)$。\n\n## 代码分解\n\n```pseudocode\nfunction countSubarrays(nums):\n    ans ← 0\n    for i from 1 to length(nums)-2:\n        a ← nums[i-1]\n        b ← nums[i]\n        c ← nums[i+1]\n        if 2*(a + c) == b:\n            ans ← ans + 1\n    return ans\n\n```\n\n- `range(1, len(nums)-1)`：因为窗口长度固定 3，首元素索引为 $i-1$，尾元素索引为 $i+1$，故 $i$ 取值区间为 $[1, n-2]$。\n\n- 每次循环只做一次加法、一次乘法、一次比较，都是 $O(1)$ 操作。\n\n## 代码实现\n\n```python\nfrom typing import List\n\nclass Solution:\n    def countSubarrays(self, nums: List[int]) -> int:\n        \"\"\"\n        统计所有长度=3 的连续子数组 [a, b, c] 满足 2*(a + c) == b。\n        时间复杂度：O(n)，空间复杂度：O(1)。\n        \"\"\"\n        ans = 0                     # 计数器，初始为 0\n        \n        # i 从 1 到 len(nums)-2，确保 i-1, i, i+1 都在数组内\n        for i in range(1, len(nums) - 1):\n            a = nums[i - 1]         # 子数组首元素\n            b = nums[i]             # 子数组中间元素\n            c = nums[i + 1]         # 子数组尾元素\n            \n            # 判断核心条件：2*(a + c) == b\n            if 2 * (a + c) == b:\n                ans += 1            # 条件满足时，计数器加 1\n        \n        return ans                  # 返回最终结果\n\n```\n\n","tags":["Algorithm","暴力搜索","简单","滑动窗口"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-26","url":"/post/count-subarrays-with-fixed-bounds.html","content":"\n# [2444. 统计定界子数组的数目](https://leetcode.cn/problems/count-subarrays-with-fixed-bounds/) H\n\n给你一个整数数组 `nums` 和两个整数 `minK` 以及 `maxK` 。\n\n`nums` 的定界子数组是满足下述条件的一个子数组：\n\n- 子数组中的 **最小值** 等于 `minK` 。\n- 子数组中的 **最大值** 等于 `maxK` 。\n\n返回定界子数组的数目。\n\n子数组是数组中的一个连续部分。\n\n \n\n**示例 1：**\n\n> 输入：nums = [1,3,5,2,7,5], minK = 1, maxK = 5\n> 输出：2\n> 解释：定界子数组是 [1,3,5] 和 [1,3,5,2] 。\n\n**示例 2：**\n\n> 输入：nums = [1,1,1,1], minK = 1, maxK = 1\n> 输出：10\n> 解释：nums 的每个子数组都是一个定界子数组。共有 10 个子数组。\n\n \n\n**提示：**\n\n- 2 `<= nums.length <=` $10^5$\n- 1 `<= nums[i], minK, maxK <=` $10^6$\n\n\n\n## 问题分析\n\n我们要统计所有「最小值＝`minK` 且 最大值＝`maxK`」的子数组个数。核心在于：\n\n1. **无效区间**：任何超出区间 $minK, maxK$ 的元素都会“破坏”子数组；我们记录它的最近位置 `last_invalid`，子数组一旦跨过此位置就一定包含不合格元素。\n\n2. **关键位置**：必须同时出现 `minK` 和 `maxK`，因此我们分别记录扫描到当前位置为止，最后一次出现 `minK` 的下标 `last_min`，以及最后一次出现 `maxK` 的下标 `last_max`。\n\n3. **结尾贡献**：对于每个位置 `i`，以它为结尾的所有合法子数组，起始位置 `j` 必须满足：\n\n   - `j > last_invalid`（子数组中不包含任何无效元素）\n   - 而且子数组要同时包含最近一次的 `minK` 和 `maxK`，也就是说 `j ≤ min(last_min, last_max)`。\n\n   因此，以 `i` 结尾的合法子数组数量是：\n\n   ```pseudocode\n   max(0, min(last_min, last_max) - last_invalid)\n   ```\n\n   累加到全局答案中即可。\n\n## 算法思路\n\n1. 定义三个指针/下标变量：\n   - `last_invalid`：上一个不满足 `minK ≤ nums[i] ≤ maxK` 的位置（初始化为 −1）。\n   - `last_min`：上一个等于 `minK` 的位置（初始化为 −1）。\n   - `last_max`：上一个等于 `maxK` 的位置（初始化为 −1）。\n2. 从左至右遍历数组，每到索引 `i`：\n   - 若 `nums[i] < minK` 或 `nums[i] > maxK`，则更新 `last_invalid = i`。\n   - 若 `nums[i] == minK`，则更新 `last_min = i`。\n   - 若 `nums[i] == maxK`，则更新 `last_max = i`。\n3. 以 `i` 结尾的所有合法子数组，起始点必须在 `(last_invalid, min(last_min, last_max)]` 之间，故可累加 `max(0, min(last_min, last_max) - last_invalid)` 到答案中。\n4. 最终累加得到所有定界子数组的数量。\n\n## 时间复杂度\n\n- 时间复杂度：$O(n)$，其中 $n$ 为数组长度\n- 空间复杂度：$O(1)$（仅使用常数额外变量）\n\n## 代码实现\n\n```python\nclass Solution:\n    def countSubarrays(self, nums: list[int], minK: int, maxK: int) -> int:\n        last_invalid = -1     # 最后一个不在 [minK, maxK] 范围内的索引\n        last_min = -1         # 最后一个出现 minK 的索引\n        last_max = -1         # 最后一个出现 maxK 的索引\n        count = 0             # 结果计数\n\n        for i, x in enumerate(nums):\n            # 1）如果 x 超出 [minK, maxK] 区间，则标记为无效\n            if x < minK or x > maxK:\n                last_invalid = i\n\n            # 2）记录最新出现 minK 和 maxK 的位置\n            if x == minK:\n                last_min = i\n            if x == maxK:\n                last_max = i\n\n            # 3）计算以 i 结尾的合法子数组个数\n            #    起始点 j 必须 > last_invalid，且 ≤ min(last_min, last_max)\n            valid_start = min(last_min, last_max)\n            if valid_start > last_invalid:\n                count += (valid_start - last_invalid)\n\n        return count\n\n```\n\n以 `nums = [1,3,5,2,7,5]`, `minK = 1`, `maxK = 5`为例：\n\n| i    | nums[i] | last_invalid | last_min | last_max | min(last_min, last_max) | 新增子数组 = max(0, min–last_invalid) | 累计 count |\n| ---- | ------- | ------------ | -------- | -------- | ----------------------- | ------------------------------------- | ---------- |\n| -1   | —       | -1           | -1       | -1       | —                       | —                                     | 0          |\n| 0    | 1       | -1           | 0        | -1       | -1                      | max(0, -1 − (-1)) = 0                 | 0          |\n| 1    | 3       | -1           | 0        | -1       | -1                      | max(0, -1 − (-1)) = 0                 | 0          |\n| 2    | 5       | -1           | 0        | 2        | 0                       | max(0, 0 − (-1)) = 1                  | 1          |\n| 3    | 2       | -1           | 0        | 2        | 0                       | max(0, 0 − (-1)) = 1                  | 2          |\n| 4    | 7 (>5)  | 4            | 0        | 2        | 0                       | max(0, 0 − 4) = 0                     | 2          |\n| 5    | 5       | 4            | 0        | 5        | 0                       | max(0, 0 − 4) = 0                     | 2          |\n\n- **i=2** 时，`nums[2]=5`，更新 `last_max=2`，此时 `min(last_min,last_max)=0`，新增子数组有 `1` 个，即 `[1,3,5]`。\n- **i=3** 时，`nums[3]=2`，没有更新 `last_min/last_max`，但依然可延伸前面那个“有效段”贡献 `1` 个，即 `[1,3,5,2]`。\n- **i=4** 时跳到 `7`（无效），`last_invalid=4`，后续以任何 `i≥4` 结尾的子数组都必须从 5 之后开始；此时在位置 5 上虽然又出现了 `maxK`，但最早的 `minK` 还是在 0，所以 `min(last_min,last_max)=0≤ last_invalid=4`，无有效子数组。\n\n最终总数为 **2**。\n\n**边界**\n\n1. **minK == maxK**\n   算法依然适用，此时要求子数组内所有元素都等于同一个值 `K`，也就统计所有连续等于 `K` 的子数组个数。\n2. **数组中无 minK 或 maxK**\n   某一关键位置永远为 −1，则 `min(last_min,last_max) = −1`，每次贡献都为 0，最终答案 0。\n3. **整型溢出**\n   累加次数最多是 $\\mathcal{O}(n^2/2)$ 级别（当所有子数组都合法时），对于 n≤ $10^5$，要用 64 位整型（Python 中 int 自动大整型）。\n\n","tags":["Algorithm","困难","滑动窗口","双指针"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-25","url":"/post/count-of-interesting-subarrays.html","content":"\n# [2845. 统计趣味子数组的数目](https://leetcode.cn/problems/count-of-interesting-subarrays/) M\n\n给你一个下标从 **0** 开始的整数数组 `nums` ，以及整数 `modulo` 和整数 `k` 。\n\n请你找出并统计数组中 **趣味子数组** 的数目。\n\n如果 **子数组** `nums[l..r]` 满足下述条件，则称其为 **趣味子数组** ：\n\n- 在范围 `[l, r]` 内，设 `cnt` 为满足 `nums[i] % modulo == k` 的索引 `i` 的数量。并且 `cnt % modulo == k` 。\n\n以整数形式表示并返回趣味子数组的数目。\n\n**注意：** 子数组是数组中的一个连续非空的元素序列。\n\n \n\n**示例 1：**\n\n> 输入：nums = [3,2,4], modulo = 2, k = 1\n> 输出：3\n> 解释：在这个示例中，趣味子数组分别是： \n> 子数组 nums[0..0] ，也就是 [3] 。 \n>\n> - 在范围 [0, 0] 内，只存在 1 个下标 i = 0 满足 nums[i] % modulo == k 。\n> - 因此 cnt = 1 ，且 cnt % modulo == k 。\n> 子数组 nums[0..1] ，也就是 [3,2] 。\n> - 在范围 [0, 1] 内，只存在 1 个下标 i = 0 满足 nums[i] % modulo == k 。\n> - 因此 cnt = 1 ，且 cnt % modulo == k 。\n> 子数组 nums[0..2] ，也就是 [3,2,4] 。\n> - 在范围 [0, 2] 内，只存在 1 个下标 i = 0 满足 nums[i] % modulo == k 。\n> - 因此 cnt = 1 ，且 cnt % modulo == k 。\n> 可以证明不存在其他趣味子数组。因此，答案为 3 。\n\n**示例 2：**\n\n> 输入：nums = [3,1,9,6], modulo = 3, k = 0\n> 输出：2\n> 解释：在这个示例中，趣味子数组分别是： \n> 子数组 nums[0..3] ，也就是 [3,1,9,6] 。\n>\n> - 在范围 [0, 3] 内，只存在 3 个下标 i = 0, 2, 3 满足 nums[i] % modulo == k 。\n> - 因此 cnt = 3 ，且 cnt % modulo == k 。\n> 子数组 nums[1..1] ，也就是 [1] 。\n> - 在范围 [1, 1] 内，不存在下标满足 nums[i] % modulo == k 。\n> - 因此 cnt = 0 ，且 cnt % modulo == k 。\n> 可以证明不存在其他趣味子数组，因此答案为 2 。\n\n \n\n**提示：**\n\n- 1 `<= nums.length <=` $10^5$\n- 1 `<= nums[i] <=` $10^9$\n- 1 `<= modulo <=` $10^9$\n- `0 <= k < modulo`\n\n\n\n## 问题分析\n\n我们要统计子数组中满足以下两个条件的子数组个数：\n\n- 在子数组范围内，满足 `nums[i] % modulo == k` 的元素个数记为 `cnt`\n- 且 `cnt % modulo == k`\n\n## 算法思路\n\n1. 为了更方便地计数，我们先把原数组 `nums` 转换成一个二值数组 `b`：\n\n   ```python\n   b[i] = 1 if nums[i] % modulo == k else 0\n   ```\n\n   此时，任意子数组 `[l..r]` 中满足条件的元素个数\n\n   就是 `b[l] + b[l+1] + … + b[r]`。\n\n2. 引入**前缀和** + **模运算**\n\n   定义前缀和数组 `P`，并对 `modulo` 取模，使得计算更简单：\n\n   ```pseudocode\n   P[0] = 0\n   P[i] = (b[0] + b[1] + … + b[i-1]) % modulo    （1 ≤ i ≤ n）\n   ```\n\n   - 注意：`P[i]` 表示前 `i` 个元素（即 `b[0..i-1]`）的和 mod `modulo`\n\n   那么子数组 `[l..r]` 的“有趣计数” `cnt = b[l] + … + b[r]`，可以写成：\n\n   ```pseudocode\n   cnt = (P[r+1] - P[l] + modulo) % modulo\n   ```\n\n   我们需要 `cnt % modulo == k`，即\n\n   ```pseudocode\n   (P[r+1] - P[l]) % modulo == k\n   ⇔ P[r+1] ≡ P[l] + k   (modulo)\n   ⇔ P[l] ≡ P[r+1] - k   (modulo)\n   ```\n\n3. 利用**哈希表**计数\n\n   由上面等式可知：在遍历到位置 `r`（即计算出 `P[r+1]`）时，我们只要知道有多少个 `l < r+1` 使得\n   $$\n   P[l] \\equiv (P[r+1] - k) \\bmod \\text{modulo}\n   $$\n   即可将这些子数组都计入答案。因此，我们用一个哈希表 `cntMap` 来维护“每种前缀和出现的次数”：\n\n   - **键**：某个值 `v` 表示前缀和 `P[*] = v`\n   - **值**：该前缀和出现了多少次\n\n## 时间复杂度\n\n**时间复杂度**：\n\n- 遍历一次数组，共 `n` 步\n- 每步中哈希表的查询与更新均摊 O(1) → 总体 O(n)\n\n**空间复杂度**：哈希表 `cntMap` 最多存储 `O(min(n, modulo))` 个不同的前缀和值 → 最坏 O(n)，通常远小于 n\n\n## 代码分解\n\n1. 初始化\n\n   ```python\n   cntMap = defaultdict(int)\n   cntMap[0] = 1\n   cur = 0    # 当前前缀和 P[i]（初始化为 P[0]）\n   ans = 0\n   ```\n\n   - `cntMap[0] = 1`：表示空前缀（即 `P[0]`）出现 1 次，便于统计以开头就满足条件的子数组\n\n2. 遍历数组\n\n   对于每个 `x = nums[i]`，更新：\n\n   ```python\n   if x % modulo == k:\n       cur = (cur + 1) % modulo\n   # 此时 cur = P[i+1]\n   ```\n\n3. 查询并累加\n\n   计算目标前缀和值：\n\n   ```python\n   target = (cur - k + modulo) % modulo\n   ans += cntMap[target]\n   ```\n\n   这一步相当于“找到所有 l，使得 P[l] == target”，将其数量直接加到答案中\n\n4. 更新哈希表\n\n   ```python\n   cntMap[cur] += 1\n   ```\n\n   将当前前缀和也记入哈希表，以便后续作为 `l` 被使用\n\n遍历结束后，`ans` 即为所有“趣味子数组”的总数\n\n## 代码实现\n\n```python\nfrom collections import defaultdict\nfrom typing import List\n\nclass Solution:\n    def countInterestingSubarrays(self, nums: List[int], modulo: int, k: int) -> int:\n        # b[i] = 1 if nums[i] % modulo == k else 0\n        # 前缀和计数映射\n        cntMap = defaultdict(int)\n        cntMap[0] = 1    # 初始：空前缀和为 0 出现过一次\n        \n        cur = 0          # 当前前缀和（modulo 取模后）\n        ans = 0\n        \n        for x in nums:\n            # 转换 b[i] 并更新前缀和\n            if x % modulo == k:\n                cur = (cur + 1) % modulo\n            \n            # 计算能与当前前缀和配对的目标值\n            target = (cur - k + modulo) % modulo\n            ans += cntMap[target]\n            \n            # 记录当前前缀和出现次数\n            cntMap[cur] += 1\n        \n        return ans\n\n```\n\n以 `nums = [3,2,4]，modulo = 2，k = 1` 为例：\n\n| i    | nums[i] | nums[i]%2==1? | b[i] | cur (P[i+1]) | target=(cur−k)%2 | cntMap before | 新增 ans | cntMap after |\n| ---- | ------- | ------------- | ---- | ------------ | ---------------- | ------------- | -------- | ------------ |\n| 初始 |         |               |      | cur = 0      |                  | {0:1}         | 0        | {0:1}        |\n| i=0  | 3       | 是            | 1    | (0+1)%2 = 1  | (1-1)%2 = 0      | {0:1}         | +1 → 1   | {0:1, 1:1}   |\n| i=1  | 2       | 否            | 0    | (1+0)%2 = 1  | (1-1)%2 = 0      | {0:1,1:1}     | +1 → 2   | {0:1, 1:2}   |\n| i=2  | 4       | 否            | 0    | (1+0)%2 = 1  | (1-1)%2 = 0      | {0:1,1:2}     | +1 → 3   | {0:1, 1:3}   |\n\n- **i=0**：`cur=1`，`target=0`，`cntMap[0]=1`，`ans=1`\n\n- **i=1**：`cur=1`，`target=0`，`cntMap[0]=1`，`ans=2`\n\n- **i=2**：`cur=1`，`target=0`，`cntMap[0]=1`，`ans=3`","tags":["Algorithm","中等","数据结构","哈希表","前缀和"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-24","url":"/post/count-complete-subarrays-in-an-array.html","content":"\n# [2799. 统计完全子数组的数目](https://leetcode.cn/problems/count-complete-subarrays-in-an-array/) M\n\n给你一个由 **正** 整数组成的数组 `nums` 。\n\n如果数组中的某个子数组满足下述条件，则称之为 **完全子数组** ：\n\n- 子数组中 **不同** 元素的数目等于整个数组不同元素的数目。\n\n返回数组中 **完全子数组** 的数目。\n\n**子数组** 是数组中的一个连续非空序列。\n\n \n\n**示例 1：**\n\n> **输入**：nums = [1,3,1,2,2]\n> **输出**：4\n> **解释**：完全子数组有：[1,3,1,2]、[1,3,1,2,2]、[3,1,2] 和 [3,1,2,2] 。\n\n**示例 2：**\n\n> **输入**：nums = [5,5,5,5]\n> **输出**：10\n> **解释**：数组仅由整数 5 组成，所以任意子数组都满足完全子数组的条件。子数组的总数为 10 。\n\n \n\n**提示：**\n\n- `1 <= nums.length <= 1000`\n- `1 <= nums[i] <= 2000`\n\n\n\n## 问题分析\n\n- 给定正整数数组 `nums`，长度为 `n`（$\\le 1000$）。\n\n- 记数组 `nums` 中 **不同** 元素的总数为 $K$。\n\n- 我们需要统计「子数组中不同元素数 **等于**$K$」的子数组个数。\n\n## 算法思路\n\n*暴力枚举*：枚举左端点 $i\\text{ }(0\\cdots n-1)$ ，再枚举右端点 $j\\text{ }(i\\cdots n-1)$，对每个子数组 `nums[i:j+1]` 用哈希或 `set` 统计不同元素数，再对比是否等于 $K$。\n\n时间复杂度：\n\n- 枚举子数组一共 $O(n^2)$\n- 每个子数组去重也要 $O(n)$\n- 合计 $O(n^3)$，在 $n=1000$ 时是不可行的（$10^9$ 级别的操作）。\n\n> 暴力+优化也可通过测试：采用双重循环遍历所有可能的子数组，并检查每个子数组是否符合条件，对于每一个起始索引 `i`，逐步扩展结束索引 `j`，使用集合记录当前子数组中的元素。一旦集合大小达到整个数组的不同元素数量，则计数加一；若超过该数量则提前终止内层循环，时间复杂度最坏为$O(n^2)$\n>\n> ```python\n> class Solution:\n>     def countCompleteSubarrays(self, nums: List[int]) -> int:\n>         total_unique = len(set(nums))\n>         if total_unique == 0:\n>             return 0\n>         \n>         K = total_unique\n>         result = 0\n>         n = len(nums)\n>         \n>         for i in range(n):\n>             current_set = set()\n>             for j in range(i, n):\n>                 current_set.add(nums[j])\n>                 if len(current_set) == K:\n>                     result += 1\n>                 elif len(current_set) > K:\n>                     break  # 一旦超出所需的唯一计数，就不需要检查其他元素\n>         return result\n> \n> ```\n\n\n\n**我们令函数**\n$$\nF(k) = \\text{“不同元素数} \\leq k \\text{”的子数组数量}.\n$$\n则恰好等于 $K$ 的子数组数目\n$$\n\\#\\{\\text{distinct} = K\\} = F(K) - F(K - 1).\n$$\n所有「不同数 $\\le K$」的子数组共 $F(K)$ 个，\n\n但其中也包括「不同数 $\\le K−1$」的 $F(K-1)$ 个，\n\n二者相减，即剩下「不同数恰好 = $K$」的部分。\n\n\n\n使用**滑动窗口 + 双指针**：\n\n1. **窗口定义**\n   - 左指针 `i`，右指针 `j`，初始都指向 0。\n   - 窗口 `nums[i…j]` 内维护哈希表 `count`，记录每个数字出现的次数。\n   - 变量 `distinct` 表示当前窗口内 **不同** 元素的个数。\n2. **右指针扩展**\n   - 遍历 `j` 从 0 到 $n-1$：\n     - 将 `nums[j]` 加入窗口：若原来 `count[nums[j]]==0`，则 `distinct += 1`；再 `count[nums[j]] += 1`。\n3. **左指针收缩**\n   - **当** `distinct > k` 时，需要不断移动左指针 `i`：\n     - 从窗口移出 `nums[i]`：`count[nums[i]] -= 1`；若 `count[nums[i]]` 变为 0，则 `distinct -= 1`；然后 `i += 1`\n   - 收缩后，窗口再次保证 `distinct ≤ k`。\n4. **计数子数组**\n   - 对于每一个新的 `j` 位置，**当前窗口** 所包含的所有合法子数组（以 `j` 为右端）数量就是窗口长度：`j - i + 1`。\n     - 因为任意左端点 $L$ 满足 $i \\le L \\le j$，子数组 `nums[L…j]` 都有 `distinct ≤ k`。\n5. **累加结果**\n   - 对每个 `j`，将 `j - i + 1` 累加到 `res`，最终 `res = F(k)`。\n\n以 `nums = [1,3,1,2,2]`，$k=2$ 为例，计算「不同数 $\\le 2$」的子数组数：\n\n| 步骤   | j    | 加入 nums[j]   | window                     | distinct     | i    | 新增子数组数 j−i+1 | 累计 res |\n| ------ | ---- | -------------- | -------------------------- | ------------ | ---- | ------------------ | -------- |\n| 初始化 | —    | —              | []                         | 0            | 0    | —                  | 0        |\n| 1      | 0    | 1              | [1]                        | 1            | 0    | 0−0+1 = 1          | 1        |\n| 2      | 1    | 3              | [1,3]                      | 2            | 0    | 1−0+1 = 2          | 3        |\n| 3      | 2    | 1              | [1,3,1]                    | 2            | 0    | 2−0+1 = 3          | 6        |\n| 4      | 3    | 2 → distinct=3 | [1,3,1,2] → 收缩 → [3,1,2] | 2 → 经过收缩 | 1    | 3−1+1 = 3          | 9        |\n| 5      | 4    | 2              | [3,1,2,2]                  | 3→收缩→2     | 2    | 4−2+1 = 3          | 12       |\n\n最终我们得到 `F(2) = 12`。\n类似地可以算出 `F(1)`，最后 `F(2) - F(1)` 就是「不同数恰好 $=2$」的子数组数。\n\n## 时间复杂度\n\n- **时间复杂度**：一次 `atMost` 为 $O(n)$，每个元素最多进出窗口各一次共两次，故 $O(n)$\n- **空间复杂度**：哈希表存储最多 $n$ 个键，故 $O(n)$\n\n## 代码分解\n\n1. 用「$\\le K$」和「$\\le K−1$」之差得到「$=K$」。\n\n2. 滑动窗口维护「不同元素数 $\\le k$」的区间，通过左右指针一遍扫描完成。\n\n3. 累加 `(j - i + 1)` 即可统计当前右端下所有合法子数组。\n\n## 代码实现\n\n```python\nclass Solution:\n    def countCompleteSubarrays(self, nums):\n        # 整体不同元素个数\n        K = len(set(nums))\n\n        # 计算「不同元素 ≤ k」的子数组数量\n        def atMost(k):\n            count = {}       # 哈希表：元素 -> 频次\n            res = 0\n            distinct = 0     # 当前窗口中不同元素数\n            left = 0         # 窗口左指针\n            for right, x in enumerate(nums):\n                # 右指针加入\n                if count.get(x, 0) == 0:\n                    distinct += 1\n                count[x] = count.get(x, 0) + 1\n\n                # 如果超过 k，左指针收缩\n                while distinct > k:\n                    y = nums[left]\n                    count[y] -= 1\n                    if count[y] == 0:\n                        distinct -= 1\n                    left += 1\n\n                # 以 right 为结尾的「不同元素 ≤ k」子数组有 (right - left + 1) 个\n                res += right - left + 1\n\n            return res\n\n        # 答案 = 至多 K 不同 − 至多 (K-1) 不同\n        return atMost(K) - atMost(K - 1)\n\n```\n\n","tags":["Algorithm","中等","滑动窗口","哈希表","双指针"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-23","url":"/post/count-largest-group.html","content":"\n# [1399. 统计最大组的数目](https://leetcode.cn/problems/count-largest-group/) E\n\n给你一个整数 `n` 。请你先求出从 `1` 到 `n` 的每个整数 10 进制表示下的数位和（每一位上的数字相加），然后把数位和相等的数字放到同一个组中。\n\n请你统计每个组中的数字数目，并返回数字数目并列最多的组有多少个。\n\n \n\n**示例 1：**\n\n> 输入：n = 13\n> 输出：4\n> 解释：总共有 9 个组，将 1 到 13 按数位求和后这些组分别是：\n> [1,10]，[2,11]，[3,12]，[4,13]，[5]，[6]，[7]，[8]，[9]。总共有 4 个组拥有的数字并列最多。\n\n**示例 2：**\n\n> 输入：n = 2\n> 输出：2\n> 解释：总共有 2 个大小为 1 的组 [1]，[2]。\n\n**示例 3：**\n\n> 输入：n = 15\n> 输出：6\n\n**示例 4：**\n\n> 输入：n = 24\n> 输出：5\n\n \n\n**提示：**\n\n- 1 `<= n <=` $10^4$\n\n\n\n## 问题分析\n\n给定一个整数 `n`，计算从1到`n`的每个数字的十进制位数和，并将具有相同位数和的数字分组。统计各组大小并找出最大值出现的次数。\n\n## 算法思路\n\n1. **计算每位数字的和**：遍历每个数字 `i`，将各位相加得到其和。\n2. **统计每种和的频率**：使用字典记录每个位数和对应有多少个数字。\n3. 找出最大组大小及对应的组数量：\n   - 找出所有组中的最大组大小。\n   - 统计有多少个不同的位数和的组达到该最大值。\n\n## 时间复杂度\n\n- **计算位数和**：对于每个数字 $i$，分解其各位需要 $O(\\log i)$ 的时间（由于每次除以10）。总时间为 $O(n \\times \\log n)$。\n- **统计与查找最大值**：遍历所有键值对的时间为 $O(k)$，其中 $k$ 是不同位数和的组的数量。在最坏情况下 $k$ 约为 `37`（例如数字 `9999` 的各位和是 `9+9+9+9 = 36`），因此这部分可以视为常量时间。\n\n总的时间复杂度：$O(n \\log n)$，对于 `n ≤` $10^4$ 是可接受的。\n\n- 使用字典存储不同位数和对应的计数值，空间复杂度为 $O(k)$。最坏情况下 $k \\approx O(\\log n)$（例如所有数字位数和都唯一），因此是**线性空间**。\n\n## 代码分解\n\n1. 初始化字典`groups`\n2. 从1遍历到n，计算 i 的数位和，在 `groups` 中将对应键的计数加 1\n3. 计算出最大频次 `max_size`\n4. 遍历 `groups`，统计有多少个键的值等于 `max_size` 并返回\n\n## 代码实现\n\n```python\nfrom collections import defaultdict\n\nclass Solution:\n    def countLargestGroup(self, n: int) -> int:\n        # 使用字典统计每个数位和出现的次数\n        groups = defaultdict(int)\n        \n        for i in range(1, n + 1):\n            # 计算当前数字i的十进制各位之和\n            digit_sum = sum(map(int, str(i)))\n            groups[digit_sum] += 1\n        \n        if not groups:\n            return 0\n        \n        # 找出最大的组大小\n        max_size = max(groups.values())\n        \n        # 统计有多少个组达到了这个最大值\n        return sum(1 for size in groups.values() if size == max_size)\n\n```\n\n","tags":["Algorithm","暴力搜索","数位处理","简单","枚举与剪枝"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-22","url":"/post/count-the-number-of-ideal-arrays.html","content":"\n# [2338. 统计理想数组的数目](https://leetcode.cn/problems/count-the-number-of-ideal-arrays/) H\n\n给你两个整数 `n` 和 `maxValue` ，用于描述一个 **理想数组** 。\n\n对于下标从 **0** 开始、长度为 `n` 的整数数组 `arr` ，如果满足以下条件，则认为该数组是一个 **理想数组** ：\n\n- 每个 `arr[i]` 都是从 `1` 到 `maxValue` 范围内的一个值，其中 `0 <= i < n` 。\n- 每个 `arr[i]` 都可以被 `arr[i - 1]` 整除，其中 `0 < i < n` 。\n\n返回长度为 `n` 的 **不同** 理想数组的数目。由于答案可能很大，返回对 $10^9 + 7$ 取余的结果。\n\n \n\n**示例 1：**\n\n> **输入**：n = 2, maxValue = 5\n> **输出**：10\n> **解释**：存在以下理想数组：\n>\n> - 以 1 开头的数组（5 个）：[1,1]、[1,2]、[1,3]、[1,4]、[1,5]\n> - 以 2 开头的数组（2 个）：[2,2]、[2,4]\n> - 以 3 开头的数组（1 个）：[3,3]\n> - 以 4 开头的数组（1 个）：[4,4]\n> - 以 5 开头的数组（1 个）：[5,5]\n> 共计 5 + 2 + 1 + 1 + 1 = 10 个不同理想数组。\n\n**示例 2：**\n\n> **输入**：n = 5, maxValue = 3\n> **输出**：11\n> **解释**：存在以下理想数组：\n>\n> - 以 1 开头的数组（9 个）：\n>    - 不含其他不同值（1 个）：[1,1,1,1,1] \n>    - 含一个不同值 2（4 个）：[1,1,1,1,2], [1,1,1,2,2], [1,1,2,2,2], [1,2,2,2,2]\n>    - 含一个不同值 3（4 个）：[1,1,1,1,3], [1,1,1,3,3], [1,1,3,3,3], [1,3,3,3,3]\n> - 以 2 开头的数组（1 个）：[2,2,2,2,2]\n> - 以 3 开头的数组（1 个）：[3,3,3,3,3]\n> 共计 9 + 1 + 1 = 11 个不同理想数组。\n\n \n\n**提示：**\n\n- 2 `<= n <=` $10^4$\n\n- 1 `<= maxValue <=` $10^4$\n\n  \n\n## 问题分析\n\n**注意到**：\n\n- 任意理想数组 ${a_i}$ 满足 $1\\le a_0\\mid a_1\\mid\\cdots\\mid a_{n-1}= y,\\text{ }a_i\\le \\text{maxValue}$ 。\n\n- 对于固定的末尾值 $y\\le\\mathrm{maxValue}$，从 1 变到 $y$ 的“除数链”可看作在每个质因数方向上“累积指数”的过程（把它的每个质因子 $p$、指数 $e_p$ 看成要在前 $n-1$ 个“空位”中放 $e_p$ 个“乘 $p$”操作）。\n\n- 若 $y=\\prod p_i^{e_i}$，则在长度为 $n$ 的链中，需要分配这 $e_i$ 次“乘以 $p_i$”操作到 $n-1$ 个相邻位置上，属于 **「Stars and Bars」** 模型（ **“星星与条纹”** ），每种质因子独立，所以总方案数是：\n  $$\n  \\#\\{\\text{链数}\\}=\\prod_i\\binom{(n-1)+e_i}{e_i}.\n  $$\n\n- 最后对所有 $y$ 累加，并对 $10^9+7$ 取模，因此，答案就是\n  $$\n  \\sum_{y=1}^\\mathrm{maxValue}\\left[\\prod_{p^e\\|y}\\binom{(n-1)+e}{e}\\right]\\mathrm{mod}(10^9+7).\n  $$\n\n`预处理` → `枚举 y=1…maxValue` → `分解 y 的质因子` → `用“comb”累乘` → `累加取模` → `返回`\n\n## 算法思路\n\n1. **预处理阶乘与逆元阶乘**，支持快速计算组合数 $\\binom{a}{b}$。\n2. 用 **线性／筛法**（`SPF` 最小质因子）对 $[1\\ldots\\mathrm{maxValue}]$ 做一次质因数分解，整体复杂度约 $O(\\mathrm{maxValue}\\log\\log \\mathrm{maxValue})$。\n3. 对每个 $y$ 枚举其质因数指数 $e_i$，累乘组合数即可。\n\n## 时间复杂度\n\n- 阶乘 & 逆元：$O(n + \\log \\mathrm{maxValue})$\n- `SPF` 筛：$O(\\max\\mathrm{Value}\\log\\log\\mathrm{maxValue})$\n- 主循环：每个 $y$ 仅分解一次，总体 $O(\\max\\mathrm{Value}\\log\\mathrm{maxValue})$\n- **总体**：$O(n+\\max\\mathrm{Value}\\log\\log\\mathrm{maxValue}+\\max\\mathrm{Value}\\log\\mathrm{maxValue})$ ，低于DP\n\n空间复杂度：$O(n+\\max\\mathrm{Value})$ ，主要用于阶乘数组与 SPF 数组。\n\n\n\n## 代码实现\n\n```python\nimport math\nclass Solution:\n    def idealArrays(self, n: int, maxValue: int) -> int:\n        MOD = 10**9 + 7\n\n        # —— 1. 预处理：阶乘 & 逆阶乘 —— \n        # 最大可能的指数增量 ≈ log2(maxValue)\n        maxE = int(math.log2(maxValue)) + 1\n        up = n - 1 + maxE\n        fact = [1] * (up + 1)\n        invfact = [1] * (up + 1)\n        for i in range(1, up + 1):\n            fact[i] = fact[i-1] * i % MOD\n        invfact[up] = pow(fact[up], MOD-2, MOD)\n        for i in range(up, 0, -1):\n            invfact[i-1] = invfact[i] * i % MOD\n\n        def comb(a: int, b: int) -> int:\n            if b < 0 or b > a: \n                return 0\n            return fact[a] * invfact[b] % MOD * invfact[a-b] % MOD\n\n        # —— 2. SPF 最小质因子筛 —— \n        spf = list(range(maxValue + 1))\n        for p in range(2, int(maxValue**0.5) + 1):\n            if spf[p] == p:\n                for j in range(p*p, maxValue + 1, p):\n                    if spf[j] == j:\n                        spf[j] = p\n\n        # —— 3. 主循环：对每个 y 分解、累乘组合数 —— \n        ans = 0\n        for y in range(1, maxValue + 1):\n            ways = 1\n            v = y\n            while v > 1:\n                p = spf[v]\n                e = 0\n                while v % p == 0:\n                    v //= p\n                    e += 1\n                # 在 n-1 个间隔里放置 e 次“乘 p”操作\n                ways = ways * comb((n-1) + e, e) % MOD\n            ans = (ans + ways) % MOD\n\n        return ans\n\n```\n\n另看到题解：\n\n```python\nclass Solution:\n    def idealArrays(self, n: int, maxValue: int) -> int:\n        MOD = 10**9 + 7\n\n        # —— 1. 预处理：组合数 Pascal 三角 —— \n        maxE = int(math.log2(maxValue)) + 1\n        up = n - 1 + maxE\n        C = [[0] * (maxE + 1) for _ in range(up + 1)]\n        for i in range(up + 1):\n            C[i][0] = 1\n            for j in range(1, min(i, maxE) + 1):\n                C[i][j] = (C[i-1][j] + C[i-1][j-1]) % MOD\n\n        # —— 2. 预处理：EXP 质因子指数列表 —— \n        EXP = [[] for _ in range(maxValue + 1)]\n        for y in range(2, maxValue + 1):\n            v = y\n            p = 2\n            while p * p <= v:\n                e = 0\n                while v % p == 0:\n                    v //= p\n                    e += 1\n                if e:\n                    EXP[y].append(e)\n                p += 1\n            if v > 1:\n                EXP[y].append(1)\n\n        # —— 3. 主循环：对每个 y 累乘组合数 —— \n        ans = 0\n        for y in range(1, maxValue + 1):\n            ways = 1\n            for e in EXP[y]:\n                ways = ways * C[n - 1 + e][e] % MOD\n            ans = (ans + ways) % MOD\n\n        return ans\n\n```\n\n1. **DP 转组合**：把「每一步都要保持可整除」的递推，转化为「质因子指数如何在 $n$ 个位置上非负分配」的组合计数；\n2. **枚举**：对每个可能的末尾值 $x$ 计算它的组合数贡献，再求和。\n\n- 对于固定的 $y$，它的每个质因子 $p$ 在 $a_0,\\dots,a_{n-1}$ 中的**指数序列**\n  $$\n  e_0=0(\\text{不一定为0})\\le e_1\\le\\cdots\\le e_{n−1}=E,\n  $$\n  且 $\\sum$ 个位置上的“增加量”恰好等于 $E$ （ $e_1 + e_2 + ... + e_k = E$ ）（即 $y$ 中该质因子的总指数）。\n\n- **“星星与条纹”**：前文已解释\n\n- 实现\n\n  - **预处理每个 $x≤\\text{maxValue}$ 的质因数指数列表**，`EXP[x]` 存放 $x$ 分解后，每个质因子的指数 $[e_1,e_2,\\dots]$。\n  - **预计算组合数 $\\binom{N}{k}$**：由于 $n\\le10^4$, 指数 $E_p$ 也最多 $\\log_2(10^4)\\approx14$，我们只需算到 $N=n+14-1$。\n    用帕斯卡三角，这样 `C[N][k]` 就是 $\\binom{N}{k}\\bmod(10^9+7)$。\n  - **枚举所有 $x=1…maxValue$**，累加它们作为数组末尾的方案数，注意 $x=1$ 时 `EXP[1]` 为空，`res=1`，对应 “全 1 数组” 这一类。\n\n- 复杂度：\n\n  - **质因数分解**：$\\sum_{x=1}^{M}\\sqrt{x}=O(M^{3/2})$，这里 $M=\\text{maxValue}\\le10^4$ 足够快。\n  - **组合数预处理**：$O\\bigl((n+\\max E)\\times \\max E\\bigr)\\approx O(n\\cdot\\log M)$。\n  - **枚举累加**：$O\\bigl(M\\times (\\text{平均质因子数})\\bigr)\\approx O(M\\log M)$。\n\n| 特性           | 第一个实现（阶乘 + 逆元 comb + SPF 筛分解）                  | 第二个实现（Pascal 组合表 + 试除分解）                       |\n| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| **组合数计算** | 预计算 `fact` 和 `invfact` 数组，用公式 <br/>$\\binom{a}{b} = \\frac{\\text{fact}[a]}{\\text{fact}[b] \\times \\text{fact}[a - b]} \\mod p$ 每次 $O(1)$ 快速计算 | 用帕斯卡三角预计算 $C[i][j] = \\binom{i}{j}$ <br>查询时直接 $O(1)$ 取表 |\n| **质因子分解** | 先用线性/埃氏思路构造 `SPF`（最小质因子）表 $spf[i]$ <br>分解时不断 $v //= spf[v]$，复杂度约 $O(\\log{v})$ | 每个 $x$ 用试除法 $\\sqrt{x}$ 搜索素因子，累计其指数          |\n| **预处理时间** | 构造 `fact`, `invfact`：$O(n + \\max E)$（再加一次快速幂取逆）  构造 `SPF`：$O(M \\log \\log M)$ | 构造 $C$ 表：$O\\bigl((n + \\max E) \\times \\max E\\bigr)$  <br>试除分解：$\\sum_{x=1}^M O(\\sqrt{x}) \\approx O(M^{3/2})$ |\n| **空间开销**   | 两个长度 $n + \\max E$ 的数组 + 一个长度 $M$ 的 `SPF` 数组    | $C$ 表大约 $(n + \\max E) \\times (\\max E)$ 个整数             |\n| **适用场景**   | 当  $\\max{Value}$ 更大（比如 $10^5$ 、$10^6$） 时，`SPF` 分解会更快、更稳，阶乘逆元计算组合数也更节省空间 | $n, \\max{Value} \\le 10^4$ 都较小，预先填表和试除都能在 `1–2s` 内完成 |\n| **代码复杂度** | 略微复杂一些，需要处理逆元和 `SPF` 数组                      | 直观易懂，组合表和试除都很朴素                               |\n\n`Qwen QWQ 32b`给出的解，思路大致相同\n(预处理最小质因数 → 质因数分解存储 → 阶乘与逆元预计算 → DP到组合数学 → 前缀和优化)：\n\n```python\nclass Solution:\n    def idealArrays(self, n: int, maxValue: int) -> int:\n        MOD = 10**9 + 7\n        t = n - 1\n        if t == 0:\n            return maxValue % MOD\n        \n        max_num = maxValue\n        \n        # 步骤 1：计算筛的 min_prime 数组.\n        min_prime = [0] * (max_num + 1)\n        for i in range(2, max_num + 1):\n            if min_prime[i] == 0:\n                min_prime[i] = i\n                for j in range(i*i, max_num+1, i):\n                    if min_prime[j] == 0:\n                        min_prime[j] = i\n        \n        # 预计算 factor_list[m]：从质数到指数的字典.\n        factor_list = [{} for _ in range(max_num + 1)]\n        \n        for m in range(2, max_num + 1):\n            num = m\n            factors = {}\n            while num > 1:\n                p = min_prime[num]\n                cnt = 0\n                while num % p == 0:\n                    cnt += 1\n                    num //= p\n                factors[p] = cnt\n            factor_list[m] = factors.copy() if factors else {}\n        \n        # 步骤 2：预计算 fact 和 inv_fact，最多 N=2e5.\n        N_fact = 2 * 10**5\n        fact = [1] * (N_fact + 1)\n        for i in range(1, N_fact + 1):\n            fact[i] = (fact[i-1] * i) % MOD\n        \n        inv_fact = [1]*(N_fact + 1)\n        inv_fact[N_fact] = pow(fact[N_fact], MOD -2, MOD)\n        for i in range(N_fact -1, -1, -1):\n            inv_fact[i] = (inv_fact[i+1] * (i+1)) % MOD\n        \n        # 步骤 3：计算 fm 数组.\n        fm = [0]*(max_num + 1)  # 从 0 到 maxValue 的索引.\n        \n        for m in range(1, max_num + 1):\n            if m == 1:\n                factors_dict = {}\n            else:\n                factors_dict = factor_list[m]\n            \n            product = 1\n            for p in factors_dict:\n                a_i = factors_dict[p]\n                n_val = a_i + t - 1\n                k_val = t - 1\n                \n                # 选择 k 和 (n_val -k) 之间的较小值，以减少计算量.\n                if k_val > (n_val - k_val):\n                    k_val = n_val - k_val\n                \n                # 计算 C(n_val, k_val)\n                c_n_k = fact[n_val] * inv_fact[k_val] % MOD\n                c_n_k = c_n_k * inv_fact[n_val - k_val] % MOD\n                product = (product * c_n_k) % MOD\n            \n            fm[m] = product\n        \n        # 计算前缀数组.\n        prefix = [0]*(max_num + 1)\n        for i in range(1, max_num+1):\n            prefix[i] = (prefix[i-1] + fm[i]) % MOD\n        \n        res = 0\n        for a_val in range(1, maxValue + 1):\n            m_max = maxValue // a_val\n            res += prefix[m_max]\n            res %= MOD\n        \n        return res\n\n```\n\n","tags":["Algorithm","组合数学","快速幂","枚举与剪枝","困难"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-21","url":"/post/count-the-hidden-sequences.html","content":"\n# [2145. 统计隐藏数组数目](https://leetcode.cn/problems/count-the-hidden-sequences/) M\n\n给你一个下标从 **0** 开始且长度为 `n` 的整数数组 `differences` ，它表示一个长度为 `n + 1` 的 **隐藏** 数组 **相邻** 元素之间的 **差值** 。更正式的表述为：我们将隐藏数组记作 `hidden` ，那么 `differences[i] = hidden[i + 1] - hidden[i]` 。\n\n同时给你两个整数 `lower` 和 `upper` ，它们表示隐藏数组中所有数字的值都在 **闭** 区间 `[lower, upper]` 之间。\n\n- 比方说，`differences = [1, -3, 4]` ，`lower = 1` ，`upper = 6` ，那么隐藏数组是一个长度为`4` 且所有值都在 `1` 和 `6` （包含两者）之间的数组。\n  - `[3, 4, 1, 5]` 和 `[4, 5, 2, 6]` 都是符合要求的隐藏数组。\n  - `[5, 6, 3, 7]` 不符合要求，因为它包含大于 `6` 的元素。\n  - `[1, 2, 3, 4]` 不符合要求，因为相邻元素的差值不符合给定数据。\n\n请你返回 **符合** 要求的隐藏数组的数目。如果没有符合要求的隐藏数组，请返回 `0` 。\n\n \n\n**示例 1：**\n\n> **输入**：differences = [1,-3,4], lower = 1, upper = 6\n> **输出**：2\n> **解释**：符合要求的隐藏数组为：\n>\n> - [3, 4, 1, 5]\n> - [4, 5, 2, 6]\n>\n> 所以返回 2 。\n\n**示例 2：**\n\n> **输入**：differences = [3,-4,5,1,-2], lower = -4, upper = 5\n> **输出**：4\n> **解释**：符合要求的隐藏数组为：\n>\n> - [-3, 0, -4, 1, 2, 0]\n> - [-2, 1, -3, 2, 3, 1]\n> - [-1, 2, -2, 3, 4, 2]\n> - [0, 3, -1, 4, 5, 3]\n>\n> 所以返回 4 。\n\n**示例 3：**\n\n> **输入**：differences = [4,-7,2], lower = 3, upper = 6\n> **输出**：0\n> **解释**：没有符合要求的隐藏数组，所以返回 0 。\n\n \n\n**提示：**\n\n- `n == differences.length`\n- 1 `<= n <=` $10^5$\n- $-10^5$ `<= differences[i] <=` $10^5$\n- $-10^5$ `<= lower <= upper <=` $10^5$\n\n\n\n## 问题分析\n\n1. **前缀和（Prefix Sums）**\n\n   定义\n   $$\n   P_0=0,\\quad P_i=\\sum_{k=0}^{i-1}\\text{differences}[k]\\quad(1\\leq i\\leq n).\n   $$\n   则隐藏数组第 $i$ 个元素有\n   $$\n   \\text{hidden}[i]=\\text{hidden}[0]+P_i.\n   $$\n\n2. **区间约束转化**\n\n   要保证所有元素都在 $[\\text{lower},\\;\\text{upper}]$ 之间，即对所有 $0\\le i\\le n$ 都有\n   $$\n   \\text{lower}\\le \\text{hidden}[0]+P_i \\le \\text{upper}.\n   $$\n   等价于\n   $$\n   \\max_{i}\\bigl(\\mathrm{hidden}[0] + P_{i}\\bigr) \\leq \\mathrm{upper} \\quad\\Longrightarrow\\quad \\mathrm{hidden}[0] \\leq \\mathrm{upper} - \\max_{i} P_{i},\n   $$\n\n   $$\n   \\min_{i}\\bigl(\\mathrm{hidden}[0] + P_{i}\\bigr) \\geq \\mathrm{lower} \\quad\\Longrightarrow\\quad \\mathrm{hidden}[0] \\geq \\mathrm{lower} - \\min_{i} P_{i}.\n   $$\n\n   $$\n   \\mathrm{hidden}[0]\\leq\\mathrm{upper}-\\max_iP_i,\\quad\\mathrm{hidden}[0]\\geq\\mathrm{lower}-\\min_iP_i.\n   $$\n\n3. **可行起始值个数**\n\n   记 $minP=\\min_iP_i,maxP=\\max_iP_i$ 。\n\n   那么\n   $$\n   \\mathrm{hidden}[0]∈[\\mathrm{lower}−\\min\\text{P},\\mathrm{upper}−\\max\\text{P}],\n   $$\n   区间长度（整数个数）为\n   $$\n   (\\mathrm{~upper}-maxP)-(\\mathrm{~lower}-minP)+1=(\\mathrm{upper}-\\mathrm{lower})-(maxP-minP)+1.\n   $$\n   若该值为负，则答案是0。\n\n   \n\n## 算法思路\n\n1. **遍历一次 differences**，用变量 `curr` 累加差分，实时维护 `minP = min(minP, curr)` 和 `maxP = max(maxP, curr)`。\n\n2. 根据上面推导，计算可行的 `hidden[0]` 的左端点 `L = lower - minP`，右端点 `R = upper - maxP`。\n\n3. 答案即为 `max(0, R - L + 1)`。\n\n## 时间复杂度\n\n- 算法的时间复杂度为$O(n)$，其中$n$是`differences`数组的长度。因为只需遍历一次差异数组即可计算所有必要的参数，没有嵌套循环，因此效率较高。\n\n- 仅使用常数级额外空间，故空间复杂度为$O(1)$。\n\n## 代码实现\n\n```python\n# 先求前缀极值再统一算区间\nclass Solution:\n    def numberOfArrays(self, differences: List[int], lower: int, upper: int) -> int:\n        # 初始化前缀和的最小值和最大值\n        minP = 0\n        maxP = 0\n        curr = 0\n        \n        # 遍历差分数组，更新前缀和区间\n        for d in differences:\n            curr += d\n            minP = min(minP, curr)\n            maxP = max(maxP, curr)\n        \n        # 计算起始值 hidden[0] 的可行区间 [L, R]\n        L = lower - minP\n        R = upper - maxP\n        \n        # 区间长度即为符合要求的数组个数\n        return max(0, R - L + 1)\n\n```\n\n也可直接把对每个位置的区间约束（本质相同）\n$$\n\\mathrm{lower}\\leq\\mathrm{hidden}[0]+P_i\\leq\\mathrm{upper}\n$$\n转化为对 `hidden[0]` 的上下界，并在遍历中不断收缩，最终得出相同可行区间 $[\\max\\{\\underline{L}\\},\\min\\{\\overline{R}\\}]$\n\n**维护上下界**\n\n- 令 `curr = P_i`，初始 `curr = 0`。\n- 看到新的`curr`就把 $\\mathrm{hidden}[0]\\geq\\mathrm{lower}-\\mathrm{curren}t_s$ 转化为下界 `L = lower - curr`并往上取最大，把 $\\mathrm{hidden}[0]\\leq\\mathrm{upper}-\\mathrm{curren}t_s$ 转化为上界 `R = upper - curr`并往下取最小。\n- 每步累加差分 `curr += d` 后\n\n若 `L > R` 则 0，否则 `R - L + 1`。\n\n```python\n# 遍历中直接收敛上下界\nfrom typing import List\n\nclass Solution:\n    def numberOfArrays(self, differences: List[int], lower: int, upper: int) -> int:\n        curr = 0\n        L = lower      # lower - 0\n        R = upper      # upper - 0\n        for d in differences:\n            curr += d\n            candL = lower - curr\n            if candL > L:\n                L = candL\n            candR = upper - curr\n            if candR < R:\n                R = candR\n        return max(0, R - L + 1)\n\n```\n\n","tags":["Algorithm","组合数学","中等","数据结构","前缀和"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-20","url":"/post/rabbits-in-forest.html","content":"\n# [781. 森林中的兔子](https://leetcode.cn/problems/rabbits-in-forest/) M\n\n森林中有未知数量的兔子。提问其中若干只兔子 **\"还有多少只兔子与你（指被提问的兔子）颜色相同?\"** ，将答案收集到一个整数数组 `answers` 中，其中 `answers[i]` 是第 `i` 只兔子的回答。\n\n给你数组 `answers` ，返回森林中兔子的最少数量。\n\n \n\n**示例 1：**\n\n> **输入**：answers = [1,1,2]\n> **输出**：5\n> **解释**：\n> 两只回答了 \"1\" 的兔子可能有相同的颜色，设为红色。 \n> 之后回答了 \"2\" 的兔子不会是红色，否则他们的回答会相互矛盾。\n> 设回答了 \"2\" 的兔子为蓝色。 \n> 此外，森林中还应有另外 2 只蓝色兔子的回答没有包含在数组中。 \n> 因此森林中兔子的最少数量是 5 只：3 只回答的和 2 只没有回答的。\n\n**示例 2：**\n\n> **输入**：answers = [10,10,10]\n> **输出**：11\n\n \n\n**提示：**\n\n- `1 <= answers.length <= 1000`\n- `0 <= answers[i] < 1000`\n\n\n\n## 问题分析\n\n我们需要根据兔子的回答 `answers` 数组计算森林中最少的兔子数量。每只回答为 `a` 的兔子表示其颜色族群中有 `a + 1` 只兔子（包括自己）。关键在于将相同答案的兔子尽可能分到同一族群，以最小化总数。\n\n## 算法思路\n\n1. 遍历 `answers` 数组，使用哈希表 `count` 统计每个回答值 `x` 出现的频次 `c`\n\n2. 对于每个不同的 `x`：\n\n   - 每组最多能容纳 `x+1` 只兔子；\n\n   - 如果有 `c` 只兔子都回答了 `x`，则需要的组数为：\n     $$\n     \\text{groups} = \\left\\lceil \\frac{c}{x+1} \\right\\rceil\n     $$\n\n   - 每个族群贡献 `x + 1` 只兔子，这些组中总兔子数为：\n     $$\n     \\text{groups} \\times (x+1)\n     $$\n\n3. 将所有不同回答值对应的最少兔子数累加，即可得到森林中兔子的最少数量。\n\n## 时间复杂度\n\n- 统计频率的时间复杂度：$O(n)$，其中数组长度 $n=answers.length$ ，因为仅需一次遍历统计，再对哈希表键值进行遍历。\n- 分组计算的时间复杂度：$O(m)$，其中 $m$ 是不同答案的个数 $(m ≤ n)$。因此总时间复杂度为 $O(n)$。\n- 空间复杂度：$O(m)$，其中 $m$ 是不同回答值的数量，最坏情况 $m = n$。\n\n## 代码分解\n\n1. **统计答案频率**：使用 `collections.Counter` 记录每个回答的出现次数。\n2. **分组计算**：\n   - 对于每个回答`x`和对应的计数`c`：\n     - 分组数目为 `(c + x) // (x + 1)`（使用整数运算 `(c + group_size - 1) // group_size` 来替代向上取整）。\n     - 总兔子数累加 `groups * (x + 1)`。\n\n## 代码实现\n\n```python\nfrom collections import Counter\nfrom typing import List\n\nclass Solution:\n    def numRabbits(self, answers: List[int]) -> int:\n        count = Counter(answers)\n        total = 0\n        for x, c in count.items():\n            # 每组容量为 x+1\n            group_size = x + 1\n            # 计算需要的最少族群数量（ceil(c / group_size)向上取整）\n            groups = (c + group_size - 1) // group_size\n            # 累加该回答值对应的最少兔子数\n            total += groups * group_size\n        return total\n\n```\n\n","tags":["Algorithm","组合数学","中等","哈希表","贪心"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-19","url":"/post/count-the-number-of-fair-pairs.html","content":"\n# [2563. 统计公平数对的数目](https://leetcode.cn/problems/count-the-number-of-fair-pairs/) M\n\n给你一个下标从 **0** 开始、长度为 `n` 的整数数组 `nums` ，和两个整数 `lower` 和 `upper` ，返回 **公平数对的数目** 。\n\n如果 `(i, j)` 数对满足以下情况，则认为它是一个 **公平数对** ：\n\n- `0 <= i < j < n`，且\n- `lower <= nums[i] + nums[j] <= upper`\n\n \n\n**示例 1：**\n\n> **输入**：nums = [0,1,7,4,4,5], lower = 3, upper = 6\n> **输出**：6\n> **解释**：共计 6 个公平数对：(0,3)、(0,4)、(0,5)、(1,3)、(1,4) 和 (1,5) 。\n\n**示例 2：**\n\n> **输入**：nums = [1,7,9,2,5], lower = 11, upper = 11\n> **输出**：1\n> **解释**：只有单个公平数对：(2,3) 。\n\n \n\n**提示：**\n\n- 1 `<= nums.length <=` $10^5$\n- `nums.length == n`\n- $-10^9$ `<= nums[i] <=` $10^9$\n- $-10^9$ `<= lower <= upper <=` $10^9$\n\n\n\n## 问题分析\n\n问题本质上是寻找满足特定条件的数对 $(i, j)$，其中 $i$ 和 $j$ 是数组的索引，且它们的和在给定的范围 `[lower, upper]` 内。这是一个典型的双指针或者排序后使用二分查找的问题，通过排序将问题转化为在有序数组中快速定位满足和的区间的边界。\n\n## 算法思路\n\n1. **排序数组**：将输入的`nums`数组进行升序排列，便于后续操作。\n\n2. 方法一（**双指针**滑动窗口）\n\n   **可以将问题化简为两个「≤ 某值」的问题**\n\n   定义函数\n   $$\n   f(k)=\\#\\{0\\leq i<j<n\\mid nums[i]+nums[j]\\leq k\\}.\n   $$\n   那么题目要的答案就是\n   $$\n   f(upper)−f(lower−1).\n   $$\n   对于每个左端点 `i`（`0 ≤ i < n-1`），我们维护两个指针 `l` 与 `r`：\n\n   - 左指针 `l` 从头开始（0），右指针 `r` 从尾开始（n−1）；\n\n   - 如果 `nums[l] + nums[r] ≤ k`，那么对于固定的 `l`，所有 `(l, l+1),…,(l, r)` 都满足，因为排序保证 `nums[l] + nums[j] ≤ nums[l] + nums[r]`；可以一次性加上 `r−l` 个对，把 `l` 右移：`l += 1`。\n\n     否则（和太大）就让 `r` 左移：`r -= 1`。\n\n   - 直到 `l >= r`，整个过程需 $O(n)$ 级的指针移动，配合排序总复杂度 $O(n \\log n)$。\n\n3. 方法二（**二分查找**）\n    **遍历每个元素作为固定点**：对于每一个元素`nums[i]`（其中`i < j`），直接对排序后的数组在区间 `(i+1, n-1]` 上执行两次二分查找：\n\n   计算目标和的上下界：`lower - nums[i]` 和 `upper - nums[i]`，即要求`nums[j]`必须落在这个范围内。\n\n   **二分查找边界**：在有序数组中利用二分查找快速定位满足条件的`j`的位置区间：\n\n   枚举每个 `i`，目标是找满足\n   $$\n   lower≤nums[i]+nums[j]≤upper,j>i\n   $$\n   等价于\n   $$\n   lower−nums[i]≤nums[j]≤upper−nums[i].\n   $$\n   \n\n   - `left`：在排序数组的区间 `(i+1, n)` 上，第一个大于等于目标下界`lower - nums[i]`的元素位置\n     `lo = lower - nums[i]`，查 `bisect_left(nums, lo, i+1)`；\n   - `right`：第一个大于目标上界`upper - nums[i]`的元素位置\n     `hi = upper - nums[i]`，查 `bisect_right(nums, hi, i+1) - 1`；\n\n   **统计有效数目**：计算符合条件的索引区间长度，并累加到总数中\n\n   -  二分查找各 $O(\\log n)$，共 $O(n \\log n)$。\n\n## 时间复杂度\n\n- 排序数组的时间为 $O(n \\log n)$，其中 $n$ 是 `nums.length`\n- 双指针扫描需 $O(n)$\n- 遍历每个元素并进行两次二分查找的操作时间为 $O(n \\log n)$\n- 两种方法**总时间复杂度**都为：$O(n \\log n)$\n- **空间复杂度**：$O(n)$（排序需要复制或原地排序），$O(1)$（忽略排序所需栈或语言内部额外空间）\n\n## 代码实现\n\n**双指针法**：\n\n```python\nclass Solution:\n    def countFairPairs(self, nums: list[int], lower: int, upper: int) -> int:\n        # 排序\n        nums.sort()\n        # 结果 = ≤upper 的对数 - ≤(lower-1) 的对数\n        return self._count_leq(nums, upper) - self._count_leq(nums, lower - 1)\n\n    def _count_leq(self, nums: list[int], k: int) -> int:\n        \"\"\"\n        返回 排序后数组中 和 <= k 的数对数量 f(k)。\n        \"\"\"\n        l, r = 0, len(nums) - 1\n        cnt = 0\n        while l < r:\n            if nums[l] + nums[r] <= k:\n                # 对于当前 l，(l, l+1)...(l, r) 都是合法对\n                cnt += (r - l)\n                l += 1\n            else:\n                # 和太大，缩小右侧\n                r -= 1\n        return cnt\n```\n\n**二分法**：\n\n```python\nclass Solution:\n    def countFairPairs(self, nums: List[int], lower: int, upper: int) -> int:\n        nums.sort()\n        n = len(nums)\n        count = 0\n        for i in range(n - 1):\n            lo = lower - nums[i]\n            hi = upper - nums[i]\n            left = bisect_left(nums, lo, i + 1, n)\n            right = bisect_right(nums, hi, i + 1, n) - 1\n            if left < n and left <= right:\n                count += (right - left + 1)  # 符合条件的元素数目\n        return count\n```\n\n","tags":["Algorithm","中等","枚举与剪枝","数据结构","逆序对计数","滑动窗口","双指针","二分查找","排序"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-18","url":"/post/count-number-of-bad-pairs.html","content":"\n# [2364. 统计坏数对的数目](https://leetcode.cn/problems/count-number-of-bad-pairs/) M\n\n给你一个下标从 **0** 开始的整数数组 `nums` 。如果 `i < j` 且 `j - i != nums[j] - nums[i]` ，那么我们称 `(i, j)` 是一个 **坏数对** 。\n\n请你返回 `nums` 中 **坏数对** 的总数目。\n\n \n\n**示例 1：**\n\n> **输入**：nums = [4,1,3,3]\n> **输出**：5\n> **解释**：数对 (0, 1) 是坏数对，因为 1 - 0 != 1 - 4 。\n> 数对 (0, 2) 是坏数对，因为 2 - 0 != 3 - 4, 2 != -1 。\n> 数对 (0, 3) 是坏数对，因为 3 - 0 != 3 - 4, 3 != -1 。\n> 数对 (1, 2) 是坏数对，因为 2 - 1 != 3 - 1, 1 != 2 。\n> 数对 (2, 3) 是坏数对，因为 3 - 2 != 3 - 3, 1 != 0 。\n> 总共有 5 个坏数对，所以我们返回 5 。\n\n**示例 2：**\n\n> **输入**：nums = [1,2,3,4,5]\n> **输出**：0\n> **解释**：没有坏数对。\n\n \n\n**提示：**\n\n- 1 <= `nums.length` <= $10^5$\n- 1 <= `nums[i]` <= $10^9$\n\n\n\n## 问题分析\n\n1.**化简判定条件**\n\n我们通过数学变换将条件转化为统计差值相等的数对数量，最终用总数减去好的数对得到答案：\n\n对于一对索引 $i<j$，当且仅当\n$$\nj - i = \\text{nums}[j] - \\text{nums}[i]\n$$\n时，这对 $(i,j)$ 不是坏数对；等价于\n$$\n\\text{nums}[j] - j = \\text{nums}[i] - i.\n$$\n将所有元素映射为“调整值” $A_k = \\text{nums}[k] - k$，计算所有元素与索引的差值，统计相同差值出现次数，则“好数对”数目就是所有相同 $A$ 值之间的组合对数。\n\n2.**总对数与好对数**\n\n数组长度为 $n$ 时，总对数为 $\\tfrac{n(n-1)}2$。\n\n对于每个不同的调整值 $v$，若出现次数为 $c_v$，则它内部的好对数为 $\\tfrac{c_v(c_v-1)}2$。\n\n坏数对数 = 总对数 – $\\displaystyle\\sum_v \\tfrac{c_v(c_v-1)}2$。\n\n## 算法思路\n\n1. 遍历一次数组，使用哈希表统计每个 $A_k=\\text{nums}[k]-k$ 出现的频次。\n2. 计算总对数 $\\tfrac{n(n-1)}2$。\n3. 对哈希表中每个频次 $c$，累加 $\\tfrac{c(c-1)}2$ 得到“好对数”。\n4. 用总对数减去好对数，得到坏数对数。\n\n## 时间复杂度\n\n时间复杂度：$O(n)$，只需一次遍历加上对哈希表的小量遍历。\n\n空间复杂度：$O(n)$，哈希表最坏存储 $n$ 个不同键。\n\n## 代码实现\n\n```python\nclass Solution:\n    def countBadPairs(self, nums: list[int]) -> int:\n        from collections import Counter\n        \n        n = len(nums)\n        # 1. 统计调整值频次\n        freq = Counter(nums[i] - i for i in range(n))\n        \n        # 2. 总对数\n        total_pairs = n * (n - 1) // 2\n        \n        # 3. 累加所有“好对数”\n        good_pairs = sum(c * (c - 1) // 2 for c in freq.values())\n        \n        # 4. 坏数对 = 总对数 - 好对数\n        return total_pairs - good_pairs\n\n```\n\n","tags":["Algorithm","组合数学","中等","数据结构","哈希表"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-17","url":"/post/count-equal-and-divisible-pairs.html","content":"\n# [2176. 统计数组中相等且可以被整除的数对](https://leetcode.cn/problems/count-equal-and-divisible-pairs-in-an-array/) E\n\n给你一个下标从 **0** 开始长度为 `n` 的整数数组 `nums` 和一个整数 `k` ，请你返回满足 `0 <= i < j < n` ，`nums[i] == nums[j]` 且 `(i * j)` 能被 `k` 整除的数对 `(i, j)` 的 **数目** 。\n\n \n\n**示例 1：**\n\n> 输入：nums = [3,1,2,2,2,1,3], k = 2\n> 输出：4\n> **解释**：\n> 总共有 4 对数符合所有要求：\n>\n> - nums[0] == nums[6] 且 0 * 6 == 0 ，能被 2 整除。\n> - nums[2] == nums[3] 且 2 * 3 == 6 ，能被 2 整除。\n> - nums[2] == nums[4] 且 2 * 4 == 8 ，能被 2 整除。\n> - nums[3] == nums[4] 且 3 * 4 == 12 ，能被 2 整除。\n\n**示例 2：**\n\n> 输入：nums = [1,2,3,4], k = 1\n> 输出：0\n> 解释：由于数组中没有重复数值，所以没有数对 (i,j) 符合所有要求。\n\n \n\n**提示：**\n\n- `1 <= nums.length <= 100`\n- `1 <= nums[i], k <= 100`\n\n\n\n## 问题分析\n\n统计所有满足\n\n1. **索引约束**：`0 ≤ i < j < n`\n2. **数值相等**：`nums[i] == nums[j]`\n3. **整除性**：`(i * j) % k == 0`\n\n的数对数量。\n\n## 算法思路\n\n对数组`nums`中相同数值的下标进行分组（哈希表分组），然后在各组内部枚举下标对并检查乘积能否被 k 整除。\n\n对于每个数值对应的索引列表：\n\n- 若长度小于2，则跳过（无有效对）。\n- 否则，遍历所有可能的数对`(i, j)`（i < j），检查`i * j % k == 0`是否成立，若成立则计数加1。\n\n## 时间复杂度\n\n- **预处理时间**：$O(n)$，遍历数组一次存储索引。\n- 最坏情况下所有元素都相同(每个元素形成一组)，枚举组内所有 $\\binom{n}{2}$ 对，复杂度 $O(n^2)$。由于n的最大为100，总计算量约为5000次，在可行范围内。\n- **空间复杂度**：$O(n)$，用于存储分组字典。\n\n## 代码实现\n\n```python\nfrom collections import defaultdict\nfrom typing import List\n\nclass Solution:\n    def countPairs(self, nums: List[int], k: int) -> int:\n        \"\"\"\n        返回满足 nums[i] == nums[j] 且 (i * j) 能被 k 整除的 (i, j) 对数。\n        \"\"\"\n        num_indices = defaultdict(list)\n        for idx, num in enumerate(nums):\n            num_indices[num].append(idx)\n        \n        count = 0\n        for indices_list in num_indices.values():\n            n = len(indices_list)\n            if n < 2:\n                continue\n            # 遍历所有i<j的组合\n            for i in range(n):\n                for j in range(i + 1, n):\n                    a = indices_list[i]\n                    b = indices_list[j]\n                    product = a * b\n                    if product % k == 0:\n                        count += 1\n        return count\n\n```\n\n用单次遍历 `+` 边加边算的方式可以稍微降低常数，只遍历一遍 `nums`，每遇到一个新下标就与之前同值下标配对判定，复杂度仍为$O(n^2)$，但常数略优\n\n```python\nclass Solution:\n    def countPairs(self, nums: List[int], k: int) -> int:\n        index_map = defaultdict(list)\n        ans = 0\n        for i, v in enumerate(nums):\n            for j in index_map[v]:\n                if (i * j) % k == 0:\n                    ans += 1\n            index_map[v].append(i)\n        return ans\n\n```\n\n","tags":["Algorithm","暴力搜索","简单","枚举与剪枝","数据结构","哈希表"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-16","url":"/post/countGoodsubarrays.html","content":"\n# [2537. 统计好子数组的数目](https://leetcode.cn/problems/count-the-number-of-good-subarrays/) M\n\n给你一个整数数组 `nums` 和一个整数 `k` ，请你返回 `nums` 中 **好** 子数组的数目。\n\n一个子数组 `arr` 如果有 **至少** `k` 对下标 `(i, j)` 满足 `i < j` 且 `arr[i] == arr[j]` ，那么称它是一个 **好** 子数组。\n\n**子数组** 是原数组中一段连续 **非空** 的元素序列。\n\n \n\n**示例 1：**\n\n> **输入**：nums = [1,1,1,1,1], k = 10\n> **输出**：1\n> **解释**：唯一的好子数组是这个数组本身。\n\n**示例 2：**\n\n> **输入**：nums = [3,1,4,3,2,2,4], k = 2\n> **输出**：4\n> **解释**：总共有 4 个不同的好子数组：\n>\n> - [3,1,4,3,2,2] 有 2 对。\n> - [3,1,4,3,2,2,4] 有 3 对。\n> - [1,4,3,2,2,4] 有 2 对。\n> - [4,3,2,2,4] 有 2 对。\n\n \n\n**提示：**\n\n- 1 <= `nums.length` <= $10^5$\n- 1 <= `nums[i], k` <= $10^9$\n\n\n\n## 问题分析\n\n给定一个整数数组 `nums` 和一个整数 `k`，要求返回数组中好子数组的数目。题目中“好子数组”的定义为：子数组中存在至少 `k` 对下标 `(i, j)` 满足 `i < j` 且 `arr[i] == arr[j]`，也就是我们需要找出数组中所有满足至少有 `k` 对下标 `(i, j)`（其中 `i < j` 且元素相同）的子数组的数量。\n\n## 算法思路\n\n1. 当一个元素 `x` 在窗口中出现了 `c` 次时，它贡献的配对数量为组合数 $C(c,2)=\\frac{c(c−1)} 2$，但动态调整更高效的方式是通过增量/减量来维护总数。\n2. 使用双指针（滑动窗口）技术来遍历所有连续子数组。\n3. 维护一个窗口 `[l, r]`，以及窗口中每个数字出现的频数 `freq`。\n4. 同时在每一步更新窗口内的成对数字数量 `count`。当我们向窗口中添加新元素 `x` 时，窗口中原先 `x` 出现的次数为 `freq[x]`，那么新增的对数为 `freq[x]`（每个已有的 `x` 和新加入的 `x` 都可以构成一对）。因此更新 `count += freq[x]`，然后 `freq[x]` 加 1。\n5. 对于每个左边界 `l`，利用右指针 `r` 尽可能扩展窗口，直到 `count >= k`。设当窗口达到条件时，当前的 `r` 满足条件，则对于定左边界 `l`，所有右边界 `r'` 属于 `[r, n-1]` 的窗口均满足条件，因此可以直接将 `n - r` 加入答案。\n6. 随后移动左边界 `l`，同时更新 `count`。在移除窗口最左边元素时，假设其值为 `x`，此时删除该元素会导致窗口中 `x` 的出现次数减少，进而需要减少的对数为 `freq[x] - 1`（因为该 `x` 和其它 `x` 形成的对数就少了）。\n\n## 时间复杂度\n\n每个元素最多被右指针和左指针访问（加入和移除窗口）各一次，因此双指针方法整体时间复杂度为 $O(n)$，其中 n 是数组的长度。\n\n## 代码分解\n\n**窗口扩展：**\n 对于每个窗口左边界 `l`，通过右指针 `r`向右扩展窗口，直到窗口内满足 `count >= k`。在扩展过程中使用频次统计更新 `count`。\n\n**直接计数：**\n 一旦找到最小的右边界 `r` 使得 `[l, r]` 满足条件，则所有 `[l, r]`, `[l, r+1]`, ..., `[l, n-1]` 的子数组也均满足条件，因此可以直接加上 `n - r`。\n\n**滑动窗口收缩：**\n 移动左边界 `l`时，需要将 `nums[l]` 从窗口中移除，同时调整 `freq` 和 `count`。移除时由于原先 `x` 出现次数为 `freq[x]`，其对对数贡献为 `freq[x] - 1`（移除后剩余的配对数为 `freq[x] - 1`，因此减少 `freq[x] - 1`）。\n\n## 代码实现\n\n```python\nfrom collections import defaultdict\n\nclass Solution:\n    def countGood(self, nums, k: int) -> int:\n        n = len(nums)\n        # 字典存储每个数字的频次\n        freq = {}\n        count = 0  # 当前窗口中满足条件的对数数量\n        res = 0    # 结果计数\n        r = 0\n        \n        # 遍历左边界\n        for l in range(n):\n            # 不断扩展右边界，使窗口对数数量至少为 k\n            while r < n and count < k:\n                x = nums[r]\n                # 在添加前，x已有 freq.get(x, 0) 次，新增的对数即为这个频次\n                count += freq.get(x, 0)\n                freq[x] = freq.get(x, 0) + 1\n                r += 1\n            \n            # 如果当前窗口 [l, r-1] 的配对数量至少为 k，则右边所有扩展窗口都满足条件\n            if count >= k:\n                res += (n - r + 1)\n            \n            # 在将 l 右移前需要移除 nums[l] 对 count 的贡献\n            x = nums[l]\n            freq[x] -= 1\n            # 当移除一个 x 时，其对配对数的贡献为移除前该 x 与其它相同元素之间的对数数目，即 freq[x]（因为移除后，剩余的 x 数量为 freq[x]）\n            count -= freq[x]\n            \n        return res\n```\n\n","tags":["Algorithm","组合数学","中等","数据结构","滑动窗口"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-15","url":"/post/goodTriplets.html","content":"\n# [2179. 统计数组中好三元组数目](https://leetcode.cn/problems/count-good-triplets-in-an-array/) H\n\n给你两个下标从 **0** 开始且长度为 `n` 的整数数组 `nums1` 和 `nums2` ，两者都是 `[0, 1, ..., n - 1]` 的 **排列** 。\n\n**好三元组** 指的是 `3` 个 **互不相同** 的值，且它们在数组 `nums1` 和 `nums2` 中出现顺序保持一致。换句话说，如果我们将 pos$1_v$ 记为值 `v` 在 `nums1` 中出现的位置，pos$2_v$ 为值 `v` 在 `nums2` 中的位置，那么一个好三元组定义为 `0 <= x, y, z <= n - 1` ，且 pos$1_x$ < pos$1_y$ < pos$1_z$ 和 pos$2_x$ < pos$2_y$ < pos$2_z$ 都成立的 `(x, y, z)` 。\n\n请你返回好三元组的 **总数目** 。\n\n \n\n**示例 1：**\n\n> 输入：nums1 = [2,0,1,3], nums2 = [0,1,2,3]\n> 输出：1\n> 解释：\n> 总共有 4 个三元组 (x,y,z) 满足 pos$1_x$ < pos$1_y$ < pos$1_z$ ，分别是 (2,0,1) ，(2,0,3) ，(2,1,3) 和 (0,1,3) 。\n> 这些三元组中，只有 (0,1,3) 满足 pos$2_x$ < pos$2_y$ < pos$2_z$ 。所以只有 1 个好三元组。\n\n**示例 2：**\n\n> 输入：nums1 = [4,0,1,3,2], nums2 = [4,1,0,2,3]\n> 输出：4\n> 解释：总共有 4 个好三元组 (4,0,3) ，(4,0,2) ，(4,1,3) 和 (4,1,2) 。\n\n \n\n**提示：**\n\n- `n == nums1.length == nums2.length`\n- 3 <= n <= $10^5$\n- `0 <= nums1[i], nums2[i] <= n - 1`\n- `nums1` 和 `nums2` 是 `[0, 1, ..., n - 1]` 的排列。\n\n## 问题分析\n\n题目给定两个长度为*n*且下标从0开始的整数数组`nums1`和`nums2`，这两个数组都是`[0,1,...,n−1]`的排列。定义了好三元组为3个<u>互不相同</u>的值，且它们在数组`nums1`和`nums2`中出现**顺序**保持**一致**，\n即若`pos1v`为值v在`nums1`中出现的位置，`pos2v`为值v在`nums2`中出现的位置，\n好三元组需满足`0 <= x, y, z <= n−1`，且`pos1x < pos1y < pos1z`和`pos2x < pos2y < pos2z`都成立的`(x,y,z)` ，要求返回好三元组的总数目。\n\n## 算法思路\n\n由于两个数组都是 0 到 n - 1 的排列，考虑以下转换：\n\n1. **构造新数组**\n    我们先建立一个数组 `p`，其中\n   $$\n   p[i]=\\text{pos2}[\\text{nums1}[i]]\n   $$\n   这里的 $\\text{pos2}[v]$ 表示值 $v$ 在 `nums2` 中的位置。\n   由于 `nums1` 本身已经按其在原数组中的顺序排序，因此原题中要求 “pos1$x$ < pos1$y$ < pos1$z$” 已自动满足。问题就转化为：在数组 `p` 中计数满足\n   $$\n   p[i]<p[j]<p[k]\n   $$\n   且满足 $i<j<k$ 的三元组。\n\n2. **双遍扫描计数**\n    对于数组中的每个中间元素 $p[j]$，设：\n\n   - $L_j$：在 $j$ 之前（即 $i<j$）满足 $p[i] < p[j]$ 的数量；\n   - $R_j$：在 $j$ 之后（即 $k>j$）满足 $p[k] > p[j]$ 的数量；\n\n   则以 $p[j]$ 为中间元素的有效三元组数量为 $L_j \\times R_j$。整个三元组数量为所有 $j$ 上的累加和。\n\n3. **树状数组（Fenwick Tree）的作用**\n    由于 $n$ 可能达到 $10^5$ 级别，直接遍历统计 $L_j$​ 和 $R_j$​ 是 $O(n^2)$ 的效率。借助树状数组，我们可以在 $O(\\log n)$ 内查询某个前缀的值，从而：\n\n   - 正向遍历计算每个位置 $j$ 的 $L_j$；\n   - 逆向遍历计算每个位置 $j$ 的 $R_j$。\n\n## 时间复杂度\n\n- **构造映射与数组转换**：$O(n)$\n\n- **正序与逆序遍历树状数组操作**：使用两个树状数组分别进行两次扫描(每个元素需要正向逆向各一次)，每个查询和更新均为 $O(\\log n$，共计 $O(n \\log n)$\n\n- **总体时间复杂度**：$O(n \\log n)$\n- **空间复杂度**：$O(n)$, 用于存储两个计数数组及树状数组的结构\n\n## 代码分解\n\n**FenwickTree 类**\n 负责单点更新和区间查询，从而在 $O(\\log n)$ 时间内计算前缀和。\n\n**构造映射与数组转换**\n 将 `nums2` 中每个数值映射到对应的位置，构造数组 `p` 后，数组 `p` 就是按照 `nums1` 顺序排列的 `nums2` 中的下标，即 `p[i]` 是 nums1 的第 i 个元素在 nums2 中的位置。\n\n**左侧计数（L[j]）**\n 使用树状数组，从左到右扫描数组 `p`，对于每个位置 `j`，查询 `p[j]` 之前比它小的数字个数，并更新树状数组，通过遍历 `p` 数组并动态查询当前值之前的前缀和实现。\n\n**右侧计数（R[j]）**\n 使用另一个树状数组，从右到左扫描数组 `p`，对于每个位置 `j`，查询已经处理的右侧元素中比 `p[j]` 大的数量，通过总已处理元素数减去小于等于 `p[j]` 的数目得到。\n\n**三元组数量累加**\n 对每个中间位置 `j`，三元组数量为 $L[j] \\times R[j]$，对所有可能的中间位置累加即为最终答案。\n\n## 代码实现\n\n```python\nclass FenwickTree:\n    def __init__(self, size: int):\n        self.size = size\n        self.tree = [0] * (size + 1)\n    \n    def update(self, index: int, delta: int):\n        # index 从 0 开始转换到 1-based\n        index += 1\n        while index <= self.size:\n            self.tree[index] += delta\n            index += index & -index\n\n    def query(self, index: int) -> int:\n        # 查询前缀和 [0, index]，index 为 0-based\n        index += 1\n        res = 0\n        while index:\n            res += self.tree[index]\n            index -= index & -index\n        return res\n\nclass Solution:\n    @staticmethod\n    def goodTriplets(nums1: list, nums2: list) -> int:\n        n = len(nums1)\n        \n        # 建立 nums2 中值 -> 位置 的映射\n        pos2 = [0] * n\n        for idx, num in enumerate(nums2):\n            pos2[num] = idx\n        \n        # 构造数组 p，其中 p[i] = pos2[nums1[i]]\n        p = [pos2[num] for num in nums1]\n        \n        # 第一步：正序遍历，计算每个 j 左侧比 p[j] 小的数量 L[j]\n        left_count = [0] * n\n        fenwick_left = FenwickTree(n)\n        for j in range(n):\n            # p[j] 前有多少数比它小\n            left_count[j] = fenwick_left.query(p[j] - 1)\n            fenwick_left.update(p[j], 1)\n        \n        # 第二步：逆序遍历，计算每个 j 右侧比 p[j] 大的数量 R[j]\n        right_count = [0] * n\n        fenwick_right = FenwickTree(n)\n        for j in range(n - 1, -1, -1):\n            # 右侧比 p[j] 大的数量 = 当前已处理的个数中 p 值大于 p[j] 的数量\n            # 先查询 p[j] 的前缀和，已加入的元素总数为 (n-1 - j)\n            right_count[j] = fenwick_right.query(n - 1) - fenwick_right.query(p[j])\n            fenwick_right.update(p[j], 1)\n        \n        # 三元组数量：对每个 j 中间元素，累加 L[j] * R[j]\n        result = 0\n        for j in range(n):\n            result += left_count[j] * right_count[j]\n        return result\n```\n\n","tags":["Algorithm","组合数学","困难","树状数组","数据结构","逆序对计数"],"categories":["算法"]},{"title":"Tableau分析与可视化看板","url":"/post/Tableau.html","content":"\n# Tableau数据连接与可视化分析\n\n本文主要介绍 Tableau 的基础连接与使用，包括数据可视化的原理以及常用的图表制作，针对不同分析使用的图表类型，BI看板的搭建等内容。\n\n## 目录\n\n1. [数据连接](#数据连接)\n2. [数据可视化原理](#数据可视化原理)\n3. [基础图表制作](#基础图表制作)\n4. [数据可视化原则](#数据可视化原则)\n5. [BI仪表盘搭建](#bi仪表盘搭建)\n\n------\n\n[社区大佬可视化方案参考学习](https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day)\n\n**Tableau能做什么？**\n\n- 数据赋能\n\n  *让业务一线也可以轻松使用最新数据*\n\n  - 分析师可以直接将数据看板发布到线上\n\n  - 自动更新看板\n\n  - 自由下载数据\n\n  - 线上修改图表\n\n  - 邮箱发送数据\n\n  - 设置数据预警\n\n- 数据探索\n\n  *通过统计分析和数据可视化，从数据发现问题，用数据验证假设*\n\n  - 支持亿级数据的连接和处理\n\n  - 自由地对字段进行各种计算\n\n  - 拖拽就可以轻松制作图表\n\n  - 数据可以随意聚合下钻\n\n  - 图表类型可以灵活转换\n\n  - 内置算法智能建模\n\n------\n\n## 1. 数据连接\n\n### 1.1 连接类型\n\n#### 1.1.1 本地文件\n\n| 文件类型         | 连接方式         |\n| ---------------- | ---------------- |\n| CSV              | 文本连接         |\n| Excel (xls/xlsx) | Excel文件连接    |\n| JSON             | 直接连接JSON文件 |\n\n![Tableau 1](https://s2.loli.net/2025/04/14/uqs9Rby5v7HIKz1.png)\n\n![Tableau 连接](https://s2.loli.net/2025/04/14/utRx2ONTqLSlIa5.png)\n\n#### 1.1.2数据库\n\n1. **驱动配置**  \n   下载对应数据库驱动后，配置地址、端口、认证等参数\n2. **数据连接**  \n   数据库连接方法与SQL相似\n\n![Tableau支持的数据库](https://s2.loli.net/2025/04/14/HZVSOk8EFhKqnJC.png)\n\n### 1.2 连接方式\n\n1. **智能连接**（默认）\n   - 自动识别字段类型，只需选择连接字段\n   - ✅支持字段计算和编辑\n   - ✅支持排序、重命名、拆分等操作\n2. **字段计算**：连接字段可通过函数进行计算和编辑（动态）\n\n```\n# 示例函数计算字段\n  DATE_TRUNC('day', \"下单日期\") AS 订单日维度\n```\n\n1. **表格连接**：表格之间的连接原理同SQL\n2. **连接原理**\n   - 多表连接机制同SQL\n   - ✅支持多条件组合连接\n\n![Tableau表连接](https://s2.loli.net/2025/04/14/B7sdH3OvqjoG9zl.png)\n\n**操作示例**：\n\n1. 连接 `shop` 表 → 拖拽 `cpc` 表，设置连接条件：\n   - 门店ID = 门店ID\n   - 日期 = 日期\n2. 连接 `orders` 表→ 拖拽 `shop`表，设置连接条件：\n   - 门店ID = 门店ID\n   - 日期 = 下单日期\n\n![Tableau多表连接](https://s2.loli.net/2025/04/14/ZxR3CoeU6bWiYcD.png)\n\n### 1.3 提取方式\n\n| 方式     | 特点                                                         | 适用场景          |\n| -------- | ------------------------------------------------------------ | ----------------- |\n| 实时查询 | 每次操作触发数据库查询（查询语言VizQL）                      | 小数据量/频繁更新 |\n| 数据提取 | 1.提取连接数据，保存为`.hyper`文件，支持增量刷新<br />2.`.twbx` 文件会将 `.hyper` 数据打包<br />3.修改数据源后需重新提取数据，实时连接则无此限制<br />4.一般大型数据推荐提取，除非频繁修改连接字段 | 大数据量/离线分析 |\n\n![Tableau数据提取选项](https://s2.loli.net/2025/04/14/SGBk1gjnxI37AOy.png)\n\n**注意事项**：\n\n- 上传Tableau Server必须使用数据提取\n\n- 提取数据后可进行预筛选，仅保留需要的数据用于视图操作\n\n- ❌预筛选建议在连接阶段设置，而非视图层过滤\n\n  ![Tableau数据筛选器](https://s2.loli.net/2025/04/14/TIyzC5XuEMjNJnW.png)\n\n- 提取选项支持增量刷新策略（基于字段/函数）\n\n  ```python\n  # 示例：每日仅更新新增行\n  EXTRACT_INCREMENTAL ON \"last_updated_date\" > DATEADD('day', -1, CURRENT_DATE())\n  ```\n\n- `.twb`文件不包含数据仅保存连接与视图信息，`.twbx`打包数据，可打包共享<u>（Tableau Server发布**必须使用**`.twbx`）</u>\n\n- ⚠️百万级数据建议使用增量刷新\n\n### 1.4 数据处理\n\n- 查看、排序、重命名、拆分等操作\n\n  ![Tableau描述与拆分](https://s2.loli.net/2025/04/14/GYRPgVtKEU7IZo6.png)\n\n  ![Tableau筛选显示行与排序查看日期](https://s2.loli.net/2025/04/14/p1O3gDjbYtK6MQs.png)\n\n- 图表界面也可完成大部分数据操作，包括预测，趋势线，描述性统计分析指标等\n\n------\n\n## 2. 数据可视化原理\n\n### 2.1 核心概念\n\n1. **为什么要可视化**\n\n- 图表能让人更快理解最大/最小值等信息\n- 人类具备视觉优势，图比字更易识别\n- 文字源自象形，图形表达更直观\n\n![Tableau视觉元素感知排序](https://s2.loli.net/2025/04/14/lem8E7B5LJxt6vW.png)\n\n![Tableau可视化辞典](https://s2.loli.net/2025/04/14/1vA2egZYFDdiGBu.jpg)\n\n2. **度量与维度**\n   - **度量（Measures）**：数值型变量 → 图形面积/长度/颜色深浅 → 数轴\n   - **维度（Dimensions）**：类别型变量 → 图形颜色/位置/分类 → 标签\n\n| 类型     | 特征描述                       | 典型示例          |\n| -------- | ------------------------------ | ----------------- |\n| **度量** | 数值型可计算变量               | GMV总和, 订单数量 |\n| **维度** | 非数值分类变量（如城市、性别） | 用户ID, 源渠道    |\n\n> Tableau 自动识别变量类型，类型可互相转换\n\n![Tableau度量与维度](https://s2.loli.net/2025/04/14/XvD7u1aYMWbSeCR.png)\n\n### 2.2 Tableau 可视化基础操作\n\n1. **拖拽操作**\n\n   - 行/列：决定图表坐标轴\n\n   - 标记卡：控制图形颜色、大小、标签等\n\n     ![Tableau标记卡与筛选器](https://s2.loli.net/2025/04/14/6o2ph1j7CJqMfyY.png)\n\n   - 筛选器：设定可视条件\n\n     ![对应的筛选器](https://s2.loli.net/2025/04/14/OgKIaeTutl5LkAY.png)\n\n2. **五大可视化原理**\n\n   1. *度量默认聚合运算（SUM/AVG）*\n\n      - 拖动“消耗”到行 → 自动生成柱状图（求和）\n\n      - Tableau 会自动聚合度量（默认总和）\n\n        ![Tableau条形图](https://s2.loli.net/2025/04/14/7LIuidNJFCaPhxm.png)\n\n   2. *图形标记自由切换*\n\n      - 标记卡中可选择不同图形（柱状图、饼图、折线图等）\n\n      - 一个度量只有一个值无法形成折线（需多个点）\n\n      - 拖拽度量至行/列形成**图表**，拖拽至标签区域形成**表格**\n\n        ![Tableau表格](https://s2.loli.net/2025/04/14/fsq3QRO4lHFnDbr.png)\n\n        ![Tableau表格2](https://s2.loli.net/2025/04/14/jIdGCVpLw7kREHl.png)\n\n        ![等同于变换成离散放在行](https://s2.loli.net/2025/04/14/m5npR8wQuqLHeJg.png)\n\n   3. *维度增加信息密度（多层级对比）*\n\n      - 拖入维度字段 → 将一个点拆解为多个 → 可连成线\n\n      - 维度可拖至：颜色、标签、详细信息、行、列，会增强信息密度\n\n      - 示例：将日期字段转换为字符串 → 拖至列 → 形成折线图\n\n        ![Tableau折线图](https://s2.loli.net/2025/04/14/OS84L5eEyHXs2bk.png)\n\n      - 拖日期 → 标签、拖消耗 → 大小、选“文本” → 形成词云图、选“圆形” → 形成气泡图\n\n        ![Tableau词云](https://s2.loli.net/2025/04/14/HcgiSUYWdKXoLIb.png)\n\n        ![Tableau气泡图](https://s2.loli.net/2025/04/14/6ehfDbNLFyJwiS4.png)\n\n   4. *图表类型决定坐标轴形态（有轴图表 vs 无轴图表（极坐标图表））*\n\n      - 有轴：折线图、柱状图（需数轴）\n\n      - 无轴：饼图、树地图、词云、气泡图（极坐标）\n\n      - 示例饼图制作：将 GMV 拖到大小，门店拖到颜色 → 树地图(树地图是升级版的饼图，按照顺序展示大小，还能增加颜色等维度)；\n        更改标记类型为饼图 → 映射角度与面积\n\n        ![Tableau树地图](https://s2.loli.net/2025/04/14/bVwOT7f6KrSDakI.png)\n\n        ![Tableau饼图](https://s2.loli.net/2025/04/14/K76QD1mVy8XJFrM.png)\n\n   5. *连续变量生成**坐标轴**，离散变量生成**标签***\n\n      - 连续度量 → 数轴（逻辑连续参考系）\n      - 离散维度 → 标签（顺序可调的参考系）\n\n      | 类型                 | 作用               |\n      | -------------------- | ------------------ |\n      | **离散变量（维度）** | 形成标签，构成表格 |\n      | **连续变量（度量）** | 形成数轴，构成图形 |\n\n      - 示例：拖维度构建表格（如日期、门店、品牌）\n        将度量字段设置为离散 → 变为维度\n        拖度量至列或行 → 生成图形（数轴）\n\n### 2.3 视觉映射类型\n\n[可视化辞典Github仓库](https://github.com/Financial-Times/chart-doctor/tree/main/visual-vocabulary)与[Web](https://ft-interactive.github.io/visual-vocabulary/)\n\n| 视觉元素    | 适用场景                                         | 示例               | 适用图表         |\n| ----------- | ------------------------------------------------ | ------------------ | ---------------- |\n| 位置        | x/y 轴呈现度量，分布趋势分析                     | 人均收入与寿命关系 | 散点图           |\n| 长度        | 长度反映数值对比                                 | 地区销售额对比     | 柱状图/条形      |\n| 角度        | 用于表示部分与整体的占比关系                     | 性别比例分析       | 饼图/玫瑰图/环形 |\n| 颜色        | 分类/数值密度，饱和度/色调表现维度分类或度量高低 | 地理区域分布       | 热力图           |\n| 面积 & 体积 | 多维度占比，面积/体积与度量成正比                | 通过大小表示数值   | 树地图           |\n| 方向        | 展示度量随维度（如时间）变化趋势                 | 四季电力消耗趋势   | 折线图           |\n\n> 形状可用于标记不同组别（维度），如散点图标记点形状\n\n------\n\n## 3. 基础图表制作\n\n### 3.1 对比分析\n\n| 图表类型    | 制作要点                   | 适用场景       |\n| ----------- | -------------------------- | -------------- |\n| 柱状图      | 维度→列，度量→行           | ≤5个分类对比   |\n| 条形图      | 维度→行，度量→列           | ≥5个分类对比   |\n| 热力图      | 文本表+颜色映射，使用合计% | 多维度交叉对比 |\n| 气泡图/词云 | 度量→大小，维度→颜色/标签  | 百级分类对比   |\n\n- 创建分层结构可以在拖动标签时将整个结构组都拖动，并根据需要点击+或-在工作表内展示数据的量\n\n  ![Tableau分层结构](https://s2.loli.net/2025/04/14/Kij1uzPnY9MAxGI.png)\n\n- 筛选器选项可以自定义筛选器单项或多项的样式\n\n  ![Tableau筛选器选项](https://s2.loli.net/2025/04/14/S8eE2IK6TRPYtL9.png)\n\n- 热力图设置标记为方形，适用于多【维度】下多变量的同时对比，并且需要同时查看对比效果和数值，如各组/商品类别之间的销售额、利润同时对比\n\n  ![Tableau热力图](https://s2.loli.net/2025/04/14/vo5HaqX7ZLcduis.png)\n\n### 3.2 变化/趋势分析\n\n| 图表类型 | 制作要点                                                     | 适用场景   |\n| -------- | ------------------------------------------------------------ | ---------- |\n| 折线图   | 时间→列（连续），度量→行<br />季节性调整需手动添加移动平均线 | 趋势分析   |\n| 面积图   | 折线图→区域填充                                              | 累计值分析 |\n\n- 给折线图添加趋势线可以增加内容的丰富程度，并提升专业性，还可以增加预测（实际应用中一般都是高维数据，R²低误差高，参考性不大）\n\n  ![Tableau折线图趋势线与预测](https://s2.loli.net/2025/04/14/7xWyXzjFalT8CKf.png)\n\n- 将画折线图时的标记从线改为区域，即可形成面积图。适用于有内部累计关系的值，并会随时间变化，不强调趋势，强调绝对值\n\n  ![Tableau面积图](https://s2.loli.net/2025/04/14/hzpao1I7xlK8sT3.png)\n\n### 3.3 构成/占比分析\n\n| 图表类型 | 制作要点                  | 适用场景           |\n| -------- | ------------------------- | ------------------ |\n| 饼图     | 维度→颜色，度量→角度      | ≤3分类占比         |\n| 树地图   | 维度→颜色/标签，度量→大小 | 多层级（维度）占比 |\n| 堆积图   | 维度→颜色，主维度→轴      | 多维度累计占比     |\n\n- 饼图需要设置合计百分比显示占比（百分比差异类似同比环比计算）\n\n  ![饼图合计百分比](https://s2.loli.net/2025/04/14/sTZo8P57fcyzpQC.png)\n\n  ![饼图设置格式控制百分比小数位数](https://s2.loli.net/2025/04/14/WXgMzQJ7BasPwf9.png)\n\n- 堆积图适用于相同【度量】下，比较一个【维度】下另一个【维度】的占比。堆积图显示合计百分比需要在快速表计算后再编辑表计算并选择计算依据为\"表(向下)\"，否则会显示占整体数据的百分比，再按住`CTRL`将该计算字段拖动至'行'，即可看到占整体的比例（<u>只能看到占比，忽略绝对值大小</u>）\n\n  ![Tableau堆积图设置](https://s2.loli.net/2025/04/14/UiXBGmpI82Wu4tS.png)\n\n- 因此一般需要同时查看值的大小和占比，在标记区域选择未使用快速计算的字段（没有Δ），然后将其中的标签移除并更换为原始字段\n\n  ![Tableau堆积图设置2](https://s2.loli.net/2025/04/14/k1FhdRaJlbfy5m7.png)\n\n### 3.4 分布分析\n\n| 图表类型 | 制作要点                          | 适用场景     |\n| -------- | --------------------------------- | ------------ |\n| 散点图   | X/Y轴→度量，维度→颜色             | 相关性分析   |\n| 直方图   | 度量→自动分箱                     | 单变量分布   |\n| 地图     | 地理角色→详细信息，度量→大小/颜色 | 空间分布分析 |\n\n- 散点图：将Cpc总费用拖入列，GMV拖入行，然后将字符串形式的日期放入**标记**的**详细信息**，门店名称放入颜色，即可看到各个店铺的投放效果（斜率越大投放效果越好）\n\n  ![Tableau散点图](https://s2.loli.net/2025/04/14/ANPaJw2VteGyBFC.png)\n\n- 还可以对散点图进行聚类，，具有相同分布特征的变量会被分为一类，可选自动或手动设置聚类(Cluster)数 (K-means聚类算法，基于欧式距离计算)\n\n  ![Tableau散点图聚类](https://s2.loli.net/2025/04/14/CE8Fm2PGui5nXjZ.png)\n\n- 直方图与数据桶：在数据型字段右键 → 创建 → 数据桶。数据桶本质是根据设定的数据桶大小作为间隔(箱宽度)，将离散的点分类并计数。用于查看单一度量下的数据分布\n\n- 常见分布；2/8法则；马太效应；40-20-10（如果你想让你的APP保持增长势头，那么你的新用户次日留存率，7天留存率和30天留存率应该分别维持在40%、20%和10%左右）\n\n  ![Tableau数据桶](https://s2.loli.net/2025/04/14/uYtLPdMyCVJvnSo.png)\n\n- 地图：对于数据中的城市，需要将字段的属性设置为地理角色中的某个值，然后双击即可在工作表中显示地图。\n\n  ![Tableau地图设置](https://s2.loli.net/2025/04/14/WJxS56yvGtHrwfM.png)\n\n  对于经纬度坐标，则需要将地理角色设置为经纬度，然后分别双击，即可在工作表显示地图\n\n  ![Tableau经纬度](https://s2.loli.net/2025/04/14/aHeLUIpo3xshvW1.png)\n\n  - 由于多数情况下数据会经过脱敏处理，原来可表示唯一值的订单id等字段会有重复值出现，因此需要创建主键来自行计算出一个唯一值。左键点击创建计算字段，拖拽选择合适的字段进行计算，表达式需要确保计算的字段**格式相同**，因此对于数值型变量可以使用`STR()`函数将其转换为字符串进行计算\n\n    ![Tableau创建主键](https://s2.loli.net/2025/04/14/4HgrBnEuwDMKSVL.png)\n\n  - 使用计算出的\"主键\"作为详细信息，距离作为颜色，用户实付作为大小，即可在地图上画出大小、颜色均进行区分的散点地图\n\n    ![Tableau配送距离与实付图](https://s2.loli.net/2025/04/14/lUe2pcYZbjtR8aw.png)\n\n> 例：南丁格尔玫瑰图实现步骤（用色块圆饼展示战地死亡率，促进英国军方改善医疗条件）：\n>\n> - 将角度字段设置为度量值\n> - 在标记卡选择\"极坐标系\"\n> - 添加颜色区分分类变量（如月份）\n>\n\n------\n\n## 4. 数据可视化原则\n\n1. **用户导向**\n\n   - 区分观众层级（执行/管理/决策）\n\n     ![Tableau用户区分](https://s2.loli.net/2025/04/14/rNBQHb58A2vaeOY.png)\n2. **信息层级**\n\n   - 主指标放大，辅助指标弱化\n3. **视觉真实**\n   - 坐标轴从0开始\n   - 避免3D变形\n4. **认知适配**\n\n   - 使用行业通用图表类型(地理位置用地图、随时间变化用折线图等)\n5. **设计规范**\n   - 颜色≤8种，简化设计，突出重点，少即是多\n   - 图表需在 5 秒内传达核心信息\n6. **辅助说明**\n\n   - 添加标题/图例/数据标签/结论等(右键数据添加注释)\n\n多到[Tableau社区](https://public.tableau.com/zh-cn/gallery/?tab=viz-of-the-day&type=viz-of-the-day)去学习好的方案\n\n![Tableau好的可视化方案](https://s2.loli.net/2025/04/14/1psaqdOuXGTUvQi.png)\n\n------\n\n## 5. BI仪表盘搭建\n\n### 5.1 设计流程\n\n1. **明确主题**\n\n   - 受众是谁？关注点是什么？\n   - 例：每日营收监控 → GMV/转化率/订单分布\n\n2. **数据准备/拆解指标**\n\n   - 营收数据：GMV、商家实收、用户实付、总订单数、cpc总费用、各平台数据对比\n\n   - 流量数据：曝光人数、进店人数、下单人数、进店转化率、下单转化率、新客数、老客数、复购率\n   - 关键指标：GMV、流量数据*（每日营收）*进店率、复购率*（用户行为）*\n   - 辅助指标：CPC费用、无效订单*（投放效果）*\n\n   **先**设计好要使用的元素，**后**进行可视化的调整，与Excel相同，下面是某店铺外卖的营收数据设计\n\n   1. 首先需要将筛选器设置为联动(使用相关数据源的所有项)，实现图表间的数据统一\n\n   ![Tableau联动筛选](https://s2.loli.net/2025/04/14/YOaodfxpQVDiTUu.png)\n\n   2. 需要一个经营状况总览，拖动字段直至出现智能显示即可在数据的左右加入新的列，也可直接拖入度量值中，若出现其它图形，可以先尝试更改字段类型为离散\n\n      ![Tableau智能显示](https://s2.loli.net/2025/04/15/RNksrp6zx5H72KM.png)\n\n      ![Tableau经营状况总览](https://s2.loli.net/2025/04/15/SwcgoXtidHDuL4Q.png)\n\n   3. 新建工作表，用同样的方式制作详情表，'行'中字段根据需要添加\n\n      ![Tableau经营数据详情](https://s2.loli.net/2025/04/15/ygUSfQEaPqb3vDn.png)\n\n   4. 每日营收数据，需要多条曲线时，添加多个度量值将字段直接拖到纵轴上\n\n      ![Tableau每日营收数据](https://s2.loli.net/2025/04/15/q46A21Qe3uJlSHI.png)\n\n   5. 并非所有有用的字段都会在业务数据中直接提供，因此有时需要添加计算字段\n\n      ![Tableau进店率与成交率计算](https://s2.loli.net/2025/04/15/ZeG8hdrgTKsO1bN.png)\n\n      ![Tableau右键设置默认数字格式-百分比，减少重复修改](https://s2.loli.net/2025/04/15/F7egSsflDbX8kqU.png)\n\n   6. 多曲线的单位差异会导致在同一张图中显示时，某一或多条曲线因值过小而导致可视化效果差，不具备参考意义，这时可以设置双轴\n\n      ![Tableau双轴](https://s2.loli.net/2025/04/15/CWFNEY452txsc6M.png)\n\n   7. 多曲线共同影响的字段可以作为背景展示，通过调整颜色、大小、不透明度等方式隐式的显示在曲线后（可选面积图或条形图）\n\n      ![Tableau条形图调整大小和不透明度](https://s2.loli.net/2025/04/15/TdaPi8yKuHDICro.png)\n\n      ![Tableau每日流量数据](https://s2.loli.net/2025/04/15/GN5jhylqC8HtJVY.png)\n\n   8. 根据数据ORDER90，我们自定义90天内未下单的用户为新客，用于展示新老客对比\n\n      ![Tableau新老客字段计算](https://s2.loli.net/2025/04/15/EXTPzol5a2kqjcS.png)\n\n   9. Tableau没有内置的环形图，需要自己手动设置实现近似效果\n      环形图：双击行 → 输入0 → 右键双轴 → 将其中一个的视觉元素全部移除 → 颜色改为白色 → 调整两个饼图的大小 → 环形图 → 取消零值线和取消显示标题（调整完成后使用`CTRL`+`←`或`→`可以调整环形图**整体的大小**，此功能不局限于饼图）需要多个环形图时，为保证一致性，可以使用拷贝工作表，然后更改字段\n\n      ![Tableau环形图](https://s2.loli.net/2025/04/15/kS2eOKbqUj1Lft3.png)\n\n   10. 有时业务数据的标签并不是想要展示的值，可以通过右键设置别名来更改为想要的值\n\n       ![Tableau别名设置](https://s2.loli.net/2025/04/15/5mnF4t6sj8pqk19.png)\n\n       ![Tableau门店占比](https://s2.loli.net/2025/04/15/pC6cy8YeEDROmZB.png)\n\n   11. 纵轴设置为GMV，横轴设置cpc总费用，可以看到各门店的投放情况，斜率越高效果越好\n\n       ![Tableau投放情况](https://s2.loli.net/2025/04/15/JyuZz1q4TMBY7Vx.png)\n\n   12. 面积图可以展示订单分布时间段（根据需要将下单日期格式设置为小时）与整体订单趋势\n\n       ![Tableau面积图订单分布](https://s2.loli.net/2025/04/15/Ei4tPymVJUpak3A.png)\n\n   13. 分组设置：在想要分组的位置按住shift单击，并点击分组，即可选中以上的全部数据分为一组，同时可以给组进行命名，可以使用if函数实现相同效果\n\n       ![Tableau创建距离分组](https://s2.loli.net/2025/04/15/pm9qoesgyxXjuRh.png)\n\n       ![Tableau配送分布](https://s2.loli.net/2025/04/15/x9vqF6nz8sca54U.png)\n\n3. **布局设计**\n\n   1. F型视线布局：关键指标置于左上区域\n   2. 动态筛选器统一放置顶部中央\n   3. 数据钻取深度不超过三级\n\n   ```\n   [仪表盘布局示例]\n   | 经营总览 | 趋势分析 |\n   |----------|----------|\n   | 占比分析 | 分布地图 |\n   ```\n\n   经营总览->数据详情->趋势分析->占比分析->分布分析\n\n   - 总览：文本突出显示\n   - 趋势：多轴折线图\n   - 分布：热力图 / 地图\n\n   仪表盘大小可以选择通用桌面1366 * 768，然后手动调整高度，从左边的工作表区域拖动需要的表到仪表盘，手动调整位置和大小\n\n   ![Tableau仪表盘对象选择](https://s2.loli.net/2025/04/15/Pj7GMtrUJZcvei9.png)\n\n   ![Tableau仪表盘工作表区](https://s2.loli.net/2025/04/15/E9Iy3VbQgMZTcvW.png)\n\n4. **交互优化**\n\n   - **逻辑顺序**：从上到下 / 从主到次\n   - **交互设计**：主题明确 + 交互友好，纵/横布局，强制设置所有图表共享联动筛选器\n   - **图表联动**（通过筛选器）\n   - **动态参数**（通过筛选器）\n   - **细节优化**：统一字体、配色（参考[Tableau 社区](https://public.tableau.com/zh-cn/gallery/)）\n   - **图表选择**：4 大金刚（<u>散点图、柱状图、饼图、折线图</u>），大多数数据可视化都可用这四种组合完成，人感知最强的可视化字典（位置、长度、角度/方向、面积/颜色）\n\n   ![Tableau仪表盘设置筛选器浮动，便于摆放](https://s2.loli.net/2025/04/15/rogRAGQyfXmNquD.png)\n\n   ![Tableau仪表盘工作表点击用作筛选器实现联动](https://s2.loli.net/2025/04/15/I5nXPq9wDflSKjM.png)\n\n### 5.2 开发规范\n\n1. **配色方案**\n   - 主色≤3种，辅色≤2种，推荐组合：`#2A5E8F（深蓝）+ #FF6B35（橙红）+ #4ECDC4（青绿）`\n   - 使用企业VI色系\n   - 参考：[Color Hunt](https://colorhunt.co/)\n2. **字体规范**\n   - 中文：微软雅黑\n   - 英文：Arial\n   - 文字标注使用12pt的微软雅黑字体\n3. **性能优化**\n   - 数据提取预处理\n   - 隐藏非必要细节\n\n**细节优化过程**\n\n1. 设置边框提升专业性\n\n   ![Tableau仪表盘设置边框](https://s2.loli.net/2025/04/15/MWAi8TDgqYuxOpz.png)\n\n2. 去掉一些数据表的行列分隔边线，提升美观度\n\n   ![Tableau仪表盘去掉原边框](https://s2.loli.net/2025/04/15/N7SmH1payYG8lTo.png)\n\n3. 更改地图背景，使其简洁，提升视觉效果，修改冲蚀更改背景透明度\n\n   ![Tableau仪表盘地图设置](https://s2.loli.net/2025/04/15/tU1OgzDdNVvE7Gi.png)\n\n4. 最后优化各工作表在仪表盘的标题、数据信息的格式，设置字体微软雅黑，颜色风格统一，如需更改标题的背景颜色，可以在布局中修改\n\n   ![Tableau仪表盘字体颜色](https://s2.loli.net/2025/04/15/AwbqvzVujasYUNd.png)\n\n   ![Tableau仪表盘数据分行颜色](https://s2.loli.net/2025/04/15/4Hgx3pqwR61TOLV.png)\n\n5. 优化各工作表的色调，使风格统一\n\n   ![Tableau仪表盘地图点颜色](https://s2.loli.net/2025/04/15/yKrtqT5gQimuFeJ.png)\n\n[Tableau社区案例参考](https://public.tableau.com/zh-cn/gallery)\n\n**最终效果：**\n\n![BI看板](https://s2.loli.net/2025/04/14/Dl3rBSGtINyE7nh.png)\n\n[参考文档](https://yrzu9y4st8.feishu.cn/mindnotes/bmncnQCbk8yr68s4eBikgB06Awd)","tags":["数据操作","可视化","看板与报表"],"categories":["数据分析"]},{"title":"LeetCode每日一题2025-04-14","url":"/post/countGoodTriplets.html","content":"\n# [1534. 统计好三元组](https://leetcode.cn/problems/count-good-triplets/) E\n\n给你一个整数数组 `arr` ，以及 `a`、`b` 、`c` 三个整数。请你统计其中好三元组的数量。\n\n如果三元组 `(arr[i], arr[j], arr[k])` 满足下列全部条件，则认为它是一个 **好三元组** 。\n\n- `0 <= i < j < k < arr.length`\n- `|arr[i] - arr[j]| <= a`\n- `|arr[j] - arr[k]| <= b`\n- `|arr[i] - arr[k]| <= c`\n\n其中 `|x|` 表示 `x` 的绝对值。\n\n返回 **好三元组的数量** 。\n\n \n\n**示例 1：**\n\n> **输入：** arr = [3,0,1,1,9,7], a = 7, b = 2, c = 3\n> **输出：** 4\n> **解释：** 一共有 4 个好三元组：[(3,0,1), (3,0,1), (3,1,1), (0,1,1)] 。\n\n**示例 2：**\n\n> **输入：** arr = [1,1,2,2,3], a = 0, b = 0, c = 1\n> **输出：** 0\n> **解释：** 不存在满足所有条件的三元组。\n\n \n\n**提示：**\n\n- `3 <= arr.length <= 100`\n- `0 <= arr[i] <= 1000`\n- `0 <= a, b, c <= 1000`\n\n## **问题分析**\n\n 给定数组 arr，以及三个整数 a、b、c，需要统计满足以下三个条件的三元组 (arr[i], arr[j], arr[k]) 的数量（其中 0 <= i < j < k < len(arr)）：\n\n- `|arr[i] - arr[j]| <= a`\n- `|arr[j] - arr[k]| <= b`\n- `|arr[i] - arr[k]| <= c`\n\n## **算法思路**\n\n- **暴力枚举**：直接使用三重循环枚举所有可能的三元组，然后检查是否满足条件。\n- **提前剪枝**：在第二层循环中，若`abs(arr[i] - arr[j]) > a`则直接跳过第三层循环（k），减少无效计算。\n\n## 时间复杂度\n\n- 对于数组长度 n，每个三元组枚举的时间复杂度为 O(n³)。由于题目约束 3 <= n <= 100，当 n = 100 时，最多循环大约 161700 次，在可接受的范围内。\n\n- 除了输入数组与常数级变量外，未使用额外数据结构，因此空间复杂度为 O(1)。\n\n## 代码实现\n\n```python\nfrom typing import List\n\nclass Solution:\n    def countGoodTriplets(self, arr: List[int], a: int, b: int, c: int) -> int:\n        count = 0\n        n = len(arr)\n        for i in range(n):\n            for j in range(i + 1, n):\n                if abs(arr[i] - arr[j]) > a:\n                    continue  # 提前剪枝，不满足a条件则跳过后续k的判断\n                for k in range(j + 1, n):\n                    # 同时检查b和c的条件\n                    if (abs(arr[j] - arr[k]) <= b) and (abs(arr[i] - arr[k]) <= c):\n                        count += 1\n        return count\n\n```\n\n","tags":["Algorithm","暴力搜索","简单","枚举与剪枝"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-13","url":"/post/countGoodNumbers.html","content":"\n# [1922. 统计好数字的数目](https://leetcode.cn/problems/count-good-numbers/) M\n\n我们称一个数字字符串是 **好数字** 当它满足（下标从 **0** 开始）**偶数** 下标处的数字为 **偶数** 且 **奇数** 下标处的数字为 **质数** （`2`，`3`，`5` 或 `7`）。\n\n- 比方说，`\"2582\"` 是好数字，因为偶数下标处的数字（`2` 和 `8`）是偶数且奇数下标处的数字（`5` 和 `2`）为质数。但 `\"3245\"` **不是** 好数字，因为 `3` 在偶数下标处但不是偶数。\n\n给你一个整数 `n` ，请你返回长度为 `n` 且为好数字的数字字符串 **总数** 。由于答案可能会很大，请你将它对 `109 + 7` **取余后返回** 。\n\n一个 **数字字符串** 是每一位都由 `0` 到 `9` 组成的字符串，且可能包含前导 0 。\n\n\n\n**示例 1：**\n\n> 输入：n = 1\n> 输出：5\n> 解释：长度为 1 的好数字包括 \"0\"，\"2\"，\"4\"，\"6\"，\"8\" 。\n\n**示例 2：**\n\n> 输入：n = 4\n> 输出：400\n\n**示例 3：**\n\n> 输入：n = 50\n> 输出：564908303\n\n \n\n**提示：**\n\n- 1 <= n <= $10^{15}$\n\n## **分析题意：**\n\n- 数字字符串为好数字需满足：偶数下标（0、2、4…）处的数字为偶数（0、2、4、6、8），共有 5 个选择；奇数下标（1、3、5…）处的数字为质数（只允许 2、3、5、7），共有 4 个选择。\n- 偶数位的数量 `k` 为 `(n + 1) // 2`, 奇数位的数量为 `n - k`\n- 对于长度为 $n$ 的数字字符串，偶数下标的数量为 $⌈n/2⌉ = \\frac{n+1}{2}$ 向下取整, 因此总共有 $5^k$ 种可能，奇数下标的数量为 $⌊n/2⌋$（由于数组下标从 0 开始），因此总共有 $4^{(n-k)}$ 种可能。\n\n\n\n## **构造方案：**\n\n 因此，好数字的总数量可表示为：\n$$\n\\text{ans} = 5^{ k } \\times 4^{ n-k } \\mod (10^9+7)\n$$\n给定 $n$ 可能高达 $10^{15}$，直接计算大数幂需要使用快速幂算法（快速指数求幂），Python 内置的 `pow` 函数可以直接接受第三个参数来进行模运算并实现快速幂。\n\n## **时间复杂度：**\n\n- 使用快速幂算法对大指数进行求幂取模，保证运算效率且不溢出。利用指数二进制分解实现指数运算，快速幂算法的时间复杂度为 $O(\\log n)$，即使 $n$ 高达 $10^{15}$ 也可以在极短时间内求出结果。\n\n- 使用乘法原理，将两个独立的选择相乘，即可得到所有可能性的乘积。\n\n## 代码实现：\n\n```python\nclass Solution:\n    def countGoodNumbers(self, n: int) -> int:\n        MOD = 10**9 + 7\n        # 计算偶数下标的数量：\n        k = (n + 1) // 2\n        part5 = pow(5, k, MOD)    # 偶数下标：0, 2, 4, ...，利用内置的 pow 函数进行快速幂取模计算\n        part4 = pow(4, n - k, MOD)# 奇数下标：1, 3, 5, ...\n        return (part5 * part4) % MOD\n```\n\n","tags":["Algorithm","组合数学","快速幂","乘法","中等"],"categories":["算法"]},{"title":"LeetCode每日一题2025-04-12","url":"/post/countGoodIntegers.html","content":"\n# [3272. 统计好整数的数目](https://leetcode.cn/problems/find-the-count-of-good-integers/) H\n\n给你两个 **正** 整数 `n` 和 `k` 。\n\n如果一个整数 `x` 满足以下条件，那么它被称为 **k** **回文** 整数 。\n\n- `x` 是一个 回文整数 。\n- `x` 能被 `k` 整除。\n\n如果一个整数的数位重新排列后能得到一个 **k 回文整数** ，那么我们称这个整数为 **好** 整数。比方说，`k = 2` ，那么 2020 可以重新排列得到 2002 ，2002 是一个 k 回文串，所以 2020 是一个好整数。而 1010 无法重新排列数位得到一个 k 回文整数。\n\n请你返回 `n` 个数位的整数中，有多少个 **好** 整数。\n\n**注意** ，任何整数在重新排列数位之前或者之后 **都不能** 有前导 0 。比方说 1010 不能重排列得到 101 。\n\n \n\n**示例 1：**\n\n> **输入：** n = 3, k = 5\n>\n> **输出：** 27\n>\n> **解释：**\n>\n> 部分好整数如下：\n>\n> - 551 ，因为它可以重排列得到 515 。\n> - 525 ，因为它已经是一个 k 回文整数。\n\n**示例 2：**\n\n> **输入：** n = 1, k = 4\n>\n> **输出：** 2\n>\n> **解释：**\n>\n> 两个好整数分别是 4 和 8 。\n\n**示例 3：**\n\n> **输入：** n = 5, k = 6\n>\n> **输出：** 2468\n\n \n\n**提示：**\n\n- `1 <= n <= 10`\n- `1 <= k <= 9`\n\n## 分析思路\n\n我们可以把问题拆分为两个部分：\n\n1. **判断数位集合是否有回文排列**\n    一个数的数位可以重新排列成回文数当且仅当：\n   - 当 n 为偶数：所有数字出现次数均为偶数。\n   - 当 n 为奇数：最多只有一个数字出现次数为奇数，其余为偶数。\n2. **存在回文排列且该排列满足被 k 整除**\n   - 由于我们要求构造的回文排列不能有前导 0，所以构造时需要保证最左位数字不为 0。\n   - 对于一个给定的符合“回文排列”条件的数位集合，若存在一种排列构成的回文数能被 k 整除，则我们将此多重集认为是合格的。\n   - 注意：一个 n 位整数只要其数位集合满足条件（存在至少一种排列构成合格的 k 回文数），那么所有拥有相同数位多重集的 n 位整数都是好整数。\n\n### 构造方案\n\n由于 n 的范围最多为 10，因此直接枚举所有 n 位**回文数**来检查被 k 整除的条件是可行的。根据 n 的奇偶性，我们可以分为两种情况：\n\n- **n 为偶数**：\n   设 m = n/2，回文数为：\n\n  ```\n  half + reverse(half)\n  ```\n\n  枚举长度为 m 的数字串，其中第一个字符（对应整体最高位）不为 0。\n\n- **n 为奇数**：\n   设 m = n//2，则回文数为：\n\n  ```\n  half + mid + reverse(half)\n  ```\n\n  其中 half 枚举同上（第一个字符非 0），mid 为 0～9 均可。\n\n对于每个构造出来的回文数，如果它满足能被 k 整除的条件，则提取其“数字多重集”（即各个数字出现的次数），并存入一个集合中，确保对于同一多重集只记录一次。\n\n### 计数方法\n\n对于一个记录下来的数字多重集（长度为 n），所有的排列数为\n$$\n\\text{total} = \\frac{n!}{\\prod_{d=0}^{9} (\\text{count}[d]!)}\n$$\n但由于存在前导 0 的问题，对于包含 0 的情况，我们需要剔除那些首位为 0 的排列。\n\n- 若多重集中 0 出现次数为 c0 > 0，则固定首位为 0后，剩余排列数为\n\n$$\n\\text{invalid} = \\frac{(n-1)!}{(c_0-1)! \\prod_{d=1}^{9} (\\text{count}[d]!)}\n$$\n\n- 故该多重集对应的合法 n 位数字数为\n  $$\n  \\text{valid} = \\text{total} - \\text{invalid} \\quad \\left( \\text{当}\\ c_0 > 0 \\right)\n  $$\n  或者当 c0=0，则 valid = total。\n\n对所有满足条件的多重集，将其合法排列数累加即为答案。\n\n### 算法时间复杂度分析\n\n- **枚举回文数**\n\n  - 对于 n 为偶数：需要枚举 $10^{\\frac{n}{2}-1} * 9$ 个数，最多约$O(10^\\frac{n}{2})$；\n  - 对于 n 为奇数：乘上 10 种中间数字情况，依然是 $O(10^\\frac{n}2)$。\n\n  由于 n ≤ 10，最坏情形枚举数量不会超过 $10^5$，计算量是可接受的。\n\n- **多重集计数**\n   对于每个多重集，计算排列数的时间复杂度为 O(10)（数字个数恒定），因此总体时间复杂度主要取决于回文数枚举部分，为 $O(10^\\frac{n}2)$。\n\n### 总结\n\n1. 枚举所有符合 n 位、无前导 0 的回文数；\n2. 检查该回文数能否被 k 整除；\n3. 对满足条件的回文数，提取其数字多重集，并保证每个多重集只计入一次；\n4. 对每个多重集，计算所有排列中首位不为 0 的排列数，并累加结果。\n\n### 代码实现：\n\n```python\nfrom math import factorial\n\nclass Solution:\n    def countGoodIntegers(self, n: int, k: int) -> int:\n        \"\"\"\n        统计 n 位整数中好整数的数量。\n        好整数定义为：其数位重新排列后可以得到一个回文且能被 k 整除，\n        且排列后不能有前导 0。\n        \"\"\"\n        # 对 n==1 情况单独处理\n        if n == 1:\n            count = 0\n            for d in range(1, 10):\n                if d % k == 0:\n                    count += 1\n            return count\n        \n        good_multisets = set()  # 存储符合条件的多重集（以元组形式存储 0~9 的数字出现次数）\n        \n        if n % 2 == 0:\n            # n 为偶数，回文数由半边构造\n            half_len = n // 2\n            start = 10 ** (half_len - 1)\n            end = 10 ** half_len\n            for num in range(start, end):\n                half_str = str(num)\n                pal_str = half_str + half_str[::-1]  # 构造回文数\n                # 已经保证 half_str 的首位不为 '0'\n                pal_num = int(pal_str)\n                if pal_num % k == 0:\n                    counts = [0] * 10\n                    for ch in pal_str:\n                        counts[int(ch)] += 1\n                    good_multisets.add(tuple(counts))\n        else:\n            # n 为奇数，多一位中间数字\n            half_len = n // 2\n            # 当 n>=3 时，half_len>=1，此时可以按原逻辑构造\n            start = 10 ** (half_len - 1)\n            end = 10 ** half_len\n            for num in range(start, end):\n                half_str = str(num)\n                for mid in range(10):\n                    pal_str = half_str + str(mid) + half_str[::-1]\n                    # half_str 保证首位不为 '0'\n                    pal_num = int(pal_str)\n                    if pal_num % k == 0:\n                        counts = [0] * 10\n                        for ch in pal_str:\n                            counts[int(ch)] += 1\n                        good_multisets.add(tuple(counts))\n        \n        # 预计算阶乘\n        fact = [1] * (n + 1)\n        for i in range(1, n + 1):\n            fact[i] = fact[i - 1] * i\n        \n        total_good = 0\n        # 对每个符合条件的数字多重集，计算满足无前导0限制的排列数\n        for counts in good_multisets:\n            # 计算该多重集所有排列数： n! / (c0! * c1! * ... * c9!)\n            total_perm = fact[n]\n            for c in counts:\n                total_perm //= fact[c]\n            \n            # 如果该多重集中包含0，需要排除首位为0的排列\n            if counts[0] > 0:\n                # 固定首位为0，剩余的排列数为 (n-1)! / ((c0-1)! * (c1)! ... (c9)!)\n                prod_nonzero = 1\n                for d in range(1, 10):\n                    prod_nonzero *= fact[counts[d]]\n                invalid = fact[n - 1] // (fact[counts[0] - 1] * prod_nonzero)\n                valid_perm = total_perm - invalid\n            else:\n                valid_perm = total_perm\n            \n            total_good += valid_perm\n        \n        return total_good\n```\n\n> 注意：需要对 n==1 的情况进行单独处理。由于一位数的重排列只能为其本身，所以对于一位数，只需要统计 1 到 9 中能被 k 整除的数字即可。\n\n1. **对 n==1 的处理**\n    直接遍历 1～9 的单个数字，检查每个数字是否能被 k 整除，若能则计数。\n\n2. **回文数生成**\n\n- 当 n 为偶数时，构造回文数格式为 `half + reverse(half)`。\n\n- 当 n 为奇数时，遍历中间数字 `mid`，构造回文数格式为 `half + mid + reverse(half)`。\n\n  >  注：此处保证 `half` 的首位非 0。\n\n3. **多重集记录与排列数计算**\n\n- 将符合条件的回文数的数字多重集（各个数字出现的次数）存入集合避免重复计入。\n- 利用阶乘及组合公式计算总排列数，再剔除那些首位为 0 的排列（当数字 0 存在时）。\n\n","tags":["Algorithm","枚举与剪枝","排列组合","回文数构造","困难"],"categories":["算法"]},{"title":"Excel函数使用与周报开发","url":"/post/excelfunc.html","content":"\n# Excel 知识笔记\n\n本文主要介绍 Excel 中的一些高级知识和常用函数，重点涵盖数据透视表、常用函数（SUM、SUMIF、SUMIFS、SUBTOTAL、IF、VLOOKUP、XLOOKUP、INDEX、MATCH）以及周报开发的相关内容。\n\n------\n\n## 1. 📊 数据透视表（Pivot Table）\n\n### 1.1. 数据透视表简介\n\n数据透视表是 Excel 中用于***快速汇总、分析和展示***大量数据的工具。它能够根据用户的需求动态调整数据的展示形式，例如按类别汇总、计算总和或平均值等。\n\n### 1.2. 创建数据透视表\n\n1. 选择数据区域（确保数据有表头）。\n\n2. 进入“插入”选项卡，点击“数据透视表”按钮。\n\n3. 在弹出的对话框中，选择新建工作表或现有工作表。\n\n   ![excel_pivot](https://s2.loli.net/2025/04/11/Gh6kwbrclpPS82o.png)\n\n4. 在数据透视表字段窗格中拖拽字段至行、列、数值和筛选区域。\n\n   ![excel_pivot2](https://s2.loli.net/2025/04/11/ZHY3WJm5oLaj74A.png)\n\n   > 将文本型拖拽至行，数值型拖拽至值，可以实现sum+group by的效果\n\n5. 双击字段可以对其进行重命名\n\n   ![excel_pivot3](https://s2.loli.net/2025/04/11/LDnbkg3AVUR4EFr.png)\n\n6. 在字段、项目和集中可以插入自定义计算字段，输入完成后修改名称点击修改即可添加，添加完成后会出现在数据透视表字段中，勾选后即可添加到数据透视表中\n\n![excel_pivot4](https://s2.loli.net/2025/04/11/lhR4vWUEztXDI1n.png)\n\n### 1.3. 数据透视表技巧\n\n- **字段筛选和排序**：利用字段列表中的筛选按钮对数据进行快速筛选和排序。\n\n- **分组数据**：右击行/列标签，选择“分组”，例如按日期分组按月或季度统计。\n\n- **数据格式化**：右键单击数据区域，选择“值字段设置”，自定义数据汇总方式和数字格式。\n\n- 拖拽字段到对应区域：\n\n  - **行/列**：分组维度（时间等）\n\n  - **值**：计算指标（求和/计数/平均值/占比）\n\n  - **筛选器**：数据过滤，直接拖拽字段即可在数据透视表增加筛选项\n\n  - 插入切片器：可视化**联动**筛选，点击不同的筛选项，数据透视表会自动更新表内数值，同时，切片器处于**当前工作表外**的工作表时点击，同样可以筛选当前表的内容，而筛选器只能在当前数据透视表内使用\n\n    ![excel_pivot5](https://s2.loli.net/2025/04/11/9pQjEZkbTftowRe.png)\n\n  - 刷新数据：右键 → 刷新\n\n- 点击数据透视表，插入数据透视图，右键可以更改图表类型，可以插入多张数据透视图，图表也会根据切片器内容进行变换\n\n![excel_pivot6](https://s2.loli.net/2025/04/11/RVvXKolMzHcIrQd.png)\n\n![excel_pivot7](https://s2.loli.net/2025/04/11/yYMwi9xvP8BSabK.png)\n\n- 插入组合图可以将多种图表混合展示\n\n![excel_pivot8](https://s2.loli.net/2025/04/11/DQKchpe7EJ9TIxH.png)\n\n------\n\n## 2.📈 进阶数据透视表技巧\n\n### 1. 计算字段与计算项\n\n- **计算字段**：在值区域添加自定义公式  \n  `分析 → 字段、项目和集 → 计算字段`  \n  示例：`利润率 = (销售额 - 成本)/销售额`\n\n- **时间智能计算**（结合Power Pivot）  \n\n  ```excel\n  MTD销售额 := TOTALMTD(SUM(数据[销售额]), 数据[日期])\n  ```\n\n### 2. 动态数据源\n\n- **超级表（Ctrl+T）**\n  将数据区域转换为表 → 透视表自动扩展范围\n- **连接Power Query**\n  通过ETL清洗后的数据自动更新透视表\n\n------\n\n## 3. 常用函数详解\n\n### 2.1. SUM\n\n- **功能**：对一组数值求和。\n\n- **语法**： `=SUM(number1, [number2], …)`\n\n- **示例**：\n\n  ```excel\n  =SUM(A1:A10)\n  ```\n\n### 2.2. SUMIF\n\n- **功能**：根据单一条件对范围内符合条件的数值求和。\n\n- **语法**： `=SUMIF(range, criteria, [sum_range])`\n\n- **示例**：\n\n  ```\n  =SUMIF(B1:B10, \">100\", C1:C10)\n  ```\n\n### 2.3. SUMIFS\n\n- **功能**：根据多个条件对范围内符合条件的数值求和。\n\n- **语法**： `=SUMIFS(sum_range, criteria_range1, criteria1, [criteria_range2, criteria2], …)`\n\n- sumifs(要返回的值所在列, 查找条件1所在列, 查找限定条件1, 查找条件2所在列, 查找限定条件2……)\n\n- **示例**：\n\n  ```\n  =SUMIFS(C1:C10, A1:A10, \"产品A\", B1:B10, \">100\")\n  ```\n\n- 通常会设计计算月总和，环比等数值，因此需要计算上个月的这一天用来作为被减项用于筛选时间范围，Excel中，日期表示的是从1900.01.01到今天的天数，有以下几种方法可以计算上个月\n  - `EDATE(start_date，months)`返回一串日期，指示起始日期之前/之后的月数，如`EDATE(A1，-1)`表示这天的前一个月，7月31日会返回6月30日\n  - `EOMONTH(start_date，months)`返回一串日期，表示指定月数之前或之后的月份的最后一天（只针对月份操作）如`EOMONTH(A1,-1)+1`表示这个时间月份的第一天，比如8月（无论几号）会返回8月1日，不+1则会返回7月31日\n  - `DATE(YEAR(A1),MONTH(A1),1)`返回本月的第一天，最直观的形式，在date函数外再-1即可返回上月的最后一天\n\n### 2.4. SUBTOTAL\n\n- **功能**：返回数据列表或数据库中的分类汇总。subtotal值会根据字段筛选而变化。\n\n- **语法**： `=SUBTOTAL(function_num, ref1, [ref2], …)`\n\n- **常用 function_num**：\n\n  - 9：求和\n  - 1：求平均值\n\n- **示例**：\n\n  ```\n  =SUBTOTAL(9, A1:A10)\n  ```\n\n### 2.5. IF\n\n- **功能**：根据条件返回不同的结果，一般需要多层嵌套使用。\n\n- **语法**： `=IF(logical_test, value_if_true, value_if_false)`\n\n- **示例**：\n\n  ```\n  =IF(A1>100, \"大于100\", \"小于等于100\")\n  ```\n\n### 2.6. VLOOKUP\n\n- **功能**：在数据区域的首列中搜索指定值，并返回该值所在行中指定列的内容。\n\n- **语法**： `=VLOOKUP(lookup_value, table_array, col_index_num, [range_lookup])`\n\n- VLOOKUP(查找值, 查找区域(要查找的必须在第一列), 返回第几列, 0)\n\n- **示例**：\n\n  ```\n  =VLOOKUP(\"产品A\", A1:D10, 3, FALSE)\n  ```\n\n### 2.7. XLOOKUP\n\n- **功能**：现代化的查找函数，能够向任意方向查找数据，取代 VLOOKUP/HLOOKUP。\n\n- **语法**： `=XLOOKUP(lookup_value, lookup_array, return_array, [if_not_found], [match_mode], [search_mode])`\n\n- XLOOKUP(查找值, 查找值所在列, 返回列, 未找到返回值(可选), 匹配模式(可选), 搜索模式(可选))\n\n- **示例**：\n\n  ```\n  =XLOOKUP(\"产品A\", A1:A10, C1:C10, \"未找到\")\n  ```\n\n### 2.8. INDEX 和 MATCH\n\n- **INDEX**\n\n  - **功能**：返回数组中指定位置的值。\n  - **语法**： `=INDEX(array, row_num, [column_num])`\n  - INDEX(区域, 行号, 列号)：根据行号从某列中返回对应的值\n\n- **MATCH**\n\n  - **功能**：返回指定值在一维数组中的相对位置。\n  - **语法**： `=MATCH(lookup_value, lookup_array, [match_type])`\n  - MATCH(查找值, 区域, 0)：在某行/列中查找指定的值，并返回其列/行号\n\n- **组合使用示例**：\n\n  ```\n  =INDEX(C1:C10, MATCH(\"产品A\", A1:A10, 0))\n  \n  index(数据区域,match(行查找顶,index数据区域的相对区域,0),match(列查找项,indexB数据区域的相对区域,0))\n  ```\n\n同时使用xlookup和index+match实现的相同功能\n\n![index_match](https://s2.loli.net/2025/04/11/tpAuPg7GJbKjSQF.png)\n\n当函数不清晰时，可以先把要实现的函数单独写好，再复制进完整的表达式，同时可以配合`ALT+ENTER`在函数中换行避免混淆\n\n## 4.🔢 常用函数总结\n\n### 基础聚合\n\n| 函数     | 语法                                                  | 说明                 | 周报应用示例                                                |\n| -------- | ----------------------------------------------------- | -------------------- | ----------------------------------------------------------- |\n| SUM      | `=SUM(range)`                                         | 基础求和             | `=SUM(C2:C100)` → 周总销售额                                |\n| SUMIF    | `=SUMIF(range, criteria, [sum_range])`                | 单条件求和           | `=SUMIF(A2:A100, \"华东\", C2:C100)` → 华东区销售总额         |\n| SUMIFS   | `=SUMIFS(sum_range, criteria_range1, criteria1, ...)` | 多条件求和           | `=SUMIFS(C2:C100, A2:A100, \"华东\", B2:B100, \">2023-01-01\")` |\n| SUBTOTAL | `=SUBTOTAL(function_num, range)`                      | 分类汇总（支持筛选） | `=SUBTOTAL(9, C2:C100)` → 筛选后可见数据求和                |\n\n### 逻辑判断\n\n| IF   | `=IF(logical_test, [value_if_true], [value_if_false])` |\n| ---- | ------------------------------------------------------ |\n| 示例 | `=IF(C2>10000, \"达标\", \"未达标\")` → 销售目标判断       |\n\n### 查找匹配\n\n| 函数        | 语法                                                         | 特点                                       |\n| ----------- | ------------------------------------------------------------ | ------------------------------------------ |\n| VLOOKUP     | `=VLOOKUP(lookup_value, table_array, col_index_num, [range_lookup])` | 纵向查找，需注意**首列匹配**和**列索引号** |\n| XLOOKUP     | `=XLOOKUP(lookup_value, lookup_array, return_array, [if_not_found], [match_mode], [search_mode])` | 支持双向查找、错误处理，更灵活             |\n| INDEX+MATCH | `=INDEX(return_range, MATCH(lookup_value, lookup_range, 0))` | 灵活组合，支持多维度查找                   |\n\n------\n\n- \n\n------\n\n## 5.🔍 高阶函数扩展\n\n### 动态数组函数（Excel 365+）\n\n| 函数   | 作用             | 周报应用                                        |\n| ------ | ---------------- | ----------------------------------------------- |\n| FILTER | 条件筛选数据区域 | `=FILTER(订单表, (销售额>10000)*(区域=\"华东\"))` |\n| SORT   | 动态排序         | `=SORT(UNIQUE(产品列表),,-1)`                   |\n| UNIQUE | 去重提取         | `=UNIQUE(销售大区)`                             |\n\n### 时间处理函数\n\n```\n=WEEKNUM(A2)  // 返回日期所属周数（周报核心函数）\n=EDATE(A2,3)  // 计算3个月后的日期（常用于滚动预测）\n=TEXT(A2,\"YYYY-MMM\")  // 日期转\"2023-Jul\"格式\n```\n\n### 错误处理\n\n```\n=IFERROR(VLOOKUP(...), \"未找到\")  // 屏蔽#N/A错误\n=AGGREGATE(9,6,C2:C100)  // 忽略隐藏行和错误值的求和\n```\n\n## 6.周报开发\n\n- [ ] 掌握数据引用、公式填写和自动化拖拽等基本功能\n- [ ] 理解数据美化、数据计算与逻辑结构的构建\n\n**整体流程建议：**\n\n- **先搭建框架：** 建立好各区域结构及基本引用和公式\n- **再填数据：** 在框架内填充各项指标数据和日期\n- **最后美化：** 格式设置、风格统一等作为最后一步处理，避免中途美化造成数据修改的不便\n\n### 6.1 周报框架搭建\n\n#### 1. 周报结构\n\n- **四大区域**：\n\n  1. 标题（包含时间范围）\n  2. 目标看板（单独区域展示周报的目标内容，如累计值，环比，同比等，同时包含筛选器）\n  3. 结果指标（GMV、商家实收、到手率等）\n  4. 过程指标（曝光人数、转化率等）\n\n  > 小看板区域（3、4）显示关键指标的概览，通常包括目标、区域、过程指标和结果指标。\n\n#### 2. 基础设置\n\n- **标题**：`A2`单元格填写`2020年8月第二周`\n\n- **日期列**：\n\n  - 输入起始日期（如在`A13`输入`2020-08-10`）\n  - 后续日期使用公式`=A13+1`并拖动填充（需从第二个单元格开始拖动）向下拖动填充至 A19，生成 8 月 10 日 - 16 日的日期。\n\n  ![zhoubao1](https://s2.loli.net/2025/04/11/JrDCv3qbeVa6XdM.png)\n\n- **星期列**：\n\n  - 右键单元格 → 设置单元格格式 → 数字 → 日期 → 选择 “周几” 格式（如 “周三”）\n\n  ![zhoubao2](https://s2.loli.net/2025/04/11/xApZhg4wFU9Inke.png)\n\n- **日期联动**：\n\n  - 所有与日期相关的操作都建议使用引用方式，这样如果改变某个日期数据，其他依赖数据也会自动更新，极大地提升工作效率\n  - 使用公式动态引用日期，避免手动修改（选中 `A13:A19`，根据需要设置为 “短日期” 格式，如`=TEXT(A2, \"m月d日\")`）\n\n#### 3.  指标体系构建\n\n1. 结果指标（核心数据）\n\n| 指标     | 说明                             | 计算公式                         |\n| -------- | -------------------------------- | -------------------------------- |\n| GMV      | 总成交额                         | 直接引用原数据或通过 SUMIFS 计算 |\n| 商家实收 | 商家实际收入                     | 同上                             |\n| 到手率   | 实收 / GMV，反映收入转化率       | `=商家实收/GMV`                  |\n| 有效订单 | 有效订单数                       | 直接引用                         |\n| 无效订单 | 无效订单数                       | 直接引用                         |\n| 客单价   | GMV / 有效订单，反映平均消费金额 | `=GMV/有效订单`                  |\n\n2. 过程指标（流量漏斗）\n\n| 指标       | 说明                                  | 计算公式             |\n| ---------- | ------------------------------------- | -------------------- |\n| 曝光人数   | 店铺曝光次数                          | 直接引用             |\n| 进店人数   | 点击进入店铺的人数                    | 直接引用             |\n| 进店转化率 | 进店人数 / 曝光人数，反映流量承接能力 | `=进店人数/曝光人数` |\n| 下单人数   | 实际下单的人数                        | 直接引用             |\n| 下单转化率 | 下单人数 / 进店人数，反映转化效率     | `=下单人数/进店人数` |\n| 营销占比   | cpc总费用 / GMV，反映投放效果         | `=cpc总费用 / GMV`   |\n\n------\n\n### 6.2 核心函数与数据引用\n\n#### 1. 数据验证（筛选器）\n\n- **步骤**：\n\n  1. 选择目标单元格（如平台筛选器）\n  2. 数据 → 数据验证 → 允许“序列”\n  3. 输入选项：`全部,美团,饿了么`（英文逗号分隔）\n  4. 点击确定，生成下拉菜单\n\n  ![zhoubao3](https://s2.loli.net/2025/04/11/RVzQnEvb31qcoOw.png)\n\n  > **作用**：通过选择平台（全部 / 美团 / 饿了么），动态筛选对应数据。\n\n#### 2. 动态条件求和（SUMIFS）\n\n- **配合筛选器的公式逻辑**：\n\n  ```excel\n  =IF(\n    平台单元格=\"全部\",\n    SUMIF(日期列, 当前日期, GMV列),\n    SUMIFS(GMV列, 日期列, 当前日期, 平台列, 平台单元格)\n  )\n  ```\n\n- **绝对引用与相对引用**：\n\n  - 固定不变的列或单元格使用绝对引用，例如: `H$5`, `A:A`\n  - 需要随拖拽变化的行或列使用相对引用，例如: `A13`\n  - 混合引用用于锁定列或行，例如: `A$13`\n  - 锁定区域：`$A$2:$X$1000`\n  - 锁定条件单元格：`$H$5`（平台筛选器）\n\n#### 3. 动态列引用（INDEX+MATCH）\n\n**目标**：让函数自动识别表头列，提高灵活性（如 GMV 列、商家实收列可动态切换），因此需要先写出日期列，平台列（筛选器），求和列的公式\n\n- **查找列名位置**：\n\n  使用MATCH 找到目标列在表头中的位置，再使用INDEX 根据列位置提取数据\n\n  ```excel\n  =INDEX(原表数据区域, 0, MATCH(列名标题, 表头行, 0))\n  ```\n\n- **示例（日期列动态引用）**：\n\n  ```excel\n  =INDEX($A:$X, 0, MATCH(\"日期\", $A$1:$X$1, 0))\n  ```\n\n- **示例（动态求和 GMV 列）：**\n\n  ```excel\n  =SUMIFS(INDEX(数据区域, , MATCH(\"GMV\", 表头, 0)), 日期列, 当天日期, 平台列, H5)\n  ```\n\n**拖拽填充：**\n\n- 从第二个有公式的单元格开始拖拽，确保公式自动更新。\n- 如果直接从第一个单元格拖拽，可能会只是简单的序列填充，而没有公式。\n- 例如，若第一个单元格手动修改为“9”，则后续单元格不会自动更新公式中的逻辑。\n\n> **注意**: \n> 使用INDEX和MATCH组合动态获取日期列、GMV列和平台列，替换SUMIF和SUMIFS公式中对应的部分\n> 替换后的公式会变得很长，要仔细核对括号和参数。\n\n### 6.3 关键指标计算\n\n#### 1. 计算型指标\n\n- **到手率**：`=商家实收/GMV`\n\n  > *注意*：结果设为百分比格式（保留 2 位小数）\n\n  ```excel\n  =IF($H$5=\"全部\",SUMIF(INDEX('拌客源数据1-8月'!$A:$X,0,MATCH($A$12,'拌客源数据1-8月'!$A$1:$X$1,0)),$A13,\n  INDEX('拌客源数据1-8月'!$A:$X,0,MATCH(C$12,'拌客源数据1-8月'!$A$1:$X$1,0))),\n  SUMIFS(INDEX('拌客源数据1-8月'!$A:$X,0,MATCH(C$12,'拌客源数据1-8月'!$A$1:$X$1,0)),\n  INDEX('拌客源数据1-8月'!$A:$X,0,MATCH($A$12,'拌客源数据1-8月'!$A$1:$X$1,0)),$A13,\n  INDEX('拌客源数据1-8月'!$A:$X,0,MATCH(\"平台i\",'拌客源数据1-8月'!$A$1:$X$1,0)),$H$5))\n  ```\n\n  逻辑在2中已经陈述\n\n- **客单价**：`=GMV/有效订单`\n\n- **转化率（进店 / 下单）**：\n\n  - 进店转化率：`=进店人数/曝光人数`\n  - 下单转化率：`=下单人数/进店人数`\n\n- **营销占比：**`=CPC总费用 / GMV`\n\n  ```excel\n  =IF($H$5=\"全部\",SUMIF(INDEX('拌客源数据1-8月'!$A:$X,0,MATCH($A$12,'拌客源数据1-8月'!$A$1:$X$1,0)),$A13,\n  INDEX('拌客源数据1-8月'!$A:$X,0,MATCH(\"cpc总费用\",'拌客源数据1-8月'!$A$1:$X$1,0))),\n  SUMIFS(INDEX('拌客源数据1-8月'!$A:$X,0,MATCH(\"cpc总费用\",'拌客源数据1-8月'!$A$1:$X$1,0)),\n  INDEX('拌客源数据1-8月'!$A:$X,0,MATCH($A$12,'拌客源数据1-8月'!$A$1:$X$1,0)),$A13,\n  INDEX('拌客源数据1-8月'!$A:$X,0,MATCH(\"平台i\",'拌客源数据1-8月'!$A$1:$X$1,0)),$H$5))/$C13\n  ```\n\n#### 2. 周累计与周环比（时间维度分析）\n\n1. **周累计（当周总和）**\n\n   - **方法**：对当周 7 天的数据求和（使用`SUM`函数或快捷键`Alt+=`）\n     *例：曝光人数周累计*：`=SUM(H13:H19)`（H13-H19 为每天曝光人数）\n\n2. **周环比（与上周对比）**\n\n   - **公式**：`=(本周数据/上周数据)-1`（结果为百分比，正增长为绿色，负增长为红色）\n   - 将日期范围向前偏移 7 天（如本周第一天为 `A13`，上周第一天为`A13-7`）\n   - **上周GMV数据公式**：\n\n   ```excel\n   =SUMIFS(\n     数值列,\n     日期列, \">=\"&起始日期-7,\n     日期列, \"<=\"&结束日期-7(或<当前日期),\n     平台列, 平台筛选器\n   )\n   ```\n\n**例：有效订单周环比**\n\n```excel\n=A9/IF($H$5=\"全部\",SUMIFS(INDEX('拌客源数据1-8月'!$A:$X,0,MATCH(F$12,'拌客源数据1-8月'!$A$1:$X$1,0)),\nINDEX('拌客源数据1-8月'!$A:$X,0,MATCH($A$12,'拌客源数据1-8月'!$A$1:$X$1,0)),\">=\"&$A13-7,\nINDEX('拌客源数据1-8月'!$A:$X,0,MATCH($A$12,'拌客源数据1-8月'!$A$1:$X$1,0)),\"<\"&$A13),\nSUMIFS(INDEX('拌客源数据1-8月'!$A:$X,0,MATCH(F$12,'拌客源数据1-8月'!$A$1:$X$1,0)),\nINDEX('拌客源数据1-8月'!$A:$X,0,MATCH($A$12,'拌客源数据1-8月'!$A$1:$X$1,0)),\">=\"&$A13-7,\nINDEX('拌客源数据1-8月'!$A:$X,0,MATCH($A$12,'拌客源数据1-8月'!$A$1:$X$1,0)),\"<\"&$A13,\nINDEX('拌客源数据1-8月'!$A:$X,0,MATCH(\"平台i\",'拌客源数据1-8月'!$A$1:$X$1,0)),$H$5))-1\n```\n\n其中A9为本周有效订单\n\n#### 3. 业务进度计算\n\n- **当月GMV总和**：日期条件为大于等于本月第一天（在SUMIFS中介绍了3种实现方式）\n\n  ```excel\n  =SUMIFS(GMV列, 日期列, \">=\"&EOMONTH(TODAY(),-1)+1)\n  ```\n\n- **进度公式**：`=当月累计GMV/目标值`目标值的设置使用IF嵌套，将在6.5中提到\n\n  ```excel\n  =IF($H$5=\"全部\",SUMIFS(INDEX('拌客源数据1-8月'!$A:$X,0,MATCH(C$12,'拌客源数据1-8月'!$A$1:$X$1,0)),\n  INDEX('拌客源数据1-8月'!$A:$X,0,MATCH($A$12,'拌客源数据1-8月'!$A$1:$X$1,0)),\">=\"&EOMONTH(A13,-1)+1,\n  INDEX('拌客源数据1-8月'!$A:$X,0,MATCH($A$12,'拌客源数据1-8月'!$A$1:$X$1,0)),\"<=\"&$A19),\n  SUMIFS(INDEX('拌客源数据1-8月'!$A:$X,0,MATCH(C$12,'拌客源数据1-8月'!$A$1:$X$1,0)),\n  INDEX('拌客源数据1-8月'!$A:$X,0,MATCH($A$12,'拌客源数据1-8月'!$A$1:$X$1,0)),\">=\"&DATE(YEAR(A13),MONTH(A13),1),\n  INDEX('拌客源数据1-8月'!$A:$X,0,MATCH($A$12,'拌客源数据1-8月'!$A$1:$X$1,0)),\"<=\"&$A19,\n  INDEX('拌客源数据1-8月'!$A:$X,0,MATCH(\"平台i\",'拌客源数据1-8月'!$A$1:$X$1,0)),$H$5))/$H$8\n  ```\n\n  逻辑：判断筛选器是否为全部，是则使用sumifs计算要求的值，条件设置大于本月第一天，小于本周的最后一天，否则多使用sumifs增加一个判断平台的条件，其余相同。\n\n### 6.4 可视化与格式优化\n\n#### 1. 数值格式\n\n- **百分比**：选中转化率、到手率等单元格，按`Ctrl+Shift+%`。\n\n- **保留小数**：右键→设置单元格格式→数值→小数位数（如 2 位）/直接在开始菜单点击。\n\n  ![zhoubao4](https://s2.loli.net/2025/04/11/ORKnvWMy15TU3LX.png)\n\n#### 2. 条件格式\n\n- **数据条**：可视化进度（如业务进度）\n\n  操作：选中单元格 →【开始】→【条件格式】→【新建规则】→【基于各自值设置所有单元格的格式】→【格式样式：数据条】→【选择类型】\n  如：选中数值区域 → 条件格式 → 数据条 → 类型选择数字 → 最大值设置为1 → 设置颜色 → 渐变填充\n\n  ![zhoubao5](https://s2.loli.net/2025/04/11/Swokm5OgZEfPj89.png)\n\n- **颜色标记**：标记正负值（如周环比）\n\n  操作：新建规则 → 只为包含以下内容的单元格设置格式 → “单元格值> 0” 设为绿色，“≤0” 设为红色（设置两次）。\n\n  ![zhoubao6](https://s2.loli.net/2025/04/11/KClDevNhX5EzFGJ.png)\n\n- **图标集**：显示趋势（上升 / 下降箭头）\n\n  操作：条件格式 → 新建规则 → 基于各自值设置所有单元格的格式 → 图标集 → 选择 “三向箭头”或自定义中间值（0）为横线 → 分别设置>0, =0, <0的图标 → 类型设置为**数字**\n\n  - 大于0：绿色字体 + ↑图标\n  - 等于0：红色字体 + -图标\n  - 小于0：红色字体 + ↓图标\n\n  ![zhoubao7](https://s2.loli.net/2025/04/11/fdAN4vDgVOBFSQl.png)\n\n- **低于GMV平均值标记**：(注意混合引用)\n\n  - 标记低于周平均值的GMV数值\n  - 选中结果指标区域 →  条件格式 →  新建规则  →  使用公式确定要设置格式的单元格\n\n  ```excel\n  =$C13 < AVERAGE($C$13:$C$19)\n  ```\n\n  - 格式 →  下划线 →  加粗\n\n  ![zhoubao8](https://s2.loli.net/2025/04/11/MyVvPFasfj8xApt.png)\n\n- **格式刷**\n\n  - 单击格式刷：复制格式到单个单元格\n  - 双击格式刷：复制格式到多个单元格\n\n  点击管理自定义规则即可查看、修改设置的规则\n\n  ![zhoubao9](https://s2.loli.net/2025/04/11/bHoNGgAKUcVqwiv.png)\n\n#### 3. 迷你图制作\n\n- **步骤**：\n\n  1. 选中数据区域（如一周的曝光人数）\n\n  2. 【插入】 → 【迷你图 】→ 折线图\n\n     ![zhoubao10](https://s2.loli.net/2025/04/11/a4FrJf2NR89Y6O1.png)\n\n  3. 指定放置单元格，设置标记（显示数据点）和高点颜色\n\n     ![zhoubao11](https://s2.loli.net/2025/04/11/1an5bU8gNjm7T4M.png)\n\n#### 4. 美化技巧\n\n- **格式优先**：先确保数据计算正确，在数据与公式全部建立后，**最后**进行整体的美化设计\n\n- **隐藏网格线：**视图 → 取消勾选“网格线”\n\n- **合并单元格**：合并标题单元格并居中，标题和列名加粗、放大\n\n- **添加主题色：**给结果指标和过程指标的表头（列名）添加主题色\n\n  ![zhoubao12](https://s2.loli.net/2025/04/11/PFvjyX1lKxcqrEe.png)\n\n- **边框与字体**：给小看板、指标表格添加外边框，统一字体（推荐微软雅黑），调整字体、对齐方式等\n\n  ![zhoubao13](https://s2.loli.net/2025/04/11/P8bvOyEd2M4GrmU.png)\n\n### 6.5 目标看板与业务进度\n\n#### 1. 目标设置\n\n- 按平台设定 GMV 目标（如全部 = 20 万，美团 = 15 万，饿了么 = 5 万）。\n  *示例*：在 H8 单元格输入公式\n  `=IF(H5=\"全部\",200000,IF(H5=\"美团\",150000,50000))`。\n\n#### 2. 业务进度\n\n- **公式**：`=截至目前GMV/目标`（如 `=SUMIFS(GMV列, 日期列, \">=\"&DATE(YEAR(A13),MONTH(A13),1))`表示大于当月第一天）。\n\n  > 已在6.3.3中做出陈述\n\n- **进度条**：通过条件格式→数据条可视化，最大值设为 1（100%）。\n\n  ![zhoubao14](https://s2.loli.net/2025/04/11/avTSQ9Vn3iJbsoG.png)\n\n### 6.6 自动化维护\n\n- **日期联动**：所有日期、星期、平台筛选均通过引用和公式实现，修改`A13`单元格日期（初始设置日期的单元格）后，所有关联数据自动更新\n- **数据扩展**：新增数据时，调整公式引用范围（如`$A:$X`改为`$A:$Z`）\n- **模板复用**：保存为模板文件（.xltx），每周复制使用\n\n> **提示**  \n>\n> 1. 所有公式中的区域引用需根据实际表格调整（如`A:X`为示例列范围）  \n> 2. 建议逐步测试每个函数模块，使用`F9`键分解验证公式逻辑  \n> 3. 格式美化可最后进行，避免干扰数据处理\n\n- 最终效果\n\n  ![zhoubao15](https://s2.loli.net/2025/04/11/cWlSQYHTry19Z4D.png)","tags":["数据操作","可视化","看板与报表"],"categories":["数据分析"]},{"title":"LeetCode每日一题2025.04.11","url":"/post/countSymmetricIntegers.html","content":"\n## [2843. 统计对称整数的数目](https://leetcode.cn/problems/count-symmetric-integers/) E\n\n给你两个正整数 `low` 和 `high` 。\n\n对于一个由 `2 * n` 位数字组成的整数 `x` ，如果其前 `n` 位数字之和与后 `n` 位数字之和相等，则认为这个数字是一个对称整数。\n\n返回在 `[low, high]` 范围内的 **对称整数的数目** 。\n\n**示例 1：**\n\n```\n输入：low = 1, high = 100\n输出：9\n解释：在 1 到 100 范围内共有 9 个对称整数：11、22、33、44、55、66、77、88 和 99 。\n```\n\n**示例 2：**\n\n```\n输入：low = 1200, high = 1230\n输出：4\n解释：在 1200 到 1230 范围内共有 4 个对称整数：1203、1212、1221 和 1230 。\n```\n\n- **提示：**$1 <= low <= high <= 10^4$\n\n\n\n题目需要找出在给定范围内满足特定数字对称条件的所有整数的数量。\n\n1. **检查位数是否为偶数**：只有当数字的位数是偶数时才有可能成为对称整数，否则直接跳过。\n2. **分割数字前后半部分**：对于一个 2*n 位数字，将该数字转换为字符串，然后将其前 n 位数字和后 n 位数字分别累加求和，判断两部分是否相等。两者之和相等，则该数字符合条件。\n3. **遍历范围**： low 和 high 的范围较小（最高 $10^4$），可以直接遍历 [low, high] 区间内的所有数字，对符合条件的数字进行计数。\n\n代码如下：\n\n```python\nclass Solution:\n    def countSymmetricIntegers(self, low: int, high: int) -> int:\n        count = 0\n        for num in range(low, high + 1):\n            num_str = str(num)\n            # 数字必须为偶数位，才能分成两部分比较\n            if len(num_str) % 2 == 0:\n                half = len(num_str) // 2\n                # 将前一半和后一半的各个数字相加\n                left_sum = sum(int(digit) for digit in num_str[:half])\n                right_sum = sum(int(digit) for digit in num_str[half:])\n                if left_sum == right_sum:\n                    count += 1\n        return count\n```\n\n- 首先通过 `str(num)` 将整数转换为字符串，以便判断数字的位数是否为偶数。\n- 如果是偶数位，则将字符串分为前后两部分，分别计算各自数字的和。\n- 如果两部分的和相等，则计数器 `count` 累加。\n\n通过遍历 [𝑙𝑜𝑤,ℎ𝑖𝑔ℎ]范围内的每个整数，对于每个数字：\n\n1. 将数字转换为字符串：复杂度 $O(d)$（其中 ddd 为数字的位数）。\n2. 对前半部分和后半部分求和，各需要 $O(d/2)$，加起来也是 $O(d)$。\n\n总体时间复杂度大致为 $O(N×d)$，其中 $N=high−low+1$，$d$通常为常数","tags":["Algorithm","暴力搜索","数位处理","字符串处理","简单"],"categories":["算法"]},{"title":"SQL常用函数补充","url":"/post/SQLfunc.html","content":"\n# SQL 执行顺序与常用函数\n\n## 🔄 SQL 语句执行顺序\n\n1. **FROM**  \n   从数据库复制原始表（生成临时表）\n2. **WHERE**  \n   在临时表中筛选符合条件的`数据行`\n3. **GROUP BY**  \n   按指定字段分组（类似Excel数据透视表的行标签）\n4. **HAVING**  \n   筛选满足条件的`分组`\n5. **ORDER BY**  \n   对结果进行排序\n6. **LIMIT**  \n   限制显示行数\n7. **SELECT**  \n   最终提取显示的字段\n\n> 📝 注意：SELECT *实际在最后阶段执行\n\n------\n\n## 常用函数汇总\n\n### 一、数学函数\n\n**`CEIL(x) / CEILING(x)`**\n\n- **功能**：向上取整，返回大于或等于x的最小整数\n\n- **参数**：\n\n  - `x`：要取整的数值\n\n- **示例**：\n\n  | 表达式        | 结果 |\n  | ------------- | ---- |\n  | CEIL(3.14)    | 4    |\n  | CEIL(-3.14)   | -3   |\n  | CEILING(2.01) | 3    |\n\n------\n\n**`FLOOR(x)`**\n\n- **功能**：向下取整，返回小于或等于x的最大整数\n\n- **参数**：\n\n  - `x`：要取整的数值\n\n- **示例**：\n\n  | 表达式       | 结果 |\n  | ------------ | ---- |\n  | FLOOR(3.97)  | 3    |\n  | FLOOR(-3.14) | -4   |\n\n------\n\n**`ROUND(x, y)`**  \n\n- 功能：四舍五入\n\n- 参数：\n\n  - `y>0`：保留小数点后y位  \n  - `y=0`：取整数  \n  - `y<0`：小数点左侧指定位变0  \n\n- 示例：\n\n  | 表达式           | 结果 |\n  | ---------------- | ---- |\n  | ROUND(3.15, 1)   | 3.2  |\n  | ROUND(14.15, -1) | 10   |\n\n------\n\n### 二、字符串函数\n\n| 函数名/用法                  | 功能说明                                                     | 示例                              | 示例结果 |\n| ---------------------------- | ------------------------------------------------------------ | --------------------------------- | -------- |\n| `CONCAT(s1, s2, ...)`        | 连接字符串（含NULL则返回NULL）                               | CONCAT('My',' ','SQL')            | My SQL   |\n|                              |                                                              | CONCAT('My', NULL, 'SQL')         | NULL     |\n| `REPLACE(s, s1, s2)`         | 全量替换字符串                                               | REPLACE('MySQL','SQL','sql')      | Mysql    |\n| `LEFT(s, n)`                 | 截取左侧n字符                                                | LEFT('abcdefg', 3)                | abc      |\n| `RIGHT(s, n)`                | 截取右侧n字符                                                | RIGHT('abcdefg', 3)               | efg      |\n| `SUBSTRING(s, n, len)`       | 从位置n截取len长度（支持负数位置）                           | SUBSTRING('abcdefg', -2, 3)       | fg       |\n|                              |                                                              | SUBSTRING('abcdefg', 2)           | bcdefg   |\n| `LOWER(s)`                   | 将字母变为小写                                               | LOWER('A')                        | a        |\n| `UPPER(s)`                   | 将字母变为大写                                               | UPPER('a')                        | A        |\n| `CHAR_LENGTH(s)`             | 返回字符串的字符数                                           | CHAR_LENGTH('数')                 | 1        |\n| `LENGTH(s)`                  | 返回字符串的字节数，对于 ASCII 字符，与`CHAR_LENGTH`的结果是相同的 | LENGTH('数')                      | 3        |\n| `LOCATE(substr, s, [pos])`   | 返回substr在s中首次出现的位置，pos为起始                     | LOCATE('b', 'abcde')              | 2        |\n|                              |                                                              | LOCATE('b', 'abcdebcd', 3)        | 6        |\n| `POSITION(substr IN s)`      | 返回substr在s中首次出现的位置                                | POSITION('b' IN 'abcde')          | 2        |\n| `SUBSTRING_INDEX(s, d, n)`   | 以分隔符d分割，取第n段（正/负数）                            | SUBSTRING_INDEX('a,b,c', ',', 2)  | a,b      |\n|                              |                                                              | SUBSTRING_INDEX('a,b,c', ',', -2) | b,c      |\n| TRIM(s)                      | 去除字符串两端的空格                                         | TRIM(' abc ')                     | abc      |\n| TRIM([remstr FROM] s)        | 去除字符串两端的指定字符                                     | TRIM('a' FROM 'aaabcaa')          | bc       |\n| TRIM(LEADING remstr FROM s)  | 去除字符串左侧的指定字符                                     | TRIM(LEADING 'a' FROM 'aaabcaa')  | bcaa     |\n| TRIM(TRAILING remstr FROM s) | 去除字符串右侧的指定字符                                     | TRIM(TRAILING 'a' FROM 'aaabcaa') | aaabc    |\n\n#### **补充：GROUP_CONCAT 函数**\n\n**功能说明**\n将分组内的多个字符串值**合并为一个字符串**，常用于多值拼接（需配合 `GROUP BY` 使用）。\n\n```sql\nGROUP_CONCAT(\n    [DISTINCT] 字段名 \n    [ORDER BY 排序字段 [ASC|DESC]] \n    [SEPARATOR '分隔符']\n)\n```\n\n**示例数据**（表 `students`）：\n\n| class | name |\n| ----- | ---- |\n| A     | 张三 |\n| A     | 李四 |\n| B     | 王五 |\n\n```sql\nSELECT \n    class,\n    GROUP_CONCAT(name) AS members\nFROM students\nGROUP BY class;\n```\n\n**结果**：\n\n| class | members   |\n| ----- | --------- |\n| A     | 张三,李四 |\n| B     | 王五      |\n\n```sql\n-- 去重 + 自定义分隔符 + 排序\nSELECT \n    class,\n    GROUP_CONCAT(\n        DISTINCT name\n        ORDER BY name DESC\n        SEPARATOR '|'\n    ) AS members\nFROM students\nGROUP BY class;\n```\n\n> **注意事项**\n>\n> 1. **长度限制**：受 `group_concat_max_len` 参数限制（默认1024字节），超长部分被截断\n> 2. **NULL处理**：自动忽略 NULL 值\n> 3. **跨数据库差异**：\n>    - MySQL：`GROUP_CONCAT`\n>    - PostgreSQL：`STRING_AGG`\n>    - SQL Server：`STRING_AGG`（2017+版本）\n\n**典型应用场景**\n\n1. **标签聚合**\n\n   ```sql\n   -- 文章表+标签表联查，合并文章的所有标签\n   SELECT \n       a.title,\n       GROUP_CONCAT(t.tag_name) AS tags\n   FROM articles a\n   JOIN article_tags at ON a.id = at.article_id\n   JOIN tags t ON at.tag_id = t.id\n   GROUP BY a.id;\n   ```\n\n2. **路径生成**\n\n   ```sql\n   -- 生成层级路径（部门树结构）\n   SELECT \n       dept_id,\n       GROUP_CONCAT(parent_name SEPARATOR ' > ') AS full_path\n   FROM department_hierarchy\n   GROUP BY dept_id;\n   ```\n\n3. **动态SQL拼接**\n\n   ```sql\n   -- 生成批量更新语句（示例用途）\n   SELECT \n       CONCAT(\n           'UPDATE users SET status=1 WHERE id IN (',\n           GROUP_CONCAT(id SEPARATOR ','),\n           ');'\n       ) AS sql_statement\n   FROM temp_ids;\n   ```\n\n#### **补充：正则表达式函数**\n\n##### **1. 字符集（[] 内可用的符号）**\n\n| **符号** | **含义**                                                     | **示例**                                   | **匹配示例**                 |\n| -------- | ------------------------------------------------------------ | ------------------------------------------ | ---------------------------- |\n| `a-z`    | 任意小写字母                                                 | `[a-z]`                                    | `a`, `b`, ..., `z`           |\n| `A-Z`    | 任意大写字母                                                 | `[A-Z]`                                    | `A`, `B`, ..., `Z`           |\n| `0-9`    | 任意数字                                                     | `[0-9]`                                    | `0`, `1`, ..., `9`           |\n| `.`      | 字面量点（需转义 `\\.`）                                      | `[a-z.]`                                   | `a`, `b`, `.`                |\n| `_`      | 下划线                                                       | `[a-z_]`                                   | `a`, `_`                     |\n| `%`      | 百分号                                                       | `[a-z%]`                                   | `a`, `%`                     |\n| `+`      | 加号（在 `[]` 内是普通字符）                                 | `[a-z+]`                                   | `a`, `+`                     |\n| `-`      | 减号（需放在开头或结尾，否则表示范围如 `a-z`）               | `[-a-z]` 或 `[a-z-]`                       | `-`, `a`                     |\n| `^`      | 在 `[]` 内开头表示**否定**（如 `[^a-z]` 匹配非小写字母）     | `[^0-9]`                                   | `A`, `!`（不匹配 `1`）       |\n| `\\w`     | 等价于 `[a-zA-Z0-9_]`（单词字符）                            | `[\\w]`                                     | `a`, `1`, `_`                |\n| `\\d`     | 等价于 `[0-9]`（数字）                                       | `[\\d]`                                     | `0`, `1`                     |\n| `\\s`     | 空白字符（空格、制表符 `\\t`、换行 `\\n` 等）                  | `[\\s]`                                     | ``, `\\t`                     |\n| `\\b`     | 匹配 **单词和非单词字符之间的位置**（如空格、标点符号、字符串开头/结尾等） | `\\\\bword`<br />`word\\\\b`<br />`\\\\bword\\\\b` | 匹配单词开头、结尾和整个单词 |\n\n------\n\n##### **2. 量词（控制出现次数，单个字符不用加）**\n\n| **量词** | **含义**           | **示例** | **匹配示例**                    |\n| -------- | ------------------ | -------- | ------------------------------- |\n| `*`      | 零次或多次         | `a*`     | `\"\"`, `a`, `aa`（允许空字符串） |\n| `+`      | 一次或多次         | `a+`     | `a`, `aa`（不匹配空字符串）     |\n| `?`      | 零次或一次（可选） | `a?`     | `\"\"`, `a`                       |\n| `{n}`    | 恰好 `n` 次        | `a{2}`   | `aa`                            |\n| `{n,}`   | 至少 `n` 次        | `a{2,}`  | `aa`, `aaa`                     |\n| `{n,m}`  | `n` 到 `m` 次      | `a{2,4}` | `aa`, `aaa`, `aaaa`             |\n\n------\n\n##### **3. 边界和转义**\n\n| **符号** | **含义**                        | **示例**        | **作用**                    |\n| -------- | ------------------------------- | --------------- | --------------------------- |\n| `^`      | 匹配字符串开头                  | `^[a-z]`        | 必须以小写字母开头          |\n| `$`      | 匹配字符串结尾                  | `[a-z]$`        | 必须以小写字母结尾          |\n| `\\`      | 转义特殊字符（如 `\\\\.` 匹配点） | `example\\\\.com` | 避免 `.` 被解释为\"任意字符\" |\n| `|`      | 或逻辑（匹配左边或右边）        | `cat|dog`       | 匹配 `cat` 或 `dog`         |\n\n------\n\n##### **4. 组合用法示例**\n\n| **正则表达式**                 | **含义**                                   | **匹配示例**                     |\n| ------------------------------ | ------------------------------------------ | -------------------------------- |\n| `^[a-zA-Z0-9._%+-]+@`          | 邮箱本地部分（字母/数字/._%+-，至少1字符） | `user`, `name+123`               |\n| `@[a-zA-Z0-9.-]+\\\\.[a-z]{2,}$` | 域名部分（含点和至少2字母TLD）             | `@example.com`, `@sub.domain.co` |\n\n------\n\n> **注意事项**\n>\n> 1. **减号 -**：在 `[]` 内如果不是开头/结尾，表示范围（如 `a-z`）。\n>    - ✅ 正确：`[a-z-]` 或 `[-a-z]`\n>    - ❌ 错误：`[a-z-0-9]`（会被解析为 `z` 到 `-` 的范围）\n> 2. **点 .**：在 `[]` 外是通配符（匹配任意字符），需转义 `\\.` 才能匹配字面量点。\n> 3. **大小写敏感**：默认区分大小写，添加 `i` 标志可忽略（如 `/^[a-z]+$/i`）。\n\n**1. 正则匹配检测**\n\n| 函数/操作符                 | 功能说明                   | 数据库支持          | 示例                                                         |\n| --------------------------- | -------------------------- | ------------------- | ------------------------------------------------------------ |\n| `REGEXP_LIKE(str, pattern)` | 检查字符串是否匹配正则模式 | Oracle, MySQL 8.0+, | `SELECT * FROM users WHERE REGEXP_LIKE(email, '^[a-z0-9]+@[a-z]+\\.com$')` |\n| `str REGEXP pattern`        | 简写匹配操作符             | MySQL, MariaDB      | `SELECT 'abc123' REGEXP '^[a-z]+[0-9]+$' → 1 (匹配)`         |\n| `~`                         | 正则匹配操作符             | PostgreSQL          | `SELECT 'abc' ~ '^a' → true`                                 |\n\n**2. 正则替换**\n\n| 函数                                        | 功能说明           | 示例                                                         |\n| ------------------------------------------- | ------------------ | ------------------------------------------------------------ |\n| `REGEXP_REPLACE(str, pattern, replacement)` | 替换匹配正则的内容 | `REGEXP_REPLACE('Tel: 010-12345678', '[^0-9]', '') → '01012345678'` |\n\n**3. 子串提取**\n\n| 函数                          | 功能说明             | 示例                                                        |\n| ----------------------------- | -------------------- | ----------------------------------------------------------- |\n| `REGEXP_SUBSTR(str, pattern)` | 提取第一个匹配的子串 | `REGEXP_SUBSTR('2023Q4 Report', '[0-9]+Q[1-4]') → '2023Q4'` |\n\n**4. 常用正则模式**\n\n| 模式                                             | 说明             | 应用场景示例     |\n| ------------------------------------------------ | ---------------- | ---------------- |\n| `^abc`                                           | 以\"abc\"开头      | 验证身份证号开头 |\n| `xyz$`                                           | 以\"xyz\"结尾      | 检测文件扩展名   |\n| `[0-9]{4}`                                       | 连续4位数字      | 提取年份信息     |\n| `\\d{3}-\\d{8}`                                    | 匹配电话号码格式 | 010-12345678     |\n| `[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}` | 邮箱格式验证     | 过滤无效邮箱地址 |\n\n**5. 跨数据库语法对比**\n\n| 操作         | MySQL/MariaDB      | PostgreSQL                    | Oracle           | SQL Server             |\n| ------------ | ------------------ | ----------------------------- | ---------------- | ---------------------- |\n| **匹配检测** | `REGEXP` / `RLIKE` | `~`                           | `REGEXP_LIKE`    | `LIKE`（有限支持）     |\n| **替换**     | `REGEXP_REPLACE`   | `REGEXP_REPLACE`              | `REGEXP_REPLACE` | 无内置函数             |\n| **提取子串** | `REGEXP_SUBSTR`    | `SUBSTRING(str FROM pattern)` | `REGEXP_SUBSTR`  | `PATINDEX`+`SUBSTRING` |\n\n**6. 使用示例**\n\n```sql\n-- 验证手机号格式（11位数字）\nSELECT *\nFROM customers \nWHERE phone REGEXP '^1[3-9][0-9]{9}$';\n\n-- 提取带区号的电话号码\nSELECT \n  REGEXP_SUBSTR(contact_info, '\\([0-9]{3}\\) [0-9]{8}') AS phone \nFROM contacts;\n\n-- 清理混合文本中的字母\nSELECT REGEXP_REPLACE('a1b2c3', '[A-Za-z]', '') → '123';\n\n-- 查找包含价格的描述\nSELECT * \nFROM products \nWHERE description ~ '\\$[0-9]+\\.[0-9]{2}';\n```\n\n> 1. **字符集敏感**：注意数据库字符集设置（如中文匹配需用`[一-龥]`）\n> 2. **特殊字符转义**：需用`\\\\`转义（如匹配点号需写`\\\\.`）\n\n\n\n------\n\n### 三、日期函数\n\n**时间计算**  \n\n```sql\nDATE_ADD(date, INTERVAL expr type)  -- 时间加法\nDATE_SUB(date, INTERVAL expr type)  -- 时间减法\n```\n\n- 示例：\n\n```sql\nSELECT DATE_ADD('2021-08-03 23:59:59', INTERVAL 1 SECOND) → '2021-08-04 00:00:00'\nSELECT DATE_SUB('2021-08-03', INTERVAL 2 MONTH) → '2021-06-03'\n```\n\n**时间差与格式化**\n\n| 函数                        | 功能说明               | 示例                                   |\n| --------------------------- | ---------------------- | -------------------------------------- |\n| `DATEDIFF(date1, date2)`    | 计算日期差（忽略时间） | DATEDIFF('2021-06-08','2021-06-01') →7 |\n| `DATE_FORMAT(date, format)` | 日期格式化             | DATE_FORMAT(NOW(),'%Y-%m') → 2023-12   |\n\n### 📅 DATE_FORMAT 格式符对照表\n\n| 格式符       | 描述                          | 示例值             |\n| ------------ | ----------------------------- | ------------------ |\n| **日期相关** |                               |                    |\n| `%Y`         | 四位年份                      | 2023               |\n| `%y`         | 两位年份                      | 23                 |\n| `%m`         | 两位月份（01-12）             | 07                 |\n| `%c`         | 月份（1-12，无前导零）        | 7                  |\n| `%M`         | 月份英文全称                  | January, December  |\n| `%b`         | 月份缩写                      | Jan, Dec           |\n| `%d`         | 两位日期（01-31）             | 09                 |\n| `%e`         | 日期（1-31，无前导零）        | 9                  |\n| `%D`         | 英文后缀日期（1st, 2nd...）   | 1st, 22nd          |\n| **时间相关** |                               |                    |\n| `%H`         | 24小时制小时（00-23）         | 15                 |\n| `%h`         | 12小时制小时（01-12）         | 03                 |\n| `%i`         | 分钟（00-59）                 | 08                 |\n| `%S`         | 秒（00-59）                   | 45                 |\n| `%p`         | AM/PM                         | AM, PM             |\n| **星期相关** |                               |                    |\n| `%W`         | 星期全称                      | Monday, Sunday     |\n| `%a`         | 星期缩写                      | Mon, Sun           |\n| `%w`         | 数字星期（0=周日, 1=周一...） | 1 (周一), 0 (周日) |\n| **组合格式** |                               |                    |\n| `%T`         | 时间（HH:mm:ss）              | 23:59:58           |\n| `%r`         | 带AM/PM的时间（hh:mm:ss AM）  | 11:59:58 PM        |\n| `%x`         | 年份周编号（年份部分）        | 2023 (用于周计算)  |\n| `%v`         | 周编号（周一为周起始）        | 52                 |\n\n#### 使用示例\n\n```sql\n-- 原始时间：2023-07-25 14:30:45\nDATE_FORMAT(date, '%Y/%m/%d %H:%i')    → 2023/07/25 14:30\nDATE_FORMAT(date, '%b %D %Y %h:%i %p') → Jul 25th 2023 02:30 PM\nDATE_FORMAT(date, '%W, %M %e')         → Tuesday, July 25\n```\n\n------\n\n### 四、条件判断函数\n\n**IF 函数**\n\n```sql\nIF(expr, v1, v2)  -- expr为真返回v1，否则v2\n```\n\n- 示例：`IF(1>2, 'Y', 'N') → N`\n\n**CASE 表达式**\n\n```\n-- 简单CASE\nCASE expr \n    WHEN v1 THEN r1 \n    WHEN v2 THEN r2 \n    ELSE rn \nEND\n\n-- 搜索CASE\nCASE \n    WHEN condition1 THEN r1 \n    WHEN condition2 THEN r2 \n    ELSE rn \nEND\n```\n\n- 示例：\n\n```sql\nCASE WHEN 1<0 THEN 'T' ELSE 'F' END → F\n```\n\n***NULLIF vs. IFNULL***\n\n| 特性         | `NULLIF`                                  | `IFNULL`                                     |\n| ------------ | ----------------------------------------- | -------------------------------------------- |\n| **功能**     | 比较两个值，相等时返回 `NULL`             | 检查一个值是否为 `NULL`，并提供替代值        |\n| **返回值**   | 返回 `NULL` 或 `expression1`              | 返回 `expression1` 或 `expression2`          |\n| **常见用途** | 避免除零错误、处理重复值                  | 提供默认值、数据清洗                         |\n| **示例**     | `NULLIF(a, b)`：如果 `a = b`，返回 `NULL` | `IFNULL(a, b)`：如果 `a` 是 `NULL`，返回 `b` |\n\n**COALESCE 函数**\n\n**功能说明**\n\n返回参数列表中**第一个非 NULL 的值**，常用于处理缺失值替换。\n\n**语法**\n\n```sql\nCOALESCE(v1, v2, v3, ..., vn)\n```\n\n**执行逻辑**\n\n1. 从左到右依次检查参数\n2. 返回第一个不为 `NULL` 的值\n3. 如果所有参数均为 `NULL`，则返回 `NULL`\n\n**示例**\n\n```sql\n-- 数据示例：name字段为NULL，nickname='小张'，default_name='匿名用户'\nCOALESCE(NULL, '小张', '匿名用户') → '小张'\nCOALESCE(NULL, NULL, '2023-01-01') → '2023-01-01'\nCOALESCE(NULL, NULL, NULL) → NULL\n```\n\n**与 IFNULL 的对比**\n\n| 特性         | `COALESCE`             | `IFNULL`       |\n| ------------ | ---------------------- | -------------- |\n| **参数数量** | 支持多个参数           | 仅支持两个参数 |\n| **功能范围** | 多条件NULL处理         | 简单双值替换   |\n| **可读性**   | 更适合多字段优先级选择 | 适合简单场景   |\n\n**等价写法**\n\n```sql\nCOALESCE(a, b, c) \n-- 等价于 \nCASE \n    WHEN a IS NOT NULL THEN a \n    WHEN b IS NOT NULL THEN b \n    ELSE c \nEND\n```\n\n**常见使用场景**\n\n1. **多级备用值选择**\n\n   ```sql\n   -- 优先显示用户昵称，其次邮箱，最后显示'未知用户'\n   SELECT COALESCE(nickname, email, '未知用户') AS display_name FROM users;\n   ```\n\n2. **NULL值数据清洗**\n\n   ```sql\n   -- 将NULL金额转换为0计算总和\n   SELECT SUM(COALESCE(amount, 0)) AS total FROM orders;\n   ```\n\n3. **多字段优先级合并**\n\n   ```sql\n   -- 合并地址信息（优先使用详细地址，没有时使用区域地址）\n   SELECT COALESCE(detail_address, area_address) AS full_address FROM locations;\n   ```\n\n### 五、类型转换函数\n\n**CAST(x AS type)**\n\n- 支持类型：`CHAR(n)`, `DATE`, `TIME`,`DATETIME`,`DECIMAL`等\n- 示例：`CAST('2023' AS DECIMAL) → 2023`\n\n### 六、表连接补充自连接\n\n#### 自连接介绍\n\n自连接是一种特殊的连接查询，指的是同一个表自己与自己进行连接。常用于处理具有层级关系的数据，例如员工与经理、分类的父类与子类等场景。自连接实际上是将同一个表视为两个不同的实例，通过别名进行区分，并根据关联条件进行连接。\n\n#### 自连接语法\n\n自连接可以使用内连接或外连接语法，核心是为同一表赋予不同的别名：\n\n```sql\n-- 内自连接（查询匹配条件的记录）\nSELECT 字段 \nFROM 表 AS 别名1 \nINNER JOIN 表 AS 别名2 \nON 别名1.字段 = 别名2.关联字段;\n\n-- 左自连接（以左表为主，查询右表可能不存在的记录）\nSELECT 字段 \nFROM 表 AS 别名1 \nLEFT JOIN 表 AS 别名2 \nON 别名1.字段 = 别名2.关联字段;\n```\n\n#### 自连接示例\n\n**场景**：假设有员工表 `employees`，结构如下：\n\n| id   | name | manager_id |\n| ---- | ---- | ---------- |\n| 1    | 张三 | NULL       |\n| 2    | 李四 | 1          |\n| 3    | 王五 | 1          |\n| 4    | 赵六 | 2          |\n\n**需求**：查询每个员工及其对应经理的名字（包括没有经理的员工）。\n\n**SQL语句**：\n\n```sql\nSELECT \n    e1.name AS employee_name,\n    e2.name AS manager_name\nFROM employees e1\nLEFT JOIN employees e2 \nON e1.manager_id = e2.id;\n```\n\n**查询结果**：\n\n| employee_name | manager_name |\n| ------------- | ------------ |\n| 张三          | NULL         |\n| 李四          | 张三         |\n| 王五          | 张三         |\n| 赵六          | 李四         |\n\n#### 自连接应用场景\n\n1. **层级关系**：如组织架构、分类层级（父类与子类）。\n2. **数据对称性分析**：如社交网络中的用户关系（用户A和用户B互为好友）。\n3. **路径查询**：如地铁站点之间的连接关系。\n\n#### 注意事项\n\n1. **别名必要性**：必须为表指定不同的别名以区分左、右表。\n2. **性能优化**：自连接可能引发较大的计算开销，尤其是大表操作时，建议在关联字段上创建索引。\n3. **连接类型选择**：\n   - 使用 **内自连接** 时，只返回满足条件的记录（如“有经理的员工”）。\n   - 使用 **左自连接** 时，会包含左表所有记录，右表无匹配则填充 `NULL`（如“包括无经理的员工”）。\n\n### 七、交叉连接 CROSS JOIN\n\n#### 功能说明\n\n生成两个表的**笛卡尔积**（所有行的组合），无关联条件。\n特点：\n\n- 结果集行数 = 表A行数 × 表B行数\n- 不需要连接条件（无`ON`子句）\n- 常用于生成组合数据、测试数据等场景\n\n#### 语法形式\n\n```sql\n-- 显式语法\nSELECT * \nFROM table1 \nCROSS JOIN table2;\n\n-- 隐式语法（等同于CROSS JOIN）\nSELECT * \nFROM table1, table2;\n```\n\n#### 典型应用场景\n\n1. **生成组合数据**\n   如：颜色与尺寸组合、日期与产品组合\n2. **数据模拟测试**\n   快速生成大量测试数据\n3. **全量关联分析**\n   计算所有可能的组合关系\n\n#### 与INNER JOIN的区别\n\n| 特性           | `CROSS JOIN`     | `INNER JOIN`       |\n| -------------- | ---------------- | ------------------ |\n| **连接条件**   | 无需`ON`子句     | 必须使用`ON`子句   |\n| **结果集逻辑** | 强制所有行组合   | 仅匹配关联条件的行 |\n| **数据量**     | 可能极大（慎用） | 通常较小           |\n\n### 八、集合操作符 UNION ALL\n\n#### 功能说明\n\n用于合并多个查询结果，**保留所有记录**（包括重复行）\n\n#### 基本语法\n\n```sql\nSELECT 字段列表 FROM 表1\nUNION ALL\nSELECT 字段列表 FROM 表2\n...\n```\n\n#### 与UNION的区别\n\n| 特性         | `UNION ALL`              | `UNION`      |\n| ------------ | ------------------------ | ------------ |\n| **去重处理** | 保留所有记录，包括重复行 | 自动去重     |\n| **排序操作** | 不排序                   | 默认进行排序 |\n| **性能**     | 更高（无去重、排序开销） | 较低         |\n\n#### 使用场景\n\n1. 合并分表数据（如按年份拆分的订单表）\n2. 需要保留重复记录的统计场景\n3. 明确知道数据无重复时的性能优化选择\n\n#### 注意事项\n\n- 合并的SELECT语句必须包含**相同数量**的字段\n- 对应字段的**数据类型必须兼容**\n- 最终结果集的字段名以第一个SELECT语句为准\n\n#### 使用示例\n\n```sql\n-- 合并两个季度的销售数据（保留重复）\nSELECT product_id, sales FROM Q1_sales\nUNION ALL\nSELECT product_id, sales FROM Q2_sales;\n\n-- 组合不同表结构数据（使用别名统一字段）\nSELECT id, name, 'employee' AS type FROM employees\nUNION ALL\nSELECT customer_id, company_name, 'customer' FROM customers;\n```\n\n------\n\n### 小结\n\n- **自连接本质**：同一表通过别名模拟两个表的连接操作，支持内连接或外连接语法。\n- **核心步骤**：\n  1. 为同一表赋予不同别名（如 `e1`, `e2`）。\n  2. 指定连接条件（如 `e1.manager_id = e2.id`）。\n- **适用场景**：处理数据内部的层级或对称关系。\n- **优化建议**：合理使用索引，避免全表扫描带来的性能问题。\n\n# 👀 窗口函数详解\n\n## 一、什么是窗口函数？\n\n窗口函数（Window Function）是一种**对查询结果集进行逐行计算**的特殊函数，能够：\n\n- 在保留原始数据行的同时进行聚合/排序等操作\n- 实现复杂的分组统计需求（如：累计值、移动平均值、排名等）\n- 不会像`GROUP BY`那样合并结果集\n\n## 二、标准语法\n\n```sql\n函数名() OVER (\n    [PARTITION BY 字段]  -- 定义分组窗口\n    [ORDER BY 字段 [ASC|DESC]]  -- 定义排序规则\n)\n```\n\n## 三、核心组件\n\n### 1. PARTITION BY\n\n- 作用：将数据**按指定字段分组**，每组称为一个窗口\n- 类似`GROUP BY`但**不合并结果集**\n- 示例：`PARTITION BY department` 按部门分组\n\n### 2. ORDER BY\n\n- 作用：在窗口内**指定排序规则**\n- 示例：`ORDER BY sales DESC` 按销售额降序排列\n\n## 四、常用窗口函数\n\n### 1. 排序函数\n\n| 函数           | 特点                          | 示例结果（相同值处理） |\n| -------------- | :---------------------------- | :--------------------- |\n| `RANK()`       | 出现并列时**跳号**（1,1,3）   | 1,1,3,4                |\n| `DENSE_RANK()` | 出现并列时**不跳号**（1,1,2） | 1,1,2,3                |\n| `ROW_NUMBER()` | **强制生成唯一序号**          | 1,2,3,4                |\n\n📝 示例数据（按成绩排序）：\n\n```sql\nSELECT \n    name,\n    score,\n    RANK() OVER(ORDER BY score DESC) AS rank,\n    DENSE_RANK() OVER(ORDER BY score DESC) AS dense_rank,\n    ROW_NUMBER() OVER(ORDER BY score DESC) AS row_num\nFROM students;\n```\n\n| name | score | rank | dense_rank | row_num |\n| ---- | ----- | ---- | ---------- | ------- |\n| 张三 | 95    | 1    | 1          | 1       |\n| 李四 | 95    | 1    | 1          | 2       |\n| 王五 | 90    | 3    | 2          | 3       |\n\n### 2. 偏移分析函数\n\n| 函数                           | 功能说明                   | 参数说明                  |\n| ------------------------------ | -------------------------- | ------------------------- |\n| `LAG(字段, 偏移量[, 默认值])`  | 获取**当前行向上偏移**的值 | 默认偏移量=1，默认值=NULL |\n| `LEAD(字段, 偏移量[, 默认值])` | 获取**当前行向下偏移**的值 | 默认偏移量=1，默认值=NULL |\n\n📝 示例（查看相邻订单金额）：\n\n```sql\nSELECT \n    order_date,\n    amount,\n    LAG(amount, 1) OVER(ORDER BY order_date) AS prev_amount,\n    LEAD(amount, 1) OVER(ORDER BY order_date) AS next_amount\nFROM orders;\n```\n\n| order_date | amount | prev_amount | next_amount |\n| ---------- | ------ | ----------- | ----------- |\n| 2023-01-01 | 100    | NULL        | 150         |\n| 2023-01-02 | 150    | 100         | 200         |\n| 2023-01-03 | 200    | 150         | NULL        |\n\n### 3.滑动窗口（窗口框架）\n\n#### 核心概念\n\n通过定义窗口框架（Window Frame），**动态控制计算范围**。支持两种模式：\n\n- **基于行数**（`ROWS`）：物理行偏移\n- **基于数值范围**（`RANGE`）：逻辑值偏移\n\n#### 标准语法\n\n```sql\n函数() OVER (\n    PARTITION BY ... \n    ORDER BY ...\n    [ROWS|RANGE BETWEEN 起始点 AND 结束点]\n)\n```\n\n#### 框架边界定义\n\n| 关键词                | 说明                            |\n| --------------------- | ------------------------------- |\n| `UNBOUNDED PRECEDING` | 窗口起始位置（第一行/最小值）   |\n| `UNBOUNDED FOLLOWING` | 窗口结束位置（最后一行/最大值） |\n| `CURRENT ROW`         | 当前行                          |\n| `n PRECEDING`         | 当前行向前n行/n值（包含当前行） |\n| `n FOLLOWING`         | 当前行向后n行/n值（包含当前行） |\n\n#### 常用模式示例\n\n##### 1. 累计计算（默认模式）\n\n```sql\nSUM(sales) OVER (\n    ORDER BY date \n    ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n) \n-- 等价简写：\nSUM(sales) OVER (ORDER BY date)\n```\n\n##### 2. 移动平均（近3天）\n\n```\nAVG(temperature) OVER (\n    ORDER BY date \n    ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n)\n```\n\n##### 3. 对称窗口（前后各1行）\n\n```\nMAX(score) OVER (\n    ORDER BY id \n    ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING\n)\n```\n\n#### ROWS vs RANGE 对比\n\n| 对比项       | `ROWS`                  | `RANGE`                       |\n| ------------ | ----------------------- | ----------------------------- |\n| **计算逻辑** | 按物理行偏移            | 按ORDER BY字段的数值偏移      |\n| **适用场景** | 明确行数移动（如近3行） | 按数值区间计算（如3天范围）   |\n| **性能**     | 更高                    | 较低（需排序计算）            |\n| **数据要求** | 无特殊要求              | ORDER BY字段需为数值/日期类型 |\n\n```sql\n-- ROWS模式（物理行）\nSUM(amount) OVER (\n    ORDER BY date \n    ROWS BETWEEN 1 PRECEDING AND CURRENT ROW\n) → 当前行+前1行\n\n-- RANGE模式（逻辑值）\nSUM(amount) OVER (\n    ORDER BY date \n    RANGE BETWEEN INTERVAL 1 DAY PRECEDING AND CURRENT ROW\n) → 当天+前一天的所有记录\n```\n\n#### 典型应用场景\n\n1. **金融分析**\n   - 7日移动平均线\n   - 滚动波动率计算\n2. **电商分析**\n   - 近30天消费趋势\n   - 周环比增长率\n3. **运营监控**\n   - 每小时累计UV\n   - 滑动窗口异常检测\n\n#### 高级用法示例\n\n动态最近N条记录统计\n\n```sql\nSELECT \n    order_id,\n    order_time,\n    AVG(amount) OVER (\n        ORDER BY order_time \n        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n    ) AS last_10_avg\nFROM orders;\n```\n\n#### 时间段累计（日期类型）\n\n```sql\nSELECT \n    report_date,\n    SUM(revenue) OVER (\n        ORDER BY report_date \n        RANGE BETWEEN INTERVAL 6 DAY PRECEDING AND CURRENT ROW\n    ) AS 7day_revenue \nFROM daily_stats;\n```\n\n> #### 注意事项\n>\n> 1. **性能优化**\n>    - 避免大范围窗口（如`UNBOUNDED`+大数据量表）\n>    - 优先使用`ROWS`模式\n>    - 配合合适的索引（ORDER BY字段）\n> 2. **边界处理**\n>    - 窗口起始前的行返回`NULL`\n>    - 使用`COALESCE`处理空值\n> 3. **框架限制**\n>    - `RANGE`模式不支持`n FOLLOWING`（MySQL限制）\n>    - 不同数据库实现细节可能有差异\n\n## 五、综合应用场景\n\n### 案例：**部门薪资排名**\n\n```sql\nSELECT \n    department,\n    name,\n    salary,\n    RANK() OVER(PARTITION BY department ORDER BY salary DESC) AS dept_rank\nFROM employees;\n```\n\n| department | name | salary | dept_rank |\n| ---------- | ---- | ------ | --------- |\n| 技术部     | 张三 | 15000  | 1         |\n| 技术部     | 李四 | 12000  | 2         |\n| 市场部     | 王五 | 13000  | 1         |\n\n## 六、注意事项\n\n1. 窗口函数执行顺序：在`WHERE`、`GROUP BY`之后，`ORDER BY`之前\n2. 可以组合使用多个窗口函数\n3. 不同数据库支持情况可能不同（MySQL 8.0+支持）\n4. 大数据量时注意性能优化\n\n","tags":["数据操作","SQL","数据库"],"categories":["大数据"]},{"title":"Linux基础","url":"/post/linuxba.html","content":"\n# 所需软件的安装和配置\n\n## 1.VMware和远程连接软件（FinalShell、Xshell等）的安装\n\nVMware软件安装简单，激活码查找也方便，FinalShell若不使用专业版内容也是直接安装即可。\n\n下面是FinalShell3.9.5.7及之前版本的高级/专业版激活码获取方式。\n\n打开FinalShell后点击激活，选择离线激活，随便输入账号密码，复制机器码，粘贴即可获取\n\n```php\n<?php\n    if(!empty($_POST['k'])){\n        if($_POST['s'] == 1){\n            $a = '激活码为：'.strtolower(substr(md5('2356'.$_POST['k'].'13593'),8,16));\n        }\n        if($_POST['s'] == 0){\n            $a = '激活码为：'.strtolower(substr(md5('61305'.$_POST['k'].'8552'),8,16));\n        }\n    }\n?>\n```\n\nsubstr截取md5的一部分，从第八位开始往后面的16个字符，strtolower()将字符串全部转为小写\n\n```html\n<form action=\"#\" method=\"post\">\n        <input type=\"text\" name=\"k\" id=\"k\">\n        <input type=\"radio\" name=\"s\" id=\"s\" value=\"1\">专业版\n        <input type=\"radio\" name=\"s\" id=\"s\" value=\"0\">高级版\n        <input type=\"submit\" value=\"提交\">\n    </form>\n```\n\nphp文件内容应为\n\n```php+HTML\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>FinalShell激活码计算</title>\n</head>\n\n<body>\n\n<form action=\"#\" method=\"post\">\n    <input type=\"text\" name=\"k\" id=\"k\">\n    <input type=\"radio\" name=\"s\" id=\"s1\" value=\"1\">专业版\n    <input type=\"radio\" name=\"s\" id=\"s2\" value=\"0\">高级版\n    <input type=\"submit\" value=\"提交\">\n</form>\n\n<?php\n    $a = '';\n    if(!empty($_POST['k'])){\n        if($_POST['s'] == 1){\n            $a = '激活码为：'.strtolower(substr(md5('2356'.$_POST['k'].'13593'),8,16));\n        }\n        if($_POST['s'] == 0){\n            $a = '激活码为：'.strtolower(substr(md5('61305'.$_POST['k'].'8552'),8,16));\n        }\n    }\n    echo $a;\n?>\n\n</body>\n</html>\n```\n\n\n\nJava代码 [附在线运行网站](https://www.json.cn/runcode/run_java/)\n\n```java\nimport java.io.IOException;\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\nimport java.util.Scanner;\n\nclass Main{\n    public static void main(String[] args) throws NoSuchAlgorithmException, IOException {\n        System.out.print(\"请输入FinalShell的离线机器码：\");\n        @SuppressWarnings(\"resource\")\n        //Scanner reader = new Scanner(System.in);\n        String machineCode = \"aa@6a6c73491cbe6c6e\"; // 在此处放置机器码\n        generateKey(machineCode);\n    }\n\n    public static void generateKey(String hardwareId) throws NoSuchAlgorithmException {\n        String proKey = transform(61305 + hardwareId + 8552); //高级版\n        String pfKey = transform(2356 + hardwareId + 13593); //专业版\n        System.out.println(\"请将此行复制到离线激活中：\" + pfKey);\n    }\n\n    public static String transform(String str) throws NoSuchAlgorithmException {\n\n        @SuppressWarnings(\"unused\")\n        String md5 = hashMD5(str);\n\n        return hashMD5(str).substring(8, 24);\n    }\n\n    public static String hashMD5(String str) throws NoSuchAlgorithmException {\n        MessageDigest digest = MessageDigest.getInstance(\"MD5\");\n        byte[] hashed = digest.digest(str.getBytes());\n        StringBuilder sb = new StringBuilder();\n        for (byte b : hashed) {\n            int len = b & 0xFF;\n            if (len < 16) {\n                sb.append(\"0\");\n            }\n            sb.append(Integer.toHexString(len));\n        }\n        return sb.toString();\n    }\n}\n\n```\n\n\n\n### 虚拟网络配置\n\n安装好本地虚拟机后，需要对网络进行配置，~~*使用vps可跳过这个步骤*~~ 课程中使用的是CentOS7的系统，不同版本的具体配置可能不尽相同。在虚拟机设置中，将虚拟机的网络模式设置为NAT模式。\n\n\n\n在终端界面输入`ifconfig` 查看ens33的ip地址，ip地址为192.168.88.100，然后打开虚拟网络编辑器，选中VMnet8更改配置\n\n![linux01.png](https://s2.loli.net/2024/03/15/lPkyoLge326WTBd.png)\n\n![linux02.png](https://s2.loli.net/2024/03/15/LFHSh8DZvm3cKPo.png)\n\n子网IP更改为192.168.88.0，点击将主机虚拟适配器连接到此网络，点击NAT设置，将网关IP改为192.168.88.2，点击确定，保存。\n\n\n\n修改配置文件，IP地址192.168.88.100和网关地址192.168.88.2、DNS192.168.88.2\n\n```\nvim /etc/sysconfig/network-scripts/ifcfg-ens33\n```\n\n![linux03.png](https://s2.loli.net/2024/03/15/atjAwCNBLsIOlWu.png)\n\n然后修改网络适配器\n\n![linux04.png](https://s2.loli.net/2024/03/15/oAz421RPdbOt86q.png)\n\n删除`/etc/sysconfig/network-scripts/` 下的以ifcfg开头除ifcfg-ens33和ifcfg-lo以外的文件（ifcfg-配置_1， ifcfg-ens33.bak），重启网络`systemctl restart network` 此时虚拟机应能正常访问网络。\n\n## 2.Linux命令\n\nLinux是树状存储结构，在一个根节点下存放了系统的不同文件夹，Windows是森林结构\n\n/bin：这个目录存放着最经常使用的命令,ls、cp、rm、chmod 等常用命令都在此目录\n\n/boot 系统启动目录，保存与系统启动相关的文件，如内核文件和启动引导程序；\n\n/dev 设备文件保存位置；\n\n/etc：存放在配置文件\n\n/home：用户的主目录 \n\n/lib：存放程序所需的动态库和静态库文件；\n\n/root ：超级用户 home目录\n\n### 2.1.Linux基础命令\n\n#### 2.1.1.linux命令的构成\n\nlinux指令=命令（做什么） +选项（怎么做） +参数（对谁做）\n\n​\t\t\t-command ：命令名 ：使用英文单词的缩写或者英文单词\n\n​\t\t\t-options：选项     ，可以对命令进行控制   但是 也可以省略\n\n​\t\t\t-parameter：给命令传参数， 可以是一个 ，也可以是多个或者零个\n\n**在使用命令时，可以使用man 命令名查看使用说明**\n\n./ ：代表当前目录\n\n../：上一级目录\n\n使用这两种方式可实现绝对路径和相对路径访问文件\n\n**ctrl+r：历史记录中所搜命令（输入命令中的任意一个字符）；**\n\n**ctrl+c：终止当前的命令**\n\n#### 2.1.2 ls命令\n\nls命令：展示linux系统中指定位置的目录信息   -F 查看目录中的文件\n\n```\n-a ：查看所有文件，包括隐藏的文件，Linux下隐藏文件 隐藏目录 名称都是以.开头，图形界面下可以使用ctrl+h切换是否显示隐藏文件\n\n-l ：展示文件的详细信息，包括权限、归属、文件大小、创建修改时间、文件名称，linux内置了ll命令作为ls -l的别名\nls -ld：显示目录和链接信息；\n\n-h ：人性化显示文件大小，赋予最恰当的单位 但是需要和 l一起使用  \n\nls -R：递归显示子目录结构；\n\nls [0-9] ：显示包含数字的文件名和目录名\n```\n\n\n\n#### 2.1.3 cd命令\n\n```\ncd ../   返回上一级目录\ncd ../.. 返回上两级目录\n\ncd - 返回上一次操作的工作目录\n\ncd / 进入根目录\n\ncd ~ 返回家目录中   ~ 可以省略\n```\n\n#### 2.1.4 pwd命令\n\npwd命令：获取当前所在工作目录的绝对路径\n\n#### 2.1.5 mkdir命令\n\nmkdir命令用来创建空目录的命令，我们可以在指定的路径下厨房间一个空目录\n\n```\nmkdir 文件夹名字  ：在当前目录下创建一个文件夹\n\nmkdir -p 文件路径   指定路径下创建一个空目录，同时创建其父目录\n```\n\n#### 2.1.6 touch命令\n\ntouch命令可以创建一个新的文件，文件的拓展名随意，甚至可以是一个不存在的拓展名，当文件存在的时候，修改文件的创建时间\n\ntouch 可以一次性创建多个文件，但是这个文件路径**必须正确**\n\n```\ntouch -t 0712250000 file1 修改一个文件或目录的时间戳 - (YYMMDDhhmm)\ntouch * ：将当前下的文件时间修改为系统的当前时间\n\ntouch –d 20040210 test：将test文件的日期改为20040210\n\ntouch abc　：若abc文件存在，则修改为系统的当前时间；若不存在，则生成一个为当前时间的空文件\n```\n\n#### 2.1.7 rm命令\n\nrm 是删除文件的指令，可以删除文件 ，也可以删除文件夹\n\n```\n-r  递归删除，删除文件夹的时候使用\n\n-f  强制删除 ，不进行询问\n\nrm  可以删除任意文件，路径可以是相对/绝对的\n```\n\n#### 2.1.8 mv命令\n\nmv是一个移动文件的指令，将文件从一个位置移动到另一个位置，在移动的过程中可以修改文件或者目录的**名称**，格式：mv 源文件路径（相对/绝对）   目标路径。移动文件或者目录时，目标路径必须存在，改名只需输入相同的路径不同的文件名即可，可同时改名并移动文件\n\n```\nmv dir1 new_dir 重命名/移动 一个目录\n```\n\n\n\n#### 2.1.9 cp命令\n\ncp命令就是可以复制文件或者目录的命令，在复制的过程中，源文件不会被删除，复制完成后，文件可以修改名称，格式：cp 源文件路径  目标路径\n\n```\ncp -r #复制目录时需要- r\n\ncp file1 file2 复制一个文件\ncp dir/* . 复制一个目录下的所有文件到当前工作目录\ncp -a /tmp/dir1 . 复制一个目录到当前工作目录\ncp -a dir1 dir2 复制一个目录\n```\n\nmv和cp的使用方式基本一致，只有两个地方不一样：\n\n1：mv移动目录时不需要使用-r，cp需要使用-r\n\n2：cp不会删除源文件，而mv源文件会消失\n\n#### 2.1.10 echo命令\n\n功能：输出内容\n\n语法：`echo 参数`\n\n- 参数：被输出的内容\n- 被两个反引号包围的内容，会作为命令执行，echo \\`pwd\\`，会输出当前工作目录\n\n#### 2.1.11 重定向符\n\n功能：将符号左边的结果，输出到右边指定的文件中去\n\n- `>`，表示覆盖输出\n- `>>`，表示追加输出\n\n### 2.2 进阶命令\n\n#### 2.2.1 cat命令\n\n用于查看linux中**小型的**文本文件，cat 文件名\n\n因为他会一次行将所有的文件内容加载终端中，终端显示的数据有限，大的文件会显示不全，且消耗内存\n\n使用生产场景：   大数据框架的运行日志、大数据计算的运行日志\n\n```\ncat file1 从第一个字节开始正向查看文件的内容\ntac file1 从最后一行开始反向查看一个文件的内容\n```\n\n\n\n#### 2.2.2 more命令\n\n用于查看linux中中型的文本文件\n\n使用more进行文件的查看可以按页，手动翻页或者回滚，更灵活。但是统一也消耗内存\n\n```\n -回车   向下一行\n -空格    向下一页\n b   向上一页\n q   退出查看\n \nmore file1 查看一个长文件的内容\nless file1 类似于 'more' 命令，但是它允许在文件中和正向操作一样的反向操作\n```\n\ncat 和 more 都可用来查看文件内容。不同点在于：cat 指令查看完毕后会自动返回到正常模式而 more 指令则需要用户手动退出查看模式。cat 命令用于显示整个文件的内容，单独使用没有翻页功能。而 more 命令则可以分页显示文件内容，可以向前或向后翻页，可**与cat配合使用**。\n\n#### 2.2.3 head，tail命令\n\nhead功能：查看文件头部内容\n\n语法：`head [-n] 参数`\n\n- 参数：被查看的文件\n- 选项：-n，查看的行数\n\ntail默认查看该文件的最新10行（如果这个文件发生变动，有新的内容添加到文件的尾部，tail命令会把新添加的内容展示出来，**实时查看** ）\n\n```\ntail -f 文件名\nhead -2 file1 查看一个文件的前两行\ntail -2 file1 查看一个文件的最后两行\n```\n\n#### 2.2.4 ps命令\n\n查看当前活跃的进程\n\nps -ef 作用：查看当前所有的进程，查看PID和了解进程cpu资源占比情况\n\n```\nUID：表示是哪个一个用户执行的\n\nPPID：进行的父进行标识号\n\nC：cpu使用资源的百分比\n\nStime：进程开始执行的时间\n```\n\n#### 2.2.5 kill命令\n\n用于结束linux中的软件或者服务，格式： kill -9 进程编号  \n\nkill -9 可以快速的杀死进程，但是不安全，因为我们的服务在运行的过程中，可能会需要保存或者某执行完某一个任务在关闭。所以不轻易使用，一般都是用于杀死闲置进程或者不响应的进行。\n\n#### 2.2.6 ifconfig命令\n\n作用：用于查看服务器网络信息\n\n#### 2.2.7 free命令\n\n作用：查看内存的使用情况\n\n```\ntotal：表示总计的物理内存大小\n\nused：表示已经使用的多了\n\nfree：表示还可以用多少\n\nshared：表示多个进行共享的内存总额\n\nbuff：表示缓存的大小\n\nfree -k：以kb为单位来显示内存（默认就是k）\n\nfree -m：以m为单位来显示内存信息\n\nfree -g ：以m为单位来显示内存信息\n\nfree -h ：以用户适合的方式去显示内存\n\nfree -t：显示linux全部的内存（total）\n\nfree -s：表示每个N秒打印一次内存信息，直到使用crtl+c结束\n\n\nfree -hs  5：生产使用场景：提交大数据计算任务后，动态的查看内存变化情况\n```\n\n#### 2.2.8 df命令\n\n作用：查看磁盘的使用情况\n\n```\ndf -h：以用户方便的单位进行显示\ndf-Th：显示文件系统的类型\n```\n\n#### 2.2.9 clear命令 \n\n清除终端窗口的信息=crlt+l\n\n#### 2.2.10 关机&重启命令\n\n```\n1：reboot命令\n\n重启计算机，reboot属于安全重启，不属于强制重启，可以放心的使用\n\n2：shutdown命令\n\nshutdown命令主要用于关机操作，关闭过程中，可以指定关机时间\n\nshutdown -h now 立即关机\n\nshutdown -h 1 一分钟后关机\nshutdown -h hours:minutes & 按预定时间关闭系统\n\nshutdown -c 取消按预定时间关闭系统\n\nshutdown -r now 重启\n\ninit 0    关闭系统\ntelinit 0 关闭系统\nlogout    注销\n```\n\n#### 2.2.11 which命令\n\n查看脚本或者终端命令文件所在位置\n\n一般情况下可以使用which命令找到**终端指令**的安装目录\n\n#### 2.2.12 grep命令\n\ngrep就是根据一定的规则做全文检索，在文件中查询到满足规则的文本内容\n\ngrep是在文件中查询文本，指定的文件中查找特定的字符组合\n\n用法: grep [选项]... \n\n生产使用场景：从日志中找到错误信息，方便我们分析日志\n\n​\tgrep ERROR 文件名\n\n​\t警告：grep INFO 文件名\n\n##### pgrep \n\n用于列举进程ID，下面两条命令是等效的\n\n```\npgrep -u hchen2244122444\nps -ef | egrep '^hchen' | awk '{print $2}'\n```\n\n\n\n#### 2.2.13 hostname命令\n\n查看主机名\n\n#### 2.2.14 | 无名管道命令\n\n管道指令，是连接两个命令的指令，前一个命令的输出，就是下一个命令的输入\n\n```\n查找文件：ls -l | grep 创建时间 |grep 文件名\n\n查找进程：ps -ef | grep 进程名 | grep 进程归属\n```\n\n#### 2.2.14.1 mkfifo 命名管道\n\n用法：mkfifo [选项] 文件名\n\n命名管道是一种特殊的文件类型，可以用于实现进程间通信（IPC，Inter-Process Communication），允许不同进程之间通过读写同一个文件来传递数据\n\n使用 `mkfifo` 命令创建的命名管道可以像普通文件一样被读取和写入。一个进程可以将数据写入命名管道，而另一个进程可以从同一个命名管道中读取这些数据，从而实现了进程间的通信。命名管道通常用于在不同的进程之间传递数据，例如在Shell脚本中用于管道操作、在不同的程序之间传递数据等\n\n命名管道在使用时需要注意同步和阻塞的问题，因为命名管道是基于文件系统的，读写操作可能会阻塞，导致进程在没有数据可读或可写时被阻塞。此外，命名管道在使用完毕后需要手动删除，可以使用 `rm` 命令删除对应的文件\n\n```\n# mkfifo /tmp/aapipe           创建命名管道\n# ls -l /tmp\n输出 prw-rw-r-- 1 aa  aa  0 05-10 18:58 aapipe\n# ls -al > /tmp/aapipe         在一个shell中运行此命令，命令不会返回，除非有人从这个有名管道中把信息读走\n# head /tmp/aapipe             在另一命令窗口读取管道中的信息，同时上一命令会返回\n输出 drwx------ 8 aa aa    4096 05-10 18:27 .\n    drwxr-xr-x 7 root  root     4096 03-05 00:06 ..\n    drwxr-xr-x 3 aa aa    4096 03-01 18:13 backup\n    -rw------- 1 aa aa     721 05-05 22:12 .bash_history\n    -rw-r--r-- 1 aa aa      24 02-28 22:20 .bash_logout\n    -rw-r--r-- 1 aa aa     176 02-28 22:20 .bash_profile\n    -rw-r--r-- 1 aa aa     124 02-28 22:20 .bashrc\n    -rw-r--r-- 1 root  root    14002 03-07 00:29 index.htm\n    -rw-r--r-- 1 aa aa   31465 03-01 23:48 index.php\n```\n\n\n\n#### 2.2.15 tar命令\n\ntar命令是进行打包，解包，压缩和解压的命令\n\n打包：将多个文件归档为一个文件，文件大小不会减少\t\n\n解包（拆包）：将一个包文件分拆多个实体的文件\n\n压缩：将文件按照一定的算法减少体积，但是文件的内容和信息不会发送改变\n\n解压缩：将一个压缩文件还原到正常的状态\n\n```\n参数：\nc：打包选项\nx：解包选项\nz：压缩或者解压缩选项\nv：展示过程\nf：指定文件名\n一般情况tar -cxvf压缩 tar -zxvf解压\n```\n\n**其它压缩指令**\n\n```\nbunzip2 file1.bz2           解压一个叫做 'file1.bz2'的文件\nbzip2 file1                 压缩一个叫做 'file1' 的文件\ngunzip file1.gz             解压一个叫做 'file1.gz'的文件\ngzip file1                  压缩一个叫做 'file1'的文件\ngzip -9 file1               最大程度压缩\nrar a file1.rar test_file          创建一个叫做 'file1.rar' 的包\nrar a file1.rar file1 file2 dir1   同时压缩 'file1', 'file2' 以及目录 'dir1'\nrar x file1.rar     压缩rar包\nunrar x file1.rar   解压rar包\ntar -cvf archive.tar file1     创建一个非压缩的 tarball\ntar -tf archive.tar            显示一个包中的内容\ntar -xvf archive.tar           释放一个包\ntar -xvf archive.tar -C /tmp   将压缩包释放到 /tmp目录下\ntar -cvfj archive.tar.bz2 dir1 创建一个bzip2格式的压缩包\ntar -xvfj archive.tar.bz2      解压一个bzip2格式的压缩包\ntar -cvfz archive.tar.gz dir1  创建一个gzip格式的压缩包\ntar -xvfz archive.tar.gz       解压一个gzip格式的压缩包\nzip file1.zip file1            创建一个zip格式的压缩包\nzip -r file1.zip file1 file2 dir1   将几个文件和目录同时压缩成一个zip格式的压缩包\nunzip file1.zip                     解压一个zip格式压缩包\n```\n\n\n\n#### 2.2.16 useradd，groupadd命令\n\nuseradd 可以添加一个linux用户，/home目录会创建一个该用户的家目录 \n\n```\ngroupmod -n new_group_name old_group_name                              重命名一个用户组\nuseradd -c \"Name Surname \" -g admin -d /home/user1 -s /bin/bash user1  创建一个属于 \"admin\" 用户组的用户\n```\n\n\n\n#### 2.2.17 userdel，groupdel命令\n\n删除用户同时会删除用户的家目录\n\n```\nuserdel -r user1              删除一个用户 ( '-r' 排除主目录)\nusermod -c \"User FTP\" -g system -d /ftp/user1 -s /bin/nologin user1   修改用户属性\nnewgrp group_name             登陆进一个新的群组以改变新创建文件的预设群组\n```\n\n\n\n#### 2.2.18 passwd命令\n\n格式：passwd 用户名 更改指定用户的密码，不可使用数字小键盘\n\n```\npasswd user1               修改一个用户的密码 (只允许root执行)\nchage -E 2023-04-10 user1  设置用户密码的失效期限\n\npwck                       检查 '/etc/passwd' 的文件格式和语法修正以及存在的用户\ngrpck                      检查 '/etc/passwd' 的文件格式和语法修正以及存在的群组\n```\n\n\n\n#### 2.2.19 chmod，chown命令\n\ninux的文件**权限**\n\n|           |         | 权值 |\n| --------- | ------- | ---- |\n| 读：r     | read    | 4    |\n| 写：w     | write   | 2    |\n| 执行： x  | excuter | 1    |\n| 无权限：- |         | 0    |\n\nlinux文件**归属**\n\n属主：文件拥有者，一般是创建者 u   –user\n\n属组：文件拥有者所在的用户组   g    -group\n\n其他用户： 除了 属主和数组的其他用户 o -other\n\nls -l 可以查看文件的详细信息，包含文件权限其中d ：代表目录，-：普通文件\n\n```\nchmod 777 文件名                #表示给当前用户，用户所在组，其他用户都给予全部权限\nchmod u+x,g+x,o+x 文件名        #增加权限，-则为删除权限\nchmod u=rwx, g=wx, o=r 文件名   #同时编辑多个权限\n\nchmod go-rwx directory1        删除群组(g)与其他人(o)对目录的读写执行权限\n\nchown [-R] [用户][:][用户组] 文件或文件夹\nchown -R user1 directory1      改变一个目录的所有人属性并同时改变改目录下所有文件的属性\nchgrp group1 file1             改变文件的群组\n\nchmod u+s /bin/file1       设置一个二进制文件的 SUID 位 - 运行该文件的用户也被赋予和所有者同样的权限\nchmod u-s /bin/file1       禁用一个二进制文件的 SUID位\nchmod g+s /home/public     设置一个目录的 SGID 位 - 类似SUID ，不过这是针对目录的\nchmod g-s /home/public     禁用一个目录的 SGID 位\nchmod o+t /home/public     设置一个文件的 STIKY 位 - 只允许合法所有人删除文件\nchmod o-t /home/public     禁用一个目录的 STIKY 位\n```\n\n#### 2.2.20 tree命令（需安装）\n\ntree    显示文件和目录由根目录开始的树形结构\n        lstree 显示文件和目录由根目录开始的树形结构\n\n#### 2.2.21 ln命令\n\n功能：在文件和目录之间建立链接\n\n格式：ln [参数] <源文件或目录> <目标文件或目录>\n\n```\nln -s file1 lnk1 创建一个指向文件或目录的软链接\nln file1 lnk1    创建一个指向文件或目录的物理链接\n```\n\n#### 2.2.22 chattr命令\n\n```\nchattr +a file1    只允许以追加方式读写文件\nchattr +c file1    允许这个文件能被内核自动压缩/解压\nchattr +d file1    在进行文件系统备份时，dump程序将忽略这个文件\nchattr +i file1    设置成不可变的文件，不能被删除、修改、重命名或者链接\nchattr +s file1    允许一个文件被安全地删除\nchattr +S file1    一旦应用程序对这个文件执行了写操作，使系统立刻把修改的结果写到磁盘\nchattr +u file1    若文件被删除，系统会允许你在以后恢复这个被删除的文件\nlsattr             显示特殊的属性\n```\n\n#### 2.2.23 wc命令\n\n功能：统计\n\n语法：`wc [-c -m -l -w] 文件路径`\n\n- 选项，-c，统计bytes数量\n- 选项，-m，统计字符数量\n- 选项，-l，统计行数\n- 选项，-w，统计单词数量\n- 参数，文件路径，被统计的文件，可作为内容输入端口\n\n### 2.3 系统指令\n\n#### 2.3.1 系统信息查看\n\n```\nuname -m         显示机器的处理器架构\nuname -r         显示正在使用的内核版本\nhdparm -tT /dev/sda                在磁盘上执行测试性读取操作系统信息\n(SMBIOS / DMI) hdparm -i /dev/hda  罗列一个磁盘的架构特性\nhdparm -i /dev/hda   罗列一个磁盘的架构特性\narch                 显示机器的处理器架构\ndmidecode -q         显示硬件系统部件 - (SMBIOS / DMI)\ncat /proc/cpuinfo    显示CPU info的信息\ncat /proc/interrupts 显示中断\ncat /proc/meminfo    校验内存使用\ncat /proc/swaps      显示哪些swap被使用\ncat /proc/version    显示内核的版本\ncat /proc/net/dev    显示网络适配器及统计\ncat /proc/mounts     显示已加载的文件系统\nlspci -tv            罗列 PCI 设备\nlsusb -tv            显示 USB 设备\nlsmod                查看加载的模块(驱动)\ndate                 显示系统日期\ncal 2007             显示2007年的日历表\ndate 041217002007.00 设置日期和时间 - 月日时分年.秒\nclock -w             将时间修改保存到 BIOS\niconv -l             列出已知的编码\n```\n\n#### 2.3.2 文件查找\n\n```\nfind / -name file1                          从 '/' 开始进入根文件系统搜索文件和目录\nfind / -user user1                          搜索属于用户 'user1' 的文件和目录\nfind /home/user1 -name \\.bin                在目录 '/ home/user1' 中搜索带有'.bin' 结尾的文件\nfind /usr/bin -type f -atime +100           搜索在过去100天内未被使用过的执行文件\nfind /usr/bin -type f -mtime -10            搜索在10天内被创建或者修改过的文件\nfind / -name \\.rpm -exec chmod 755 '{}' \\;  搜索以 '.rpm' 结尾的文件并定义其权限\nfind / -xdev -name \\.rpm                    搜索以 '.rpm' 结尾的文件，忽略光驱等可移动设备\nfind / -perm -u+s                           罗列一个系统中所有使用了SUID控制的文件\nlocate \\.ps                                 寻找以 '.ps' 结尾的文件 - 先运行 'updatedb' 命令\nwhereis halt                                显示一个二进制文件、源码或man的位置\nwhich halt                                  显示一个二进制文件或可执行文件的完整路径\n```\n\n#### 2.3.3 文件系统挂载\n\n```\nmount /dev/hda2 /mnt/hda2                挂载一个叫做hda2的盘 - 确定目录 '/ mnt/hda2' 已经存在\numount /dev/hda2                         卸载一个叫做hda2的盘 - 先从挂载点 '/ mnt/hda2' 退出\nfuser -km /mnt/hda2                      当设备繁忙时强制卸载\numount -n /mnt/hda2                      运行卸载操作而不写入 /etc/mtab 文件- 当文件为只读或当磁盘写满时非常有用\nmount /dev/fd0 /mnt/floppy               挂载一个软盘\nmount /dev/cdrom /mnt/cdrom              挂载一个cdrom或dvdrom\nmount /dev/hdb /mnt/cdrecorder           挂载一个cdrw或dvdrom\nmount -o loop file.iso /mnt/cdrom        挂载一个文件或ISO镜像文件\nmount -t vfat /dev/hda5 /mnt/hda5        挂载一个Windows FAT32文件系统\nmount /dev/sda1 /mnt/usbdisk             挂载一个usb 捷盘或闪存设备\nmount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share 挂载一个windows网络共享\n```\n\n#### 2.3.4 磁盘查看\n\n```\ndf -h                                               显示已经挂载的分区列表\nls -lSr |more                                       以尺寸大小排列文件和目录\ndu -sh dir1                                         估算目录 'dir1' 已经使用的磁盘空间'\ndu -sk * | sort -rn                                 以容量大小为依据依次显示文件和目录的大小\ndmesg                                               显示系统诊断信息、操作系统版本号、物理内存的大小以及其它信息\nrpm -q -a --qf '%10{SIZE}t%{NAME}n' | sort -k1,1n   以大小为依据依次显示已安装的rpm包所使用的空间 (fedora, redhat类系统)\ndpkg-query -W -f='${Installed-Size;10}t${Package}n' | sort -k1,1n   以大小为依据显示已安装的deb包所使用的空间 (ubuntu, debian类系统)\n```\n\n#### 2.3.5 软件安装命令\n\n##### rpm\n\n```\nrpm -ivh package.rpm             安装一个rpm包\nrpm -ivh --nodeeps package.rpm   安装一个rpm包而忽略依赖关系警告\nrpm -U package.rpm               更新一个rpm包但不改变其配置文件\nrpm -F package.rpm               更新一个确定已经安装的rpm包\nrpm -e package_name.rpm          删除一个rpm包\nrpm -qa                          显示系统中所有已经安装的rpm包\nrpm -qa | grep httpd             显示所有名称中包含 \"httpd\" 字样的rpm包\nrpm -qi package_name             获取一个已安装包的特殊信息\nrpm -qg \"System Environment/Daemons\"     显示一个组件的rpm包\nrpm -ql package_name                     显示一个已经安装的rpm包提供的文件列表\nrpm -qc package_name                     显示一个已经安装的rpm包提供的配置文件列表\nrpm -q package_name --whatrequires       显示与一个rpm包存在依赖关系的列表\nrpm -q package_name --whatprovides       显示一个rpm包所占的体积\nrpm -q package_name --scripts            显示在安装/删除期间所执行的脚本l\nrpm -q package_name --changelog          显示一个rpm包的修改历史\nrpm -qf /etc/httpd/conf/httpd.conf       确认所给的文件由哪个rpm包所提供\nrpm -qp package.rpm -l                   显示由一个尚未安装的rpm包提供的文件列表\nrpm --import /media/cdrom/RPM-GPG-KEY    导入公钥数字证书\nrpm --checksig package.rpm               确认一个rpm包的完整性\nrpm -qa gpg-pubkey                       确认已安装的所有rpm包的完整性\nrpm -V package_name                      检查文件尺寸、 许可、类型、所有者、群组、MD5检查以及最后修改时间\nrpm -Va                                  检查系统中所有已安装的rpm包- 小心使用\nrpm -Vp package.rpm                      确认一个rpm包还未安装\nrpm2cpio package.rpm | cpio --extract --make-directories *bin* 从一个rpm包运行可执行文件\nrpm -ivh /usr/src/redhat/RPMS/`arch`/package.rpm               从一个rpm源码安装一个构建好的包\nrpmbuild --rebuild package_name.src.rpm                        从一个rpm源码构建一个 rpm 包\n```\n\n##### yum[-y 自动确认] [install / remove / search] 软件名称\n\n```\nyum install package_name            下载并安装一个rpm包\nyum localinstall package_name.rpm   将安装一个rpm包，使用你自己的软件仓库为你解决所有依赖关系\nyum update package_name.rpm         更新当前系统中所有安装的rpm包\nyum update package_name             更新一个rpm包\nyum remove package_name             删除一个rpm包\nyum list                            列出当前系统中安装的所有包\nyum search package_name             在rpm仓库中搜寻软件包\nyum clean packages                  清理rpm缓存删除下载的包\nyum clean headers                   删除所有头文件\nyum clean all                       删除所有缓存的包和头文件\n```\n\n##### deb\n\n```\ndpkg -i package.deb         安装/更新一个 deb 包\ndpkg -r package_name        从系统删除一个 deb 包\ndpkg -l                     显示系统中所有已经安装的 deb 包\ndpkg -l | grep httpd        显示所有名称中包含 \"httpd\" 字样的deb包\ndpkg -s package_name        获得已经安装在系统中一个特殊包的信息\ndpkg -L package_name        显示系统中已经安装的一个deb包所提供的文件列表\ndpkg --contents package.deb 显示尚未安装的一个包所提供的文件列表\ndpkg -S /bin/ping           确认所给的文件由哪个deb包提供\n```\n\n##### apt(用于Debian, Ubuntu 以及类似系统)[-y 自动确认] [install / remove / search] 软件名称\n\n```\napt-get install package_name       安装/更新一个 deb 包\napt-cdrom install package_name     从光盘安装/更新一个 deb 包\napt-get update                     升级列表中的软件包\napt-get upgrade                    升级所有已安装的软件\napt-get remove package_name        从系统删除一个deb包\napt-get check                      确认依赖的软件仓库正确\napt-get clean                      从下载的软件包中清理缓存\napt-cache search searched-package  返回包含所要搜索字符串的软件包名称\n```\n\n#### 2.3.6 文本处理\n\n```\ncat file1 file2 ... | command <> file1_in.txt_or_file1_out.txt general syntax for text manipulation using PIPE, STDIN and STDOUT\ncat file1 | command( sed, grep, awk, grep, etc...) > result.txt  合并一个文件的详细说明文本，并将简介写入一个新文件中\ncat file1 | command( sed, grep, awk, grep, etc...) >> result.txt 合并一个文件的详细说明文本，并将简介写入一个已有的文件中\ngrep Aug /var/log/messages    在文件 '/var/log/messages'中查找关键词\"Aug\"\ngrep ^Aug /var/log/messages   在文件 '/var/log/messages'中查找以\"Aug\"开始的词汇\ngrep [0-9] /var/log/messages  选择 '/var/log/messages' 文件中所有包含数字的行\ngrep Aug -R /var/log/         在目录 '/var/log' 及随后的目录中搜索字符串\"Aug\"\nsed 's/stringa1/stringa2/g' example.txt     将example.txt文件中的 \"string1\" 替换成 \"string2\"\nsed '/^$/d' example.txt                     从example.txt文件中删除所有空白行\nsed '/ *#/d; /^$/d' example.txt             从example.txt文件中删除所有注释和空白行\necho 'esempio' | tr '[:lower:]' '[:upper:]' 合并上下单元格内容\nsed -e '1d' result.txt                      从文件example.txt 中排除第一行\nsed -n '/stringa1/p'                        查看只包含词汇 \"string1\"的行\nsed -e 's/ *$//' example.txt                删除每一行最后的空白字符\nsed -e 's/stringa1//g' example.txt          从文档中只删除词汇 \"string1\" 并保留剩余全部\nsed -n '1,5p;5q' example.txt                查看从第一行到第5行内容\nsed -n '5p;5q' example.txt                  查看第5行\nsed -e 's/00*/0/g' example.txt              用单个零替换多个零\ncat -n file1                                标示文件的行数\ncat example.txt | awk 'NR%2==1'             删除example.txt文件中的所有偶数行\necho a b c | awk '{print $1}'               查看一行第一栏\necho a b c | awk '{print $1,$3}'            查看一行的第一和第三栏\npaste file1 file2                           合并两个文件或两栏的内容\npaste -d '+' file1 file2                    合并两个文件或两栏的内容，中间用\"+\"区分\nsort file1 file2                            排序两个文件的内容\nsort file1 file2 | uniq                     取出两个文件的并集(重复的行只保留一份)\nsort file1 file2 | uniq -u                  删除交集，留下其他的行\nsort file1 file2 | uniq -d                  取出两个文件的交集(只留下同时存在于两个文件中的文件)\ncomm -1 file1 file2                         比较两个文件的内容只删除 'file1' 所包含的内容\ncomm -2 file1 file2                         比较两个文件的内容只删除 'file2' 所包含的内容\ncomm -3 file1 file2                         比较两个文件的内容只删除两个文件共有的部分\n```\n\n#### 2.3.7 字符/文件格式转换\n\n```\ndos2unix filedos.txt fileunix.txt     将一个文本文件的格式从MSDOS转换成UNIX\nunix2dos fileunix.txt filedos.txt     将一个文本文件的格式从UNIX转换成MSDOS\nrecode ..HTML < page.txt > page.html  将一个文本文件转换成html\nrecode -l | more                      显示所有允许的转换格式\n```\n\n#### 2.3.8 文件系统操作\n\n```\nbadblocks -v /dev/hda1    检查磁盘hda1上的坏磁块\nfsck /dev/hda1            修复/检查hda1磁盘上linux文件系统的完整性\nfsck.ext2 /dev/hda1       修复/检查hda1磁盘上ext2文件系统的完整性\ne2fsck /dev/hda1          修复/检查hda1磁盘上ext2文件系统的完整性\ne2fsck -j /dev/hda1       修复/检查hda1磁盘上ext3文件系统的完整性\nfsck.ext3 /dev/hda1       修复/检查hda1磁盘上ext3文件系统的完整性\nfsck.vfat /dev/hda1       修复/检查hda1磁盘上fat文件系统的完整性\nfsck.msdos /dev/hda1      修复/检查hda1磁盘上dos文件系统的完整性\ndosfsck /dev/hda1         修复/检查hda1磁盘上dos文件系统的完整性\n\nmkfs /dev/hda1         在hda1分区创建一个文件系统\nmke2fs /dev/hda1       在hda1分区创建一个linux ext2的文件系统\nmke2fs -j /dev/hda1    在hda1分区创建一个linux ext3(日志型)的文件系统\nmkfs -t vfat 32 -F /dev/hda1  创建一个 FAT32 文件系统\nfdformat -n /dev/fd0          格式化一个软盘\nmkswap /dev/hda3              创建一个swap文件系统\nswapon /dev/hda3              启用一个新的swap文件系统\nswapon /dev/hda2 /dev/hdb3    启用两个swap分区\n```\n\n#### 2.3.9 备份\n\n```\ndump -0aj -f /tmp/home0.bak /home    制作一个 '/home' 目录的完整备份\ndump -1aj -f /tmp/home0.bak /home    制作一个 '/home' 目录的交互式备份\nrestore -if /tmp/home0.bak           还原一个交互式备份\nrsync -rogpav --delete /home /tmp    同步两边的目录\nrsync -rogpav -e ssh --delete /home ip_address:/tmp           通过SSH通道rsync\nrsync -az -e ssh --delete ip_addr:/home/public /home/local    通过ssh和压缩将一个远程目录同步到本地目录\nrsync -az -e ssh --delete /home/local ip_addr:/home/public    通过ssh和压缩将本地目录同步到远程目录\ndd bs=1M if=/dev/hda | gzip | ssh user@ip_addr 'dd of=hda.gz' 通过ssh在远程主机上执行一次备份本地磁盘的操作\ndd if=/dev/sda of=/tmp/file1     备份磁盘内容到一个文件\ntar -Puf backup.tar /home/user   执行一次对 '/home/user' 目录的交互式备份操作\n( cd /tmp/local/ && tar c . ) | ssh -C user@ip_addr 'cd /home/share/ && tar x -p'  通过ssh在远程目录中复制一个目录内容\n( tar c /home ) | ssh -C user@ip_addr 'cd /home/backup-home && tar x -p'           通过ssh在远程目录中复制一个本地目录\ntar cf - . | (cd /tmp/backup ; tar xf - )      本地将一个目录复制到另一个地方，保留原有权限及链接\nfind /home/user1 -name '*.txt' | xargs cp -av --target-directory=/home/backup/ --parents 从一个目录查找并复制所有以 '.txt' 结尾的文件到另一个目录\nfind /var/log -name '*.log' | tar cv --files-from=- | bzip2 > log.tar.bz2          查找所有以 '.log' 结尾的文件并做成一个bzip包\ndd if=/dev/hda of=/dev/fd0 bs=512 count=1      做一个将 MBR (Master Boot Record)内容复制到软盘的动作\ndd if=/dev/fd0 of=/dev/hda bs=512 count=1 从已经保存到软盘的备份中恢复MBR内容\n```\n\n#### 2.3.10 光盘\n\n```\ncdrecord -v gracetime=2 dev=/dev/cdrom -eject blank=fast -force 清空一个可复写的光盘内容\nmkisofs /dev/cdrom > cd.iso            在磁盘上创建一个光盘的iso镜像文件\nmkisofs /dev/cdrom | gzip > cd_iso.gz  在磁盘上创建一个压缩了的光盘iso镜像文件\nmkisofs -J -allow-leading-dots -R -V \"Label CD\" -iso-level 4 -o ./cd.iso data_cd 创建一个目录的iso镜像文件\ncdrecord -v dev=/dev/cdrom cd.iso  刻录一个ISO镜像文件\ngzip -dc cd_iso.gz | cdrecord dev=/dev/cdrom - 刻录一个压缩了的ISO镜像文件\nmount -o loop cd.iso /mnt/iso      挂载一个ISO镜像文件\ncd-paranoia -B           从一个CD光盘转录音轨到 wav 文件中\ncd-paranoia -- \"-3\"      从一个CD光盘转录音轨到 wav 文件中（参数-3）\ncdrecord --scanbus       扫描总线以识别scsi通道\ndd if=/dev/hdc | md5sum  校验一个设备的md5sum编码，例如一张 CD\n```\n\n#### 2.3.11 网络\n\n```\nifconfig eth0：显示网络接口“eth0”的配置详细信息，例如IP地址、子网掩码和其他网络设置\n\nifup eth0：    启动网络接口“eth0”，使其能够发送和接收网络流量\n\nifdown eth0：  关闭网络接口“eth0”，禁止其发送或接收网络流量\n\nifconfig eth0 192.168.1.1 netmask 255.255.255.0：将网络接口“eth0”的IP地址和子网掩码配置为分别为“192.168.1.1”和“255.255.255.0”\n\nifconfig eth0 promisc：      将网络接口“eth0”设置为混杂模式，允许其捕获所有网络流量，包括不是发送到其MAC地址的数据包。\n\ndhclient eth0：              请求网络接口“eth0”从DHCP服务器获取IP地址租约。\n\nroute -n show routing table：显示当前系统的路由表，显示当前的路由配置。\n\nroute add -net 0/0 gw IP_Gateway：  为系统添加默认网关，其中网关IP地址设置为“IP_Gateway”。\n\nroute add -net 192.168.0.0 netmask 255.255.0.0 gw 192.168.1.1：通过网关“192.168.1.1”添加静态路由，以便通过该网关访问网络“192.168.0.0/16”。\n\nroute del 0/0 gw IP_gateway：删除之前添加的默认网关。\n\necho \"1\" > /proc/sys/net/ipv4/ip_forward：激活IP转发，允许系统在不同的网络接口之间进行IP数据包路由。\n\nhostname：显示系统的主机名，即在网络上标识系统的名称。\n\nhost www.example.com：    执行DNS查找，将主机名“www.example.com”解析为IP地址，反之亦然。\n\nnslookup www.example.com：同样执行DNS查找，将主机名“www.example.com”解析为IP地址，反之亦然。\n\nip link show： 显示所有网络接口的状态，包括其链路状态（已启用或已禁用）和其他信息。\n\nmii-tool eth0：使用Media Independent Interface（MII）工具显示网络接口“eth0”的链路状态。\n\nethtool eth0： 显示网络卡“eth0”的统计信息和详细信息，例如速度、双工模式和错误计数器。\n\nnetstat -tup： 显示使用TCP和UDP协议的所有活动网络连接及其关联的进程（通过PID标识）。\n\nnetstat -tupl：显示系统上所有监听的网络服务及其关联的进程（通过PID标识）使用TCP和UDP协议。\n\n`tcpdump tcp port 80`：显示所有在端口80上使用TCP协议的网络流量，通常用于监控HTTP（超文本传输协议）流量。\n\niwlist scan：  显示无线网络接口的扫描结果，列出可用的无线网络。\n\niwconfig eth1：显示无线网络接口“eth1”的配置信息，包括SSID、信号强度和加密设置等。\n\nhostname：     显示系统的主机名，即在网络上标识系统的名称。\n\nhost www.example.com：    执行DNS查找，将主机名“www.example.com”解析为IP地址，反之亦然。\n\nnslookup www.example.com：同样执行DNS查找，将主机名“www.example.com”解析为IP地址，反之亦然。\n\nwhois www.example.com：   在Whois数据库中查找主机名“www.example.com”的注册信息，包括域名所有者、注册商、联系信息等。\n```\n\n#### 2.3.12 其它命令\n\n**bc**  用于编写脚本进行高精度数学运算\n\n编写如下sqrt脚本，可使用`./sqrt 数字` 进行平方根运算\n\n```\n#!/bin/bash\nif [ $# -ne 1 ]\nthen\n    echo 'Usage: sqrt number'\n    exit 1else\n    echo -e \"sqrt($1)\\nquit\\n\" | bc -q -i\nfi\n```\n\n**split** 用于分割大型文件\n\n用法：split [选项] [输入文件] [输出文件前缀]\n\n```\n-b：指定每个输出文件的大小，后面跟着的参数可以是以字节（B）、千字节（K）、兆字节（M）等为单位的数值。例如 \n\n-b 1M 表示每个输出文件的大小为1兆字节\n\n-l：指定每个输出文件的行数，后面跟着的参数为整数。例如 -l 1000 表示每个输出文件包含1000行\n\n-d：设置输出文件的后缀数字的长度，默认为2\n\n-a：设置输出文件的后缀字符，默认为字母 \"a\"\n```\n\n```\n# ls -l largefile.tar.gz\n输出-rw-r--r-- 1 aa aa 436774774 04-17 02:00 largefile.tar.gz\n# split -b 50m largefile.tar.gz LF_\n# ls -l LF_*-rw-r--r-- 1 aa aa 52428800 05-10 18:34 LF_aa\n输出-rw-r--r-- 1 aa aa 52428800 05-10 18:34 LF_ab\n   -rw-r--r-- 1 aa aa 52428800 05-10 18:34 LF_ac\n   -rw-r--r-- 1 aa aa 52428800 05-10 18:34 LF_ad\n   -rw-r--r-- 1 aa aa 52428800 05-10 18:34 LF_ae\n   -rw-r--r-- 1 aa aa 52428800 05-10 18:35 LF_af\n   -rw-r--r-- 1 aa aa 52428800 05-10 18:35 LF_ag\n   -rw-r--r-- 1 aa aa 52428800 05-10 18:35 LF_ah\n   -rw-r--r-- 1 aa aa 17344374 05-10 18:35 LF_ai\n```\n\n拆分后合并\n\n```\ncat LF_* >largefile.tar.gz\n```\n\n**nl** nl命令其它和cat命令很像，只不过它会打上行号\n\n**ldd** 查看一个可执行文件所使用的动态链接库 ldd+文件目录/文件名\n\n**col** 把man文件转成纯文本文件\n\n```\n# PAGER=cat# man less | col -b > less.txt\n```\n\n**xmlwf** 检查一个XML文档是否是所有的tag都是正常的\n\n```\n# curl 'https://coolshell.cn/?feed=rss2' > cocre.xml\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 64882    0 64882    0     0  86455      0 --:--:-- --:--:-- --:--:-- 2073k\n# xmlwf cocre.xml\n# perl -i -pe 's@<link>@<br>@g' cocre.xml\n# xmlwf cocre.xmlcocre.xml:13:23: mismatched tag\n```\n\n**lsof** 可以列出打开了的文件\n\n```\n# lsof | grep TCPhttpd       548    apache    4u     IPv6   14300967    TCP *:http (LISTEN)\nhttpd       548    apache    6u     IPv6   14300972    TCP *:https (LISTEN)\nhttpd       561    apache    4u     IPv6   14300967    TCP *:http (LISTEN)\nhttpd       561    apache    6u     IPv6   14300972    TCP *:https (LISTEN)\nsshd       1764      root    3u     IPv6       4993    TCP *:ssh (LISTEN)\ntcpserver  8965      root    3u     IPv4  153795500    TCP *:pop3 (LISTEN)\nmysqld    10202     mysql   10u     IPv4   73819697    TCP *:mysql (LISTEN)\nsshd      10735      root    3u     IPv6  160731956    TCP 210.51.0.232:ssh->123.117.239.68:31810 (ESTABLISHED)\nsshd      10767     hchen    3u     IPv6  160731956    TCP 210.51.0.232:ssh->123.117.239.68:31810 (ESTABLISHED)\nvsftpd    11095      root    3u     IPv4  152157957    TCP *:ftp (LISTEN)\n```\n\n\n\n### 2.4 vim的使用\n\nvim有三种模式\n\n![linux_vim3.png](https://s2.loli.net/2024/03/15/OGYkAc25yVW4brl.png)\n\n**<u>使用技巧</u>**帮助系统（内容收集于vimtutor）\n\n```\n- 按下 <HELP> 键 (如果键盘上有的话)\n- 按下 <F1> 键 (如果键盘上有的话)\n- 输入 :help <回车>\n输入 CTRL-W CTRL-W   可以在窗口之间跳转。\n输入 :q <回车> 可以关闭帮助窗口\n\nVim 的功能特性要比 Vi 多得多，但其中大部分都没有缺省启用，创建一个vimrc文件以启用更多特性\n1. 开始编辑 vimrc 文件\n :edit ~/.vimrc\t\t这是 Unix 系统所使用的命令\n :edit $VIM/_vimrc\t这是 MS-Windows 系统所使用的命令\n2. 接着读取 vimrc 示例文件的内容：\n :r $VIMRUNTIME/vimrc_example.vim\n\n3. 保存文件，命令为：\n :write\n  下次您启动 Vim 时，编辑器就会有了语法高亮的功能，要了解更多信息，添加设置请输入 :help vimrc-intro\n```\n\n#### 2.4.1基本插入删除，保存退出\n\nh、j、k、l 键分别对应光标键的左、下、上、右\n\n按<ESC>键。然后输入`:q!` <回车>   表示不保存退出，使用 `:wq` 可以保存文件并退出\n\n命令模式下按`x`即可删除字符\n\n命令模式下按`i`即可进入插入模式，按`a`键可在光标之后插入文本\n\n命令模式输入 `o` 将在光标的**下方**打开新的一行并进入插入模式\n\n命令模式输入 `O` 将在光标的**上方**打开新的一行并进入插入模式\n\n#### 2.4.2删除与撤销\n\n输入 `dw` 可以从光标处删除至一个单词的末尾\n\n输入 `d$` 从当前光标删除到行末\n\n输入 `dd` 可以删除整一个当前行\n\n```\n    d      - 删除操作符。\n    motion - 操作符的操作对象。\n\n    w - 从当前光标当前位置直到下一个单词起始处，不包括它的第一个字符。\n    e - 从当前光标当前位置直到单词末尾，包括最后一个字符。\n    $ - 从当前光标当前位置直到当前行末。\n    \n    在动作前输入数字会使它重复那么多次，如输入 2w 使光标向前移动两个单词，输入 3e 使光标向前移动到第三个单词的末尾，因此输入 d2w 可以删除两个大写字母单词，输入 2dd 可以删除两行\n```\n\n```\n输入 u 来撤消最后执行的命令，输入 U 来撤消对整行的修改，输入 CTRL+R 可以重做被撤消的命令\n```\n\n#### 2.4.3更改与替换\n\n输入 `p` 可以将最后一次删除的内容置入光标之后\n\n```\n输入 dd 删除整行，这样会将该行保存到 Vim 的一个寄存器中\n接着将光标移动到 准备置入的位置的上方，然后在命令模式下输入 p 将该行粘贴置入\n```\n\n输入 `r` 和**一个字符**替换光标所在位置的字符\n\n输入 `R` 可连续替换多个字符\n\n输入  `ce` 可以改变文本直到一个单词的末尾\n\n改类操作符的工作方式跟删除类是一致的，动作参数（motion）也是相同的。\n\n#### 2.4.4查找与定位\n\n1.输入 `CTRL-G` 显示当前编辑文件中当前**光标所在行**位置以及文件状态信息\n\n输入 `CTRL-O` 可以回到之前的位置\n\n`CTRL-I` 会跳转到较新的位置\n\n```\n输入大写 G 可以使得当前光标直接跳转到文件最后一行，行号+G跳转到指定行\n输入 gg 可以使得当前光标直接跳转到文件第一行\n```\n\n2.在命令模式下输入`/ 想查找的字符` 可以实现查找操作，按n键可以查找同上一次的字符串，N向相反方向查找同上一次的字符串`？ 想查找的字符` 可以逆向查找字符串\n\n3.输入 `%` 可以查找配对的括号 )、]、}，当光标在括号上时按`%` 即可跳转到与之匹配的括号处，再按则返回原来位置，可用于程序调试\n\n4.输入 :s/old/new 可以替换第一个匹配到的字符串 old 为 new\n\n```\n     输入   :s/old/new/g      可以替换整行 old 为 new\n     输入   :#,#s/old/new/g   其中 #,# 代表的是替换操作的若干行中首尾两行的行号。\n     输入   :%s/old/new/g     则是替换整个文件中的每个匹配串。\n     输入   :%s/old/new/gc    会找到整个文件中的每个匹配串，并且对每个匹配串提示是否进行替换。\n```\n\n#### 2.4.5移动与批量操作\n\n输入 `:!` 然后紧接着输入一个外部命令+<回车>即可执行该外部命令\n\n输入 `:w FILENAME`可以把对当前文件的改动保存到FILENAME文件中\n\n```\n部分保存：\n按 v 键，将光标从第一个想保存的字符移动至最后一个，这之间的文本被高亮了，按 : 字符。屏幕底部会出现 :'<,'> \n输入 w TEST， TEST 应是一个未被使用的文件名。在出现:'<,'>w TEST 之后按 <回车> 键\n```\n\n插入\n\n```\n输入 :r FILENAME向当前文件中插入另外的文件的内容，提取进来的文件将从光标所在位置处开始置入\n```\n\n复制\n\n```\n按 v 键，将光标从第一个想保存的字符移动至最后一个，这之间的文本被高亮了，输入y复制，接着输入 p 粘贴。\ny 可以当作操作符来使用，如yw复制一个单词\n```\n\n```\n输入 :set xxx 可以设置 xxx 选项。一些有用的选项如下：\n    'ic' 'ignorecase'   查找时忽略字母大小写\n    'is' 'incsearch'    查找短语时显示部分匹配\n    'hls' 'hlsearch'    高亮显示所有的匹配短语\n    :set nu             显示行号\n    :set nonu           不显示行号\n     选项名可以用完整版本，也可以用缩略版本，在选项前加上 no 可以关闭选项：  :set noic\n```\n\n#### 2.4.6补全功能\n\n使用 CTRL+D 和 <TAB> 可以进行命令行补全\n\n```\n  1. 确保 Vim 不是在以兼容模式运行： :set nocp\n  2. 查看一下当前目录下已经存在哪些文件，输入： :!ls   或者  :!dir\n  3. 现在输入一个目录的起始部分，例如输入： :e\n  4. 接着按 CTRL+D 键，Vim 会显示以 e 开始的命令的列表。\n  5. 然后按 <TAB> 键，Vim 会补全命令为 :edit 。\n  6. 现在添加一个空格，以及一个已有文件的文件名的起始部分，例如： :edit FIL\n  7. 接着按 <TAB> 键，Vim 会补全文件名(如果它是唯一匹配的)。\n```","tags":["vim","shell","linux"],"categories":["大数据"]},{"title":"大数据套件安装","url":"/post/datainstall.html","content":"\n# 大数据套件安装\n\n本文记录了jdk，FineBI，kettle的安装过程。\n\n## jdk安装\n\n把jdk1.8.0_301.zip文件解压缩，放在某个目录中，本教程中是D:\\program files\\\n\n![jdk01.png](https://s2.loli.net/2024/03/15/T638VMZOIGXkPDH.png)\n\n![jdk02.png](https://s2.loli.net/2024/03/15/D9BxGebIt54kmWj.png)\n\n![jdk03.png](https://s2.loli.net/2024/03/15/Vo5H4jxE8TLYNeg.png)\n\n确认jdk安装成功，在cmd中输入 java -version\n\n![jdk04.png](https://s2.loli.net/2024/03/15/5EXqCWRSnt6wVl4.png)\n\n## FineBI安装使用\n\nBI：business intelligence\n\n### FineBI介绍\n\n1：数据可以帮助我们做什么 ？\n\n​\t1-1  历史数据分析：分析已有的数据，对之前发生的事情做分析，找到原因\n\n​\t1-2  实时数据分析：对当下发生的数据进行处理，及时展示数据信息。让企业关注实时发展动态\n\n​\t1-3  未来数据：对未来即将发生的事情进行预测，帮助企业调整方向  \n\n2：FineBI有哪些优势\n\n​\t1：个人用户完全免费，企业用户收费较低\n\n​\t2：自动式BI工具，企业或者个人自己搭建服务器，就可以访问BI版块\n\n​\t3：兼容多种数据源\n\n​\t4：零编码设计，让数据可视化工具通过拖拉拽就可以完成日常的需求\n\n​\t5：有超强的数据录入能力，在数据源加载以后依然可以修改、删除补录数据\n\n\n\n3：FineBI的使用场景\n\n​\tFineBI在大数据的场景中，使用一般是将我们抽取的数据源加载完毕后，满足数据分析要求的数据或者指标的数据在进行BI开发。\n\n### FineBI的安装\n\n第一步：找到软件，右键安装\n\n第二步：配置安装路径\n\n第三步：修改jvm内存（默认-本机内存的二分之一）\n\n第四步：安装后运行之激活码的获取\n\n第五步：启动界面分析\n\n![finebi1.png](https://s2.loli.net/2024/03/15/5NYWSD6VXmJjOTq.png)\n\n第六步：密码设置\n\n第七步：数据库的选择\n\n第八步：页面介绍\n\n![finebi2.png](https://s2.loli.net/2024/03/15/XBFx7AvksMcOlDQ.png)\n\n#### 网页开发优点\n\n如果企业中，我们将FineBI部署在一个服务器中，所有人都可以访问浏览器访问这个服务器进行BI开发\n\n1、此时所有的人的使用开发环境是相同\n\n2、方便数据源的使用，绑定或者提取一次数据源所有的开发者都可以使用\n\n3、开发结果所有的人都可以通过浏览器的方式查看\n\n4、可以快速分析数据报表（表格和图形）给非专业人事看\n\n#### 开发前的数据准备\n\n1、大数据开发，既不产生数据，也不消费数据\n\n​     业务部门各个数据源提供生产数据（抽）\n\n​    BI开发、数据分析师、运营部门、产品经理\n\n因为BI开发都是大数据的下游部门，所以开发之前必须有数据！！！\n\n\n\n操作：把我们提供给大家的sql脚本，导入到数据库中\n\n##### 1：启动datagrip ，选择一个数据库连接，找到结构，右键 run sql Script\n\n![finebi3.png](https://s2.loli.net/2024/03/15/yEZUi6v3RTPfK2r.png)\n\n##### 2：找到要执行sql脚本文件\n\n![finebi4.png](https://s2.loli.net/2024/03/15/uAJKLMZQON2tYzG.png)\n\n##### 3：导入数据结果\n\n![finebi5.png](https://s2.loli.net/2024/03/15/4Dexl6sOC7PQJcZ.png)\n\n### 数据准备\n\n##### 1：创建数据库连接\n\n![finebi6.png](https://s2.loli.net/2024/03/15/HumxMIjN5GUTZQt.png)\n\n##### 2：创建分组&业务包\n\n![finebi7.png](https://s2.loli.net/2024/03/15/vGkxCuwKsF2D6dE.png)\n\n##### 3：给业务包添加数据\n\n![finebi8.png](https://s2.loli.net/2024/03/15/Fb2aWqe5LynPsAR.png)\n\n##### 4：最重要的一步\n\n![finebi9.png](https://s2.loli.net/2024/03/15/BmitKnvarHYSF97.png)\n\n\n\n##### 仪表版内容\n\n![finebi10.png](https://s2.loli.net/2024/03/15/fy2QtpqY9hgzIUA.png)\n\n1：新建仪表板\n\n![finebi11.png](https://s2.loli.net/2024/03/15/BZYusIOzKh8XlGv.png)\n\n2：选择仪表板样式\n\n![finebi12.png](https://s2.loli.net/2024/03/15/HzA7tkjagdZi38q.png)\n\n3：选择数据源\n\n![finebi13.png](https://s2.loli.net/2024/03/15/bgdrt4OKjmFTD2Y.png)\n\n4：页面编辑界面介绍\n\n![finebi14.png](https://s2.loli.net/2024/03/15/bXSQHAf3mag7uPM.png)\n\n5：点击分区柱形图\n\n6：拖拽字段\n\n![finebi15.png](https://s2.loli.net/2024/03/15/2eyawqHhcn9OpoY.png)\n\n7：通过自定义图标将下面的展示改为线\n\n\n\n8：修改图表颜色\n\n\n\n第九步：取消图例\n\n![finebi16.png](https://s2.loli.net/2024/03/15/3MQ25cjH1DvnuKe.png)\n\n### 不同地区访问人数表\n\n1：加载数据源\n\n![finebi17.png](https://s2.loli.net/2024/03/15/5SbzNi9AOwWEkDu.png)\n\n第二步：选择分析数据表\n\n![finebi18.png](https://s2.loli.net/2024/03/15/RAQjfEiC13ozIeJ.png)\n\n第三步：更新业务数据包\n\n![finebi19.png](https://s2.loli.net/2024/03/15/uJk7BQjcLAlDtW5.png)\n\n\n\n第四步：进入仪表盘\n\n![finebi20.png](https://s2.loli.net/2024/03/15/I9sJSgUZujEMPRA.png)\n\n第五步：选择要分析的数据表\n\n![finebi21.png](https://s2.loli.net/2024/03/15/M3JQYAT7RNa4PUv.png)\n\n第六步：选择 地图\n\n![finebi22.png](https://s2.loli.net/2024/03/15/fbgNq872OHaBJGD.png)\n\n\n\n第七步：构建地图（添加横轴、纵轴）\n\n![finebi23.png](https://s2.loli.net/2024/03/15/vHlKe62Y7XQ3Udm.png)\n\n\n\n总结：大屏展示的步骤\n\n1：连接内部（外部的数据库）-找到要展示bi库  \n\n2：数据准备、 创建分组，根据数据连接创建业务包【注意！！一定要记得点更新】\n\n3：进入仪表板\n\n​\t3-1：创建组件 \n\n​\t3-2：加载数据源\n\n​\t3-3：配置\n\n拓展：\n\n​\t遇到问题！！！记载页面数据发现有点卡\n\n1：进入安装目录下的bin文件夹， 找到 finebi.vmoptions\n\n### 集团数据分析_数据准备\n\n1：找到数据需要数据\n\n![finebi24.png](https://s2.loli.net/2024/03/15/SGmNX8D5ePoCJqL.png)\n\n2：分析数据之前的关系\n\n![finebi25.png](https://s2.loli.net/2024/03/15/FawKpMVYmHD8tXC.png)\n\n3：自主选取数据，选择字段\n\n![finebi26.png](https://s2.loli.net/2024/03/15/83eytUAWIEwNXnm.png)\n\n\n\n4：数据自助选取结果\n\n![finebi27.png](https://s2.loli.net/2024/03/15/NZ3nG7UYdLz5Tgs.png)\n\n5：添加新增了-毛利额\n\n![finebi28.png](https://s2.loli.net/2024/03/15/mM9sFB2UpQLH8z3.png)\n\n6：创建集团分析源表\n\n![finebi29.png](https://s2.loli.net/2024/03/15/yivjopRnPrBA6HM.png)\n\n7：查看源数据集是否创建成功\n\n![finebi30.png](https://s2.loli.net/2024/03/15/r4G3awAdoxM5iec.png)\n\n8：创建仪表盘\n\n![finebi31.png](https://s2.loli.net/2024/03/15/iuyJzIrtqK8YACe.png)\n\n### 集团数据分析_月销售额\n\n1：使用sql分析\n\n![finebi32.png](https://s2.loli.net/2024/03/15/2p4x1XjKPwuagSd.png)\n\n\n\n2：创建图表\n\n![finebi33.png](https://s2.loli.net/2024/03/15/y7LowKvkPcQhq9l.png)\n\n3：解决时间的问题&毛利额问题\n\n![finebi34.png](https://s2.loli.net/2024/03/15/b4S2xtfszGPpvRT.png)\n\n**同比&环比**【拓展】\n\n1：同比是本期与同期做对比   eg： 2020-1    2019-1\n\n​\t\t–本期指一定时期如**月**、季度、年\n\n​\t\t同期\n\n2：环比：表示连续2个统计周期内的量的变化比  eg：2020-1   2020-2\n\n\n\n![finebi35.png](https://s2.loli.net/2024/03/15/eS7wdsZIqhfoM9r.png)\n\n\n\n![finebi36.png](https://s2.loli.net/2024/03/15/s1w7S4qcgIENokt.png)\n\n4：修改组件颜色\n\n![finebi37.png](https://s2.loli.net/2024/03/15/WUsOdD2r4JqB7fl.png)\n\n## Kettle安装使用\n\nkettle是一个etl工具，etl是进行数据抽取 转换 加载\n\nkettle用java开发的，所以要安装jdk（java development kit），\n\n\n\n> windows下使用 kettle打开Spoon.bat\n\n> mac 下打开 kettle 使用终端 cd  切换到 你解压的kettle的目录下，  ==sh ./spoon.sh== \n\n##### txt数据转换Excel数据\n\n1. 新建转换\n\n![kettle1.png](https://s2.loli.net/2024/03/15/vC1LaWb8XEUTApq.png)\n\n2. 创建文本输入组件\n\n![kettle2.png](https://s2.loli.net/2024/03/15/BylHVEw3fLGm4nh.png)\n\n   \n\n3. ![kettle3.png](https://s2.loli.net/2024/03/15/2cnfBZ9wq71L6Hg.png)\n\n4. ![kettle4.png](https://s2.loli.net/2024/03/15/7LaKBvZJmgQwG3x.png)\n\n5. ![kettle5.png](https://s2.loli.net/2024/03/15/9lOnRoQNuVCBMe7.png)\n\n6. ![kettle6.png](https://s2.loli.net/2024/03/15/elq3fVckPT6GZ4y.png)\n\n7. ![kettle7.png](https://s2.loli.net/2024/03/15/6VrijyLchdlQTOX.png)\n\n8. 获取好字段之后，点击确定保存即可。\n\n9. ![kettle8.png](https://s2.loli.net/2024/03/15/vogj6dZIAsaLNmu.png)\n\n10. ![kettle9.png](https://s2.loli.net/2024/03/15/SqyVTG3uAo1kbnM.png)\n\n11. ![kettle10.png](https://s2.loli.net/2024/03/15/NKrUtLYDlWBXveC.png)\n\n    \n\n12. ![kettle11.png](https://s2.loli.net/2024/03/15/AHqoJynOWVdj6Dz.png)\n\n13. 当看到流程上面有绿色的对勾 表示转换成功了\n\n## Excel数据转换Mysql数据\n\n1. 找到要转换为excel文件\n\n2. 打开DG或者是使用命令行进入到mysql数据库，创建一个数据库\n\n   ```sql\n   CREATE DATABASE kettle_db CHARSET =utf8;\n   ```\n\n3. 配置kettle和mysql连接，\n\n   ![kettle12.png](https://s2.loli.net/2024/03/15/UlGgcFup39tNA1Z.png)\n\n   ![kettle13.png](https://s2.loli.net/2024/03/15/tq34LjXBzO68fDK.png)\n\n   ![kettle14.png](https://s2.loli.net/2024/03/15/WIowGyBzk4ENRgM.png)\n\n   ![kettle15.png](https://s2.loli.net/2024/03/15/csDNY62uaoyFmOP.png)\n\n   ```mysql\n   kettle_demo/type=javax.sql.DataSource  \n   kettle_demo/driver=com.mysql.cj.jdbc.Driver\n   kettle_demo/url=jdbc:mysql://192.168.88.100:3306/kettle_demo?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=GMT\n   kettle_demo/user=root\n   kettle_demo/password=123456\n   ```\n\n   \n\n4. 先去新建输入和输出组件\n\n![kettle16.png](https://s2.loli.net/2024/03/15/iy26VlrcBtWH8PG.png)\n\n![image-20211202104034187.png](https://s2.loli.net/2024/03/15/UHLs2tqEeGXY567.png)\n\n5. ![kettle17.png](https://s2.loli.net/2024/03/15/2HmDj45c3WduvYX.png)\n\n6. ![kettle18.png](https://s2.loli.net/2024/03/15/bGWBT1UPFlMfE2D.png)\n\n7. ![kettle19.png](https://s2.loli.net/2024/03/15/1FUY4JmkjAgxNhw.png)\n\n8. ![kettle20.png](https://s2.loli.net/2024/03/15/bl5qvSARpD8taBQ.png)\n\n9. ![kettle21.png](https://s2.loli.net/2024/03/15/YcMJhNZTutsnajH.png)\n\n10. ![kettle22.png](https://s2.loli.net/2024/03/15/f41nWPrqpaEUoXl.png)\n\n11. ![kettle23.png](https://s2.loli.net/2024/03/15/eqMjbadQyvcpSgR.png)\n\n12. ![kettle24.png](https://s2.loli.net/2024/03/15/hjLyXT9Pxc152qU.png)\n\n13. ctrl+s 将流程进行保存，保存之后，点击执行即可。\n\n错误问题\n\n![kettle25.png](https://s2.loli.net/2024/03/15/eiQCgBShnbJEjwm.png)\n\n1. 找到自己的mysql的配置文件 my.ini\n\ndefault_authentication_plugin 这个选项后面的值 改为 \n\n```sql\ndefault_authentication_plugin=mysql_native_password\n```\n\n保存这个文件， 打开 win+R， 输入services.msc，重启此服务\n\n\n\n## Mysql表间转换\n\n设置数据库连接的共享\n\n![kettle26.png](https://s2.loli.net/2024/03/15/cpXqEG8xovrV6P7.png)\n\n1. ![kettle27.png](https://s2.loli.net/2024/03/15/gltfuIj1iwBEnMC.png)\n2. ![kettle28.png](https://s2.loli.net/2024/03/15/1MUFNLkxXnViSrQ.png)\n3. ![kettle29.png](https://s2.loli.net/2024/03/15/rROkWXlBwHfdxPt.png)\n4. ![kettle30.png](https://s2.loli.net/2024/03/15/ugACReU6pbjtG1k.png)\n5. 保存并执行即可\n\n## 插入-更新组件\n\n1. 清空 new_user 表中的数据（右键Database Tools Truncate）\n2. 先将 t_user 表中的张三 改为 20岁，重新的去执行 刚才的 table_to_table 这个脚本，将t_user表中的数据 ，添加到 new_user 表。\n3. ![kettle31.png](https://s2.loli.net/2024/03/15/ju1K3qFZDC6s8UA.png)\n4. ![kettle32.png](https://s2.loli.net/2024/03/15/vf5Ny9cDMSiHnds.png)\n5. ![kettle33.png](https://s2.loli.net/2024/03/15/pFOXJRcv6TrEn2d.png)\n6. ![kettle34.png](https://s2.loli.net/2024/03/15/XtzJcqeM6DoFZAE.png)\n7. 保存并执行\n\n## switch-case组件\n\n1， ![kettle35.png](https://s2.loli.net/2024/03/15/uovrAZagDOEJbHN.png)\n\n2. ![kettle36.png](https://s2.loli.net/2024/03/15/CcIw6DNajsrQPqt.png)\n3. ![kettle37.png](https://s2.loli.net/2024/03/15/ECmuKAtxgLYa9FV.png)\n4. ![kettle38.png](https://s2.loli.net/2024/03/15/uOrWP6z2SdZhcYH.png)\n5. excel输出男和女的时候，配置基本一样，女的配置参照男的截图（3-4）\n6. 保存这个流程 并执行。\n\n## SQL脚本组件\n\n![kettle39.png](https://s2.loli.net/2024/03/15/yg2QmV9uTDvOZ7F.png)\n\n\n\n## 设置转换参数\n\n![kettle40.png](https://s2.loli.net/2024/03/15/mQy8Lg3v1KtVNHz.png)\n\n![kettle41.png](https://s2.loli.net/2024/03/15/WSaAPo4T1mHtVqE.png)\n\n![kettle42.png](https://s2.loli.net/2024/03/15/acTtHq9xWKLd7bF.png)\n\n![kettle43.png](https://s2.loli.net/2024/03/15/jJf9CyDbpKsqW58.png)\n\n接下来就可以保存去执行了\n\n\n\n## job开发\n\n1. 新建job![kettle44.png](https://s2.loli.net/2024/03/15/fQ3j1Ds86ySO5KF.png)\n2. 先将job保存完毕之后，再去设置转换![kettle45.png](https://s2.loli.net/2024/03/15/5RfM8pOhq3YQvtx.png)\n3. ![kettle46.png](https://s2.loli.net/2024/03/15/eyGjtOIHQ2cBvZ7.png)\n\n\n\n==[Kettle中文网 – Kettle安装、Kettle使用、Kettle中文](https://www.kettle.net.cn/)==\n\n","tags":["大数据"],"categories":["大数据"]},{"title":"SQL基础","url":"/post/SQLba.html","content":"\n\n## 一、数据库概述\n\n### 1、数据库介绍\n\n数据库就是存储数据的仓库，其本质是一个文件系统，按照特定的格式将数据存储起来，用户可以对数据库中的数据进行增加，修改，删除及查询操作。\n\n随着互联网的高速发展，大量的数据在不断的产生，伴随而来的是如何高效安全的存储数据和处理数据，而这一问题成为了信息时代的一个非常大的问题，而使用数据库可以高效的有条理的储存数据。\n\n- 可以结构化存储大量的数据；\n- 可以有效的保持数据的一致性、完整性；\n- 读写效率极高。\n\n### 2、数据库分类\n\n数据库又分为关系型数据库和非关系型数据库\n\n#### 关系型数据库RDBMS\n\n关系型数据库：指采用了关系模型来组织数据的数据库。\n\n关系模型指的就是二维表格模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织。\n\n#### 非关系型数据库NoSQL\n\n非关系型数据库：又被称为NoSQL（Not Only SQL )，意为不仅仅是SQL，对NoSQL 最普遍的定义是“非关联型的”，强调 Key-Value 的方式存储数据。\n\nKey-Value结构存储： Key-value数据库是一种以键值对存储数据的一种数据库，类似Java中的map。可以将整个数据库理解为一个大的map，每个键都会对应一个唯一的值。\n\n![mysql图1.png](https://s2.loli.net/2024/03/15/ASPFqNxer8mgMa9.png)\n\n关系型数据库（RDBMS）和非关系型数据库（NoSQL）是两种不同类型的数据库管理系统，用于存储和管理数据的方式不同，它们之间的一些主要区别如下：\n\n1. 数据结构：关系型数据库使用表格（表）来组织数据，每个表都有固定的列和行。表之间可以建立关系，通过键（键值对）进行连接。而非关系型数据库则没有固定的表结构，数据可以以文档、键值对、列族或者图等形式存储。\n2. 可扩展性：非关系型数据库通常具有更好的可扩展性，可以更容易地处理大规模和高并发的数据。关系型数据库在处理大量数据和高并发请求时可能会面临性能瓶颈。\n3. 数据一致性：关系型数据库通常具有强一致性，即数据在数据库中的状态是一致的。而非关系型数据库则可能具有弱一致性或最终一致性，即在某一时刻数据在不同节点之间可能存在不一致，但最终会达到一致状态。\n4. 灵活性：非关系型数据库通常更加灵活，可以在不需要事先定义数据结构的情况下存储和处理各种不同类型的数据。而关系型数据库需要事先定义表结构，并在存储数据之前进行严格的模式设计。\n5. 查询语言：关系型数据库通常使用结构化查询语言（SQL）来查询和操作数据。而非关系型数据库使用不同的查询语言，例如键值对数据库使用键（key）来查询数据，文档数据库使用类似于JSON的查询语法，列族数据库使用列族和列来查询数据。\n6. 数据库设计：关系型数据库通常适用于复杂的事务性应用，需要保持数据的一致性和完整性，如金融系统、人力资源管理系统等。而非关系型数据库通常适用于需要处理大量半结构化或非结构化数据、需要高度可扩展性和灵活性的应用，如社交媒体、物联网应用、日志数据等。\n\n### 3、常见数据库介绍\n\n####  关系型数据库\n\n| **数据库**    | **介绍**                                                     |\n| ------------- | ------------------------------------------------------------ |\n| **MySQL**     | 开源免费的中型数据库,已经被Oracle收购.MySQL6.x版本也开始收费。 |\n| **Oracle**    | 收费的大型数据库，Oracle公司的产品。Oracle收购SUN公司，收购MYSQL。 |\n| **DB2**       | IBM公司的数据库产品,收费的。常应用在银行系统中.              |\n| **SQLserver** | MicroSoft 公司收费的中型的数据库。C#、.net等语言常使用。     |\n| **SQLite**    | 嵌入式的小型数据库，应用在手机端。                           |\n\n#### 非关系型数据库\n\n| **数据库**  | **介绍**                                                     |\n| ----------- | ------------------------------------------------------------ |\n| **Redis**   | 是一个小而美的数据库，主要用在key-value的内存缓存，读写性能极佳 |\n| **HBase**   | HBase是列式数据库，目标是高效存储大量数据                    |\n| **MongoDB** | MongoDB是文档型数据库，非常接近关系型数据库的。              |\n\n## 二、MySQL数据库\n\n### 1、MySQL介绍\n\nMySQL是一个关系型数据库管理系统，在 WEB 应用方面，MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件，它是由瑞典MySQL AB 公司开发，目前属于 Oracle 旗下产品，MySQL 是最流行的关系型数据库管理系统中的一个。\n\n### 2、MySQL特点\n\n1.MySQL支持大型的数据库。可以处理拥有上千万条记录的大型数据库。\n        2.MySQL使用标准的SQL数据语言形式。\n        3.MySQL可以安装在不同的操作系统，并且提供多种编程语言的操作接口。这些编程语言包括C、C++、Python、Java、Ruby等等。\n\n### 3、MySQL版本\n\nMySQL Community Server：社区版本，开源免费，但不提供官方技术支持。\n\nMySQL Enterprise Edition：企业版本，需付费，可以试用30天。\n\nMySQL Cluster：集群版，开源免费。可将几个MySQL Server封装成一个Server。\n\nMySQL Cluster CGE：高级集群版，需付费。\n\nMySQL Workbench（GUITOOL）：一款专为MySQL设计的ER/数据库建模工具。它是著名的数据库设计工具DBDesigner4的继任者。MySQL Workbench又分为两个版本，分别是社区版（MySQL Workbench OSS）、商用版（MySQL WorkbenchSE）。\n\n## 三、Linux系统MySQL使用\n\n### 1、登陆MySQL数据库\n\nMySQL是一个需要账户名密码登录的数据库，登陆后使用，它提供了一个默认的root账号，使用安装时设置的密码即可登录，目前有两种登录场景：\n\n####  本地登录\n\n```\n# mysql -uroot –p 回车  \npassword：输入密码\n```\n\n-u 后面是登录的用户名\n        -p 后面是登录密码, 如果不填写, 回车之后会提示输入密码\n\n#### 远程登录\n\n```\n# mysql -h 远程服务器IP地址 -P 端口号 -u用户名 -p 回车\npassword：输入密码\n```\n\n#### 退出\n\n```\nmysql> exit\n\nmysql> quit\n\n快捷键Ctrl + d\n```\n\n### 2.DataGrip使用\n\n### 创建工程\n\n点击File->New->Project新建DataGrip工程\n\n输入项目名称，点击确定。\n\n选择新项目打开方式：This Windows（在本窗口中打开），New Windows（在新窗口中打开）， Attach（附加模式）\n\n### 连接数据库\n\n选择Database下的➕，点击DataSource菜单下的MySQL。\n       填写对应的参数，连接数据库：连接名，IP，用户名，密码等，点击OK完成连接。\n       如果是第一次使用，需要下载mysql驱动文件。\n\n\n\n设置数据库时区：\n\n1. 点击Advanced按钮；\n2. 在VM options后面写入`-Duser.timezone=Asia/Shanghai\n\n\n\n设置完成后，单击Apply（应用），单击OK，连接完成\n\n### 选择要使用的数据库\n\n点击连接名称之后的按钮可以选择所要使用的数据库：![mysql图2.png](https://s2.loli.net/2024/03/15/UgTEJmiSWzwtKH6.png)\n\n### DataGrip软件设置\n\n####  设置字体大小\n\n设置文字大小： File--->settings--->Editor---->Font，可以设置文字尺寸Size和行高Line height\n\n#### 设置关键字大写\n\n设置关键字大写： File--->settings--->Editor---->Code Style--->SQL--->MySql(需要设置的数据库)--->Case\n\n![mysql图3.png](https://s2.loli.net/2024/03/15/l85hCm9oiXQzfIN.png)\n\n#### 自动排版\n\n自动排版布局： File--->settings--->Editor---->Code Style--->SQL--->MySql(需要设置的数据库)--->Queries\n自动排版快捷键：Ctrl+ Alt + L![mysql图4.png](https://s2.loli.net/2024/03/15/gecvOzLyQsxPmjR.png)\n\n## 四、SQL语句\n\n### 1、连接数据库\n\n结构化查询语言(Structured Query Language)简称SQL，是关系型数据库管理系统都需要遵循的规范，是数据库认识的语句。不同的数据库生产厂商都支持SQL语句，但都有特有内容。\n\n**举例：**\n\n普通话：各数据库厂商都遵循的ISO标准\n\n方言：数据库特有的关键字\n\n### 2、SQL语句分类\n\n#### DDL\n\nDDL（Data Definition Language）用于定义和管理数据库中的数据结构，包括表、视图、索引、触发器、存储过程、用户等。\n\nDDL通常包括以下几种常见的语句：\n\n1. CREATE：用于创建数据库中的各种对象，如创建表、视图、索引、触发器、存储过程等。例如，CREATE TABLE用于创建表，CREATE VIEW用于创建视图。\n2. ALTER：用于修改数据库中已存在的对象，如修改表结构、修改视图定义等。例如，ALTER TABLE用于修改表结构，ALTER VIEW用于修改视图定义。\n3. DROP：用于删除数据库中的对象，如删除表、删除视图等。例如，DROP TABLE用于删除表，DROP VIEW用于删除视图。\n4. TRUNCATE：用于删除表中的所有数据，并且保留表结构和属性。例如，TRUNCATE TABLE用于删除表中的所有数据。\n5. RENAME：用于修改数据库中对象的名称，如修改表名、修改视图名等。例如，RENAME TABLE用于修改表名，RENAME VIEW用于修改视图名。\n6. GRANT和REVOKE：用于授权和撤销数据库对象的权限，如授权用户对表进行增、删、改、查操作等。例如，GRANT SELECT, INSERT, UPDATE, DELETE ON table_name TO user_name用于授权用户对表进行查询、插入、更新、删除操作。\n\nDDL语句通常由数据库管理员或具有相应权限的用户执行，用于定义数据库的结构和元数据，对数据库的整体架构进行管理和控制。\n\n#### DML\n\nDML（Data Manipulation Language）用于对数据库中的数据进行操作，包括查询、插入、更新、删除等操作。\n\nDML通常包括以下几种常见的语句：\n\n1. SELECT：用于查询数据库中的数据，包括单表查询、多表查询、嵌套查询、聚合查询、排序、分组等操作。例如，SELECT * FROM table_name用于查询表中的所有数据，SELECT column1, column2 FROM table_name用于查询表中指定列的数据。\n2. INSERT：用于向数据库中插入新数据，包括单行插入和多行插入。例如，INSERT INTO table_name (column1, column2) VALUES (value1, value2)用于向表中插入一行数据。\n3. UPDATE：用于更新数据库中的数据，可以更新单表或多表中的数据。例如，UPDATE table_name SET column1 = value1, column2 = value2 WHERE condition用于更新表中符合条件的数据。\n4. DELETE：用于删除数据库中的数据，可以删除单表或多表中的数据。例如，DELETE FROM table_name WHERE condition用于删除表中符合条件的数据。\n\nDML语句用于对数据库中的数据进行增、删、改、查等操作，由应用程序或数据库用户执行，用于操作数据库中的具体数据记录。DML操作可以通过执行DML语句来实现对数据库中数据的增加、删除、修改和查询。\n\n#### DQL\n\nDQL（Data Query Language）用于查询数据库中的数据，即实现从数据库中获取数据的操作。\n\nDQL通常包括以下几种常见的语句：\n\n1. SELECT：用于查询数据库中的数据，包括单表查询、多表查询、嵌套查询、聚合查询、排序、分组等操作。SELECT语句可以通过指定要查询的表、列、条件、排序方式等来获取数据。例如，SELECT * FROM table_name用于查询表中的所有数据，SELECT column1, column2 FROM table_name用于查询表中指定列的数据。\n2. FROM：用于指定要查询的表名，可以查询单个表或多个表的数据。例如，SELECT * FROM table1, table2用于从table1和table2两个表中获取数据。\n3. WHERE：用于指定查询的条件，可以使用逻辑运算符、比较运算符、通配符等来定义查询条件。例如，SELECT * FROM table_name WHERE column1 = 'value'用于查询column1等于特定值的数据。\n4. ORDER BY：用于指定查询结果的排序方式，可以按照一个或多个列进行升序或降序排序。例如，SELECT * FROM table_name ORDER BY column1 ASC用于按照column1列的升序排序。\n5. GROUP BY：用于将查询结果按照一个或多个列进行分组，并对每个分组进行聚合计算。例如，SELECT column1, SUM(column2) FROM table_name GROUP BY column1用于按照column1列的值进行分组，并计算每个分组中column2列的和。\n6. JOIN：用于连接多个表的数据，可以通过不同的连接方式（如内连接、外连接、自连接等）来获取联接后的结果。例如，SELECT * FROM table1 INNER JOIN table2 ON table1.id = table2.id用于执行内连接操作，连接两个表的id列相等的记录。\n\nDQL语句用于查询数据库中的数据，并通过结果集返回查询结果。DQL语句可以通过执行查询操作来实现从数据库中获取数据，并支持丰富的查询功能，用于满足应用程序或用户对数据库中数据的查询需求。\n\n#### DCL\n\nDCL（Data Control Language用于控制数据库中的数据访问和权限管理。\n\nDCL主要包括以下两种常见的语句：\n\n1. GRANT：用于授权用户或角色对数据库对象（如表、视图、存储过程等）进行特定的操作权限。GRANT语句可以授权用户或角色执行SELECT、INSERT、UPDATE、DELETE等数据库操作，也可以授权用户或角色对特定的数据库对象进行操作。例如，GRANT SELECT, INSERT ON table_name TO user_name或GRANT UPDATE ON table_name TO role_name用于授权用户或角色对表进行SELECT、INSERT或UPDATE操作。\n2. REVOKE：用于撤销用户或角色对数据库对象的操作权限。REVOKE语句可以撤销之前通过GRANT语句授权的权限。例如，REVOKE SELECT ON table_name FROM user_name或REVOKE INSERT ON table_name FROM role_name用于撤销用户或角色对表的SELECT或INSERT权限。\n\nDCL语句用于对数据库中的数据访问进行控制，包括授权用户或角色对数据库对象的操作权限，以及撤销之前授权的权限。通过DCL语句，数据库管理员可以灵活地管理用户或角色对数据库的操作权限，确保数据库的安全性和数据的合法性。\n\n#### 要点\n\n① SQL语句可以单行或多行书写，以分号结尾\n\n② 可使用空格和缩进来增强语句的可读性\n\n③ MySQL数据库的SQL语句不区分大小写，关键字建议使用大写\n\n④ 可以使用单行与多行注释（#和/*）\n\n## 五、DDL数据库操作\n\n### 1、MySQL的组成结构\n\n![mysql图5.png](https://s2.loli.net/2024/03/15/6tPWEkzJH4G9Soh.png)\n\n一个MySQL DBMS可以同时存放多个数据库，理论上一个项目就对应一个数据库\n\n一个数据库中还可以同时包含多个数据表，而数据表才是真正用于存放数据的位置。（类似Office软件中的Excel表格），理论上一个功能就对应一个数据表。如博客系统中的用户管理功能，就需要一个user数据表、博客中的文章就需要一个article数据表、博客中的评论就需要一个message数据表\n\n一个数据表又可以拆分为多个字段，每个字段就是一个属性\n\n一个数据表除了字段以外，还有很多行，每一行都是一条完整的数据（记录）\n\n### 2、数据库的基本操作\n\n#### ① 创建数据库\n\ncreate database 数据库名称(字母+数字+下划线组成，以字母开头，不能出现中文以及特殊字符，不能重名)\n\n```powershell\nmysql> create database 数据库名称 [设置编码格式];\ncreate database if not exists db_itheima default character set utf8 指定默认字符集设置编码格式\n```\n\n国内汉字无法通过256个字符进行描述，所以国内开发了自己的编码格式gb2312，升级gbk\n\n中国台湾业开发了一套自己的编码格式big5\n\n很多项目并不仅仅只在本地使用，也可能支持多国语言，标准化组织开发了一套通用编码utf8，后来5.6版本以后又进行了升级utf8mb4\n\n> 编写SQL语句是一个比较细致工作，不建议直接在终端中输入SQL语句，可以先把要写的SQL语句写入一个记事本中，然后拷贝执行。\n\n#### ② 查询数据库\n\n基本语法：显示所有数据库\n\n```powershell\nmysql> show databases;\n```\n\n#### ③ 删除数据库\n\n基本语法：\n\n```powershell\nmysql> drop database 数据库名称;\n```\n\n#### ④ 选择数据库\n\n从数据库列表中查找需要使用的数据库 格式：\n\n```mysql\nmysql> use datab;\n```\n\n查看正在使用的数据库（8.0以后版本需要基于select查询来获取当前数据库）\n\n```powershell\nmysql> select database();\n```\n\n## 六、DDL数据表操作\n\n特别注意：创建数据表必须有一个前提，首先要明确选择某一个数据库。\n\n### 1、数据表的基本操作\n\n####  数据表的创建\n\n基本语法：\n\n```powershell\nmysql> create table 数据表名称(\n\t字段1 字段类型 [字段约束],\n\t字段2 字段类型 [字段约束],\n\t...\n); \n```\n\n> use在MySQL中的含义代表选择，use 数据库名称相当于选择指定的数据库。而且use比较特殊，其选择结束后，其尾部可以不加分号；但是强烈建议所有的SQL语句都要加分号，养成一个好习惯。\n\n```powershell\nmysql> create table aa(\n\tid tinyint,\n    username varchar(20),\n    password char(32)\n) engine=innodb default charset=utf8;\n```\n\n> tinyint ：微整型，范围-128 ~ 127，无符号型，则表示0 ~ 255\n\n> 表示字符串类型可以使用char与varchar，char代表固定长度的字段，varchar代表变化长度的字段。\n\n创建一个article文章表，拥有4个字段（编号、标题、作者、内容）\n\n```powershell\nmysql> use datab;\nmysql> create table article(\n\tid int,\n\ttitle varchar(50),\n\tauthor varchar(20),\n\tcontent text\n) engine=innodb default charset=utf8;\n```\n\n> text ：文本类型，一般情况下，用varchar存储不了的字符串信息，都建议使用text文本进行处理。\n\n> varchar存储的最大长度，理论值65535个字符。但是实际上，有几个字符是用于存放内容的长度的，所以真正可以使用的不足65535个字符，另外varchar类型存储的字符长度还和编码格式有关。1个GBK格式的占用2个字节长度，1个UTF8格式的字符占用3个字节长度。GBK = 65532~65533/2，UTF8 = 65532~65533/3\n\n\n\n####  查询已创建数据表\n\n显示所有数据表（当前数据库）\n\n```powershell\nmysql> use 数据库名称;\nmysql> show tables;\n```\n\n显示数据表的（编码格式、字段等信息）\n\n```powershell\nmysql> desc 数据表名称;\n```\n\n####  修改数据表信息\n\n##### ① 数据表字段添加\n\n```powershell\nmysql> alter table 数据表名称 add 新字段名称 字段类型 first|after 其他字段名称;\n选项说明：\nfirst：把新添加字段放在第一位\nafter 字段名称：把新添加字段放在指定字段的后面\n```\n\n案例：在tb_article文章表中添加一个addtime字段，类型为date(年-月-日)\n\n```powershell\nmysql> alter table tb_article add addtime date after content;\nmysql> desc tb_article;\n```\n\n##### ② 修改字段名称或字段类型\n\n修改字段名称与字段类型（也可以只修改名称）\n\n```powershell\nmysql> alter table tb_admin change username user varchar(40);\nmysql> desc tb_admin;\n```\n\n仅修改字段的类型\n\n```powershell\nmysql> alter table tb_admin modify user varchar(20\nmysql> desc tb_admin;\n```\n\n##### ③ 删除某个字段\n\n```powershell\nmysql> alter table tb_article drop 字段名称;\nmysql> desc tb_article;\n```\n\n##### ④ 修改数据表名称\n\n```powershell\nrename table 旧名称 to 新名称;\n```\n\n####  删除数据表\n\n```powershell\nmysql> drop table IF EXISTS 数据表名称;\n```\n\n### 2、字段类型详解\n\n① 整数类型\n\n| **分类**     | **类型名称**   | **说明**                 |\n| ------------ | -------------- | ------------------------ |\n| tinyint      | 很小的整数     | -128 ~ 127               |\n| smallint     | 小的整数       | -32768 ~ 32767           |\n| mediumint    | 中等大小的整数 | -8388608 ~ 8388607       |\n| int(integer) | 普通大小的整数 | -2147483648 ~ 2147483647 |\n\n② 浮点类型\n\n浮点类型（精度失真情况）和定点类型（推荐使用定点类型）\n\n| 分类         | 类型名称              |\n| ------------ | --------------------- |\n| float        | 单精度浮点数          |\n| double       | 双精度浮点数          |\n| decimal(m,d) | 定点数，decimal(10,2) |\n\n> decimal(10,2) ：代表这个数的总长度为10 = 整数长度 + 小数长度，2代表保留2位小数\n\n③ 日期类型\n\n| 分类      | 类型名称                                                     |\n| --------- | ------------------------------------------------------------ |\n| year      | YYYY 1901~2155                                               |\n| time      | HH:MM:SS -838:59:59~838:59:59                                |\n| date      | YYYY-MM-DD  1000-01-01~9999-12-3                             |\n| datetime  | YYYY-MM-DD  HH:MM:SS 1000-01-01 00:00:00~ 9999-12-31 23:59:59 |\n| timestamp | YYYY-MM-DD  HH:MM:SS 1970~01~01 00:00:01  UTC~2038-01-19 03:14:07UTC |\n\n④ 文本\n\n| **类型名称** | **说明**                             |\n| ------------ | ------------------------------------ |\n| char(m)      | m为0~255之间的整数定长（固定长度）   |\n| varchar(m)   | m为0~65535之间的整数变长（变化长度） |\n| text         | 允许长度0~65535字节                  |\n| mediumtext   | 允许长度0~167772150字节              |\n| longtext     | 允许长度0~4294967295字节             |\n\n## 七、DML数据操作语言\n\n### 1、DML的SQL语句\n\ninsert插入、update更新、delete删除\n\n### 2、数据的增删改\n\n#### 数据的增加操作\n\n```powershell\nmysql> insert into 数据表名称([字段1,字段2,字段3...]) values (字段1的值,字段2的值,字段3的值...);\n```\n\n> 特别注意：在SQL语句中，除了数字，其他类型的值，都需要使用引号引起来，否则插入时会报错。\n\n第一步：准备一个数据表\n\n```powershell\nmysql> use aa;\nmysql> create table tb_user(\n\tid int,\n\tusername varchar(20),\n\tage tinyint unsigned,\n\tgender enum('男','女','保密'),\n\taddress varchar(255)\n) engine=innodb default charset=utf8;\n```\n\n> unsigned代表无符号型，只有0到正数。tinyint unsigned无符号型，范围0 ~ 255\n\n> enum枚举类型，多选一。只能从给定的值中选择一个\n\n第二步：使用insert语句插入数据\n\n```powershell\nmysql> insert into tb_user values (1,'刘备',34,'男','广州市天河区');\nmysql> insert into tb_user(id,username,age) values (2,'关羽',33);\n```\n\n第三步：批量插入多条数据\n\n```powershell\nmysql> insert into tb_user values (3,'大乔',19,'女','上海市浦东新区'),(4,'小乔',18,'女','上海市浦东新区'),(5,'马超',26,'男','北京市昌平区');\n\nINSERT INTO aaa(name)VALUES ('heheh');                               #单独插入一个数据\nINSERT INTO aaa(name,gender,age)VALUES ('hehe','male',18);           #插入多个列出数据\nINSERT INTO aaa VALUES ('hehe1','male',18);                          #插入一条完整数据\nINSERT INTO aaa VALUES ('hehe2','male',18),('hehehe','female',18);   #插入多条完整数据\nINSERT INTO aaa(name,gender)VALUES ('hehe3','male'),('hehe4','male');#插入多条列出数据\n```\n\n#### 数据的修改操作\n\n```powershell\nmysql> update 数据表名称 set 字段1=更新后的值,字段2=更新后的值,... where 更新条件;\n```\n\n> 特别说明：如果在更新数据时，不指定更新条件，则其会把这个数据表的所有记录全部更新一遍。\n\n案例：修改username='马鹏'这条记录，将其性别更新为男，家庭住址更新为广东省深圳市\n\n```powershell\nmysql> update tb_user set gender='男',address='广东省深圳市' where username='马鹏';\n```\n\n案例：今年是2020年，假设到了2021年，现在存储的学生年龄都差1岁，整体进行一次更新\n\n```powershell\nmysql> update tb_user set age=age+1;\n```\n\n#### 数据的删除操作\n\n```powershell\nmysql> delete from 数据表名称 [where 删除条件];\n```\n\n删除tb_user表中，id=1的用户信息\n\n```powershell\nmysql> delete from tb_user where id=1;\n```\n\n\n\ndelete from与truncate清空数据表操作\n\n```powershell\nmysql> delete from 数据表;\n或\nmysql> truncate 数据表;\n```\n\n\n\ndelete from与truncate区别\n\n- delete：删除数据记录\n  - 数据操作语言（DML）\n  - 删除大量记录速度慢，只删除数据，主键自增序列不清零，100 => 新插入 => 101\n  - 可以带条件删除\n- truncate：删除所有数据记录\n  - 数据定义语言（DDL）\n  - 清里大量数据速度快，主键自增序列清零, 100 => 新插入 => 1\n  - 不能带条件删除\n\n## 八、SQL约束\n\n### 1、主键约束\n\n1、PRIMARY KEY 约束唯一标识数据库表中的每条记录。\n        2、主键必须包含唯一的值。\n        3、主键列不能包含 NULL 值。\n        4、每个表都应该有一个主键，并且每个表只能有一个主键。\n\n遵循原则：\n\n1）主键应当是对用户没有意义的\n        2）永远也不要更新主键。\n        3）主键不应包含动态变化的数据，如时间戳、创建时间列、修改时间列等。\n        4） 主键应当由计算机自动生成。\n\n创建主键约束：创建表时，在字段描述处，声明指定字段为主键\n\n![mysql图6.png](https://s2.loli.net/2024/03/15/TiFnpNmeAYq8dPQ.png)\n\n如：创建一个学生信息表tb_students，包含编号id、学生姓名name、年龄age、性别gender以及家庭住址address等字段，然后将id设置为主键。\n\n```sql\ncreate table tb_students(\n\tid int primary key,\n    name varchar(20),\n    age tinyint unsigned,\n    gender enum('男', '女'),\n    address varchar(255)\n) engine=innodb default charset=utf8;\n```\n\n删除主键约束：如需撤销 PRIMARY KEY 约束，请使用下面的 SQL\n\n```powershell\nalter table persons2 drop primary key;\n```\n\n删除tb_students数据表的主键\n\n```sql\nalter table tb_students drop primary key;\n```\n\n\n\n> 自动增长\n\n我们通常希望在每次插入新记录时，数据库自动生成字段的值。\n\n我们可以在表中使用 auto_increment（自动增长列）关键字，自动增长列类型必须是整型，自动增长列必须为键(一般是主键)。\n\n**下列 SQL 语句把 \"Persons\" 表中的 \"Id\" 列定义为** **auto_increment** **主键**\n\n```powershell\ncreate table persons3(\n\tid int primary key auto_increment,\n\tfirst_name varchar(255),\n\tlast_name varchar(255),\n\taddress varchar(255),\n\tcity varchar(255)\n) default charset=utf8;\n```\n\n向persons添加数据时，可以不为Id字段设置值，也可以设置成null，数据库将自动维护主键值：\n\n```powershell\ninsert into persons3(first_name,last_name) values('Bill','Gates');\ninsert into persons3(id,first_name,last_name) values(null,'Bill','Gates');\n```\n\n\n\n如：创建一个学生信息表tb_students，包含编号id、学生姓名name、年龄age、性别gender以及家庭住址address等字段，然后将id设置为主键自动增长列。\n\n```sql\ndrop table tb_students;\n\ncreate table tb_students(\n\tid int auto_increment primary key,\n    name varchar(20),\n    age tinyint unsigned,\n    gender enum('男', '女'),\n    address varchar(255)\n) engine=innodb default charset=utf8;\n或\ncreate table tb_students(\n\tid int auto_increment,\n    name varchar(20),\n    age tinyint unsigned,\n    gender enum('男', '女'),\n    address varchar(255),\n    primary key(id)\n) engine=innodb default charset=utf8;\n\n-- 插入测试数据\ninsert into tb_students values (null, '吕布', 30, '男', '内蒙古包头市');\ninsert into tb_students values (null, '貂蝉', 19, '女', '山西忻州市');\n\n-- 删除auto_increment\nalter table 表名 change 列名 列名 类型; \n\nALTER TABLE 表名 CHANGE 列名 列名 类型;\nALTER TABLE 表名 DROP PRIMARY KEY ;#删除主键自增的值需要先更改主键类型\n```\n\n### 2、非空约束\n\nNOT NULL 约束强制列不接受 NULL 值。\nNOT NULL 约束强制字段始终包含值。这意味着，如果不向字段添加值，就无法插入新记录或者更新记录。\n下面的 SQL 语句强制 \"id\" 列和 \"last_name\" 列不接受 NULL 值：\n\n![mysql图7.png](https://s2.loli.net/2024/03/15/LH4D1AqFgcWaktz.png)\n\n创建一个tb_news新闻表，包含id主键列、title新闻标题、description描述、content新闻内容以及addtime添加时间，要求为title字段添加非空约束。\n\n```sql\ncreate table tb_news(\n\tid int auto_increment,\n    title varchar(80) not null,\n    description varchar(255),\n    content text,\n    addtime datetime,\n    primary key(id)\n) engine=innodb default charset=utf8;\n```\n\n### 3、唯一约束\n\nUNIQUE 约束唯一标识数据库表中的每条记录。\nUNIQUE 和 PRIMARY KEY 约束均为列或列集合提供了唯一性的保证。\nPRIMARY KEY 拥有自动定义的 UNIQUE 约束。\n\n请注意：\n每个表可以有多个 UNIQUE 约束，但是每个表只能有一个 PRIMARY KEY 约束。\n\n![mysql图8.png](https://s2.loli.net/2024/03/15/xoFvkLelYCJquzr.png)\n\n创建一个tb_member会员表 ，包含字段有id主键、username用户名、password密码（密码必须使用密文保存，长度为固定的32位），由于用户名不允许出现重复的情况，所以请为username添加唯一约束。\n\n```sql\ncreate table tb_member(\n\tid int auto_increment,\n    username varchar(20) unique,\n    password char(32),\n    primary key(id)\n) engine=innodb default charset=utf8;\n```\n\n### 4、默认值约束\n\n关键字：default\n\n用来指定某列的默认值。在表中插入一条新记录时，如果没有为这个字段赋值，系统就会自动为这个字段插入默认值。\n\n创建一个tb_department部门表，包含字段id主键、name部门名称以及location部门位置。由于我们的部门位置位于北京的较多，所以部门位置就可以默认为“Beijing”。\n\n```sql\ncreate table tb_department(\n\tid int auto_increment,\n    name varchar(20),\n    location varchar(50) default 'Beijing',\n    primary key(id)\n) engine=innodb default charset=utf8;\n```\n\n### 5、外键约束\n\n外键约束：关键字foreign key（主要用于多表关联使用）\n\n用于保持不同表之间的数据一致性和完整性。它是一种规定，用于确保在一个表中的外键（Foreign Key）值必须存在于另一个表中的主键（Primary Key）中。\n\n外键约束的主要目的是建立表之间的关联关系，以确保表之间的数据一致性。外键约束可以在数据库设计时定义，并且可以由数据库管理系统（DBMS）自动执行，以防止不符合约束条件的数据插入或更新操作。\n\n比如：有两张数据表，这两个数据表之间有联系，通过了某个字段可以建立连接，这个字段在其中一个表中是主键，在另外一张表中，我们就把其称之为==外键==。\n\n![mysql图9.png](https://s2.loli.net/2024/03/15/tLpQDuqBj8JPAU4.png)\n\n外键约束可以有以下特性：\n\n1. 引用完整性：外键约束可以确保表之间的关联关系是有效的，即在外键列中的值必须在主键列中存在。这可以防止插入或更新数据时出现无效的外键值，从而保持数据的完整性。\n2. 数据一致性：外键约束可以确保在关联表之间的数据一致性，因为它要求外键值与主键值相匹配。这可以防止在不同表中出现不一致的数据，从而保持数据的一致性。\n3. 数据操作控制：外键约束可以限制对外键列的插入、更新和删除操作，从而控制对关联表的数据操作。这可以帮助防止不正确的数据操作，从而提高数据的质量和准确性。\n\n外键约束可能会对数据库的性能和灵活性产生影响，因为它会增加对数据的检查和验证操作。在设计数据库时，需要仔细考虑外键约束的使用，并根据具体情况进行权衡。\n\n### 6、小结\n\n① 主键约束：唯一标示，不能重复，不能为空。\n1）主键应当是对用户没有意义的\n2）永远也不要更新主键。\n3）主键不应包含动态变化的数据，如时间戳、创建时间列、修改时间列等。\n4） 主键应当由计算机自动生成。\n\n自动增长：\n我们可以在表中使用 auto_increment（自动增长列）关键字，自动增长列类型必须是整型，自动增长列必须为键(一般是主键)。\n\n② 非空约束：\nNOT NULL 约束强制列不接受 NULL 值。\n\n③ 唯一约束：\nUNIQUE 约束唯一标识数据库表中的每条记录。\nUNIQUE 和 PRIMARY KEY 约束均为列或列集合提供了唯一性的保证。\nPRIMARY KEY 拥有自动定义的 UNIQUE 约束。\n\n④ 默认值约束\n\ndefault 默认值\n\n用来指定某列的默认值。在表中插入一条新记录时，如果没有为这个字段赋值，系统就会自动为这个字段插入默认值。\n\n⑤ 外键约束\n\n主要用于指定两张表之间的关联关系。\n\n## 九、DQL数据查询语言\n\n### 1、数据集准备\n\n```mysql\nCREATE TABLE product\n(\n    pid         INT PRIMARY KEY,\n    pname       VARCHAR(20),\n    price       DOUBLE,\n    category_id VARCHAR(32)\n);\n```\n\n插入数据：\n\n```mysql\nINSERT INTO product VALUES (1,'联想',5000,'c001');\nINSERT INTO product VALUES (2,'海尔',3000,'c001');\nINSERT INTO product VALUES (3,'雷神',5000,'c001');\nINSERT INTO product VALUES (4,'杰克琼斯',800,'c002');\nINSERT INTO product VALUES (5,'真维斯',200,'c002');\nINSERT INTO product VALUES (6,'花花公子',440,'c002');\nINSERT INTO product VALUES (7,'劲霸',2000,'c002');\nINSERT INTO product VALUES (8,'香奈儿',800,'c003');\nINSERT INTO product VALUES (9,'相宜本草',200,'c003');\nINSERT INTO product VALUES (10,'面霸',5,'c003');\nINSERT INTO product VALUES (11,'好想你枣',56,'c004');\nINSERT INTO product VALUES (12,'香飘飘奶茶',1,'c005');\nINSERT INTO product VALUES (13,'海澜之家',1,'c002');\n```\n\n### 2、select查询\n\n基础查询：\n\n```powershell\n# 根据某些条件从某个表中查询指定字段的内容\n格式：select [distinct]*| 列名,列名 from 表 where 条件\n```\n\n高级查询：SQL查询五子句\n\n```sql\nselect */列名,列名 from 数据表 where 子句 group by 子句 having 子句 order by 子句 limit 子句;\n\n① where子句\n② group by子句\n③ having子句\n④ order by子句\n⑤ limit子句\n```\n\n### 3、简单查询\n\n```mysql\n# 1.查询所有的商品.  \nselect *  from product;\n# 2.查询商品名和商品价格. \nselect pname,price from product;\n# 3.查询结果是表达式（运算查询）：将所有商品的价格+10元进行显示.\nselect pname,price+10 from product;\n```\n\n### 4、条件查询\n\n![mysql图10.png](https://s2.loli.net/2024/03/15/sWaSuJbvqHVidmw.png)\n\n####  比较查询\n\n```powershell\n# 查询商品名称为“花花公子”的商品所有信息：\nSELECT * FROM product WHERE pname = '花花公子';\n# 查询价格为800商品\nSELECT * FROM product WHERE price = 800;\n# 查询价格不是800的所有商品\nSELECT * FROM product WHERE price != 800;\nSELECT * FROM product WHERE price <> 800;\n# 查询商品价格大于60元的所有商品信息\nSELECT * FROM product WHERE price > 60;\n# 查询商品价格小于等于800元的所有商品信息\nSELECT * FROM product WHERE price <= 800;\n```\n\n####  范围查询\n\n```powershell\n# 查询商品价格在200到1000之间所有商品\nSELECT * FROM product WHERE price BETWEEN 200 AND 1000;\n# 查询商品价格是200或800的所有商品\nSELECT * FROM product WHERE price IN (200,800);\n```\n\n####  逻辑查询\n\n```powershell\n# 查询商品价格在200到1000之间所有商品\nSELECT * FROM product WHERE price >= 200 AND price <=1000;\n# 查询商品价格是200或800的所有商品\nSELECT * FROM product WHERE price = 200 OR price = 800;\n# 查询价格不是800的所有商品\nSELECT * FROM product WHERE NOT(price = 800);\n```\n\n####  模糊查询\n\n```powershell\n# 查询以'香'开头的所有商品\nSELECT * FROM product WHERE pname LIKE '香%';\n# 查询第二个字为'想'的所有商品\nSELECT * FROM product WHERE pname LIKE '_想%';\n```\n\n####  非空查询\n\n```powershell\n# 查询没有分类的商品\nSELECT * FROM product WHERE category_id IS NULL;\n# 查询有分类的商品\nSELECT * FROM product WHERE category_id IS NOT NULL;\n```\n\n### 5、排序查询\n\n```powershell\n# 通过order by语句，可以将查询出的结果进行排序。暂时放置在select语句的最后。\n格式：SELECT * FROM 表名 ORDER BY 排序字段 ASC|DESC;\nASC 升序 (默认)\nDESC 降序\n\n# 1.使用价格排序(降序)\nSELECT * FROM product ORDER BY price DESC;\n# 2.在价格排序(降序)的基础上，以分类排序(降序)\nSELECT * FROM product ORDER BY price DESC,category_id DESC;\n```\n\n### 6、聚合查询\n\n之前我们做的查询都是横向查询，它们都是根据条件一行一行的进行判断，而使用聚合函数查询是纵向查询，它是对一列的值进行计算，然后返回一个单一的值；另外聚合函数会忽略空值。\n\n今天我们学习如下五个聚合函数：\n\n| **聚合函数** | **作用**                                                     |\n| ------------ | ------------------------------------------------------------ |\n| count()      | 统计指定列不为NULL的记录行数；                               |\n| sum()        | 计算指定列的数值和，如果指定列类型不是数值类型，则计算结果为0 |\n| max()        | 计算指定列的最大值，如果指定列是字符串类型，使用字符串排序运算； |\n| min()        | 计算指定列的最小值，如果指定列是字符串类型，使用字符串排序运算； |\n| avg()        | 计算指定列的平均值，如果指定列类型不是数值类型，则计算结果为0 |\n\n演示：\n\n```powershell\n# 1、查询商品的总条数\nSELECT COUNT(*) FROM product;\n# 2、查询价格大于200商品的总条数\nSELECT COUNT(*) FROM product WHERE price > 200;\n# 3、查询分类为'c001'的所有商品的总和\nSELECT SUM(price) FROM product WHERE category_id = 'c001';\n# 4、查询分类为'c002'所有商品的平均价格\nSELECT AVG(price) FROM product WHERE categ ory_id = 'c002';\n# 5、查询商品的最大价格和最小价格\nSELECT MAX(price),MIN(price) FROM product;\n```\n\n### 7、分组查询与having子句\n\n####  分组查询介绍\n\n分组查询就是将查询结果按照指定字段进行分组，字段中数据相等的分为一组。\n\n**分组查询基本的语法格式如下：**\n\nGROUP BY 列名 [HAVING 条件表达式] [WITH ROLLUP]\n\n**说明:**\n\n- 列名: 是指按照指定字段的值进行分组。\n- HAVING 条件表达式: 用来过滤分组后的数据。\n- WITH ROLLUP：在所有记录的最后加上一条记录，显示select查询时聚合函数的统计和计算结果\n\n####  group by的使用\n\n创建数据集\n\n```sql\ncreate table students(\n\tid int auto_increment,\n\tname varchar(20),\n\tage tinyint unsigned,\n\tgender enum('male', 'female'),\n\theight float(5,2),\n\tprimary key(id)\n) engine=innodb default charset=utf8;\n\ninsert into students values (null,'郭靖',33,'male',1.80);\ninsert into students values (null,'黄蓉',19,'female',1.65);\ninsert into students values (null,'柯镇恶',45,'male',1.61);\ninsert into students values (null,'黄药师',50,'male',1.72);\ninsert into students values (null,'华筝',18,'female',1.60);\n```\n\n\n\ngroup by可用于单个字段分组，也可用于多个字段分组\n\n```sql\n-- 根据gender字段来分组\nselect gender from students group by gender;\n-- 根据name和gender字段进行分组\nselect name, gender from students group by name, gender;\n```\n\n① group by可以实现去重操作\n\n② group by的作用是为了实现分组统计（group by + 聚合函数）\n\n####  group by + 聚合函数的使用\n\n```sql\n-- 统计不同性别的人的平均年龄\nselect gender,avg(age) from students group by gender;\n-- 统计不同性别的人的个数\nselect gender,count(*) from students group by gender;\n```\n\n执行原理图\n\n![mysql图11.png](https://s2.loli.net/2024/03/15/H4dDUatMegwfKYn.png)\n\n####  group by + having的使用\n\nhaving作用和where类似都是过滤数据的，但having是过滤分组数据的，只能用于group by\n\n```sql\n-- 根据gender字段进行分组，统计分组条数大于2的\nselect gender,count(*) from students group by gender having count(*)>2;\n```\n\n\n\n```powershell\n#1 统计各个分类商品的个数\nSELECT category_id ,COUNT(*) FROM product GROUP BY category_id ;\n\n#2 统计各个分类商品的个数,且只显示个数大于1的信息\nSELECT category_id ,COUNT(*) FROM product GROUP BY category_id HAVING COUNT(*) > 1;\n```\n\n### 8、limit分页查询\n\n作用：限制数据的查询数量\n\n基本语法：\n\n```sql\nselect * from 数据表 limit 查询数量;\n```\n\n案例：查询学生表中，身高最高的3名同学信息\n\n```sql\nselect * from students order by height desc limit 3;\n```\n\n\n\nlimit除了可以限制查询数量以外，其还可以指定从哪条数据开始查起，limit完整语法：\n\n```sql\nselect * from students limit offset,count;\n\noffset：索引，默认从0开始\ncount：查询总数量\n```\n\n如：查询学生表中，身高第2、3高的同学信息\n\n```sql\nselect * from students order by height desc limit 1,2;\n```\n\n\n\nlimit子句典型应用场景：\n\n分页查询在项目开发中常见，由于数据量很大，显示屏长度有限，因此对数据需要采取分页显示方式。例如数据共有30条，每页显示5条，第一页显示1-5条，第二页显示6-10条。\n\n 格式：\n\n```powershell\nSELECT 字段1，字段2... FROM 表名 LIMIT M,N\nM: 整数，表示从第几条索引开始，计算方式 （当前页-1）* 每页显示条数\nN: 整数，表示查询多少条数据\nSELECT 字段1，字段2... FROM 表名 LIMIT 0,5\nSELECT 字段1，字段2... FROM 表名 LIMIT 5,5\n```\n\n### 9、小结\n\n```powershell\nSQL查询五子句：\nselect * from 表名 where子句 group by子句 having子句 order by子句 limit子句;\n特别注意：查询五子句中，五子句的顺序一定要严格按照以上格式。\n\n条件查询：SELECT *|字段名 FROM 表名 WHERE 条件；\n排序查询：SELECT * FROM 表名 ORDER BY 排序字段 ASC|DESC;\n聚合查询函数：count()，sum()，max()，min()，avg()。\n分组查询：SELECT 字段1,字段2… FROM 表名 GROUP BY 分组字段 HAVING 分组条件;\n分页查询：\nSELECT 字段1，字段2... FROM 表名 LIMIT M,N\nM: 整数，表示从第几条索引开始，计算方式 （当前页-1）*每页显示条数\nN: 整数，表示查询多少条数据\n```\n\n## 十、多表查询\n\n### 数据集准备\n\nclasses班级表\n\n```sql\ncreate table classes(\n\tcls_id tinyint auto_increment,\n    cls_name varchar(20),\n    primary key(cls_id)\n) engine=innodb default charset=utf8;\n\n-- 插入测试数据\ninsert into classes values (null, 'ui');\ninsert into classes values (null, 'java');\ninsert into classes values (null, 'python');\n```\n\nstudents学生表\n\n```sql\ncreate table students(\n\tid int auto_increment,\n    name varchar(20),\n    age tinyint unsigned,\n    gender enum('male','female'),\n    score float(5,1),\n\tcls_id tinyint,\n    primary key(id)\n) engine=innodb default charset=utf8;\n\n-- 插入测试数据\ninsert into students values (null,'刘备',34,'male',90.0,2);\ninsert into students values (null,'貂蝉',18,'female',75.0,1);\ninsert into students values (null,'赵云',28,'male',95.0,3);\ninsert into students values (null,'关羽',32,'male',98.0,3);\ninsert into students values (null,'大乔',19,'female',80.0,1);\n```\n\n\n\n### 交叉连接\n\n是所有连接的基础。其功能就是将表1和表2中的每一条数据进行连接。\n\n结果：\n\n字段数 = 表1字段 + 表2的字段\n\n记录数 = 表1中的总数量 * 表2中的总数量（笛卡尔积）\n\n```powershell\nselect * from students cross join classes;\n或\nselect * from students, classes;\n```\n\n\n\n### 1、内连接\n\n####  连接查询的介绍\n\n连接查询可以实现多个表的查询，当查询的字段数据来自不同的表就可以使用连接查询来完成。\n\n连接查询可以分为:\n\n1. 内连接查询\n2. 左外连接查询\n3. 右外连接查询\n\n####  内连接查询\n\n查询两个表中符合条件的共有记录\n\n![mysql图12](https://s2.loli.net/2025/04/12/NlPWnSOzx3E5fsw.png)\n\n**内连接查询语法格式:**\n\n```sql\nselect 字段 from 表1 inner join 表2 on 表1.字段1 = 表2.字段2\n```\n\n**说明:**\n\n- inner join 就是内连接查询关键字\n- on 就是连接查询条件\n\n**例1：使用内连接查询学生表与班级表:**\n\n```sql\nselect * from students as s inner join classes as c on s.cls_id = c.id;\n```\n\n####  小结\n\n- 内连接使用inner join .. on .., on 表示两个表的连接查询条件\n- 内连接根据连接查询条件取出两个表的 “交集”\n\n### 2、左外连接\n\n#### 左连接查询\n\n以左表为主根据条件查询右表数据，如果根据条件查询右表数据不存在使用null值填充\n\n![mysql图12.png](https://s2.loli.net/2024/03/15/xDXCSlnTcuWrsL4.png)\n\n**左连接查询语法格式:**\n\n```sql\nselect 字段 from 表1 left join 表2 on 表1.字段1 = 表2.字段2\n```\n\n**说明:**\n\n- left join 就是左连接查询关键字\n- on 就是连接查询条件\n- 表1 是左表\n- 表2 是右表\n\n**例1：使用左连接查询学生表与班级表:**\n\n```sql\nselect * from students as s left join classes as c on s.cls_id = c.id;\n```\n\n**例2：查询学生表中每一位学生（包括没有对应班级的学生）所属的班级信息**\n\n前提：\n\n在students学生表中，插入一条测试数据\n\n```sql\ninsert into students values (null,'林黛玉',19,'female',96.0,99);\n```\n\n执行左外连接查询：\n\n```sql\nselect * from students as s left join classes as c on s.cls_id = c.id;\n```\n\n####  小结\n\n- 左连接使用left join .. on .., on 表示两个表的连接查询条件\n- 左连接以左表为主根据条件查询右表数据，右表数据不存在使用null值填充。\n\n### 3、右外连接\n\n####  右连接查询\n\n以右表为主根据条件查询左表数据，如果根据条件查询左表数据不存在使用null值填充\n\n![mysql图13.png](https://s2.loli.net/2024/03/15/tFMayxRQZh9pYLW.png)\n\n**右连接查询语法格式:**\n\n```sql\nselect 字段 from 表1 right join 表2 on 表1.字段1 = 表2.字段2\n```\n\n**说明:**\n\n- right join 就是右连接查询关键字\n- on 就是连接查询条件\n- 表1 是左表\n- 表2 是右表\n\n**例1：使用右连接查询学生表与班级表:**\n\n```sql\nselect * from students as s right join classes as c on s.cls_id = c.id;\n```\n\n####  小结\n\n- 右连接使用right join .. on .., on 表示两个表的连接查询条件\n- 右连接以右表为主根据条件查询左表数据，左表数据不存在使用null值填充。\n\n## 十一、子查询\n\n### 1、子查询（嵌套查询）的介绍\n\n在一个 select 语句中,嵌入了另外一个 select 语句, 那么被嵌入的 select 语句称之为子查询语句，外部那个select语句则称为主查询.\n\n**主查询和子查询的关系:**\n\n1. 子查询是嵌入到主查询中\n2. 子查询是辅助主查询的,要么充当条件,要么充当数据源(数据表)\n3. 子查询是可以独立存在的语句,是一条完整的 select 语句\n\n### 2、子查询的使用\n\n**例1. 查询学生表中大于平均年龄的所有学生:**\n\n需求：查询年龄 > 平均年龄的所有学生\n\n前提：① 获取所有学生的平均年龄\n\n​\t   ② 查询表中的所有记录，判断哪个同学 > 平均年龄值\n\n第一步：写子查询\n\n```powershell\nselect avg(age) from students;\n```\n\n第二步：写主查询\n\n```powershell\nselect * from students where age > (平均值);\n```\n\n第三步：第一步和第二步进行合并\n\n```powershell\nselect * from students where age > (select avg(age) from students);\n```\n\n\n\n**例2. 查询学生在班的所有班级名字:**\n\n需求：显示所有有学生的班级名称\n\n前提：① 先获取所有学员都属于那些班级\n\n​\t         ② 查询班级表中的所有记录，判断是否出现在①结果中，如果在，则显示，不在，则忽略。\n\n第一步：编写子查询\n\n```powershell\nselect distinct cls_id from students is not null;\n```\n\n第二步：编写主查询\n\n```powershell\nselect * from classes where cls_id in (1, 2, 3);\n```\n\n第三步：把主查询和子查询合并\n\n```sql\nselect * from classes where cls_id in (select distinct cls_id from students where cls_id is not null);\n```\n\n\n\n**例3. 查找年龄最小,成绩最低的学生:**\n\n第一步：获取年龄最小值和成绩最小值\n\n```powershell\nselect min(age), min(score) from student;\n```\n\n第二步：查询所有学员信息（主查询）\n\n```sql\nselect * from students where (age, score) = (最小年龄, 最少成绩);\n```\n\n第三步：把第一步和第二步合并\n\n```powershell\nselect * from students where (age, score) = (select min(age), min(score) from students);\n```\n\n## 十二、练习部分\n\n练习使用 微软的Northwind数据集, 零售业务，包含了客户，供应商和订单数据。原始数据集可以在 [微软GitHub 仓库](https://github.com/Microsoft/sql-server-samples/tree/master/samples/databases/northwind-pubs)下载。当前使用数据库数据在原始数据基础上做了微调，放在了文末。\n\n基于此份数据，通过SQL来创建数据报表，满足业务需求。\n\n本项目中一共用到7张表\n\n1. `employees` 员工表 记录了Northwind所有员工信息.\n2. `customers` 客户表，记录了客户相关信息.\n3. `products` 记录了商品信息.\n4. `categories` 记录了商品类别信息.\n5. `suppliers` 记录了商品供应商信息.\n6. `orders` 记录了Northwind的顾客下的订单.\n7. `order_items` 记录了订单中的每一件商品明细.\n\n**数据表结构及表关系**\n\n![mysql图14.png](https://s2.loli.net/2024/03/15/dk5Le8RXhZT1FaW.png)\n\n![mysql图15.png](https://s2.loli.net/2024/03/15/UbNQkfIhJSlVE53.png)\n\n### 1.1 员工表(employees)\n\n![mysql图16.png](https://s2.loli.net/2024/03/15/WN8c5ydk9uDBVwl.png)\n\n- 保存员工基本信息：\n  - 唯一ID (`employee_id`).\n  - 姓，名(`first_name` and `last_name`).\n  - 职务 (`title`).\n- 需要注意的是 `reports_to`这一列, 保存的是员工所对应的直属领导的员工ID (也在这张表中保存) ，此外还有其它列包括入职时间，生日... ...\n\n#### 练习1\n\n- 选中`employees` 表的所有数据\n\n```sql\nselect * from employees\n```\n\n![mysql图17.png](https://s2.loli.net/2024/03/15/6rq1TGNiyuvngja.png)\n\n### 1.2 顾客表(customers)\n\n- 每一个顾客都有唯一ID`customer_id`, 顾客的ID是公司全名的缩写，用5个字母表示\n\n- 公司全名在 `company_name` 列中保存\n\n- `contact_name` 和 `contact_title` 两列代表了客户公司的联系人信息（名字和职务）\n\n  除此之外还保存了顾客的地址信息和联系方式`city`, `region`, `postal_code`, `country`, `fax`\n\n#### 练习2\n\n- 查询每个客户的 `ID`, `company name`, `contact name`, `contact title`, `city`, 和 `country`.并按照国家名字排序\n\n```sql\nselect customer_id,\n  company_name,\n  contact_name,\n  contact_title,\n  city,\n  country from customers\n  order by country\n```\n\n![mysql图18.png](https://s2.loli.net/2024/03/15/FzSiLJ3yK4DAhGV.png)\n\n### 1.3 商品(products)和商品类别(categories)表\n\n- 商品表中保存了在Northwind商店中出售的商品信息\n  - 每一种商品都有唯一的 `product_id` 和商品名字`product_name`.\n  - 每一种商品都有一个供应商 (`supplier_id`) \n  - 每一种商品都有一个商品类别 (`category_id`).\n  - 每一种商品都有确定的单价 `unit_price`. \n  - 字段 `discontinued` 代表商品是否缺货， `false` (有货)   `true` (缺货) \n- 商品类别表 `categories` ，保存了所有商品的类别\n  - 每个类别都有唯一的id\n  - 每个类别都有自己的名称 `category_name`\n  - 字段`description` 存储了类别的简短描述信息\n- 商品表中包含了  `category_id` 字段，所以可以使用join 将商品表中的信息与商品类别表中的信息进行关联查询\n\n#### 练习3\n\n- 查询每一个商品的`product_name`，`category_name`，`quantity_per_unit`，`unit_price`，`units_in_stock` 并且通过 `unit_price` 字段排序\n\n```sql\nSELECT\n  product_name,\n  category_name,\n  quantity_per_unit,\n  unit_price,\n  units_in_stock\nFROM products\nJOIN categories\n  ON products.category_id = categories.category_id\nORDER BY unit_price;\n```\n\n![mysql图19.png](https://s2.loli.net/2024/03/15/vl9HDzPXf4yh5AQ.png)\n\n### 1.4 供应商表（supplier）\n\n- 供应商表与用户表类似\n- 每个供应商都有唯一ID `supplier_id` \n- 每个供应商都有公司名字`company_name`\n- 表中还记录了供应商的地址信息 `address`，`city`，`region`，`postal_code`，`country`\n\n#### 练习4\n\n- 列出所有提供了4种以上不同商品的供应商列表\n- 所需字段：`supplier_id`, `company_name`, and `products_count` (提供的商品种类数量).\n\n```sql\nSELECT\n  s.supplier_id, \n  s.company_name, \n  COUNT(*) AS products_count\nFROM products p\nJOIN suppliers s \n  ON p.supplier_id = s.supplier_id\nGROUP BY s.supplier_id,\n  s.company_name\nHAVING COUNT(*) > 4;\n```\n\n![mysql图20.png](https://s2.loli.net/2024/03/15/NSHhZDv5rALW9O2.png)\n\n### 1.5 订单和订单明细表\n\n- 订单表 `orders` 中的每一条数据包含了一个订单的基本信息：\n  - 订单ID `order_id`，顾客ID `customer_id`, 销售员的员工ID `employee_id` \n  - 订单相关的时间信息  (下单日期`order_date` 和配送日期 `shipped_date`) 和其他配送相关信息\n    - ship_via 运输方式\n    - freight   运费\n    - ship_address  收货地址\n    - ship_city   收货城市\n    - ship_region 收货地区\n    - ship_postal_code 收货地址邮编\n    - ship_country 收货国家\n\n#### 练习5\n\n- 提取订单编号为10250的订单详情，显示如下信息：\n\n  `product_name`, `quantity`, `unit_price` （ `order_items` 表)`discount` ，`order_date` ,按商品名字排序\n\n```sql\nSELECT\n  product_name,\n  quantity,\n  order_items.unit_price,\n  discount,\n  order_date\nFROM order_items\nJOIN products\n  ON order_items.product_id = products.product_id\nJOIN orders\n  ON orders.order_id = order_items.order_id\nWHERE orders.order_id = 10250\nORDER BY product_name;\n```\n\n### 2.1 详细报告\n\n- 将一个或者多个业务对象的详细信息汇总到一张表中是一种比较常见的报表形式\n- 我们需要的信息可能分散在多张表中，在写SQL时可以通过一个或者多个`JOIN`子句将信息进行汇总\n\n```sql\nSELECT\n  c.company_name AS customer_company_name, \n  e.first_name AS employee_first_name, \n  e.last_name AS employee_last_name,\n  o.order_date,\n  o.shipped_date,\n  o.ship_country\nFROM orders o\nJOIN employees e\n  ON o.employee_id = e.employee_id\nJOIN customers c\n  ON o.customer_id = c.customer_id\nWHERE o.ship_country = 'France';\n```\n\n- 在上面的SQL查询中，我们想收集运输到法国的订单的相关信息，包括订单涉及的顾客和员工信息，下单和发货日期等\n- 由于相关数据保存在不同的表中，所以需要将`orders` 表， `employees` 表和 `customers` 表连接在一起\n- 注意在写SQL时，我们可以为每一张表都起了一个别名，可以减少输入的字符数\n\n#### 练习6\n\n- 需求：提供订单编号为10248的相关信息，包括**product name**,  **unit price** (在 `order_items` 表中),  **quantity（数量）**,**company_name**（供应商公司名字 ，起别名 `supplier_name`).\n\n```sql\nSELECT\n  product_name,\n  oi.unit_price,\n  oi.quantity,\n  company_name AS supplier_name\nFROM order_items oi\nJOIN products p \n  ON oi.product_id = p.product_id\nJOIN suppliers s\n  ON s.supplier_id = p.supplier_id\nWHERE oi.order_id = 10248;\n```\n\n#### 练习7\n\n- 需求：提取每件商品的详细信息，包括  商品名称（`product_name`）, 供应商的公司名称  (`company_name`，在 `suppliers` 表中), 类别名称 `category_name`, 商品单价`unit_price`, 和每单位商品数量`quantity per unit`\n\n```sql\nSELECT \n  p.product_name,\n  s.company_name,\n  c.category_name,\n  p.unit_price,\n  p.quantity_per_unit\nFROM products p\nJOIN suppliers s\n  ON p.supplier_id = s.supplier_id\nJOIN categories c\n  ON c.category_id = p.category_id;\n```\n\n### 2.2 带时间限制的报表\n\n- 另一种常见的报表需求是查询某段时间内的业务指标\n\n```sql\nSELECT\n  COUNT(*)\nFROM orders\nWHERE order_date >= '2016-07-01' AND  order_date < '2016-08-01';\n```\n\n- 在上面的查询中，我们统计了2016年7月的订单数量，\n- 需要注意SQL中的日期总是放在单引号内，格式通常为“ YYYY-MM-DD”（年-月-日）\n\n#### 练习8\n\n- 统计2013年入职的员工数量，统计字段起别名 `number_of_employees`\n\n```sql\nSELECT\n  COUNT(*) AS number_of_employees\nFROM employees\nWHERE hire_date >= '2013-01-01' AND hire_date < '2014-01-01';\n```\n\n### 2.3 计算多个对象\n\n- 在业务报表中，我们通常希望同时计算多个业务对象的某些指标。\n\n```sql\nSELECT\n    order_id,\n    COUNT(*) AS order_items_count\nFROM\n    order_items\nWHERE\n    order_id BETWEEN 10200 AND 10300\nGROUP BY\n    order_id;\n```\n\n- 在上面的查询中，我们统计了指定范围内的`order_id`，计算每个订单中的商品数量\n  - 通过连接`orders` 和`order_items`表，在同一行显示单个订单商品及其父订单的信息\n  - 按照父顺序对所有行进行分组\n  - 使用`COUNT（*）`统计每个订单的商品数量\n\n#### 练习9\n\n- 需求：统计每个供应商供应的商品总数量\n  - 结果返回供应商ID`supplier_id` ，公司名字`company_name` ，商品种类数量（起别名`products_count` )\n  - 使用 `products` 和 `suppliers` 表.\n\n```sql\nSELECT\n  s.supplier_id,\n  company_name,\n  COUNT(*) AS products_count\nFROM products p\nJOIN suppliers s\n  ON p.supplier_id = s.supplier_id \nGROUP BY s.supplier_id,company_name;\n```\n\n需求：统计每个供应商分别供应每类商品的数量\n\n```sql\nSELECT\n    count(*) AS `products_count`,\n    s.supplier_id,\n    s.company_name,\n    category_id\nFROM\n    products AS p\n        INNER JOIN suppliers AS s ON p.supplier_id = s.supplier_id\nGROUP BY\n    s.supplier_id, s.company_name, category_id ;\n```\n\n\n\n### 2.4 总订单金额\n\n- 在销售报表中,我们经常需要计算订单的总付款额。\n\n```sql\nSELECT\n    sum(unit_price * quantity) AS total_price\nFROM\n    order_items\nWHERE\n    order_id = 10250;\n```\n\n- 我们要查找ID为10250的订单的总价（折扣前），`SUM(unit_price * quantity)`\n\n#### 练习10\n\n- Northwind商店某些产品会不定期做打折促销\n- 每个商品的折扣都存储在 `order_items` 表的`discount` 列中\n- 例如，“ 0.20”折扣意味着客户支付原始价格的“ 1-0.2 = 0.8”\n- 在下面的代码中添加第二个名为`total_price_after_discount`的列，计算打折后的商品价格\n\n```sql\nSELECT\n  SUM(unit_price * quantity) AS total_price\nFROM orders o\nJOIN order_items oi \n  ON o.order_id = oi.order_id\nWHERE o.order_id = 10250;\n```\n\n\n\n```sql\nSELECT\n    SUM(unit_price * quantity) AS total_price,\n    SUM(unit_price * quantity * (1 - discount)) AS total_price_after_discount\nFROM\n    order_items\nWHERE\n        order_id = 10250\n```\n\n### 2.5 计算多个订单的订单金额\n\n- 上面的案例中我们计算了单个订单的订单总金额，接下来我们统计多个订单的总金额\n\n```sql\nSELECT\n  o.order_id,\n  c.company_name AS customer_company_name, \n  SUM(unit_price * quantity) AS total_price\nFROM orders o\nJOIN customers c\n  ON o.customer_id = c.customer_id\nJOIN order_items oi\n  ON o.order_id = oi.order_id\nWHERE o.ship_country = 'France'\nGROUP BY o.order_id, c.company_name;\n```\n\n- 我们想计算运输到法国的所有订单的总订单金额\n- 在结果中，我们想保留订单ID和订单公司名字，可以通过`GROUP BY` 实现\n- 注意：通过`GROUP BY`  我们只需要对 `order_id` 进行分组就可以了，但MySQL 5.7之后要求，在使用`GROUP BY`分组时，SELECT 后的字段，如果没有在聚合函数中使用，就必须在GROUP BY 后出现\n\n#### 练习11\n\n- 统计每个员工处理的订单总数\n- 结果包含员工ID`employee_id`，姓名`first_name` 和 `last_name`，处理的订单总数(别名 `orders_count`)\n\n```sql\nSELECT\n  e.employee_id,\n  e.first_name,\n  e.last_name,\n  COUNT(*) AS orders_count\nFROM orders o\nJOIN employees e\n  ON e.employee_id = o.employee_id\nGROUP BY e.employee_id,\n  e.first_name,\n  e.last_name;\n```\n\n### 2.6 不同类别商品的库存\n\n- 统计每个类别中的库存产品值多少钱？ \n  - 显示三列：`category_id`, `category_name`, 和 `category_total_value`\n  - 如何计算库存商品总价：`SUM(unit_price * units_in_stock)`。\n\n```sql\nSELECT\n  c.category_id,\n  c.category_name,\n  SUM(unit_price * units_in_stock) AS category_total_value\nFROM products p\nJOIN categories c\n  ON p.category_id = c.category_id\nGROUP BY c.category_id,\n  c.category_name;\n```\n\n### 2.7 Group by分组\n\n- 接下来，我们来了解每个员工的业绩：计算每个员工的订单数量\n- 看下面的SQL是否有问题\n\n```sql\nSELECT\n  e.first_name,\n  e.last_name,\n  COUNT(*) AS orders_count\nFROM orders o\nJOIN employees e\n  ON o.employee_id = e.employee_id\nGROUP BY e.first_name,\n  e.last_name;\n```\n\n- 上面的SQL貌似正确，但是没有考虑到员工重名的问题，所以需要做一个小调整：\n\n```sql\nSELECT\n  e.employee_id,\n  e.first_name,\n  e.last_name,\n  COUNT(*) AS orders_count\nFROM orders o\nJOIN employees e\n  ON o.employee_id = e.employee_id\nGROUP BY e.employee_id,\n  e.first_name,\n  e.last_name;\n```\n\n- 在`SELECT` 和 `GROUP BY` 中添加了 员工ID `employee_id`字段后,重名的问题就可以解决了\n- 注意，在使用GROUP BY进行分组聚合统计时，需要考虑分组字段中的相同值的业务含义是否相同\n\n#### 练习12\n\n- 需求：计算每个客户的下订单数\n- 结果包含：用户id、用户公司名称、订单数量（`customer_id`, `company_name`,  `orders_count` ）\n\n```sql\nSELECT\n  c.customer_id,\n  c.company_name,\n  COUNT(*) AS orders_count\nFROM orders o\nJOIN customers c\n  ON o.customer_id = c.customer_id\nGROUP BY c.customer_id,\n  c.company_name;\n```\n\n### 2.8 选择显示部分信息\n\n- 再看一下上面的例子\n\n```sql\nSELECT\n  e.employee_id,\n  e.first_name,\n  e.last_name,\n  COUNT(*) AS orders_count\nFROM orders o\nJOIN employees e\n  ON o.employee_id = e.employee_id\nGROUP BY e.employee_id,\n  e.first_name,\n  e.last_name;\n```\n\n- 我们通过 `employee_id`进行分组, 但是`GROUP BY`中的字段，不一定在`SELECT`中出现，例如下面的SQL：\n\n```sql\nSELECT\n  e.first_name,\n  e.last_name,\n  COUNT(*) AS orders_count\nFROM orders o\nJOIN employees e\n  ON o.employee_id = e.employee_id\nGROUP BY e.employee_id,\n  e.first_name,\n  e.last_name;\n```\n\n- 之前我们强调过，`SELECT` 中的字段，如果没在聚合函数中使用，就一定更要在`GROUP BY` 子句中出现\n- 但是，`GROUPY BY`子句中的字段，可以不用都出现在`SELECT`中\n\n#### 练习13\n\n- 需求：统计2016年6月到2016年7月底用户的总下单金额并按金额从高到低排序\n- 结果包含：顾客公司名称`company_name` 和总下单金额（折后实付金额）`total_paid`\n- 提示：\n  - 计算实际总付款金额： SUM(unit_price * quantity * (1 - discount)) \n  - 日期过滤 `WHERE order_date >= '2016-06-01' AND order_date < '2016-08-01'`\n\n```sql\nSELECT\n  c.company_name, \n  SUM(unit_price * quantity * (1 - discount)) AS total_paid\nFROM orders o\nJOIN order_items oi\n  ON o.order_id = oi.order_id\nJOIN customers c\n  ON o.customer_id = c.customer_id\nWHERE order_date >= '2016-06-01' AND order_date < '2016-08-01'\nGROUP BY c.customer_id,\n  c.company_name\nORDER BY total_paid DESC;\n```\n\n### 2.9 COUNT()函数回顾\n\n- 当创建业务报表的时候，需要注意 `COUNT(*)` 和 `COUNT(列名)` 之间的区别\n- 假设我们要统计发货到不同国家/地区的订单数量以及已经发货的订单数量\n\n```sql\nSELECT\n  ship_country,\n  COUNT(*) AS all_orders,\n  COUNT(shipped_date) AS shipped_orders\nFROM orders\nGROUP BY ship_country;\n```\n\n- `COUNT（*）`将计算ship_country中的所有订单\n- `COUNT（shipped_date）`将仅计算shipped_date列值不为NULL的行\n- 在我们的数据库中，` shipped_date` 列中的`NULL`表示尚未发货，COUNT（shipped_date）` 仅计算已经发货的订单。\n\n#### 练习14\n\n- 需求：统计客户总数和带有传真号码的客户数量\n- 需要字段：`all_customers_count` 和 `customers_with_fax_count`\n\n```sql\nSELECT\n  COUNT(*) AS all_customers_count, \n  COUNT(fax) AS customers_with_fax_count\nFROM customers;\n```\n\n### 3.1 使用CASE WHEN自定义分组\n\n- 需求：我们要在报表中显示每种产品的库存量，但我们不想简单地将“ units_in_stock”列放在报表中。报表中只需要一个总体级别，例如低，高：\n\n```sql\nSELECT\n  product_id,\n  product_name,\n  units_in_stock,\n  CASE\n    WHEN units_in_stock > 100 THEN 'high'\n    WHEN units_in_stock > 50 THEN 'moderate'\n    WHEN units_in_stock > 0 THEN 'low'\n    WHEN units_in_stock = 0 THEN 'none'\n  END AS availability\nFROM products;\n```\n\n- 上面的SQL查询结果中，我们创建了一个新列`availability`， 通过 `CASE WHEN` 语句来对这一列赋值\n- `CASE WHEN` 语法回顾\n- 上面的查询中，通过  `units_in_stock` 列的值来判断库存的可用性\n  - 库存大于100 的可用性为高(high)\n  - 50到100的可用性为中等(moderate)\n  - 小于50的为低(low)\n  - 零库存 为 (none)\n\n#### 练习15\n\n运行上面的SQL，比较`units_in_stock` 和 `availability`两列的结果\n\n#### 练习16\n\n- 需求： 创建一个报表，统计员工的经验水平\n- 显示字段：`first_name`, `last_name`, `hire_date`, 和 `experience` \n- 经验字段（`experience` ）：\n  - `'junior'`  2014年1月1日以后雇用的员工\n  - `'middle'` 在2013年1月1日之后至2014年1月1日之前雇用的员工\n  - `'senior'` 2013年1月1日或之前雇用的员工\n\n```sql\nSELECT\n  first_name,\n  last_name,\n  hire_date,\n  CASE\n    WHEN hire_date > '2014-01-01' THEN 'junior'\n    WHEN hire_date > '2013-01-01' THEN 'middle'\n    WHEN hire_date <= '2013-01-01' THEN 'senior'\n  END AS experience\nFROM employees;\n```\n\n### 3.2 CASE WHEN中ELSE的使用\n\n- 我们的商店要针对北美地区的用户做促销活动：任何运送到北美地区（美国，加拿大) 的包裹免运费。 \n- 创建报表，查询订单编号为10720~10730 活动后的运费价格\n\n```sql\nSELECT \n  order_id,\n  customer_id,\n  ship_country,\n  CASE\n    WHEN ship_country = 'USA' OR ship_country = 'Canada' THEN 0.0\n  END AS shipping_cost\nFROM orders\nWHERE order_id BETWEEN 10720 AND 10730;\n```\n\n- 上面的SQL中，只定义了美国和加拿大的运费，并没有处理其他目的地的运费信息\n\n#### 练习17\n\n- 运行上面的SQL 观察 `ship_country` 和 `shipping_cost` 列，除了美国和加拿大之外，其他行的 `shipping_cost`  的值为NULL\n\n- 在上面的案例中，除了北美地区的以外的订单，运费统计为NULL, 如果将其他地区的运费设置为10美元，那么可以用如下方式处理：\n\n  ```\n  SELECT \n    order_id,\n    customer_id,\n    ship_country,\n    CASE\n      WHEN ship_country = 'USA' OR ship_country = 'Canada' THEN 0.0\n      ELSE 10.0\n    END AS shipping_cost\n  FROM orders\n  WHERE order_id BETWEEN 10720 AND 10730;\n  ```\n\n  - 我们在`CASE WHEN`结构中添加了`ELSE`\n  - 如果不满足其他条件，则执行`ELSE`。 因此，所有其他国家/地区的 `shipping_cost`都将变为“ 10.0”，而不是`NULL`。\n\n#### 练习18\n\n- 需求：创建客户基本信息报表\n- 包含字段：\n  - 客户id `customer_id`\n  - 公司名字 `company_name`\n  - 所在国家 `country`\n  - 使用语言`language`\n- 使用语言`language` 的取值按如下规则\n  - Germany, Switzerland, and Austria 语言为德语 `'German'` \n  - UK, Canada, the USA, and Ireland 语言为英语 `'English'` \n  - 其他所有国家 `'Other'` \n\n```sql\nSELECT \n  customer_id,\n  company_name,\n  country,\n  CASE\n    WHEN country IN ('Germany', 'Switzerland', 'Austria') THEN 'German'\n    WHEN country IN ('UK', 'Canada', 'USA', 'Ireland') THEN 'English'\n    ELSE 'Other'\n  END AS language\nFROM customers;\n```\n\n#### 练习19\n\n- 需求：创建报表将所有产品划分为素食和非素食两类\n- 报表中包含如下字段：\n  - 产品名字 `product_name`\n  - 类别名称 `category_name`\n  - 膳食类型 `diet_type`:\n    - 非素食 `'Non-vegetarian'`  商品类别字段的值为 `'Meat/Poultry'` 和 `'Seafood'`.\n    - 素食\n\n```sql\nSELECT\n  product_name,\n  category_name,\n  CASE\n    WHEN category_name IN ('Meat/Poultry', 'Seafood') THEN 'Non-vegetarian'\n    ELSE 'Vegetarian'\n  END AS diet_type\nFROM categories c\nJOIN products p\n  ON c.category_id = p.category_id;\n```\n\n### 3.3 在GROUP BY中使用CASE WHEN\n\n- 在引入北美地区免运费的促销策略时，我们也想知道运送到北美地区和其它国家地区的订单数量\n\n```sql\nSELECT \n  CASE\n    WHEN ship_country = 'USA' OR ship_country = 'Canada' THEN 0.0\n    ELSE 10.0\n  END AS shipping_cost,\n  COUNT(*) AS order_count\nFROM orders\nGROUP BY\n  CASE\n    WHEN ship_country = 'USA' OR ship_country = 'Canada' THEN 0.0\n    ELSE 10.0\n  END;\n```\n\n- 在`SELECT`子句和`GROUP BY`子句中，有相同的`CASE WHEN`出现在`GROUP BY`子句中\n- 这里并没有使用别名`shipping_cost`。 虽然在SELECT子句中指定了别名（shipping_cost），但标准SQL不允许在GROUP BY子句中引用别名，所以这里`CASE WHEN` 写了两次\n- MySQL允许 在`GROUP BY`中使用列别名，在本案例中两种写法都可以\n- 注意：CASE WHEN` 语句在 `GROUP BY` 和 `SELECT` 子句中，写法必须相同\n\n#### 练习20\n\n- 需求：创建报表统计供应商来自那个大洲\n- 报表中包含两个字段：供应商来自哪个大洲（`supplier_continent` ）和 供应产品种类数量（`product_count`）\n- 供应商来自哪个大洲（`supplier_continent` ）包含如下取值：\n  - `'North America'` （供应商来自 `'USA'` 和 `'Canada'`.）\n  - `'Asia'` （供应商来自 `'Japan'` 和 `'Singapore'`)\n  - `'Other'` (其它国家)\n\n```sql\nSELECT \n  CASE\n    WHEN country IN ('USA', 'Canada') THEN 'North America'\n    WHEN country IN ('Japan', 'Singapore') THEN 'Asia'\n    ELSE 'Other'\n  END AS supplier_continent,\n  COUNT(*) AS product_count\nFROM products p\nJOIN suppliers s\n  ON p.supplier_id = s.supplier_id\nGROUP BY\n  CASE\n    WHEN country IN ('USA', 'Canada') THEN 'North America'\n    WHEN country IN ('Japan', 'Singapore') THEN 'Asia'\n    ELSE 'Other'\n  END;\n```\n\n#### 练习21\n\n- 需求：创建一个简单的报表来统计员工的年龄情况\n- 报表中包含如下字段\n  - 年龄（ `age` ）：生日大于1980年1月1日 `'young'` ，其余`'old'` \n  - 员工数量 （ `employee_count`）\n\n```sql\nSELECT\n  CASE\n    WHEN birth_date > '1980-01-01' THEN 'young'\n    ELSE 'old'\n  END AS age,\n  COUNT(*) AS employee_count\nFROM employees\nGROUP BY\n  CASE\n    WHEN birth_date > '1980-01-01' THEN 'young'\n    ELSE 'old'\n  END;\n```\n\n### 3.4 CASE WHEN 和 COUNT\n\n- 可以将 `CASE WHEN` 和 `COUNT` 结合使用，自定义分组并统计每组数据数量\n\n```sql\nSELECT \n  COUNT(CASE \n    WHEN ship_country = 'USA' OR ship_country = 'Canada' THEN order_id \n  END) AS free_shipping,\n  COUNT(CASE\n    WHEN ship_country != 'USA' AND ship_country != 'Canada' THEN order_id\n  END) AS paid_shipping\nFROM orders;\n```\n\n在上面的查询中，在`COUNT（）`函数中包含了一个`CASE WHEN`子句。\n\n- 对于每一行，`CASE WHEN`子句会检查`ship_country`中的值。 如果是“ USA”或“ Canada”，则将order_id传递给`COUNT（）`并进行计数。 \n- 如果`ship_country`中的值不同，则`CASE WHEN`将返回`NULL`, `COUNT（）`不会统计`NULL`值。 `free_shipping`列将**仅计算运往美国或加拿大的订单”**\n- ` paid_shipping`列的构建方式与上述方式类似\n\n#### 练习22\n\n- 需求：统计客户的contact_title 字段值为 ’Owner' 的客户数量\n- 查询结果有两个字段：`represented_by_owner` 和 `not_represented_by_owner`\n\n```sql\nSELECT \n  COUNT(CASE\n    WHEN contact_title = 'Owner' THEN customer_id\n  END) AS represented_by_owner,\n  COUNT(CASE\n    WHEN contact_title != 'Owner' THEN customer_id\n  END) AS not_represented_by_owner\nFROM customers;\n```\n\n#### 练习23\n\n- 需求：Washington (WA) 是 Northwind的主要运营地区，统计有多少订单是由华盛顿地区的员工处理的，多少订单是有其它地区的员工处理的\n- 结果字段： `orders_wa_employees` 和 `orders_not_wa_employees`\n\n```sql\nSELECT \n  COUNT(CASE\n    WHEN region = 'WA' THEN order_id\n  END) AS orders_wa_employees,\n  COUNT(CASE\n    WHEN region != 'WA' THEN order_id\n  END) AS orders_not_wa_employees\nFROM employees e\nJOIN orders o\n  ON e.employee_id = o.employee_id;\n```\n\n### 3.5 GROUP BY 和 CASE WHEN组合使用\n\n```sql\nSELECT \n  ship_country,\n  COUNT(CASE\n    WHEN freight < 40.0 THEN order_id\n  END) AS low_freight,\n  COUNT(CASE\n    WHEN freight >= 40.0 AND freight < 80.0 THEN order_id\n  END) AS avg_freight,\n  COUNT(CASE\n    WHEN freight >= 80.0 THEN order_id\n  END) AS high_freight\nFROM orders\nGROUP BY ship_country;\n```\n\n- 将`COUNT(CASE WHEN...)` 和 `GROUP BY` 组合使用，可以创建更复杂的报表，在报表中，我们将运输到不同国家的订单根据运费高低进一步分成三组，并统计每组数量\n\n#### 练习24\n\n- 需求：创建报表，统计不同类别产品的库存量，将库存量分成两类 >30 和 <=30 两档,分别统计这两档的商品数量\n- 报表包含三个字段\n  - 类别名称  `category_name`,\n  - 库存充足  `high_availability` \n  - 库存紧张 `low_availability` \n\n```sql\nSELECT \n  c.category_name,\n  COUNT(CASE\n    WHEN units_in_stock > 30 THEN product_id\n  END) AS high_availability,\n  COUNT(CASE\n    WHEN units_in_stock <= 30 THEN product_id\n  END) AS low_availability\nFROM products p\nJOIN categories c\n  ON p.category_id = c.category_id\nGROUP BY c.category_id,\n  c.category_name;\n```\n\n### 3.6 SUM中使用CASE WHEN\n\n- 上面通过我们通过  `COUNT()` 函数 和`CASE WHEN`子句联合使用来创建的报表，也可以通过  `SUM()` 来替代 `COUNT()`\n\n```sql\nSELECT \n  SUM(CASE\n    WHEN ship_country = 'USA' OR ship_country = 'Canada' THEN 1\n  END) AS free_shipping,\n  SUM(CASE\n    WHEN ship_country != 'USA' AND ship_country != 'Canada' THEN 1\n  END) AS paid_shipping\nFROM orders;\n```\n\n- 在上面的查询中，我们将`SUM（）`与`CASE WHEN`一起使用，结果与使用 `COUNT()`相同\n\n#### 练习25\n\n```sql\nSELECT \n  COUNT(CASE\n    WHEN region = 'WA' THEN order_id\n  END) AS orders_wa_employees,\n  COUNT(CASE\n    WHEN region != 'WA' THEN order_id\n  END) AS orders_not_wa_employees\nFROM employees e\nJOIN orders o\n  ON e.employee_id = o.employee_id;\n```\n\n- 将上面的SQL修改成用 SUM（） 函数实现\n\n```sql\nSELECT \n  SUM(CASE\n    WHEN region = 'WA' THEN 1\n  END) AS orders_wa_employees,\n  SUM(CASE\n    WHEN region != 'WA' THEN 1\n  END) AS orders_not_wa_employees\nFROM employees e\nJOIN orders o\n  ON e.employee_id = o.employee_id;\n```\n\n#### 练习26\n\n- 需求：创建报表统计运输到法国的的订单中，打折和未打折订单的总数量\n- 结果包含两个字段：`full_price` （原价）和 `discounted_price`（打折）\n\n```sql\nSELECT\n  SUM(CASE\n    WHEN discount = 0 THEN 1\n  END) AS full_price,\n  SUM(CASE\n    WHEN discount != 0 THEN 1\n  END) AS discounted_price\nFROM orders o\nJOIN order_items oi\n  ON o.order_id = oi.order_id\nWHERE ship_country = 'France';\n```\n\n### 3.7 SUM中使用CASE WHEN进行复杂计算\n\n- 我们现在要统计每个订单的总付款额以及非素食产品的总付款额。\n\n> 注: 非素食产品的产品ID （ `category_id`） 是 6 和 8\n\n```sql\nSELECT\n  o.order_id,\n  SUM(oi.quantity * oi.unit_price * (1 - oi.discount)) AS total_price,\n  SUM(CASE\n    WHEN p.category_id in (6, 8) THEN oi.quantity * oi.unit_price * (1 - oi.discount)\n    ELSE 0\n  END) AS non_vegetarian_price\nFROM orders o\nJOIN order_items oi\n  ON o.order_id = oi.order_id\nJOIN products p\n  ON p.product_id = oi.product_id\nGROUP BY o.order_id;\n```\n\n- 之前的场景中，我们可以通过`SUM(CASE WHEN...)` 来替换`COUNT(CASE WHEN...)` ，但在上面的例子中，我们只能使用`SUM(CASE WHEN...)` ，因为涉及到不同值的累加，不能通过COUNT计数替代\n\n#### 练习27\n\n- 需求：输出报表，统计不同供应商供应商品的总库存量，以及高价值商品的库存量（单价超过40定义为高价值）\n- 结果显示四列：\n  - 供应商ID `supplier_id`\n  - 供应商公司名 `company_name`\n  - 由该供应商提供的总库存 `all_units` \n  - 由该供应商提供的高价值商品库存 `expensive_units` \n\n```sql\nSELECT \n  s.supplier_id,\n  s.company_name,\n  SUM(units_in_stock) AS all_units,\n  SUM(CASE\n    WHEN unit_price > 40.0 THEN units_in_stock\n    ELSE 0\n  END) AS expensive_units\nFROM products p\nJOIN suppliers s\n  ON p.supplier_id = s.supplier_id\nGROUP BY s.supplier_id,\n  s.company_name;\n```\n\n### 小结\n\n1. CASE WHEN语句检查一个或多个条件，并在找到第一个匹配条件时返回一个值。 如果没有`ELSE`子句并且没有匹配条件，则`CASE WHEN`返回`NULL`。\n\n   ```sql\n   CASE\n     WHEN condition_1 THEN result_1\n     WHEN condition_2 THEN result_2\n     ...\n     ELSE result\n   END\n   ```\n\n2. 要添加新列，从而对业务数据进行**自定义分组**，可以在`SELECT`子句中使用`CASE WHEN`：\n\n   ```sql\n   SELECT \n     CASE\n       WHEN ... THEN ...\n     END AS sample_column\n   FROM table;\n   ```\n\n3. 可以在“ GROUP BY”子句中使用“ CASE WHEN”来创建自己的分组。 同样的`CASE WHEN`子句也必须出现在`SELECT`子句中：\n\n   ```sql\n   SELECT \n     CASE\n       WHEN ... THEN ...\n     END AS sample_column,\n     COUNT(*) AS sample_count\n   FROM table\n     ...\n   GROUP BY\n     CASE WHEN ... THEN ...\n     END;\n   ```\n\n4. 可以在`COUNT()`或`SUM()`函数内使用`CASE WHEN`来创建业务对象的自定义计数：\n\n   ```sql\n   SELECT \n     COUNT(CASE\n       WHEN ... THEN column_name\n     END) AS count_column\n   FROM table;\n   ```\n\n   ```sql\n   SELECT \n     SUM(CASE\n       WHEN ... THEN 1\n     END) AS count_column\n   FROM table;\n   ```\n\n#### 练习28\n\n- 需求：创建报表来为每种商品添加价格标签，贵、中等、便宜\n- 结果包含如下字段：`product_id`, `product_name`, `unit_price`, 和 `price_level`\n- 价格等级`price_level`的取值说明：\n  - `'expensive'`  单价高于100的产品\n  - `'average'`  单价高于40但不超过100的产品\n  - `'cheap'`  其他产品\n\n```sql\nSELECT \n  product_id,\n  product_name,\n  unit_price,\n  CASE\n    WHEN unit_price > 100 THEN 'expensive'\n    WHEN unit_price > 40 THEN 'average'\n    ELSE 'cheap'\n  END AS price_level\nFROM products;\n```\n\n#### 练习29\n\n- 需求：制作报表统计所有订单的总价（不计任何折扣）对它们进行分类。\n- 包含一下字段：\n  - `order_id`\n  - `total_price`（折扣前）\n  - `price_group`\n- 字段 price_group 取值说明：\n  - 总价超过2000美元\n  - `'average'`，总价在$ 600到$ 2,000之间，包括两端\n  - `'low'` 总价低于$ 600\n\n```sql\nSELECT\n  order_id,\n  SUM(unit_price * quantity) AS total_price,\n  CASE\n    WHEN SUM(unit_price * quantity) > 2000 THEN 'high'\n    WHEN SUM(unit_price * quantity) > 600 THEN 'average'\n    ELSE 'low'\n  END AS price_group\nFROM order_items\nGROUP BY order_id;\n```\n\n#### 练习30\n\n- 需求：统计所有订单的运费，将运费高低分为三档\n- 报表中包含三个字段\n  - `low_freight` `freight`值小于“ 40.0”的订单数\n  - `avg_freight`  `freight`值大于或等于“ 40.0”但小于“ 80.0”的订单数\n  - `high_freight `  `freight`值大于或等于“ 80.0”的订单数\n\n```sql\nSELECT\n  COUNT(CASE\n    WHEN freight >= 80.0 THEN order_id\n  END) AS high_freight,\n  COUNT(CASE\n    WHEN freight < 40.0 THEN order_id\n  END) AS low_freight,\n  COUNT(CASE\n    WHEN freight >= 40.0 AND freight < 80.0 THEN order_id\n  END) AS avg_freight\nFROM orders;\n```\n\n\n\n\n\n\n\n数据\n\n```\n/*\n Navicat Premium Data Transfer\n\n Source Server         : localhost\n Source Server Type    : MySQL\n Source Server Version : 80022\n Source Host           : localhost:3306\n Source Schema         : test\n\n Target Server Type    : MySQL\n Target Server Version : 80022\n File Encoding         : 65001\n\n Date: 27/04/2021 19:38:18\n*/\n\nSET NAMES utf8mb4;\nSET FOREIGN_KEY_CHECKS = 0;\n\n-- ----------------------------\n-- Table structure for categories\n-- ----------------------------\nDROP TABLE IF EXISTS `categories`;\nCREATE TABLE `categories` (\n  `category_id` int NOT NULL,\n  `category_name` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `description` text CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci,\n  PRIMARY KEY (`category_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;\n\n-- ----------------------------\n-- Records of categories\n-- ----------------------------\nBEGIN;\nINSERT INTO `categories` VALUES (1, 'Beverages', 'Soft drinks, coffees, teas, beers, and ales');\nINSERT INTO `categories` VALUES (2, 'Condiments', 'Sweet and savory sauces, relishes, spreads, and seasonings');\nINSERT INTO `categories` VALUES (3, 'Confections', 'Desserts, candies, and sweet breads');\nINSERT INTO `categories` VALUES (4, 'Dairy Products', 'Cheeses');\nINSERT INTO `categories` VALUES (5, 'Grains/Cereals', 'Breads, crackers, pasta, and cereal');\nINSERT INTO `categories` VALUES (6, 'Meat/Poultry', 'Prepared meats');\nINSERT INTO `categories` VALUES (7, 'Produce', 'Dried fruit and bean curd');\nINSERT INTO `categories` VALUES (8, 'Seafood', 'Seaweed and fish');\nCOMMIT;\n\n-- ----------------------------\n-- Table structure for customers\n-- ----------------------------\nDROP TABLE IF EXISTS `customers`;\nCREATE TABLE `customers` (\n  `customer_id` varchar(5) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,\n  `company_name` varchar(40) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `contact_name` varchar(30) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `contact_title` varchar(30) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `address` varchar(60) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `city` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `region` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `postal_code` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `country` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `fax` varchar(24) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  PRIMARY KEY (`customer_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;\n\n-- ----------------------------\n-- Records of customers\n-- ----------------------------\nBEGIN;\nINSERT INTO `customers` VALUES ('ALFKI', 'Alfreds Futterkiste', 'Maria Anders', 'Sales Representative', 'Obere Str. 57', 'Berlin', NULL, '12209', 'Germany', '030-0076545');\nINSERT INTO `customers` VALUES ('ANATR', 'Ana Trujillo Emparedados y helados', 'Ana Trujillo', 'Owner', 'Avda. de la Constitución 2222', 'México D.F.', NULL, '5021', 'Mexico', '(5) 555-3745');\nINSERT INTO `customers` VALUES ('ANTON', 'Antonio Moreno Taquería', 'Antonio Moreno', 'Owner', 'Mataderos 2312', 'México D.F.', NULL, '5023', 'Mexico', NULL);\nINSERT INTO `customers` VALUES ('AROUT', 'Around the Horn', 'Thomas Hardy', 'Sales Representative', '120 Hanover Sq.', 'London', NULL, 'WA1 1DP', 'UK', '(171) 555-6750');\nINSERT INTO `customers` VALUES ('BERGS', 'Berglunds snabbköp', 'Christina Berglund', 'Order Administrator', 'Berguvsvägen 8', 'Luleå', NULL, 'S-958 22', 'Sweden', '0921-12 34 67');\nINSERT INTO `customers` VALUES ('BLAUS', 'Blauer See Delikatessen', 'Hanna Moos', 'Sales Representative', 'Forsterstr. 57', 'Mannheim', NULL, '68306', 'Germany', '0621-08924');\nINSERT INTO `customers` VALUES ('BLONP', 'Blondesddsl père et fils', 'Frédérique Citeaux', 'Marketing Manager', '24, place Kléber', 'Strasbourg', NULL, '67000', 'France', '88.60.15.32');\nINSERT INTO `customers` VALUES ('BOLID', 'Bólido Comidas preparadas', 'Martín Sommer', 'Owner', 'C/ Araquil, 67', 'Madrid', NULL, '28023', 'Spain', '(91) 555 91 99');\nINSERT INTO `customers` VALUES ('BONAP', 'Bon app\\'', 'Laurence Lebihan', 'Owner', '12, rue des Bouchers', 'Marseille', NULL, '13008', 'France', '91.24.45.41');\nINSERT INTO `customers` VALUES ('BOTTM', 'Bottom-Dollar Markets', 'Elizabeth Lincoln', 'Accounting Manager', '23 Tsawassen Blvd.', 'Tsawassen', 'BC', 'T2F 8M4', 'Canada', '(604) 555-3745');\nINSERT INTO `customers` VALUES ('BSBEV', 'B\\'s Beverages', 'Victoria Ashworth', 'Sales Representative', 'Fauntleroy Circus', 'London', NULL, 'EC2 5NT', 'UK', NULL);\nINSERT INTO `customers` VALUES ('CACTU', 'Cactus Comidas para llevar', 'Patricio Simpson', 'Sales Agent', 'Cerrito 333', 'Buenos Aires', NULL, '1010', 'Argentina', '(1) 135-4892');\nINSERT INTO `customers` VALUES ('CENTC', 'Centro comercial Moctezuma', 'Francisco Chang', 'Marketing Manager', 'Sierras de Granada 9993', 'México D.F.', NULL, '5022', 'Mexico', '(5) 555-7293');\nINSERT INTO `customers` VALUES ('CHOPS', 'Chop-suey Chinese', 'Yang Wang', 'Owner', 'Hauptstr. 29', 'Bern', NULL, '3012', 'Switzerland', NULL);\nINSERT INTO `customers` VALUES ('COMMI', 'Comércio Mineiro', 'Pedro Afonso', 'Sales Associate', 'Av. dos Lusíadas, 23', 'Sao Paulo', 'SP', '05432-043', 'Brazil', NULL);\nINSERT INTO `customers` VALUES ('CONSH', 'Consolidated Holdings', 'Elizabeth Brown', 'Sales Representative', 'Berkeley Gardens 12 Brewery', 'London', NULL, 'WX1 6LT', 'UK', '(171) 555-9199');\nINSERT INTO `customers` VALUES ('DRACD', 'Drachenblut Delikatessen', 'Sven Ottlieb', 'Order Administrator', 'Walserweg 21', 'Aachen', NULL, '52066', 'Germany', '0241-059428');\nINSERT INTO `customers` VALUES ('DUMON', 'Du monde entier', 'Janine Labrune', 'Owner', '67, rue des Cinquante Otages', 'Nantes', NULL, '44000', 'France', '40.67.89.89');\nINSERT INTO `customers` VALUES ('EASTC', 'Eastern Connection', 'Ann Devon', 'Sales Agent', '35 King George', 'London', NULL, 'WX3 6FW', 'UK', '(171) 555-3373');\nINSERT INTO `customers` VALUES ('ERNSH', 'Ernst Handel', 'Roland Mendel', 'Sales Manager', 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria', '7675-3426');\nINSERT INTO `customers` VALUES ('FAMIA', 'Familia Arquibaldo', 'Aria Cruz', 'Marketing Assistant', 'Rua Orós, 92', 'Sao Paulo', 'SP', '05442-030', 'Brazil', NULL);\nINSERT INTO `customers` VALUES ('FISSA', 'FISSA Fabrica Inter. Salchichas S.A.', 'Diego Roel', 'Accounting Manager', 'C/ Moralzarzal, 86', 'Madrid', NULL, '28034', 'Spain', '(91) 555 55 93');\nINSERT INTO `customers` VALUES ('FOLIG', 'Folies gourmandes', 'Martine Rancé', 'Assistant Sales Agent', '184, chaussée de Tournai', 'Lille', NULL, '59000', 'France', '20.16.10.17');\nINSERT INTO `customers` VALUES ('FOLKO', 'Folk och fä HB', 'Maria Larsson', 'Owner', 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden', NULL);\nINSERT INTO `customers` VALUES ('FRANK', 'Frankenversand', 'Peter Franken', 'Marketing Manager', 'Berliner Platz 43', 'München', NULL, '80805', 'Germany', '089-0877451');\nINSERT INTO `customers` VALUES ('FRANR', 'France restauration', 'Carine Schmitt', 'Marketing Manager', '54, rue Royale', 'Nantes', NULL, '44000', 'France', '40.32.21.20');\nINSERT INTO `customers` VALUES ('FRANS', 'Franchi S.p.A.', 'Paolo Accorti', 'Sales Representative', 'Via Monte Bianco 34', 'Torino', NULL, '10100', 'Italy', '011-4988261');\nINSERT INTO `customers` VALUES ('FURIB', 'Furia Bacalhau e Frutos do Mar', 'Lino Rodriguez', 'Sales Manager', 'Jardim das rosas n. 32', 'Lisboa', NULL, '1675', 'Portugal', '(1) 354-2535');\nINSERT INTO `customers` VALUES ('GALED', 'Galería del gastrónomo', 'Eduardo Saavedra', 'Marketing Manager', 'Rambla de Cataluña, 23', 'Barcelona', NULL, '8022', 'Spain', '(93) 203 4561');\nINSERT INTO `customers` VALUES ('GODOS', 'Godos Cocina Típica', 'José Pedro Freyre', 'Sales Manager', 'C/ Romero, 33', 'Sevilla', NULL, '41101', 'Spain', NULL);\nINSERT INTO `customers` VALUES ('GOURL', 'Gourmet Lanchonetes', 'André Fonseca', 'Sales Associate', 'Av. Brasil, 442', 'Campinas', 'SP', '04876-786', 'Brazil', NULL);\nINSERT INTO `customers` VALUES ('GREAL', 'Great Lakes Food Market', 'Howard Snyder', 'Marketing Manager', '2732 Baker Blvd.', 'Eugene', 'OR', '97403', 'USA', NULL);\nINSERT INTO `customers` VALUES ('GROSR', 'GROSELLA-Restaurante', 'Manuel Pereira', 'Owner', '5ª Ave. Los Palos Grandes', 'Caracas', 'DF', '1081', 'Venezuela', '(2) 283-3397');\nINSERT INTO `customers` VALUES ('HANAR', 'Hanari Carnes', 'Mario Pontes', 'Accounting Manager', 'Rua do Paço, 67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil', '(21) 555-8765');\nINSERT INTO `customers` VALUES ('HILAA', 'HILARION-Abastos', 'Carlos Hernández', 'Sales Representative', 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela', '(5) 555-1948');\nINSERT INTO `customers` VALUES ('HUNGC', 'Hungry Coyote Import Store', 'Yoshi Latimer', 'Sales Representative', 'City Center Plaza 516 Main St.', 'Elgin', 'OR', '97827', 'USA', '(503) 555-2376');\nINSERT INTO `customers` VALUES ('HUNGO', 'Hungry Owl All-Night Grocers', 'Patricia McKenna', 'Sales Associate', '8 Johnstown Road', 'Cork', 'Co. Cork', 'null', 'Ireland', '2967 3333');\nINSERT INTO `customers` VALUES ('ISLAT', 'Island Trading', 'Helen Bennett', 'Marketing Manager', 'Garden House Crowther Way', 'Cowes', 'Isle of Wight', 'PO31 7PJ', 'UK', NULL);\nINSERT INTO `customers` VALUES ('KOENE', 'Königlich Essen', 'Philip Cramer', 'Sales Associate', 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany', NULL);\nINSERT INTO `customers` VALUES ('LACOR', 'La corne d\\'abondance', 'Daniel Tonini', 'Sales Representative', '67, avenue de l\\'Europe', 'Versailles', NULL, '78000', 'France', '30.59.85.11');\nINSERT INTO `customers` VALUES ('LAMAI', 'La maison d\\'Asie', 'Annette Roulet', 'Sales Manager', '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France', '61.77.61.11');\nINSERT INTO `customers` VALUES ('LAUGB', 'Laughing Bacchus Wine Cellars', 'Yoshi Tannamuri', 'Marketing Assistant', '1900 Oak St.', 'Vancouver', 'BC', 'V3F 2K1', 'Canada', '(604) 555-7293');\nINSERT INTO `customers` VALUES ('LAZYK', 'Lazy K Kountry Store', 'John Steel', 'Marketing Manager', '12 Orchestra Terrace', 'Walla Walla', 'WA', '99362', 'USA', '(509) 555-6221');\nINSERT INTO `customers` VALUES ('LEHMS', 'Lehmanns Marktstand', 'Renate Messner', 'Sales Representative', 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany', '069-0245874');\nINSERT INTO `customers` VALUES ('LETSS', 'Let\\'s Stop N Shop', 'Jaime Yorres', 'Owner', '87 Polk St. Suite 5', 'San Francisco', 'CA', '94117', 'USA', NULL);\nINSERT INTO `customers` VALUES ('LILAS', 'LILA-Supermercado', 'Carlos González', 'Accounting Manager', 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela', '(9) 331-7256');\nINSERT INTO `customers` VALUES ('LINOD', 'LINO-Delicateses', 'Felipe Izquierdo', 'Owner', 'Ave. 5 de Mayo Porlamar', 'I. de Margarita', 'Nueva Esparta', '4980', 'Venezuela', '(8) 34-93-93');\nINSERT INTO `customers` VALUES ('LONEP', 'Lonesome Pine Restaurant', 'Fran Wilson', 'Sales Manager', '89 Chiaroscuro Rd.', 'Portland', 'OR', '97219', 'USA', '(503) 555-9646');\nINSERT INTO `customers` VALUES ('MAGAA', 'Magazzini Alimentari Riuniti', 'Giovanni Rovelli', 'Marketing Manager', 'Via Ludovico il Moro 22', 'Bergamo', NULL, '24100', 'Italy', '035-640231');\nINSERT INTO `customers` VALUES ('MAISD', 'Maison Dewey', 'Catherine Dewey', 'Sales Agent', 'Rue Joseph-Bens 532', 'Bruxelles', NULL, 'B-1180', 'Belgium', '(02) 201 24 68');\nINSERT INTO `customers` VALUES ('MEREP', 'Mère Paillarde', 'Jean Fresnière', 'Marketing Assistant', '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada', '(514) 555-8055');\nINSERT INTO `customers` VALUES ('MORGK', 'Morgenstern Gesundkost', 'Alexander Feuer', 'Marketing Assistant', 'Heerstr. 22', 'Leipzig', NULL, '4179', 'Germany', NULL);\nINSERT INTO `customers` VALUES ('NORTS', 'North/South', 'Simon Crowther', 'Sales Associate', 'South House 300 Queensbridge', 'London', NULL, 'SW7 1RZ', 'UK', '(171) 555-2530');\nINSERT INTO `customers` VALUES ('OCEAN', 'Océano Atlántico Ltda.', 'Yvonne Moncada', 'Sales Agent', 'Ing. Gustavo Moncada 8585 Piso 20-A', 'Buenos Aires', NULL, '1010', 'Argentina', '(1) 135-5535');\nINSERT INTO `customers` VALUES ('OLDWO', 'Old World Delicatessen', 'Rene Phillips', 'Sales Representative', '2743 Bering St.', 'Anchorage', 'AK', '99508', 'USA', '(907) 555-2880');\nINSERT INTO `customers` VALUES ('OTTIK', 'Ottilies Käseladen', 'Henriette Pfalzheim', 'Owner', 'Mehrheimerstr. 369', 'Köln', NULL, '50739', 'Germany', '0221-0765721');\nINSERT INTO `customers` VALUES ('PARIS', 'Paris spécialités', 'Marie Bertrand', 'Owner', '265, boulevard Charonne', 'Paris', NULL, '75012', 'France', '(1) 42.34.22.77');\nINSERT INTO `customers` VALUES ('PERIC', 'Pericles Comidas clásicas', 'Guillermo Fernández', 'Sales Representative', 'Calle Dr. Jorge Cash 321', 'México D.F.', NULL, '5033', 'Mexico', '(5) 545-3745');\nINSERT INTO `customers` VALUES ('PICCO', 'Piccolo und mehr', 'Georg Pipps', 'Sales Manager', 'Geislweg 14', 'Salzburg', NULL, '5020', 'Austria', '6562-9723');\nINSERT INTO `customers` VALUES ('PRINI', 'Princesa Isabel Vinhos', 'Isabel de Castro', 'Sales Representative', 'Estrada da saúde n. 58', 'Lisboa', NULL, '1756', 'Portugal', NULL);\nINSERT INTO `customers` VALUES ('QUEDE', 'Que Delícia', 'Bernardo Batista', 'Accounting Manager', 'Rua da Panificadora, 12', 'Rio de Janeiro', 'RJ', '02389-673', 'Brazil', '(21) 555-4545');\nINSERT INTO `customers` VALUES ('QUEEN', 'Queen Cozinha', 'Lúcia Carvalho', 'Marketing Assistant', 'Alameda dos Canàrios, 891', 'Sao Paulo', 'SP', '05487-020', 'Brazil', NULL);\nINSERT INTO `customers` VALUES ('QUICK', 'QUICK-Stop', 'Horst Kloss', 'Accounting Manager', 'Taucherstraße 10', 'Cunewalde', NULL, '1307', 'Germany', NULL);\nINSERT INTO `customers` VALUES ('RANCH', 'Rancho grande', 'Sergio Gutiérrez', 'Sales Representative', 'Av. del Libertador 900', 'Buenos Aires', NULL, '1010', 'Argentina', '(1) 123-5556');\nINSERT INTO `customers` VALUES ('RATTC', 'Rattlesnake Canyon Grocery', 'Paula Wilson', 'Assistant Sales Representative', '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA', '(505) 555-3620');\nINSERT INTO `customers` VALUES ('REGGC', 'Reggiani Caseifici', 'Maurizio Moroni', 'Sales Associate', 'Strada Provinciale 124', 'Reggio Emilia', NULL, '42100', 'Italy', '0522-556722');\nINSERT INTO `customers` VALUES ('RICAR', 'Ricardo Adocicados', 'Janete Limeira', 'Assistant Sales Agent', 'Av. Copacabana, 267', 'Rio de Janeiro', 'RJ', '02389-890', 'Brazil', NULL);\nINSERT INTO `customers` VALUES ('RICSU', 'Richter Supermarkt', 'Michael Holz', 'Sales Manager', 'Grenzacherweg 237', 'Genève', NULL, '1203', 'Switzerland', NULL);\nINSERT INTO `customers` VALUES ('ROMEY', 'Romero y tomillo', 'Alejandra Camino', 'Accounting Manager', 'Gran Vía, 1', 'Madrid', NULL, '28001', 'Spain', '(91) 745 6210');\nINSERT INTO `customers` VALUES ('SANTG', 'Santé Gourmet', 'Jonas Bergulfsen', 'Owner', 'Erling Skakkes gate 78', 'Stavern', NULL, '4110', 'Norway', '07-98 92 47');\nINSERT INTO `customers` VALUES ('SAVEA', 'Save-a-lot Markets', 'Jose Pavarotti', 'Sales Representative', '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA', NULL);\nINSERT INTO `customers` VALUES ('SEVES', 'Seven Seas Imports', 'Hari Kumar', 'Sales Manager', '90 Wadhurst Rd.', 'London', NULL, 'OX15 4NB', 'UK', '(171) 555-5646');\nINSERT INTO `customers` VALUES ('SIMOB', 'Simons bistro', 'Jytte Petersen', 'Owner', 'Vinbæltet 34', 'Kobenhavn', NULL, '1734', 'Denmark', '31 13 35 57');\nINSERT INTO `customers` VALUES ('SPECD', 'Spécialités du monde', 'Dominique Perrier', 'Marketing Manager', '25, rue Lauriston', 'Paris', NULL, '75016', 'France', '(1) 47.55.60.20');\nINSERT INTO `customers` VALUES ('SPLIR', 'Split Rail Beer & Ale', 'Art Braunschweiger', 'Sales Manager', 'P.O. Box 555', 'Lander', 'WY', '82520', 'USA', '(307) 555-6525');\nINSERT INTO `customers` VALUES ('SUPRD', 'Suprêmes délices', 'Pascale Cartrain', 'Accounting Manager', 'Boulevard Tirou, 255', 'Charleroi', NULL, 'B-6000', 'Belgium', '(071) 23 67 22 21');\nINSERT INTO `customers` VALUES ('THEBI', 'The Big Cheese', 'Liz Nixon', 'Marketing Manager', '89 Jefferson Way Suite 2', 'Portland', 'OR', '97201', 'USA', NULL);\nINSERT INTO `customers` VALUES ('THECR', 'The Cracker Box', 'Liu Wong', 'Marketing Assistant', '55 Grizzly Peak Rd.', 'Butte', 'MT', '59801', 'USA', '(406) 555-8083');\nINSERT INTO `customers` VALUES ('TOMSP', 'Toms Spezialitäten', 'Karin Josephs', 'Marketing Manager', 'Luisenstr. 48', 'Münster', NULL, '44087', 'Germany', '0251-035695');\nINSERT INTO `customers` VALUES ('TORTU', 'Tortuga Restaurante', 'Miguel Angel Paolino', 'Owner', 'Avda. Azteca 123', 'México D.F.', NULL, '5033', 'Mexico', NULL);\nINSERT INTO `customers` VALUES ('TRADH', 'Tradição Hipermercados', 'Anabela Domingues', 'Sales Representative', 'Av. Inês de Castro, 414', 'Sao Paulo', 'SP', '05634-030', 'Brazil', '(11) 555-2168');\nINSERT INTO `customers` VALUES ('TRAIH', 'Trail\\'s Head Gourmet Provisioners', 'Helvetius Nagy', 'Sales Associate', '722 DaVinci Blvd.', 'Kirkland', 'WA', '98034', 'USA', '(206) 555-2174');\nINSERT INTO `customers` VALUES ('VAFFE', 'Vaffeljernet', 'Palle Ibsen', 'Sales Manager', 'Smagsloget 45', 'Århus', NULL, '8200', 'Denmark', '86 22 33 44');\nINSERT INTO `customers` VALUES ('VICTE', 'Victuailles en stock', 'Mary Saveley', 'Sales Agent', '2, rue du Commerce', 'Lyon', NULL, '69004', 'France', '78.32.54.87');\nINSERT INTO `customers` VALUES ('VINET', 'Vins et alcools Chevalier', 'Paul Henriot', 'Accounting Manager', '59 rue de l\\'Abbaye', 'Reims', NULL, '51100', 'France', '26.47.15.11');\nINSERT INTO `customers` VALUES ('WANDK', 'Die Wandernde Kuh', 'Rita Müller', 'Sales Representative', 'Adenauerallee 900', 'Stuttgart', NULL, '70563', 'Germany', '0711-035428');\nINSERT INTO `customers` VALUES ('WARTH', 'Wartian Herkku', 'Pirkko Koskitalo', 'Accounting Manager', 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland', '981-443655');\nINSERT INTO `customers` VALUES ('WELLI', 'Wellington Importadora', 'Paula Parente', 'Sales Manager', 'Rua do Mercado, 12', 'Resende', 'SP', '08737-363', 'Brazil', NULL);\nINSERT INTO `customers` VALUES ('WHITC', 'White Clover Markets', 'Karl Jablonski', 'Owner', '305 - 14th Ave. S. Suite 3B', 'Seattle', 'WA', '98128', 'USA', '(206) 555-4115');\nINSERT INTO `customers` VALUES ('WILMK', 'Wilman Kala', 'Matti Karttunen', 'Owner/Marketing Assistant', 'Keskuskatu 45', 'Helsinki', NULL, '21240', 'Finland', '90-224 8858');\nINSERT INTO `customers` VALUES ('WOLZA', 'Wolski Zajazd', 'Zbyszek Piestrzeniewicz', 'Owner', 'ul. Filtrowa 68', 'Warszawa', NULL, '01-012', 'Poland', '(26) 642-7012');\nCOMMIT;\n\n-- ----------------------------\n-- Table structure for employees\n-- ----------------------------\nDROP TABLE IF EXISTS `employees`;\nCREATE TABLE `employees` (\n  `employee_id` int NOT NULL,\n  `last_name` varchar(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `first_name` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `title` varchar(30) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `birth_date` datetime DEFAULT NULL,\n  `hire_date` datetime DEFAULT NULL,\n  `address` varchar(60) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `city` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `region` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `postal_code` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `country` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `reports_to` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  PRIMARY KEY (`employee_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;\n\n-- ----------------------------\n-- Records of employees\n-- ----------------------------\nBEGIN;\nINSERT INTO `employees` VALUES (1, 'Davolio', 'Nancy', 'Sales Representative', '1968-12-08 00:00:00', '2012-05-01 00:00:00', '507 - 20th Ave. E. Apt. 2A', 'Seattle', 'WA', '98122', 'USA', '2');\nINSERT INTO `employees` VALUES (2, 'Fuller', 'Andrew', 'Vice President, Sales', '1972-02-19 00:00:00', '2012-08-14 00:00:00', '908 W. Capital Way', 'Tacoma', 'WA', '98401', 'USA', NULL);\nINSERT INTO `employees` VALUES (3, 'Smith', 'John', 'Sales Representative', '1983-08-30 00:00:00', '2012-04-01 00:00:00', '722 Moss Bay Blvd.', 'Kirkland', 'WA', '98033', 'USA', '2');\nINSERT INTO `employees` VALUES (4, 'Peacock', 'Margaret', 'Sales Representative', '1957-09-19 00:00:00', '2013-05-03 00:00:00', '4110 Old Redmond Rd.', 'Redmond', 'WA', '98052', 'USA', '2');\nINSERT INTO `employees` VALUES (5, 'Buchanan', 'Steven', 'Sales Manager', '1975-03-04 00:00:00', '2013-10-17 00:00:00', '14 Garrett Hill', 'London', 'null', 'SW1 8JR', 'UK', '2');\nINSERT INTO `employees` VALUES (6, 'Suyama', 'Michael', 'Sales Representative', '1983-07-02 00:00:00', '2013-10-17 00:00:00', 'Coventry House Miner Rd.', 'London', 'null', 'EC2 7JR', 'UK', '5');\nINSERT INTO `employees` VALUES (7, 'King', 'Robert', 'Sales Representative', '1980-05-29 00:00:00', '2014-01-02 00:00:00', 'Edgeham Hollow Winchester Way', 'London', 'null', 'RG1 9SP', 'UK', '5');\nINSERT INTO `employees` VALUES (8, 'Callahan', 'Laura', 'Inside Sales Coordinator', '1978-01-09 00:00:00', '2014-03-05 00:00:00', '4726 - 11th Ave. N.E.', 'Seattle', 'WA', '98105', 'USA', '2');\nINSERT INTO `employees` VALUES (9, 'Dodsworth', 'Anne', 'Sales Representative', '1986-01-27 00:00:00', '2014-11-15 00:00:00', '7 Houndstooth Rd.', 'London', 'null', 'WG2 7LT', 'UK', '5');\nINSERT INTO `employees` VALUES (10, 'Smith', 'John', 'Sales Representative', '1994-08-30 00:00:00', '2017-03-21 00:00:00', '22 Abbey Rd', 'London', 'null', 'NW6 5JG', 'UK', '2');\nCOMMIT;\n\n-- ----------------------------\n-- Table structure for order_items\n-- ----------------------------\nDROP TABLE IF EXISTS `order_items`;\nCREATE TABLE `order_items` (\n  `order_id` int NOT NULL,\n  `product_id` int NOT NULL,\n  `unit_price` decimal(10,2) DEFAULT NULL,\n  `quantity` smallint DEFAULT NULL,\n  `discount` double(24,2) DEFAULT NULL,\n  PRIMARY KEY (`order_id`,`product_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;\n\n-- ----------------------------\n-- Records of order_items\n-- ----------------------------\nBEGIN;\nINSERT INTO `order_items` VALUES (10248, 11, 14.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10248, 42, 9.80, 10, 0.00);\nINSERT INTO `order_items` VALUES (10248, 72, 34.80, 5, 0.00);\nINSERT INTO `order_items` VALUES (10249, 14, 18.60, 9, 0.00);\nINSERT INTO `order_items` VALUES (10249, 51, 42.40, 40, 0.00);\nINSERT INTO `order_items` VALUES (10250, 41, 7.70, 10, 0.00);\nINSERT INTO `order_items` VALUES (10250, 51, 42.40, 35, 0.15);\nINSERT INTO `order_items` VALUES (10250, 65, 16.80, 15, 0.15);\nINSERT INTO `order_items` VALUES (10251, 22, 16.80, 6, 0.05);\nINSERT INTO `order_items` VALUES (10251, 57, 15.60, 15, 0.05);\nINSERT INTO `order_items` VALUES (10251, 65, 16.80, 20, 0.00);\nINSERT INTO `order_items` VALUES (10252, 20, 64.80, 40, 0.05);\nINSERT INTO `order_items` VALUES (10252, 33, 2.00, 25, 0.05);\nINSERT INTO `order_items` VALUES (10252, 60, 27.20, 40, 0.00);\nINSERT INTO `order_items` VALUES (10253, 31, 10.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10253, 39, 14.40, 42, 0.00);\nINSERT INTO `order_items` VALUES (10253, 49, 16.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10254, 24, 3.60, 15, 0.15);\nINSERT INTO `order_items` VALUES (10254, 55, 19.20, 21, 0.15);\nINSERT INTO `order_items` VALUES (10254, 74, 8.00, 21, 0.00);\nINSERT INTO `order_items` VALUES (10255, 2, 15.20, 20, 0.00);\nINSERT INTO `order_items` VALUES (10255, 16, 13.90, 35, 0.00);\nINSERT INTO `order_items` VALUES (10255, 36, 15.20, 25, 0.00);\nINSERT INTO `order_items` VALUES (10255, 59, 44.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10256, 53, 26.20, 15, 0.00);\nINSERT INTO `order_items` VALUES (10256, 77, 10.40, 12, 0.00);\nINSERT INTO `order_items` VALUES (10257, 27, 35.10, 25, 0.00);\nINSERT INTO `order_items` VALUES (10257, 39, 14.40, 6, 0.00);\nINSERT INTO `order_items` VALUES (10257, 77, 10.40, 15, 0.00);\nINSERT INTO `order_items` VALUES (10258, 2, 15.20, 50, 0.20);\nINSERT INTO `order_items` VALUES (10258, 5, 17.00, 65, 0.20);\nINSERT INTO `order_items` VALUES (10258, 32, 25.60, 6, 0.20);\nINSERT INTO `order_items` VALUES (10259, 21, 8.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10259, 37, 20.80, 1, 0.00);\nINSERT INTO `order_items` VALUES (10260, 41, 7.70, 16, 0.25);\nINSERT INTO `order_items` VALUES (10260, 57, 15.60, 50, 0.00);\nINSERT INTO `order_items` VALUES (10260, 62, 39.40, 15, 0.25);\nINSERT INTO `order_items` VALUES (10260, 70, 12.00, 21, 0.25);\nINSERT INTO `order_items` VALUES (10261, 21, 8.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10261, 35, 14.40, 20, 0.00);\nINSERT INTO `order_items` VALUES (10262, 5, 17.00, 12, 0.20);\nINSERT INTO `order_items` VALUES (10262, 7, 24.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10262, 56, 30.40, 2, 0.00);\nINSERT INTO `order_items` VALUES (10263, 16, 13.90, 60, 0.25);\nINSERT INTO `order_items` VALUES (10263, 24, 3.60, 28, 0.00);\nINSERT INTO `order_items` VALUES (10263, 30, 20.70, 60, 0.25);\nINSERT INTO `order_items` VALUES (10263, 74, 8.00, 36, 0.25);\nINSERT INTO `order_items` VALUES (10264, 2, 15.20, 35, 0.00);\nINSERT INTO `order_items` VALUES (10264, 41, 7.70, 25, 0.15);\nINSERT INTO `order_items` VALUES (10265, 17, 31.20, 30, 0.00);\nINSERT INTO `order_items` VALUES (10265, 70, 12.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10266, 12, 30.40, 12, 0.05);\nINSERT INTO `order_items` VALUES (10267, 40, 14.70, 50, 0.00);\nINSERT INTO `order_items` VALUES (10267, 59, 44.00, 70, 0.15);\nINSERT INTO `order_items` VALUES (10267, 76, 14.40, 15, 0.15);\nINSERT INTO `order_items` VALUES (10268, 29, 99.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10268, 72, 27.80, 4, 0.00);\nINSERT INTO `order_items` VALUES (10269, 33, 2.00, 60, 0.05);\nINSERT INTO `order_items` VALUES (10269, 72, 27.80, 20, 0.05);\nINSERT INTO `order_items` VALUES (10270, 36, 15.20, 30, 0.00);\nINSERT INTO `order_items` VALUES (10270, 43, 36.80, 25, 0.00);\nINSERT INTO `order_items` VALUES (10271, 33, 2.00, 24, 0.00);\nINSERT INTO `order_items` VALUES (10272, 20, 64.80, 6, 0.00);\nINSERT INTO `order_items` VALUES (10272, 31, 10.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10272, 72, 27.80, 24, 0.00);\nINSERT INTO `order_items` VALUES (10273, 10, 24.80, 24, 0.05);\nINSERT INTO `order_items` VALUES (10273, 31, 10.00, 15, 0.05);\nINSERT INTO `order_items` VALUES (10273, 33, 2.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10273, 40, 14.70, 60, 0.05);\nINSERT INTO `order_items` VALUES (10273, 76, 14.40, 33, 0.05);\nINSERT INTO `order_items` VALUES (10274, 71, 17.20, 20, 0.00);\nINSERT INTO `order_items` VALUES (10274, 72, 27.80, 7, 0.00);\nINSERT INTO `order_items` VALUES (10275, 24, 3.60, 12, 0.05);\nINSERT INTO `order_items` VALUES (10275, 59, 44.00, 6, 0.05);\nINSERT INTO `order_items` VALUES (10276, 10, 24.80, 15, 0.00);\nINSERT INTO `order_items` VALUES (10276, 13, 4.80, 10, 0.00);\nINSERT INTO `order_items` VALUES (10277, 28, 36.40, 20, 0.00);\nINSERT INTO `order_items` VALUES (10277, 62, 39.40, 12, 0.00);\nINSERT INTO `order_items` VALUES (10278, 44, 15.50, 16, 0.00);\nINSERT INTO `order_items` VALUES (10278, 59, 44.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10278, 63, 35.10, 8, 0.00);\nINSERT INTO `order_items` VALUES (10278, 73, 12.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10279, 17, 31.20, 15, 0.25);\nINSERT INTO `order_items` VALUES (10280, 24, 3.60, 12, 0.00);\nINSERT INTO `order_items` VALUES (10280, 55, 19.20, 20, 0.00);\nINSERT INTO `order_items` VALUES (10280, 75, 6.20, 30, 0.00);\nINSERT INTO `order_items` VALUES (10281, 19, 7.30, 1, 0.00);\nINSERT INTO `order_items` VALUES (10281, 24, 3.60, 6, 0.00);\nINSERT INTO `order_items` VALUES (10281, 35, 14.40, 4, 0.00);\nINSERT INTO `order_items` VALUES (10282, 30, 20.70, 6, 0.00);\nINSERT INTO `order_items` VALUES (10282, 57, 15.60, 2, 0.00);\nINSERT INTO `order_items` VALUES (10283, 15, 12.40, 20, 0.00);\nINSERT INTO `order_items` VALUES (10283, 19, 7.30, 18, 0.00);\nINSERT INTO `order_items` VALUES (10283, 60, 27.20, 35, 0.00);\nINSERT INTO `order_items` VALUES (10283, 72, 27.80, 3, 0.00);\nINSERT INTO `order_items` VALUES (10284, 27, 35.10, 15, 0.25);\nINSERT INTO `order_items` VALUES (10284, 44, 15.50, 21, 0.00);\nINSERT INTO `order_items` VALUES (10284, 60, 27.20, 20, 0.25);\nINSERT INTO `order_items` VALUES (10284, 67, 11.20, 5, 0.25);\nINSERT INTO `order_items` VALUES (10285, 1, 14.40, 45, 0.20);\nINSERT INTO `order_items` VALUES (10285, 40, 14.70, 40, 0.20);\nINSERT INTO `order_items` VALUES (10285, 53, 26.20, 36, 0.20);\nINSERT INTO `order_items` VALUES (10286, 35, 14.40, 100, 0.00);\nINSERT INTO `order_items` VALUES (10286, 62, 39.40, 40, 0.00);\nINSERT INTO `order_items` VALUES (10287, 16, 13.90, 40, 0.15);\nINSERT INTO `order_items` VALUES (10287, 34, 11.20, 20, 0.00);\nINSERT INTO `order_items` VALUES (10287, 46, 9.60, 15, 0.15);\nINSERT INTO `order_items` VALUES (10288, 54, 5.90, 10, 0.10);\nINSERT INTO `order_items` VALUES (10288, 68, 10.00, 3, 0.10);\nINSERT INTO `order_items` VALUES (10289, 3, 8.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10289, 64, 26.60, 9, 0.00);\nINSERT INTO `order_items` VALUES (10290, 5, 17.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10290, 29, 99.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10290, 49, 16.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10290, 77, 10.40, 10, 0.00);\nINSERT INTO `order_items` VALUES (10291, 13, 4.80, 20, 0.10);\nINSERT INTO `order_items` VALUES (10291, 44, 15.50, 24, 0.10);\nINSERT INTO `order_items` VALUES (10291, 51, 42.40, 2, 0.10);\nINSERT INTO `order_items` VALUES (10292, 20, 64.80, 20, 0.00);\nINSERT INTO `order_items` VALUES (10293, 18, 50.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10293, 24, 3.60, 10, 0.00);\nINSERT INTO `order_items` VALUES (10293, 63, 35.10, 5, 0.00);\nINSERT INTO `order_items` VALUES (10293, 75, 6.20, 6, 0.00);\nINSERT INTO `order_items` VALUES (10294, 1, 14.40, 18, 0.00);\nINSERT INTO `order_items` VALUES (10294, 17, 31.20, 15, 0.00);\nINSERT INTO `order_items` VALUES (10294, 43, 36.80, 15, 0.00);\nINSERT INTO `order_items` VALUES (10294, 60, 27.20, 21, 0.00);\nINSERT INTO `order_items` VALUES (10294, 75, 6.20, 6, 0.00);\nINSERT INTO `order_items` VALUES (10295, 56, 30.40, 4, 0.00);\nINSERT INTO `order_items` VALUES (10296, 11, 16.80, 12, 0.00);\nINSERT INTO `order_items` VALUES (10296, 16, 13.90, 30, 0.00);\nINSERT INTO `order_items` VALUES (10296, 69, 28.80, 15, 0.00);\nINSERT INTO `order_items` VALUES (10297, 39, 14.40, 60, 0.00);\nINSERT INTO `order_items` VALUES (10297, 72, 27.80, 20, 0.00);\nINSERT INTO `order_items` VALUES (10298, 2, 15.20, 40, 0.00);\nINSERT INTO `order_items` VALUES (10298, 36, 15.20, 40, 0.25);\nINSERT INTO `order_items` VALUES (10298, 59, 44.00, 30, 0.25);\nINSERT INTO `order_items` VALUES (10298, 62, 39.40, 15, 0.00);\nINSERT INTO `order_items` VALUES (10299, 19, 7.30, 15, 0.00);\nINSERT INTO `order_items` VALUES (10299, 70, 12.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10300, 66, 13.60, 30, 0.00);\nINSERT INTO `order_items` VALUES (10300, 68, 10.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10301, 40, 14.70, 10, 0.00);\nINSERT INTO `order_items` VALUES (10301, 56, 30.40, 20, 0.00);\nINSERT INTO `order_items` VALUES (10302, 17, 31.20, 40, 0.00);\nINSERT INTO `order_items` VALUES (10302, 28, 36.40, 28, 0.00);\nINSERT INTO `order_items` VALUES (10302, 43, 36.80, 12, 0.00);\nINSERT INTO `order_items` VALUES (10303, 40, 14.70, 40, 0.10);\nINSERT INTO `order_items` VALUES (10303, 65, 16.80, 30, 0.10);\nINSERT INTO `order_items` VALUES (10303, 68, 10.00, 15, 0.10);\nINSERT INTO `order_items` VALUES (10304, 49, 16.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10304, 59, 44.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10304, 71, 17.20, 2, 0.00);\nINSERT INTO `order_items` VALUES (10305, 18, 50.00, 25, 0.10);\nINSERT INTO `order_items` VALUES (10305, 29, 99.00, 25, 0.10);\nINSERT INTO `order_items` VALUES (10305, 39, 14.40, 30, 0.10);\nINSERT INTO `order_items` VALUES (10306, 30, 20.70, 10, 0.00);\nINSERT INTO `order_items` VALUES (10306, 53, 26.20, 10, 0.00);\nINSERT INTO `order_items` VALUES (10306, 54, 5.90, 5, 0.00);\nINSERT INTO `order_items` VALUES (10307, 62, 39.40, 10, 0.00);\nINSERT INTO `order_items` VALUES (10307, 68, 10.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (10308, 69, 28.80, 1, 0.00);\nINSERT INTO `order_items` VALUES (10308, 70, 12.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10309, 4, 17.60, 20, 0.00);\nINSERT INTO `order_items` VALUES (10309, 6, 20.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10309, 42, 11.20, 2, 0.00);\nINSERT INTO `order_items` VALUES (10309, 43, 36.80, 20, 0.00);\nINSERT INTO `order_items` VALUES (10309, 71, 17.20, 3, 0.00);\nINSERT INTO `order_items` VALUES (10310, 16, 13.90, 10, 0.00);\nINSERT INTO `order_items` VALUES (10310, 62, 39.40, 5, 0.00);\nINSERT INTO `order_items` VALUES (10311, 42, 11.20, 6, 0.00);\nINSERT INTO `order_items` VALUES (10311, 69, 28.80, 7, 0.00);\nINSERT INTO `order_items` VALUES (10312, 28, 36.40, 4, 0.00);\nINSERT INTO `order_items` VALUES (10312, 43, 36.80, 24, 0.00);\nINSERT INTO `order_items` VALUES (10312, 53, 26.20, 20, 0.00);\nINSERT INTO `order_items` VALUES (10312, 75, 6.20, 10, 0.00);\nINSERT INTO `order_items` VALUES (10313, 36, 15.20, 12, 0.00);\nINSERT INTO `order_items` VALUES (10314, 32, 25.60, 40, 0.10);\nINSERT INTO `order_items` VALUES (10314, 58, 10.60, 30, 0.10);\nINSERT INTO `order_items` VALUES (10314, 62, 39.40, 25, 0.10);\nINSERT INTO `order_items` VALUES (10315, 34, 11.20, 14, 0.00);\nINSERT INTO `order_items` VALUES (10315, 70, 12.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10316, 41, 7.70, 10, 0.00);\nINSERT INTO `order_items` VALUES (10316, 62, 39.40, 70, 0.00);\nINSERT INTO `order_items` VALUES (10317, 1, 14.40, 20, 0.00);\nINSERT INTO `order_items` VALUES (10318, 41, 7.70, 20, 0.00);\nINSERT INTO `order_items` VALUES (10318, 76, 14.40, 6, 0.00);\nINSERT INTO `order_items` VALUES (10319, 17, 31.20, 8, 0.00);\nINSERT INTO `order_items` VALUES (10319, 28, 36.40, 14, 0.00);\nINSERT INTO `order_items` VALUES (10319, 76, 14.40, 30, 0.00);\nINSERT INTO `order_items` VALUES (10320, 71, 17.20, 30, 0.00);\nINSERT INTO `order_items` VALUES (10321, 35, 14.40, 10, 0.00);\nINSERT INTO `order_items` VALUES (10322, 52, 5.60, 20, 0.00);\nINSERT INTO `order_items` VALUES (10323, 15, 12.40, 5, 0.00);\nINSERT INTO `order_items` VALUES (10323, 25, 11.20, 4, 0.00);\nINSERT INTO `order_items` VALUES (10323, 39, 14.40, 4, 0.00);\nINSERT INTO `order_items` VALUES (10324, 16, 13.90, 21, 0.15);\nINSERT INTO `order_items` VALUES (10324, 35, 14.40, 70, 0.15);\nINSERT INTO `order_items` VALUES (10324, 46, 9.60, 30, 0.00);\nINSERT INTO `order_items` VALUES (10324, 59, 44.00, 40, 0.15);\nINSERT INTO `order_items` VALUES (10324, 63, 35.10, 80, 0.15);\nINSERT INTO `order_items` VALUES (10325, 6, 20.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10325, 13, 4.80, 12, 0.00);\nINSERT INTO `order_items` VALUES (10325, 14, 18.60, 9, 0.00);\nINSERT INTO `order_items` VALUES (10325, 31, 10.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10325, 72, 27.80, 40, 0.00);\nINSERT INTO `order_items` VALUES (10326, 4, 17.60, 24, 0.00);\nINSERT INTO `order_items` VALUES (10326, 57, 15.60, 16, 0.00);\nINSERT INTO `order_items` VALUES (10326, 75, 6.20, 50, 0.00);\nINSERT INTO `order_items` VALUES (10327, 2, 15.20, 25, 0.20);\nINSERT INTO `order_items` VALUES (10327, 11, 16.80, 50, 0.20);\nINSERT INTO `order_items` VALUES (10327, 30, 20.70, 35, 0.20);\nINSERT INTO `order_items` VALUES (10327, 58, 10.60, 30, 0.20);\nINSERT INTO `order_items` VALUES (10328, 59, 44.00, 9, 0.00);\nINSERT INTO `order_items` VALUES (10328, 65, 16.80, 40, 0.00);\nINSERT INTO `order_items` VALUES (10328, 68, 10.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10329, 19, 7.30, 10, 0.05);\nINSERT INTO `order_items` VALUES (10329, 30, 20.70, 8, 0.05);\nINSERT INTO `order_items` VALUES (10329, 38, 210.80, 20, 0.05);\nINSERT INTO `order_items` VALUES (10329, 56, 30.40, 12, 0.05);\nINSERT INTO `order_items` VALUES (10330, 26, 24.90, 50, 0.15);\nINSERT INTO `order_items` VALUES (10330, 72, 27.80, 25, 0.15);\nINSERT INTO `order_items` VALUES (10331, 54, 5.90, 15, 0.00);\nINSERT INTO `order_items` VALUES (10332, 18, 50.00, 40, 0.20);\nINSERT INTO `order_items` VALUES (10332, 42, 11.20, 10, 0.20);\nINSERT INTO `order_items` VALUES (10332, 47, 7.60, 16, 0.20);\nINSERT INTO `order_items` VALUES (10333, 14, 18.60, 10, 0.00);\nINSERT INTO `order_items` VALUES (10333, 21, 8.00, 10, 0.10);\nINSERT INTO `order_items` VALUES (10333, 71, 17.20, 40, 0.10);\nINSERT INTO `order_items` VALUES (10334, 52, 5.60, 8, 0.00);\nINSERT INTO `order_items` VALUES (10334, 68, 10.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10335, 2, 15.20, 7, 0.20);\nINSERT INTO `order_items` VALUES (10335, 31, 10.00, 25, 0.20);\nINSERT INTO `order_items` VALUES (10335, 32, 25.60, 6, 0.20);\nINSERT INTO `order_items` VALUES (10335, 51, 42.40, 48, 0.20);\nINSERT INTO `order_items` VALUES (10336, 4, 17.60, 18, 0.10);\nINSERT INTO `order_items` VALUES (10337, 23, 7.20, 40, 0.00);\nINSERT INTO `order_items` VALUES (10337, 26, 24.90, 24, 0.00);\nINSERT INTO `order_items` VALUES (10337, 36, 15.20, 20, 0.00);\nINSERT INTO `order_items` VALUES (10337, 37, 20.80, 28, 0.00);\nINSERT INTO `order_items` VALUES (10337, 72, 27.80, 25, 0.00);\nINSERT INTO `order_items` VALUES (10338, 17, 31.20, 20, 0.00);\nINSERT INTO `order_items` VALUES (10338, 30, 20.70, 15, 0.00);\nINSERT INTO `order_items` VALUES (10339, 4, 17.60, 10, 0.00);\nINSERT INTO `order_items` VALUES (10339, 17, 31.20, 70, 0.05);\nINSERT INTO `order_items` VALUES (10339, 62, 39.40, 28, 0.00);\nINSERT INTO `order_items` VALUES (10340, 18, 50.00, 20, 0.05);\nINSERT INTO `order_items` VALUES (10340, 41, 7.70, 12, 0.05);\nINSERT INTO `order_items` VALUES (10340, 43, 36.80, 40, 0.05);\nINSERT INTO `order_items` VALUES (10341, 33, 2.00, 8, 0.00);\nINSERT INTO `order_items` VALUES (10341, 59, 44.00, 9, 0.15);\nINSERT INTO `order_items` VALUES (10342, 2, 15.20, 24, 0.20);\nINSERT INTO `order_items` VALUES (10342, 31, 10.00, 56, 0.20);\nINSERT INTO `order_items` VALUES (10342, 36, 15.20, 40, 0.20);\nINSERT INTO `order_items` VALUES (10342, 55, 19.20, 40, 0.20);\nINSERT INTO `order_items` VALUES (10343, 64, 26.60, 50, 0.00);\nINSERT INTO `order_items` VALUES (10343, 68, 10.00, 4, 0.05);\nINSERT INTO `order_items` VALUES (10343, 76, 14.40, 15, 0.00);\nINSERT INTO `order_items` VALUES (10344, 4, 17.60, 35, 0.00);\nINSERT INTO `order_items` VALUES (10344, 8, 32.00, 70, 0.25);\nINSERT INTO `order_items` VALUES (10345, 8, 32.00, 70, 0.00);\nINSERT INTO `order_items` VALUES (10345, 19, 7.30, 80, 0.00);\nINSERT INTO `order_items` VALUES (10345, 42, 11.20, 9, 0.00);\nINSERT INTO `order_items` VALUES (10346, 17, 31.20, 36, 0.10);\nINSERT INTO `order_items` VALUES (10346, 56, 30.40, 20, 0.00);\nINSERT INTO `order_items` VALUES (10347, 25, 11.20, 10, 0.00);\nINSERT INTO `order_items` VALUES (10347, 39, 14.40, 50, 0.15);\nINSERT INTO `order_items` VALUES (10347, 40, 14.70, 4, 0.00);\nINSERT INTO `order_items` VALUES (10347, 75, 6.20, 6, 0.15);\nINSERT INTO `order_items` VALUES (10348, 1, 14.40, 15, 0.15);\nINSERT INTO `order_items` VALUES (10348, 23, 7.20, 25, 0.00);\nINSERT INTO `order_items` VALUES (10349, 54, 5.90, 24, 0.00);\nINSERT INTO `order_items` VALUES (10350, 50, 13.00, 15, 0.10);\nINSERT INTO `order_items` VALUES (10350, 69, 28.80, 18, 0.10);\nINSERT INTO `order_items` VALUES (10351, 38, 210.80, 20, 0.05);\nINSERT INTO `order_items` VALUES (10351, 41, 7.70, 13, 0.00);\nINSERT INTO `order_items` VALUES (10351, 44, 15.50, 77, 0.05);\nINSERT INTO `order_items` VALUES (10351, 65, 16.80, 10, 0.05);\nINSERT INTO `order_items` VALUES (10352, 24, 3.60, 10, 0.00);\nINSERT INTO `order_items` VALUES (10352, 54, 5.90, 20, 0.15);\nINSERT INTO `order_items` VALUES (10353, 11, 16.80, 12, 0.20);\nINSERT INTO `order_items` VALUES (10353, 38, 210.80, 50, 0.20);\nINSERT INTO `order_items` VALUES (10354, 1, 14.40, 12, 0.00);\nINSERT INTO `order_items` VALUES (10354, 29, 99.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10355, 24, 3.60, 25, 0.00);\nINSERT INTO `order_items` VALUES (10355, 57, 15.60, 25, 0.00);\nINSERT INTO `order_items` VALUES (10356, 31, 10.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10356, 55, 19.20, 12, 0.00);\nINSERT INTO `order_items` VALUES (10356, 69, 28.80, 20, 0.00);\nINSERT INTO `order_items` VALUES (10357, 10, 24.80, 30, 0.20);\nINSERT INTO `order_items` VALUES (10357, 26, 24.90, 16, 0.00);\nINSERT INTO `order_items` VALUES (10357, 60, 27.20, 8, 0.20);\nINSERT INTO `order_items` VALUES (10358, 24, 3.60, 10, 0.05);\nINSERT INTO `order_items` VALUES (10358, 34, 11.20, 10, 0.05);\nINSERT INTO `order_items` VALUES (10358, 36, 15.20, 20, 0.05);\nINSERT INTO `order_items` VALUES (10359, 16, 13.90, 56, 0.05);\nINSERT INTO `order_items` VALUES (10359, 31, 10.00, 70, 0.05);\nINSERT INTO `order_items` VALUES (10359, 60, 27.20, 80, 0.05);\nINSERT INTO `order_items` VALUES (10360, 28, 36.40, 30, 0.00);\nINSERT INTO `order_items` VALUES (10360, 29, 99.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (10360, 38, 210.80, 10, 0.00);\nINSERT INTO `order_items` VALUES (10360, 49, 16.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (10360, 54, 5.90, 28, 0.00);\nINSERT INTO `order_items` VALUES (10361, 39, 14.40, 54, 0.10);\nINSERT INTO `order_items` VALUES (10361, 60, 27.20, 55, 0.10);\nINSERT INTO `order_items` VALUES (10362, 25, 11.20, 50, 0.00);\nINSERT INTO `order_items` VALUES (10362, 51, 42.40, 20, 0.00);\nINSERT INTO `order_items` VALUES (10362, 54, 5.90, 24, 0.00);\nINSERT INTO `order_items` VALUES (10363, 31, 10.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10363, 75, 6.20, 12, 0.00);\nINSERT INTO `order_items` VALUES (10363, 76, 14.40, 12, 0.00);\nINSERT INTO `order_items` VALUES (10364, 69, 28.80, 30, 0.00);\nINSERT INTO `order_items` VALUES (10364, 71, 17.20, 5, 0.00);\nINSERT INTO `order_items` VALUES (10365, 11, 16.80, 24, 0.00);\nINSERT INTO `order_items` VALUES (10366, 65, 16.80, 5, 0.00);\nINSERT INTO `order_items` VALUES (10366, 77, 10.40, 5, 0.00);\nINSERT INTO `order_items` VALUES (10367, 34, 11.20, 36, 0.00);\nINSERT INTO `order_items` VALUES (10367, 54, 5.90, 18, 0.00);\nINSERT INTO `order_items` VALUES (10367, 65, 16.80, 15, 0.00);\nINSERT INTO `order_items` VALUES (10367, 77, 10.40, 7, 0.00);\nINSERT INTO `order_items` VALUES (10368, 21, 8.00, 5, 0.10);\nINSERT INTO `order_items` VALUES (10368, 28, 36.40, 13, 0.10);\nINSERT INTO `order_items` VALUES (10368, 57, 15.60, 25, 0.00);\nINSERT INTO `order_items` VALUES (10368, 64, 26.60, 35, 0.10);\nINSERT INTO `order_items` VALUES (10369, 29, 99.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10369, 56, 30.40, 18, 0.25);\nINSERT INTO `order_items` VALUES (10370, 1, 14.40, 15, 0.15);\nINSERT INTO `order_items` VALUES (10370, 64, 26.60, 30, 0.00);\nINSERT INTO `order_items` VALUES (10370, 74, 8.00, 20, 0.15);\nINSERT INTO `order_items` VALUES (10371, 36, 15.20, 6, 0.20);\nINSERT INTO `order_items` VALUES (10372, 20, 64.80, 12, 0.25);\nINSERT INTO `order_items` VALUES (10372, 38, 210.80, 40, 0.25);\nINSERT INTO `order_items` VALUES (10372, 60, 27.20, 70, 0.25);\nINSERT INTO `order_items` VALUES (10372, 72, 27.80, 42, 0.25);\nINSERT INTO `order_items` VALUES (10373, 58, 10.60, 80, 0.20);\nINSERT INTO `order_items` VALUES (10373, 71, 17.20, 50, 0.20);\nINSERT INTO `order_items` VALUES (10374, 31, 10.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10374, 58, 10.60, 15, 0.00);\nINSERT INTO `order_items` VALUES (10375, 14, 18.60, 15, 0.00);\nINSERT INTO `order_items` VALUES (10375, 54, 5.90, 10, 0.00);\nINSERT INTO `order_items` VALUES (10376, 31, 10.00, 42, 0.05);\nINSERT INTO `order_items` VALUES (10377, 28, 36.40, 20, 0.15);\nINSERT INTO `order_items` VALUES (10377, 39, 14.40, 20, 0.15);\nINSERT INTO `order_items` VALUES (10378, 71, 17.20, 6, 0.00);\nINSERT INTO `order_items` VALUES (10379, 41, 7.70, 8, 0.10);\nINSERT INTO `order_items` VALUES (10379, 63, 35.10, 16, 0.10);\nINSERT INTO `order_items` VALUES (10379, 65, 16.80, 20, 0.10);\nINSERT INTO `order_items` VALUES (10380, 30, 20.70, 18, 0.10);\nINSERT INTO `order_items` VALUES (10380, 53, 26.20, 20, 0.10);\nINSERT INTO `order_items` VALUES (10380, 60, 27.20, 6, 0.10);\nINSERT INTO `order_items` VALUES (10380, 70, 12.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10381, 74, 8.00, 14, 0.00);\nINSERT INTO `order_items` VALUES (10382, 5, 17.00, 32, 0.00);\nINSERT INTO `order_items` VALUES (10382, 18, 50.00, 9, 0.00);\nINSERT INTO `order_items` VALUES (10382, 29, 99.00, 14, 0.00);\nINSERT INTO `order_items` VALUES (10382, 33, 2.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10382, 74, 8.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10383, 13, 4.80, 20, 0.00);\nINSERT INTO `order_items` VALUES (10383, 50, 13.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10383, 56, 30.40, 20, 0.00);\nINSERT INTO `order_items` VALUES (10384, 20, 64.80, 28, 0.00);\nINSERT INTO `order_items` VALUES (10384, 60, 27.20, 15, 0.00);\nINSERT INTO `order_items` VALUES (10385, 7, 24.00, 10, 0.20);\nINSERT INTO `order_items` VALUES (10385, 60, 27.20, 20, 0.20);\nINSERT INTO `order_items` VALUES (10385, 68, 10.00, 8, 0.20);\nINSERT INTO `order_items` VALUES (10386, 24, 3.60, 15, 0.00);\nINSERT INTO `order_items` VALUES (10386, 34, 11.20, 10, 0.00);\nINSERT INTO `order_items` VALUES (10387, 24, 3.60, 15, 0.00);\nINSERT INTO `order_items` VALUES (10387, 28, 36.40, 6, 0.00);\nINSERT INTO `order_items` VALUES (10387, 59, 44.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10387, 71, 17.20, 15, 0.00);\nINSERT INTO `order_items` VALUES (10388, 45, 7.60, 15, 0.20);\nINSERT INTO `order_items` VALUES (10388, 52, 5.60, 20, 0.20);\nINSERT INTO `order_items` VALUES (10388, 53, 26.20, 40, 0.00);\nINSERT INTO `order_items` VALUES (10389, 10, 24.80, 16, 0.00);\nINSERT INTO `order_items` VALUES (10389, 55, 19.20, 15, 0.00);\nINSERT INTO `order_items` VALUES (10389, 62, 39.40, 20, 0.00);\nINSERT INTO `order_items` VALUES (10389, 70, 12.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10390, 31, 10.00, 60, 0.10);\nINSERT INTO `order_items` VALUES (10390, 35, 14.40, 40, 0.10);\nINSERT INTO `order_items` VALUES (10390, 46, 9.60, 45, 0.00);\nINSERT INTO `order_items` VALUES (10390, 72, 27.80, 24, 0.10);\nINSERT INTO `order_items` VALUES (10391, 13, 4.80, 18, 0.00);\nINSERT INTO `order_items` VALUES (10392, 69, 28.80, 50, 0.00);\nINSERT INTO `order_items` VALUES (10393, 2, 15.20, 25, 0.25);\nINSERT INTO `order_items` VALUES (10393, 14, 18.60, 42, 0.25);\nINSERT INTO `order_items` VALUES (10393, 25, 11.20, 7, 0.25);\nINSERT INTO `order_items` VALUES (10393, 26, 24.90, 70, 0.25);\nINSERT INTO `order_items` VALUES (10393, 31, 10.00, 32, 0.00);\nINSERT INTO `order_items` VALUES (10394, 13, 4.80, 10, 0.00);\nINSERT INTO `order_items` VALUES (10394, 62, 39.40, 10, 0.00);\nINSERT INTO `order_items` VALUES (10395, 46, 9.60, 28, 0.10);\nINSERT INTO `order_items` VALUES (10395, 53, 26.20, 70, 0.10);\nINSERT INTO `order_items` VALUES (10395, 69, 28.80, 8, 0.00);\nINSERT INTO `order_items` VALUES (10396, 23, 7.20, 40, 0.00);\nINSERT INTO `order_items` VALUES (10396, 71, 17.20, 60, 0.00);\nINSERT INTO `order_items` VALUES (10396, 72, 27.80, 21, 0.00);\nINSERT INTO `order_items` VALUES (10397, 21, 8.00, 10, 0.15);\nINSERT INTO `order_items` VALUES (10397, 51, 42.40, 18, 0.15);\nINSERT INTO `order_items` VALUES (10398, 35, 14.40, 30, 0.00);\nINSERT INTO `order_items` VALUES (10398, 55, 19.20, 120, 0.10);\nINSERT INTO `order_items` VALUES (10399, 68, 10.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10399, 71, 17.20, 30, 0.00);\nINSERT INTO `order_items` VALUES (10399, 76, 14.40, 35, 0.00);\nINSERT INTO `order_items` VALUES (10399, 77, 10.40, 14, 0.00);\nINSERT INTO `order_items` VALUES (10400, 29, 99.00, 21, 0.00);\nINSERT INTO `order_items` VALUES (10400, 35, 14.40, 35, 0.00);\nINSERT INTO `order_items` VALUES (10400, 49, 16.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10401, 30, 20.70, 18, 0.00);\nINSERT INTO `order_items` VALUES (10401, 56, 30.40, 70, 0.00);\nINSERT INTO `order_items` VALUES (10401, 65, 16.80, 20, 0.00);\nINSERT INTO `order_items` VALUES (10401, 71, 17.20, 60, 0.00);\nINSERT INTO `order_items` VALUES (10402, 23, 7.20, 60, 0.00);\nINSERT INTO `order_items` VALUES (10402, 63, 35.10, 65, 0.00);\nINSERT INTO `order_items` VALUES (10403, 16, 13.90, 21, 0.15);\nINSERT INTO `order_items` VALUES (10403, 48, 10.20, 70, 0.15);\nINSERT INTO `order_items` VALUES (10404, 26, 24.90, 30, 0.05);\nINSERT INTO `order_items` VALUES (10404, 42, 11.20, 40, 0.05);\nINSERT INTO `order_items` VALUES (10404, 49, 16.00, 30, 0.05);\nINSERT INTO `order_items` VALUES (10405, 3, 8.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10406, 1, 14.40, 10, 0.00);\nINSERT INTO `order_items` VALUES (10406, 21, 8.00, 30, 0.10);\nINSERT INTO `order_items` VALUES (10406, 28, 36.40, 42, 0.10);\nINSERT INTO `order_items` VALUES (10406, 36, 15.20, 5, 0.10);\nINSERT INTO `order_items` VALUES (10406, 40, 14.70, 2, 0.10);\nINSERT INTO `order_items` VALUES (10407, 11, 16.80, 30, 0.00);\nINSERT INTO `order_items` VALUES (10407, 69, 28.80, 15, 0.00);\nINSERT INTO `order_items` VALUES (10407, 71, 17.20, 15, 0.00);\nINSERT INTO `order_items` VALUES (10408, 37, 20.80, 10, 0.00);\nINSERT INTO `order_items` VALUES (10408, 54, 5.90, 6, 0.00);\nINSERT INTO `order_items` VALUES (10408, 62, 39.40, 35, 0.00);\nINSERT INTO `order_items` VALUES (10409, 14, 18.60, 12, 0.00);\nINSERT INTO `order_items` VALUES (10409, 21, 8.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10410, 33, 2.00, 49, 0.00);\nINSERT INTO `order_items` VALUES (10410, 59, 44.00, 16, 0.00);\nINSERT INTO `order_items` VALUES (10411, 41, 7.70, 25, 0.20);\nINSERT INTO `order_items` VALUES (10411, 44, 15.50, 40, 0.20);\nINSERT INTO `order_items` VALUES (10411, 59, 44.00, 9, 0.20);\nINSERT INTO `order_items` VALUES (10412, 14, 18.60, 20, 0.10);\nINSERT INTO `order_items` VALUES (10413, 1, 14.40, 24, 0.00);\nINSERT INTO `order_items` VALUES (10413, 62, 39.40, 40, 0.00);\nINSERT INTO `order_items` VALUES (10413, 76, 14.40, 14, 0.00);\nINSERT INTO `order_items` VALUES (10414, 19, 7.30, 18, 0.05);\nINSERT INTO `order_items` VALUES (10414, 33, 2.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10415, 17, 31.20, 2, 0.00);\nINSERT INTO `order_items` VALUES (10415, 33, 2.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10416, 19, 7.30, 20, 0.00);\nINSERT INTO `order_items` VALUES (10416, 53, 26.20, 10, 0.00);\nINSERT INTO `order_items` VALUES (10416, 57, 15.60, 20, 0.00);\nINSERT INTO `order_items` VALUES (10417, 38, 210.80, 50, 0.00);\nINSERT INTO `order_items` VALUES (10417, 46, 9.60, 2, 0.25);\nINSERT INTO `order_items` VALUES (10417, 68, 10.00, 36, 0.25);\nINSERT INTO `order_items` VALUES (10417, 77, 10.40, 35, 0.00);\nINSERT INTO `order_items` VALUES (10418, 2, 15.20, 60, 0.00);\nINSERT INTO `order_items` VALUES (10418, 47, 7.60, 55, 0.00);\nINSERT INTO `order_items` VALUES (10418, 61, 22.80, 16, 0.00);\nINSERT INTO `order_items` VALUES (10418, 74, 8.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10419, 60, 27.20, 60, 0.05);\nINSERT INTO `order_items` VALUES (10419, 69, 28.80, 20, 0.05);\nINSERT INTO `order_items` VALUES (10420, 9, 77.60, 20, 0.10);\nINSERT INTO `order_items` VALUES (10420, 13, 4.80, 2, 0.10);\nINSERT INTO `order_items` VALUES (10420, 70, 12.00, 8, 0.10);\nINSERT INTO `order_items` VALUES (10420, 73, 12.00, 20, 0.10);\nINSERT INTO `order_items` VALUES (10421, 19, 7.30, 4, 0.15);\nINSERT INTO `order_items` VALUES (10421, 26, 24.90, 30, 0.00);\nINSERT INTO `order_items` VALUES (10421, 53, 26.20, 15, 0.15);\nINSERT INTO `order_items` VALUES (10421, 77, 10.40, 10, 0.15);\nINSERT INTO `order_items` VALUES (10422, 26, 24.90, 2, 0.00);\nINSERT INTO `order_items` VALUES (10423, 31, 10.00, 14, 0.00);\nINSERT INTO `order_items` VALUES (10423, 59, 44.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10424, 35, 14.40, 60, 0.20);\nINSERT INTO `order_items` VALUES (10424, 38, 210.80, 49, 0.20);\nINSERT INTO `order_items` VALUES (10424, 68, 10.00, 30, 0.20);\nINSERT INTO `order_items` VALUES (10425, 55, 19.20, 10, 0.25);\nINSERT INTO `order_items` VALUES (10425, 76, 14.40, 20, 0.25);\nINSERT INTO `order_items` VALUES (10426, 56, 30.40, 5, 0.00);\nINSERT INTO `order_items` VALUES (10426, 64, 26.60, 7, 0.00);\nINSERT INTO `order_items` VALUES (10427, 14, 18.60, 35, 0.00);\nINSERT INTO `order_items` VALUES (10428, 46, 9.60, 20, 0.00);\nINSERT INTO `order_items` VALUES (10429, 50, 13.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10429, 63, 35.10, 35, 0.25);\nINSERT INTO `order_items` VALUES (10430, 17, 31.20, 45, 0.20);\nINSERT INTO `order_items` VALUES (10430, 21, 8.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10430, 56, 30.40, 30, 0.00);\nINSERT INTO `order_items` VALUES (10430, 59, 44.00, 70, 0.20);\nINSERT INTO `order_items` VALUES (10431, 17, 31.20, 50, 0.25);\nINSERT INTO `order_items` VALUES (10431, 40, 14.70, 50, 0.25);\nINSERT INTO `order_items` VALUES (10431, 47, 7.60, 30, 0.25);\nINSERT INTO `order_items` VALUES (10432, 26, 24.90, 10, 0.00);\nINSERT INTO `order_items` VALUES (10432, 54, 5.90, 40, 0.00);\nINSERT INTO `order_items` VALUES (10433, 56, 30.40, 28, 0.00);\nINSERT INTO `order_items` VALUES (10434, 11, 16.80, 6, 0.00);\nINSERT INTO `order_items` VALUES (10434, 76, 14.40, 18, 0.15);\nINSERT INTO `order_items` VALUES (10435, 2, 15.20, 10, 0.00);\nINSERT INTO `order_items` VALUES (10435, 22, 16.80, 12, 0.00);\nINSERT INTO `order_items` VALUES (10435, 72, 27.80, 10, 0.00);\nINSERT INTO `order_items` VALUES (10436, 46, 9.60, 5, 0.00);\nINSERT INTO `order_items` VALUES (10436, 56, 30.40, 40, 0.10);\nINSERT INTO `order_items` VALUES (10436, 64, 26.60, 30, 0.10);\nINSERT INTO `order_items` VALUES (10436, 75, 6.20, 24, 0.10);\nINSERT INTO `order_items` VALUES (10437, 53, 26.20, 15, 0.00);\nINSERT INTO `order_items` VALUES (10438, 19, 7.30, 15, 0.20);\nINSERT INTO `order_items` VALUES (10438, 34, 11.20, 20, 0.20);\nINSERT INTO `order_items` VALUES (10438, 57, 15.60, 15, 0.20);\nINSERT INTO `order_items` VALUES (10439, 12, 30.40, 15, 0.00);\nINSERT INTO `order_items` VALUES (10439, 16, 13.90, 16, 0.00);\nINSERT INTO `order_items` VALUES (10439, 64, 26.60, 6, 0.00);\nINSERT INTO `order_items` VALUES (10439, 74, 8.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10440, 2, 15.20, 45, 0.15);\nINSERT INTO `order_items` VALUES (10440, 16, 13.90, 49, 0.15);\nINSERT INTO `order_items` VALUES (10440, 29, 99.00, 24, 0.15);\nINSERT INTO `order_items` VALUES (10440, 61, 22.80, 90, 0.15);\nINSERT INTO `order_items` VALUES (10441, 27, 35.10, 50, 0.00);\nINSERT INTO `order_items` VALUES (10442, 11, 16.80, 30, 0.00);\nINSERT INTO `order_items` VALUES (10442, 54, 5.90, 80, 0.00);\nINSERT INTO `order_items` VALUES (10442, 66, 13.60, 60, 0.00);\nINSERT INTO `order_items` VALUES (10443, 11, 16.80, 6, 0.20);\nINSERT INTO `order_items` VALUES (10443, 28, 36.40, 12, 0.00);\nINSERT INTO `order_items` VALUES (10444, 17, 31.20, 10, 0.00);\nINSERT INTO `order_items` VALUES (10444, 26, 24.90, 15, 0.00);\nINSERT INTO `order_items` VALUES (10444, 35, 14.40, 8, 0.00);\nINSERT INTO `order_items` VALUES (10444, 41, 7.70, 30, 0.00);\nINSERT INTO `order_items` VALUES (10445, 39, 14.40, 6, 0.00);\nINSERT INTO `order_items` VALUES (10445, 54, 5.90, 15, 0.00);\nINSERT INTO `order_items` VALUES (10446, 19, 7.30, 12, 0.10);\nINSERT INTO `order_items` VALUES (10446, 24, 3.60, 20, 0.10);\nINSERT INTO `order_items` VALUES (10446, 31, 10.00, 3, 0.10);\nINSERT INTO `order_items` VALUES (10446, 52, 5.60, 15, 0.10);\nINSERT INTO `order_items` VALUES (10447, 19, 7.30, 40, 0.00);\nINSERT INTO `order_items` VALUES (10447, 65, 16.80, 35, 0.00);\nINSERT INTO `order_items` VALUES (10447, 71, 17.20, 2, 0.00);\nINSERT INTO `order_items` VALUES (10448, 26, 24.90, 6, 0.00);\nINSERT INTO `order_items` VALUES (10448, 40, 14.70, 20, 0.00);\nINSERT INTO `order_items` VALUES (10449, 10, 24.80, 14, 0.00);\nINSERT INTO `order_items` VALUES (10449, 52, 5.60, 20, 0.00);\nINSERT INTO `order_items` VALUES (10449, 62, 39.40, 35, 0.00);\nINSERT INTO `order_items` VALUES (10450, 10, 24.80, 20, 0.20);\nINSERT INTO `order_items` VALUES (10450, 54, 5.90, 6, 0.20);\nINSERT INTO `order_items` VALUES (10451, 55, 19.20, 120, 0.10);\nINSERT INTO `order_items` VALUES (10451, 64, 26.60, 35, 0.10);\nINSERT INTO `order_items` VALUES (10451, 65, 16.80, 28, 0.10);\nINSERT INTO `order_items` VALUES (10451, 77, 10.40, 55, 0.10);\nINSERT INTO `order_items` VALUES (10452, 28, 36.40, 15, 0.00);\nINSERT INTO `order_items` VALUES (10452, 44, 15.50, 100, 0.05);\nINSERT INTO `order_items` VALUES (10453, 48, 10.20, 15, 0.10);\nINSERT INTO `order_items` VALUES (10453, 70, 12.00, 25, 0.10);\nINSERT INTO `order_items` VALUES (10454, 16, 13.90, 20, 0.20);\nINSERT INTO `order_items` VALUES (10454, 33, 2.00, 20, 0.20);\nINSERT INTO `order_items` VALUES (10454, 46, 9.60, 10, 0.20);\nINSERT INTO `order_items` VALUES (10455, 39, 14.40, 20, 0.00);\nINSERT INTO `order_items` VALUES (10455, 53, 26.20, 50, 0.00);\nINSERT INTO `order_items` VALUES (10455, 61, 22.80, 25, 0.00);\nINSERT INTO `order_items` VALUES (10455, 71, 17.20, 30, 0.00);\nINSERT INTO `order_items` VALUES (10456, 21, 8.00, 40, 0.15);\nINSERT INTO `order_items` VALUES (10456, 49, 16.00, 21, 0.15);\nINSERT INTO `order_items` VALUES (10457, 59, 44.00, 36, 0.00);\nINSERT INTO `order_items` VALUES (10458, 26, 24.90, 30, 0.00);\nINSERT INTO `order_items` VALUES (10458, 28, 36.40, 30, 0.00);\nINSERT INTO `order_items` VALUES (10458, 43, 36.80, 20, 0.00);\nINSERT INTO `order_items` VALUES (10458, 56, 30.40, 15, 0.00);\nINSERT INTO `order_items` VALUES (10458, 71, 17.20, 50, 0.00);\nINSERT INTO `order_items` VALUES (10459, 7, 24.00, 16, 0.05);\nINSERT INTO `order_items` VALUES (10459, 46, 9.60, 20, 0.05);\nINSERT INTO `order_items` VALUES (10459, 72, 27.80, 40, 0.00);\nINSERT INTO `order_items` VALUES (10460, 68, 10.00, 21, 0.25);\nINSERT INTO `order_items` VALUES (10460, 75, 6.20, 4, 0.25);\nINSERT INTO `order_items` VALUES (10461, 21, 8.00, 40, 0.25);\nINSERT INTO `order_items` VALUES (10461, 30, 20.70, 28, 0.25);\nINSERT INTO `order_items` VALUES (10461, 55, 19.20, 60, 0.25);\nINSERT INTO `order_items` VALUES (10462, 13, 4.80, 1, 0.00);\nINSERT INTO `order_items` VALUES (10462, 23, 7.20, 21, 0.00);\nINSERT INTO `order_items` VALUES (10463, 19, 7.30, 21, 0.00);\nINSERT INTO `order_items` VALUES (10463, 42, 11.20, 50, 0.00);\nINSERT INTO `order_items` VALUES (10464, 4, 17.60, 16, 0.20);\nINSERT INTO `order_items` VALUES (10464, 43, 36.80, 3, 0.00);\nINSERT INTO `order_items` VALUES (10464, 56, 30.40, 30, 0.20);\nINSERT INTO `order_items` VALUES (10464, 60, 27.20, 20, 0.00);\nINSERT INTO `order_items` VALUES (10465, 24, 3.60, 25, 0.00);\nINSERT INTO `order_items` VALUES (10465, 29, 99.00, 18, 0.10);\nINSERT INTO `order_items` VALUES (10465, 40, 14.70, 20, 0.00);\nINSERT INTO `order_items` VALUES (10465, 45, 7.60, 30, 0.10);\nINSERT INTO `order_items` VALUES (10465, 50, 13.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10466, 11, 16.80, 10, 0.00);\nINSERT INTO `order_items` VALUES (10466, 46, 9.60, 5, 0.00);\nINSERT INTO `order_items` VALUES (10467, 24, 3.60, 28, 0.00);\nINSERT INTO `order_items` VALUES (10467, 25, 11.20, 12, 0.00);\nINSERT INTO `order_items` VALUES (10468, 30, 20.70, 8, 0.00);\nINSERT INTO `order_items` VALUES (10468, 43, 36.80, 15, 0.00);\nINSERT INTO `order_items` VALUES (10469, 2, 15.20, 40, 0.15);\nINSERT INTO `order_items` VALUES (10469, 16, 13.90, 35, 0.15);\nINSERT INTO `order_items` VALUES (10469, 44, 15.50, 2, 0.15);\nINSERT INTO `order_items` VALUES (10470, 18, 50.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10470, 23, 7.20, 15, 0.00);\nINSERT INTO `order_items` VALUES (10470, 64, 26.60, 8, 0.00);\nINSERT INTO `order_items` VALUES (10471, 7, 24.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10471, 56, 30.40, 20, 0.00);\nINSERT INTO `order_items` VALUES (10472, 24, 3.60, 80, 0.05);\nINSERT INTO `order_items` VALUES (10472, 51, 42.40, 18, 0.00);\nINSERT INTO `order_items` VALUES (10473, 33, 2.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10473, 71, 17.20, 12, 0.00);\nINSERT INTO `order_items` VALUES (10474, 14, 18.60, 12, 0.00);\nINSERT INTO `order_items` VALUES (10474, 28, 36.40, 18, 0.00);\nINSERT INTO `order_items` VALUES (10474, 40, 14.70, 21, 0.00);\nINSERT INTO `order_items` VALUES (10474, 75, 6.20, 10, 0.00);\nINSERT INTO `order_items` VALUES (10475, 31, 10.00, 35, 0.15);\nINSERT INTO `order_items` VALUES (10475, 66, 13.60, 60, 0.15);\nINSERT INTO `order_items` VALUES (10475, 76, 14.40, 42, 0.15);\nINSERT INTO `order_items` VALUES (10476, 55, 19.20, 2, 0.05);\nINSERT INTO `order_items` VALUES (10476, 70, 12.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10477, 1, 14.40, 15, 0.00);\nINSERT INTO `order_items` VALUES (10477, 21, 8.00, 21, 0.25);\nINSERT INTO `order_items` VALUES (10477, 39, 14.40, 20, 0.25);\nINSERT INTO `order_items` VALUES (10478, 10, 24.80, 20, 0.05);\nINSERT INTO `order_items` VALUES (10479, 38, 210.80, 30, 0.00);\nINSERT INTO `order_items` VALUES (10479, 53, 26.20, 28, 0.00);\nINSERT INTO `order_items` VALUES (10479, 59, 44.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10479, 64, 26.60, 30, 0.00);\nINSERT INTO `order_items` VALUES (10480, 47, 7.60, 30, 0.00);\nINSERT INTO `order_items` VALUES (10480, 59, 44.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10481, 49, 16.00, 24, 0.00);\nINSERT INTO `order_items` VALUES (10481, 60, 27.20, 40, 0.00);\nINSERT INTO `order_items` VALUES (10482, 40, 14.70, 10, 0.00);\nINSERT INTO `order_items` VALUES (10483, 34, 11.20, 35, 0.05);\nINSERT INTO `order_items` VALUES (10483, 77, 10.40, 30, 0.05);\nINSERT INTO `order_items` VALUES (10484, 21, 8.00, 14, 0.00);\nINSERT INTO `order_items` VALUES (10484, 40, 14.70, 10, 0.00);\nINSERT INTO `order_items` VALUES (10484, 51, 42.40, 3, 0.00);\nINSERT INTO `order_items` VALUES (10485, 2, 15.20, 20, 0.10);\nINSERT INTO `order_items` VALUES (10485, 3, 8.00, 20, 0.10);\nINSERT INTO `order_items` VALUES (10485, 55, 19.20, 30, 0.10);\nINSERT INTO `order_items` VALUES (10485, 70, 12.00, 60, 0.10);\nINSERT INTO `order_items` VALUES (10486, 11, 16.80, 5, 0.00);\nINSERT INTO `order_items` VALUES (10486, 51, 42.40, 25, 0.00);\nINSERT INTO `order_items` VALUES (10486, 74, 8.00, 16, 0.00);\nINSERT INTO `order_items` VALUES (10487, 19, 7.30, 5, 0.00);\nINSERT INTO `order_items` VALUES (10487, 26, 24.90, 30, 0.00);\nINSERT INTO `order_items` VALUES (10487, 54, 5.90, 24, 0.25);\nINSERT INTO `order_items` VALUES (10488, 59, 44.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10488, 73, 12.00, 20, 0.20);\nINSERT INTO `order_items` VALUES (10489, 11, 16.80, 15, 0.25);\nINSERT INTO `order_items` VALUES (10489, 16, 13.90, 18, 0.00);\nINSERT INTO `order_items` VALUES (10490, 59, 44.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10490, 68, 10.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10490, 75, 6.20, 36, 0.00);\nINSERT INTO `order_items` VALUES (10491, 44, 15.50, 15, 0.15);\nINSERT INTO `order_items` VALUES (10491, 77, 10.40, 7, 0.15);\nINSERT INTO `order_items` VALUES (10492, 25, 11.20, 60, 0.05);\nINSERT INTO `order_items` VALUES (10492, 42, 11.20, 20, 0.05);\nINSERT INTO `order_items` VALUES (10493, 65, 16.80, 15, 0.10);\nINSERT INTO `order_items` VALUES (10493, 66, 13.60, 10, 0.10);\nINSERT INTO `order_items` VALUES (10493, 69, 28.80, 10, 0.10);\nINSERT INTO `order_items` VALUES (10494, 56, 30.40, 30, 0.00);\nINSERT INTO `order_items` VALUES (10495, 23, 7.20, 10, 0.00);\nINSERT INTO `order_items` VALUES (10495, 41, 7.70, 20, 0.00);\nINSERT INTO `order_items` VALUES (10495, 77, 10.40, 5, 0.00);\nINSERT INTO `order_items` VALUES (10496, 31, 10.00, 20, 0.05);\nINSERT INTO `order_items` VALUES (10497, 56, 30.40, 14, 0.00);\nINSERT INTO `order_items` VALUES (10497, 72, 27.80, 25, 0.00);\nINSERT INTO `order_items` VALUES (10497, 77, 10.40, 25, 0.00);\nINSERT INTO `order_items` VALUES (10498, 24, 4.50, 14, 0.00);\nINSERT INTO `order_items` VALUES (10498, 40, 18.40, 5, 0.00);\nINSERT INTO `order_items` VALUES (10498, 42, 14.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10499, 28, 45.60, 20, 0.00);\nINSERT INTO `order_items` VALUES (10499, 49, 20.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10500, 15, 15.50, 12, 0.05);\nINSERT INTO `order_items` VALUES (10500, 28, 45.60, 8, 0.05);\nINSERT INTO `order_items` VALUES (10501, 54, 7.45, 20, 0.00);\nINSERT INTO `order_items` VALUES (10502, 45, 9.50, 21, 0.00);\nINSERT INTO `order_items` VALUES (10502, 53, 32.80, 6, 0.00);\nINSERT INTO `order_items` VALUES (10502, 67, 14.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10503, 14, 23.25, 70, 0.00);\nINSERT INTO `order_items` VALUES (10503, 65, 21.05, 20, 0.00);\nINSERT INTO `order_items` VALUES (10504, 2, 19.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10504, 21, 10.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10504, 53, 32.80, 10, 0.00);\nINSERT INTO `order_items` VALUES (10504, 61, 28.50, 25, 0.00);\nINSERT INTO `order_items` VALUES (10505, 62, 49.30, 3, 0.00);\nINSERT INTO `order_items` VALUES (10506, 25, 14.00, 18, 0.10);\nINSERT INTO `order_items` VALUES (10506, 70, 15.00, 14, 0.10);\nINSERT INTO `order_items` VALUES (10507, 43, 46.00, 15, 0.15);\nINSERT INTO `order_items` VALUES (10507, 48, 12.75, 15, 0.15);\nINSERT INTO `order_items` VALUES (10508, 13, 6.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10508, 39, 18.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10509, 28, 45.60, 3, 0.00);\nINSERT INTO `order_items` VALUES (10510, 29, 123.79, 36, 0.00);\nINSERT INTO `order_items` VALUES (10510, 75, 7.75, 36, 0.10);\nINSERT INTO `order_items` VALUES (10511, 4, 22.00, 50, 0.15);\nINSERT INTO `order_items` VALUES (10511, 7, 30.00, 50, 0.15);\nINSERT INTO `order_items` VALUES (10511, 8, 40.00, 10, 0.15);\nINSERT INTO `order_items` VALUES (10512, 24, 4.50, 10, 0.15);\nINSERT INTO `order_items` VALUES (10512, 46, 12.00, 9, 0.15);\nINSERT INTO `order_items` VALUES (10512, 47, 9.50, 6, 0.15);\nINSERT INTO `order_items` VALUES (10512, 60, 34.00, 12, 0.15);\nINSERT INTO `order_items` VALUES (10513, 21, 10.00, 40, 0.20);\nINSERT INTO `order_items` VALUES (10513, 32, 32.00, 50, 0.20);\nINSERT INTO `order_items` VALUES (10513, 61, 28.50, 15, 0.20);\nINSERT INTO `order_items` VALUES (10514, 20, 81.00, 39, 0.00);\nINSERT INTO `order_items` VALUES (10514, 28, 45.60, 35, 0.00);\nINSERT INTO `order_items` VALUES (10514, 56, 38.00, 70, 0.00);\nINSERT INTO `order_items` VALUES (10514, 65, 21.05, 39, 0.00);\nINSERT INTO `order_items` VALUES (10514, 75, 7.75, 50, 0.00);\nINSERT INTO `order_items` VALUES (10515, 9, 97.00, 16, 0.15);\nINSERT INTO `order_items` VALUES (10515, 16, 17.45, 50, 0.00);\nINSERT INTO `order_items` VALUES (10515, 27, 43.90, 120, 0.00);\nINSERT INTO `order_items` VALUES (10515, 33, 2.50, 16, 0.15);\nINSERT INTO `order_items` VALUES (10515, 60, 34.00, 84, 0.15);\nINSERT INTO `order_items` VALUES (10516, 18, 62.50, 25, 0.10);\nINSERT INTO `order_items` VALUES (10516, 41, 9.65, 80, 0.10);\nINSERT INTO `order_items` VALUES (10516, 42, 14.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10517, 52, 7.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10517, 59, 55.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10517, 70, 15.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10518, 24, 4.50, 5, 0.00);\nINSERT INTO `order_items` VALUES (10518, 38, 263.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (10518, 44, 19.45, 9, 0.00);\nINSERT INTO `order_items` VALUES (10519, 10, 31.00, 16, 0.05);\nINSERT INTO `order_items` VALUES (10519, 56, 38.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10519, 60, 34.00, 10, 0.05);\nINSERT INTO `order_items` VALUES (10520, 24, 4.50, 8, 0.00);\nINSERT INTO `order_items` VALUES (10520, 53, 32.80, 5, 0.00);\nINSERT INTO `order_items` VALUES (10521, 35, 18.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (10521, 41, 9.65, 10, 0.00);\nINSERT INTO `order_items` VALUES (10521, 68, 12.50, 6, 0.00);\nINSERT INTO `order_items` VALUES (10522, 1, 18.00, 40, 0.20);\nINSERT INTO `order_items` VALUES (10522, 8, 40.00, 24, 0.00);\nINSERT INTO `order_items` VALUES (10522, 30, 25.89, 20, 0.20);\nINSERT INTO `order_items` VALUES (10522, 40, 18.40, 25, 0.20);\nINSERT INTO `order_items` VALUES (10523, 17, 39.00, 25, 0.10);\nINSERT INTO `order_items` VALUES (10523, 20, 81.00, 15, 0.10);\nINSERT INTO `order_items` VALUES (10523, 37, 26.00, 18, 0.10);\nINSERT INTO `order_items` VALUES (10523, 41, 9.65, 6, 0.10);\nINSERT INTO `order_items` VALUES (10524, 10, 31.00, 2, 0.00);\nINSERT INTO `order_items` VALUES (10524, 30, 25.89, 10, 0.00);\nINSERT INTO `order_items` VALUES (10524, 43, 46.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10524, 54, 7.45, 15, 0.00);\nINSERT INTO `order_items` VALUES (10525, 36, 19.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10525, 40, 18.40, 15, 0.10);\nINSERT INTO `order_items` VALUES (10526, 1, 18.00, 8, 0.15);\nINSERT INTO `order_items` VALUES (10526, 13, 6.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10526, 56, 38.00, 30, 0.15);\nINSERT INTO `order_items` VALUES (10527, 4, 22.00, 50, 0.10);\nINSERT INTO `order_items` VALUES (10527, 36, 19.00, 30, 0.10);\nINSERT INTO `order_items` VALUES (10528, 11, 21.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (10528, 33, 2.50, 8, 0.20);\nINSERT INTO `order_items` VALUES (10528, 72, 34.80, 9, 0.00);\nINSERT INTO `order_items` VALUES (10529, 55, 24.00, 14, 0.00);\nINSERT INTO `order_items` VALUES (10529, 68, 12.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10529, 69, 36.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10530, 17, 39.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10530, 43, 46.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10530, 61, 28.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10530, 76, 18.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10531, 59, 55.00, 2, 0.00);\nINSERT INTO `order_items` VALUES (10532, 30, 25.89, 15, 0.00);\nINSERT INTO `order_items` VALUES (10532, 66, 17.00, 24, 0.00);\nINSERT INTO `order_items` VALUES (10533, 4, 22.00, 50, 0.05);\nINSERT INTO `order_items` VALUES (10533, 72, 34.80, 24, 0.00);\nINSERT INTO `order_items` VALUES (10533, 73, 15.00, 24, 0.05);\nINSERT INTO `order_items` VALUES (10534, 30, 25.89, 10, 0.00);\nINSERT INTO `order_items` VALUES (10534, 40, 18.40, 10, 0.20);\nINSERT INTO `order_items` VALUES (10534, 54, 7.45, 10, 0.20);\nINSERT INTO `order_items` VALUES (10535, 11, 21.00, 50, 0.10);\nINSERT INTO `order_items` VALUES (10535, 40, 18.40, 10, 0.10);\nINSERT INTO `order_items` VALUES (10535, 57, 19.50, 5, 0.10);\nINSERT INTO `order_items` VALUES (10535, 59, 55.00, 15, 0.10);\nINSERT INTO `order_items` VALUES (10536, 12, 38.00, 15, 0.25);\nINSERT INTO `order_items` VALUES (10536, 31, 12.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10536, 33, 2.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10536, 60, 34.00, 35, 0.25);\nINSERT INTO `order_items` VALUES (10537, 31, 12.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10537, 51, 53.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10537, 58, 13.25, 20, 0.00);\nINSERT INTO `order_items` VALUES (10537, 72, 34.80, 21, 0.00);\nINSERT INTO `order_items` VALUES (10537, 73, 15.00, 9, 0.00);\nINSERT INTO `order_items` VALUES (10538, 70, 15.00, 7, 0.00);\nINSERT INTO `order_items` VALUES (10538, 72, 34.80, 1, 0.00);\nINSERT INTO `order_items` VALUES (10539, 13, 6.00, 8, 0.00);\nINSERT INTO `order_items` VALUES (10539, 21, 10.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10539, 33, 2.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (10539, 49, 20.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10540, 3, 10.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10540, 26, 31.23, 40, 0.00);\nINSERT INTO `order_items` VALUES (10540, 38, 263.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10540, 68, 12.50, 35, 0.00);\nINSERT INTO `order_items` VALUES (10541, 24, 4.50, 35, 0.10);\nINSERT INTO `order_items` VALUES (10541, 38, 263.50, 4, 0.10);\nINSERT INTO `order_items` VALUES (10541, 65, 21.05, 36, 0.10);\nINSERT INTO `order_items` VALUES (10541, 71, 21.50, 9, 0.10);\nINSERT INTO `order_items` VALUES (10542, 11, 21.00, 15, 0.05);\nINSERT INTO `order_items` VALUES (10542, 54, 7.45, 24, 0.05);\nINSERT INTO `order_items` VALUES (10543, 12, 38.00, 30, 0.15);\nINSERT INTO `order_items` VALUES (10543, 23, 9.00, 70, 0.15);\nINSERT INTO `order_items` VALUES (10544, 28, 45.60, 7, 0.00);\nINSERT INTO `order_items` VALUES (10544, 67, 14.00, 7, 0.00);\nINSERT INTO `order_items` VALUES (10545, 11, 21.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10546, 7, 30.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10546, 35, 18.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10546, 62, 49.30, 40, 0.00);\nINSERT INTO `order_items` VALUES (10547, 32, 32.00, 24, 0.15);\nINSERT INTO `order_items` VALUES (10547, 36, 19.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10548, 34, 14.00, 10, 0.25);\nINSERT INTO `order_items` VALUES (10548, 41, 9.65, 14, 0.00);\nINSERT INTO `order_items` VALUES (10549, 31, 12.50, 55, 0.15);\nINSERT INTO `order_items` VALUES (10549, 45, 9.50, 100, 0.15);\nINSERT INTO `order_items` VALUES (10549, 51, 53.00, 48, 0.15);\nINSERT INTO `order_items` VALUES (10550, 17, 39.00, 8, 0.10);\nINSERT INTO `order_items` VALUES (10550, 19, 9.20, 10, 0.00);\nINSERT INTO `order_items` VALUES (10550, 21, 10.00, 6, 0.10);\nINSERT INTO `order_items` VALUES (10550, 61, 28.50, 10, 0.10);\nINSERT INTO `order_items` VALUES (10551, 16, 17.45, 40, 0.15);\nINSERT INTO `order_items` VALUES (10551, 35, 18.00, 20, 0.15);\nINSERT INTO `order_items` VALUES (10551, 44, 19.45, 40, 0.00);\nINSERT INTO `order_items` VALUES (10552, 69, 36.00, 18, 0.00);\nINSERT INTO `order_items` VALUES (10552, 75, 7.75, 30, 0.00);\nINSERT INTO `order_items` VALUES (10553, 11, 21.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10553, 16, 17.45, 14, 0.00);\nINSERT INTO `order_items` VALUES (10553, 22, 21.00, 24, 0.00);\nINSERT INTO `order_items` VALUES (10553, 31, 12.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10553, 35, 18.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10554, 16, 17.45, 30, 0.05);\nINSERT INTO `order_items` VALUES (10554, 23, 9.00, 20, 0.05);\nINSERT INTO `order_items` VALUES (10554, 62, 49.30, 20, 0.05);\nINSERT INTO `order_items` VALUES (10554, 77, 13.00, 10, 0.05);\nINSERT INTO `order_items` VALUES (10555, 14, 23.25, 30, 0.20);\nINSERT INTO `order_items` VALUES (10555, 19, 9.20, 35, 0.20);\nINSERT INTO `order_items` VALUES (10555, 24, 4.50, 18, 0.20);\nINSERT INTO `order_items` VALUES (10555, 51, 53.00, 20, 0.20);\nINSERT INTO `order_items` VALUES (10555, 56, 38.00, 40, 0.20);\nINSERT INTO `order_items` VALUES (10556, 72, 34.80, 24, 0.00);\nINSERT INTO `order_items` VALUES (10557, 64, 33.25, 30, 0.00);\nINSERT INTO `order_items` VALUES (10557, 75, 7.75, 20, 0.00);\nINSERT INTO `order_items` VALUES (10558, 47, 9.50, 25, 0.00);\nINSERT INTO `order_items` VALUES (10558, 51, 53.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10558, 52, 7.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10558, 53, 32.80, 18, 0.00);\nINSERT INTO `order_items` VALUES (10558, 73, 15.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (10559, 41, 9.65, 12, 0.05);\nINSERT INTO `order_items` VALUES (10559, 55, 24.00, 18, 0.05);\nINSERT INTO `order_items` VALUES (10560, 30, 25.89, 20, 0.00);\nINSERT INTO `order_items` VALUES (10560, 62, 49.30, 15, 0.25);\nINSERT INTO `order_items` VALUES (10561, 44, 19.45, 10, 0.00);\nINSERT INTO `order_items` VALUES (10561, 51, 53.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10562, 33, 2.50, 20, 0.10);\nINSERT INTO `order_items` VALUES (10562, 62, 49.30, 10, 0.10);\nINSERT INTO `order_items` VALUES (10563, 36, 19.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10563, 52, 7.00, 70, 0.00);\nINSERT INTO `order_items` VALUES (10564, 17, 39.00, 16, 0.05);\nINSERT INTO `order_items` VALUES (10564, 31, 12.50, 6, 0.05);\nINSERT INTO `order_items` VALUES (10564, 55, 24.00, 25, 0.05);\nINSERT INTO `order_items` VALUES (10565, 24, 4.50, 25, 0.10);\nINSERT INTO `order_items` VALUES (10565, 64, 33.25, 18, 0.10);\nINSERT INTO `order_items` VALUES (10566, 11, 21.00, 35, 0.15);\nINSERT INTO `order_items` VALUES (10566, 18, 62.50, 18, 0.15);\nINSERT INTO `order_items` VALUES (10566, 76, 18.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10567, 31, 12.50, 60, 0.20);\nINSERT INTO `order_items` VALUES (10567, 51, 53.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (10567, 59, 55.00, 40, 0.20);\nINSERT INTO `order_items` VALUES (10568, 10, 31.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10569, 31, 12.50, 35, 0.20);\nINSERT INTO `order_items` VALUES (10569, 76, 18.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10570, 11, 21.00, 15, 0.05);\nINSERT INTO `order_items` VALUES (10570, 56, 38.00, 60, 0.05);\nINSERT INTO `order_items` VALUES (10571, 14, 23.25, 11, 0.15);\nINSERT INTO `order_items` VALUES (10571, 42, 14.00, 28, 0.15);\nINSERT INTO `order_items` VALUES (10572, 16, 17.45, 12, 0.10);\nINSERT INTO `order_items` VALUES (10572, 32, 32.00, 10, 0.10);\nINSERT INTO `order_items` VALUES (10572, 40, 18.40, 50, 0.00);\nINSERT INTO `order_items` VALUES (10572, 75, 7.75, 15, 0.10);\nINSERT INTO `order_items` VALUES (10573, 17, 39.00, 18, 0.00);\nINSERT INTO `order_items` VALUES (10573, 34, 14.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10573, 53, 32.80, 25, 0.00);\nINSERT INTO `order_items` VALUES (10574, 33, 2.50, 14, 0.00);\nINSERT INTO `order_items` VALUES (10574, 40, 18.40, 2, 0.00);\nINSERT INTO `order_items` VALUES (10574, 62, 49.30, 10, 0.00);\nINSERT INTO `order_items` VALUES (10574, 64, 33.25, 6, 0.00);\nINSERT INTO `order_items` VALUES (10575, 59, 55.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10575, 63, 43.90, 6, 0.00);\nINSERT INTO `order_items` VALUES (10575, 72, 34.80, 30, 0.00);\nINSERT INTO `order_items` VALUES (10575, 76, 18.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10576, 1, 18.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10576, 31, 12.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10576, 44, 19.45, 21, 0.00);\nINSERT INTO `order_items` VALUES (10577, 39, 18.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10577, 75, 7.75, 20, 0.00);\nINSERT INTO `order_items` VALUES (10577, 77, 13.00, 18, 0.00);\nINSERT INTO `order_items` VALUES (10578, 35, 18.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10578, 57, 19.50, 6, 0.00);\nINSERT INTO `order_items` VALUES (10579, 15, 15.50, 10, 0.00);\nINSERT INTO `order_items` VALUES (10579, 75, 7.75, 21, 0.00);\nINSERT INTO `order_items` VALUES (10580, 14, 23.25, 15, 0.05);\nINSERT INTO `order_items` VALUES (10580, 41, 9.65, 9, 0.05);\nINSERT INTO `order_items` VALUES (10580, 65, 21.05, 30, 0.05);\nINSERT INTO `order_items` VALUES (10581, 75, 7.75, 50, 0.20);\nINSERT INTO `order_items` VALUES (10582, 57, 19.50, 4, 0.00);\nINSERT INTO `order_items` VALUES (10582, 76, 18.00, 14, 0.00);\nINSERT INTO `order_items` VALUES (10583, 29, 123.79, 10, 0.00);\nINSERT INTO `order_items` VALUES (10583, 60, 34.00, 24, 0.15);\nINSERT INTO `order_items` VALUES (10583, 69, 36.00, 10, 0.15);\nINSERT INTO `order_items` VALUES (10584, 31, 12.50, 50, 0.05);\nINSERT INTO `order_items` VALUES (10585, 47, 9.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (10586, 52, 7.00, 4, 0.15);\nINSERT INTO `order_items` VALUES (10587, 26, 31.23, 6, 0.00);\nINSERT INTO `order_items` VALUES (10587, 35, 18.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10587, 77, 13.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10588, 18, 62.50, 40, 0.20);\nINSERT INTO `order_items` VALUES (10588, 42, 14.00, 100, 0.20);\nINSERT INTO `order_items` VALUES (10589, 35, 18.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10590, 1, 18.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10590, 77, 13.00, 60, 0.05);\nINSERT INTO `order_items` VALUES (10591, 3, 10.00, 14, 0.00);\nINSERT INTO `order_items` VALUES (10591, 7, 30.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10591, 54, 7.45, 50, 0.00);\nINSERT INTO `order_items` VALUES (10592, 15, 15.50, 25, 0.05);\nINSERT INTO `order_items` VALUES (10592, 26, 31.23, 5, 0.05);\nINSERT INTO `order_items` VALUES (10593, 20, 81.00, 21, 0.20);\nINSERT INTO `order_items` VALUES (10593, 69, 36.00, 20, 0.20);\nINSERT INTO `order_items` VALUES (10593, 76, 18.00, 4, 0.20);\nINSERT INTO `order_items` VALUES (10594, 52, 7.00, 24, 0.00);\nINSERT INTO `order_items` VALUES (10594, 58, 13.25, 30, 0.00);\nINSERT INTO `order_items` VALUES (10595, 35, 18.00, 30, 0.25);\nINSERT INTO `order_items` VALUES (10595, 61, 28.50, 120, 0.25);\nINSERT INTO `order_items` VALUES (10595, 69, 36.00, 65, 0.25);\nINSERT INTO `order_items` VALUES (10596, 56, 38.00, 5, 0.20);\nINSERT INTO `order_items` VALUES (10596, 63, 43.90, 24, 0.20);\nINSERT INTO `order_items` VALUES (10596, 75, 7.75, 30, 0.20);\nINSERT INTO `order_items` VALUES (10597, 24, 4.50, 35, 0.20);\nINSERT INTO `order_items` VALUES (10597, 57, 19.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10597, 65, 21.05, 12, 0.20);\nINSERT INTO `order_items` VALUES (10598, 27, 43.90, 50, 0.00);\nINSERT INTO `order_items` VALUES (10598, 71, 21.50, 9, 0.00);\nINSERT INTO `order_items` VALUES (10599, 62, 49.30, 10, 0.00);\nINSERT INTO `order_items` VALUES (10600, 54, 7.45, 4, 0.00);\nINSERT INTO `order_items` VALUES (10600, 73, 15.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10601, 13, 6.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10601, 59, 55.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (10602, 77, 13.00, 5, 0.25);\nINSERT INTO `order_items` VALUES (10603, 22, 21.00, 48, 0.00);\nINSERT INTO `order_items` VALUES (10603, 49, 20.00, 25, 0.05);\nINSERT INTO `order_items` VALUES (10604, 48, 12.75, 6, 0.10);\nINSERT INTO `order_items` VALUES (10604, 76, 18.00, 10, 0.10);\nINSERT INTO `order_items` VALUES (10605, 16, 17.45, 30, 0.05);\nINSERT INTO `order_items` VALUES (10605, 59, 55.00, 20, 0.05);\nINSERT INTO `order_items` VALUES (10605, 60, 34.00, 70, 0.05);\nINSERT INTO `order_items` VALUES (10605, 71, 21.50, 15, 0.05);\nINSERT INTO `order_items` VALUES (10606, 4, 22.00, 20, 0.20);\nINSERT INTO `order_items` VALUES (10606, 55, 24.00, 20, 0.20);\nINSERT INTO `order_items` VALUES (10606, 62, 49.30, 10, 0.20);\nINSERT INTO `order_items` VALUES (10607, 7, 30.00, 45, 0.00);\nINSERT INTO `order_items` VALUES (10607, 17, 39.00, 100, 0.00);\nINSERT INTO `order_items` VALUES (10607, 33, 2.50, 14, 0.00);\nINSERT INTO `order_items` VALUES (10607, 40, 18.40, 42, 0.00);\nINSERT INTO `order_items` VALUES (10607, 72, 34.80, 12, 0.00);\nINSERT INTO `order_items` VALUES (10608, 56, 38.00, 28, 0.00);\nINSERT INTO `order_items` VALUES (10609, 1, 18.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (10609, 10, 31.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10609, 21, 10.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10610, 36, 19.00, 21, 0.25);\nINSERT INTO `order_items` VALUES (10611, 1, 18.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10611, 2, 19.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10611, 60, 34.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10612, 10, 31.00, 70, 0.00);\nINSERT INTO `order_items` VALUES (10612, 36, 19.00, 55, 0.00);\nINSERT INTO `order_items` VALUES (10612, 49, 20.00, 18, 0.00);\nINSERT INTO `order_items` VALUES (10612, 60, 34.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10612, 76, 18.00, 80, 0.00);\nINSERT INTO `order_items` VALUES (10613, 13, 6.00, 8, 0.10);\nINSERT INTO `order_items` VALUES (10613, 75, 7.75, 40, 0.00);\nINSERT INTO `order_items` VALUES (10614, 11, 21.00, 14, 0.00);\nINSERT INTO `order_items` VALUES (10614, 21, 10.00, 8, 0.00);\nINSERT INTO `order_items` VALUES (10614, 39, 18.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10615, 55, 24.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10616, 38, 263.50, 15, 0.05);\nINSERT INTO `order_items` VALUES (10616, 56, 38.00, 14, 0.00);\nINSERT INTO `order_items` VALUES (10616, 70, 15.00, 15, 0.05);\nINSERT INTO `order_items` VALUES (10616, 71, 21.50, 15, 0.05);\nINSERT INTO `order_items` VALUES (10617, 59, 55.00, 30, 0.15);\nINSERT INTO `order_items` VALUES (10618, 6, 25.00, 70, 0.00);\nINSERT INTO `order_items` VALUES (10618, 56, 38.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10618, 68, 12.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (10619, 21, 10.00, 42, 0.00);\nINSERT INTO `order_items` VALUES (10619, 22, 21.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10620, 24, 4.50, 5, 0.00);\nINSERT INTO `order_items` VALUES (10620, 52, 7.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10621, 19, 9.20, 5, 0.00);\nINSERT INTO `order_items` VALUES (10621, 23, 9.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10621, 70, 15.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10621, 71, 21.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (10622, 2, 19.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10622, 68, 12.50, 18, 0.20);\nINSERT INTO `order_items` VALUES (10623, 14, 23.25, 21, 0.00);\nINSERT INTO `order_items` VALUES (10623, 19, 9.20, 15, 0.10);\nINSERT INTO `order_items` VALUES (10623, 21, 10.00, 25, 0.10);\nINSERT INTO `order_items` VALUES (10623, 24, 4.50, 3, 0.00);\nINSERT INTO `order_items` VALUES (10623, 35, 18.00, 30, 0.10);\nINSERT INTO `order_items` VALUES (10624, 28, 45.60, 10, 0.00);\nINSERT INTO `order_items` VALUES (10624, 29, 123.79, 6, 0.00);\nINSERT INTO `order_items` VALUES (10624, 44, 19.45, 10, 0.00);\nINSERT INTO `order_items` VALUES (10625, 14, 23.25, 3, 0.00);\nINSERT INTO `order_items` VALUES (10625, 42, 14.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10625, 60, 34.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10626, 53, 32.80, 12, 0.00);\nINSERT INTO `order_items` VALUES (10626, 60, 34.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10626, 71, 21.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10627, 62, 49.30, 15, 0.00);\nINSERT INTO `order_items` VALUES (10627, 73, 15.00, 35, 0.15);\nINSERT INTO `order_items` VALUES (10628, 1, 18.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10629, 29, 123.79, 20, 0.00);\nINSERT INTO `order_items` VALUES (10629, 64, 33.25, 9, 0.00);\nINSERT INTO `order_items` VALUES (10630, 55, 24.00, 12, 0.05);\nINSERT INTO `order_items` VALUES (10630, 76, 18.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (10631, 75, 7.75, 8, 0.10);\nINSERT INTO `order_items` VALUES (10632, 2, 19.00, 30, 0.05);\nINSERT INTO `order_items` VALUES (10632, 33, 2.50, 20, 0.05);\nINSERT INTO `order_items` VALUES (10633, 12, 38.00, 36, 0.15);\nINSERT INTO `order_items` VALUES (10633, 13, 6.00, 13, 0.15);\nINSERT INTO `order_items` VALUES (10633, 26, 31.23, 35, 0.15);\nINSERT INTO `order_items` VALUES (10633, 62, 49.30, 80, 0.15);\nINSERT INTO `order_items` VALUES (10634, 7, 30.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (10634, 18, 62.50, 50, 0.00);\nINSERT INTO `order_items` VALUES (10634, 51, 53.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10634, 75, 7.75, 2, 0.00);\nINSERT INTO `order_items` VALUES (10635, 4, 22.00, 10, 0.10);\nINSERT INTO `order_items` VALUES (10635, 5, 21.35, 15, 0.10);\nINSERT INTO `order_items` VALUES (10635, 22, 21.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10636, 4, 22.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10636, 58, 13.25, 6, 0.00);\nINSERT INTO `order_items` VALUES (10637, 11, 21.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10637, 50, 16.25, 25, 0.05);\nINSERT INTO `order_items` VALUES (10637, 56, 38.00, 60, 0.05);\nINSERT INTO `order_items` VALUES (10638, 45, 9.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10638, 65, 21.05, 21, 0.00);\nINSERT INTO `order_items` VALUES (10638, 72, 34.80, 60, 0.00);\nINSERT INTO `order_items` VALUES (10639, 18, 62.50, 8, 0.00);\nINSERT INTO `order_items` VALUES (10640, 69, 36.00, 20, 0.25);\nINSERT INTO `order_items` VALUES (10640, 70, 15.00, 15, 0.25);\nINSERT INTO `order_items` VALUES (10641, 2, 19.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10641, 40, 18.40, 60, 0.00);\nINSERT INTO `order_items` VALUES (10642, 21, 10.00, 30, 0.20);\nINSERT INTO `order_items` VALUES (10642, 61, 28.50, 20, 0.20);\nINSERT INTO `order_items` VALUES (10643, 28, 45.60, 15, 0.25);\nINSERT INTO `order_items` VALUES (10643, 39, 18.00, 21, 0.25);\nINSERT INTO `order_items` VALUES (10643, 46, 12.00, 2, 0.25);\nINSERT INTO `order_items` VALUES (10644, 18, 62.50, 4, 0.10);\nINSERT INTO `order_items` VALUES (10644, 43, 46.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10644, 46, 12.00, 21, 0.10);\nINSERT INTO `order_items` VALUES (10645, 18, 62.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10645, 36, 19.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10646, 1, 18.00, 15, 0.25);\nINSERT INTO `order_items` VALUES (10646, 10, 31.00, 18, 0.25);\nINSERT INTO `order_items` VALUES (10646, 71, 21.50, 30, 0.25);\nINSERT INTO `order_items` VALUES (10646, 77, 13.00, 35, 0.25);\nINSERT INTO `order_items` VALUES (10647, 19, 9.20, 30, 0.00);\nINSERT INTO `order_items` VALUES (10647, 39, 18.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10648, 22, 21.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10648, 24, 4.50, 15, 0.15);\nINSERT INTO `order_items` VALUES (10649, 28, 45.60, 20, 0.00);\nINSERT INTO `order_items` VALUES (10649, 72, 34.80, 15, 0.00);\nINSERT INTO `order_items` VALUES (10650, 30, 25.89, 30, 0.00);\nINSERT INTO `order_items` VALUES (10650, 53, 32.80, 25, 0.05);\nINSERT INTO `order_items` VALUES (10650, 54, 7.45, 30, 0.00);\nINSERT INTO `order_items` VALUES (10651, 19, 9.20, 12, 0.25);\nINSERT INTO `order_items` VALUES (10651, 22, 21.00, 20, 0.25);\nINSERT INTO `order_items` VALUES (10652, 30, 25.89, 2, 0.25);\nINSERT INTO `order_items` VALUES (10652, 42, 14.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10653, 16, 17.45, 30, 0.10);\nINSERT INTO `order_items` VALUES (10653, 60, 34.00, 20, 0.10);\nINSERT INTO `order_items` VALUES (10654, 4, 22.00, 12, 0.10);\nINSERT INTO `order_items` VALUES (10654, 39, 18.00, 20, 0.10);\nINSERT INTO `order_items` VALUES (10654, 54, 7.45, 6, 0.10);\nINSERT INTO `order_items` VALUES (10655, 41, 9.65, 20, 0.20);\nINSERT INTO `order_items` VALUES (10656, 14, 23.25, 3, 0.10);\nINSERT INTO `order_items` VALUES (10656, 44, 19.45, 28, 0.10);\nINSERT INTO `order_items` VALUES (10656, 47, 9.50, 6, 0.10);\nINSERT INTO `order_items` VALUES (10657, 15, 15.50, 50, 0.00);\nINSERT INTO `order_items` VALUES (10657, 41, 9.65, 24, 0.00);\nINSERT INTO `order_items` VALUES (10657, 46, 12.00, 45, 0.00);\nINSERT INTO `order_items` VALUES (10657, 47, 9.50, 10, 0.00);\nINSERT INTO `order_items` VALUES (10657, 56, 38.00, 45, 0.00);\nINSERT INTO `order_items` VALUES (10657, 60, 34.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10658, 21, 10.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10658, 40, 18.40, 70, 0.05);\nINSERT INTO `order_items` VALUES (10658, 60, 34.00, 55, 0.05);\nINSERT INTO `order_items` VALUES (10658, 77, 13.00, 70, 0.05);\nINSERT INTO `order_items` VALUES (10659, 31, 12.50, 20, 0.05);\nINSERT INTO `order_items` VALUES (10659, 40, 18.40, 24, 0.05);\nINSERT INTO `order_items` VALUES (10659, 70, 15.00, 40, 0.05);\nINSERT INTO `order_items` VALUES (10660, 20, 81.00, 21, 0.00);\nINSERT INTO `order_items` VALUES (10661, 39, 18.00, 3, 0.20);\nINSERT INTO `order_items` VALUES (10661, 58, 13.25, 49, 0.20);\nINSERT INTO `order_items` VALUES (10662, 68, 12.50, 10, 0.00);\nINSERT INTO `order_items` VALUES (10663, 40, 18.40, 30, 0.05);\nINSERT INTO `order_items` VALUES (10663, 42, 14.00, 30, 0.05);\nINSERT INTO `order_items` VALUES (10663, 51, 53.00, 20, 0.05);\nINSERT INTO `order_items` VALUES (10664, 10, 31.00, 24, 0.15);\nINSERT INTO `order_items` VALUES (10664, 56, 38.00, 12, 0.15);\nINSERT INTO `order_items` VALUES (10664, 65, 21.05, 15, 0.15);\nINSERT INTO `order_items` VALUES (10665, 51, 53.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10665, 59, 55.00, 1, 0.00);\nINSERT INTO `order_items` VALUES (10665, 76, 18.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10666, 29, 123.79, 36, 0.00);\nINSERT INTO `order_items` VALUES (10666, 65, 21.05, 10, 0.00);\nINSERT INTO `order_items` VALUES (10667, 69, 36.00, 45, 0.20);\nINSERT INTO `order_items` VALUES (10667, 71, 21.50, 14, 0.20);\nINSERT INTO `order_items` VALUES (10668, 31, 12.50, 8, 0.10);\nINSERT INTO `order_items` VALUES (10668, 55, 24.00, 4, 0.10);\nINSERT INTO `order_items` VALUES (10668, 64, 33.25, 15, 0.10);\nINSERT INTO `order_items` VALUES (10669, 36, 19.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10670, 23, 9.00, 32, 0.00);\nINSERT INTO `order_items` VALUES (10670, 46, 12.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10670, 67, 14.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10670, 73, 15.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10670, 75, 7.75, 25, 0.00);\nINSERT INTO `order_items` VALUES (10671, 16, 17.45, 10, 0.00);\nINSERT INTO `order_items` VALUES (10671, 62, 49.30, 10, 0.00);\nINSERT INTO `order_items` VALUES (10671, 65, 21.05, 12, 0.00);\nINSERT INTO `order_items` VALUES (10672, 38, 263.50, 15, 0.10);\nINSERT INTO `order_items` VALUES (10672, 71, 21.50, 12, 0.00);\nINSERT INTO `order_items` VALUES (10673, 16, 17.45, 3, 0.00);\nINSERT INTO `order_items` VALUES (10673, 42, 14.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10673, 43, 46.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10674, 23, 9.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10675, 14, 23.25, 30, 0.00);\nINSERT INTO `order_items` VALUES (10675, 53, 32.80, 10, 0.00);\nINSERT INTO `order_items` VALUES (10675, 58, 13.25, 30, 0.00);\nINSERT INTO `order_items` VALUES (10676, 10, 31.00, 2, 0.00);\nINSERT INTO `order_items` VALUES (10676, 19, 9.20, 7, 0.00);\nINSERT INTO `order_items` VALUES (10676, 44, 19.45, 21, 0.00);\nINSERT INTO `order_items` VALUES (10677, 26, 31.23, 30, 0.15);\nINSERT INTO `order_items` VALUES (10677, 33, 2.50, 8, 0.15);\nINSERT INTO `order_items` VALUES (10678, 12, 38.00, 100, 0.00);\nINSERT INTO `order_items` VALUES (10678, 33, 2.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10678, 41, 9.65, 120, 0.00);\nINSERT INTO `order_items` VALUES (10678, 54, 7.45, 30, 0.00);\nINSERT INTO `order_items` VALUES (10679, 59, 55.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10680, 16, 17.45, 50, 0.25);\nINSERT INTO `order_items` VALUES (10680, 31, 12.50, 20, 0.25);\nINSERT INTO `order_items` VALUES (10680, 42, 14.00, 40, 0.25);\nINSERT INTO `order_items` VALUES (10681, 19, 9.20, 30, 0.10);\nINSERT INTO `order_items` VALUES (10681, 21, 10.00, 12, 0.10);\nINSERT INTO `order_items` VALUES (10681, 64, 33.25, 28, 0.00);\nINSERT INTO `order_items` VALUES (10682, 33, 2.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10682, 66, 17.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10682, 75, 7.75, 30, 0.00);\nINSERT INTO `order_items` VALUES (10683, 52, 7.00, 9, 0.00);\nINSERT INTO `order_items` VALUES (10684, 40, 18.40, 20, 0.00);\nINSERT INTO `order_items` VALUES (10684, 47, 9.50, 40, 0.00);\nINSERT INTO `order_items` VALUES (10684, 60, 34.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10685, 10, 31.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10685, 41, 9.65, 4, 0.00);\nINSERT INTO `order_items` VALUES (10685, 47, 9.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (10686, 17, 39.00, 30, 0.20);\nINSERT INTO `order_items` VALUES (10686, 26, 31.23, 15, 0.00);\nINSERT INTO `order_items` VALUES (10687, 9, 97.00, 50, 0.25);\nINSERT INTO `order_items` VALUES (10687, 29, 123.79, 10, 0.00);\nINSERT INTO `order_items` VALUES (10687, 36, 19.00, 6, 0.25);\nINSERT INTO `order_items` VALUES (10688, 10, 31.00, 18, 0.10);\nINSERT INTO `order_items` VALUES (10688, 28, 45.60, 60, 0.10);\nINSERT INTO `order_items` VALUES (10688, 34, 14.00, 14, 0.00);\nINSERT INTO `order_items` VALUES (10689, 1, 18.00, 35, 0.25);\nINSERT INTO `order_items` VALUES (10690, 56, 38.00, 20, 0.25);\nINSERT INTO `order_items` VALUES (10690, 77, 13.00, 30, 0.25);\nINSERT INTO `order_items` VALUES (10691, 1, 18.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10691, 29, 123.79, 40, 0.00);\nINSERT INTO `order_items` VALUES (10691, 43, 46.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10691, 44, 19.45, 24, 0.00);\nINSERT INTO `order_items` VALUES (10691, 62, 49.30, 48, 0.00);\nINSERT INTO `order_items` VALUES (10692, 63, 43.90, 20, 0.00);\nINSERT INTO `order_items` VALUES (10693, 9, 97.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10693, 54, 7.45, 60, 0.15);\nINSERT INTO `order_items` VALUES (10693, 69, 36.00, 30, 0.15);\nINSERT INTO `order_items` VALUES (10693, 73, 15.00, 15, 0.15);\nINSERT INTO `order_items` VALUES (10694, 7, 30.00, 90, 0.00);\nINSERT INTO `order_items` VALUES (10694, 59, 55.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10694, 70, 15.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10695, 8, 40.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10695, 12, 38.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10695, 24, 4.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10696, 17, 39.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10696, 46, 12.00, 18, 0.00);\nINSERT INTO `order_items` VALUES (10697, 19, 9.20, 7, 0.25);\nINSERT INTO `order_items` VALUES (10697, 35, 18.00, 9, 0.25);\nINSERT INTO `order_items` VALUES (10697, 58, 13.25, 30, 0.25);\nINSERT INTO `order_items` VALUES (10697, 70, 15.00, 30, 0.25);\nINSERT INTO `order_items` VALUES (10698, 11, 21.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10698, 17, 39.00, 8, 0.05);\nINSERT INTO `order_items` VALUES (10698, 29, 123.79, 12, 0.05);\nINSERT INTO `order_items` VALUES (10698, 65, 21.05, 65, 0.05);\nINSERT INTO `order_items` VALUES (10698, 70, 15.00, 8, 0.05);\nINSERT INTO `order_items` VALUES (10699, 47, 9.50, 12, 0.00);\nINSERT INTO `order_items` VALUES (10700, 1, 18.00, 5, 0.20);\nINSERT INTO `order_items` VALUES (10700, 34, 14.00, 12, 0.20);\nINSERT INTO `order_items` VALUES (10700, 68, 12.50, 40, 0.20);\nINSERT INTO `order_items` VALUES (10700, 71, 21.50, 60, 0.20);\nINSERT INTO `order_items` VALUES (10701, 59, 55.00, 42, 0.15);\nINSERT INTO `order_items` VALUES (10701, 71, 21.50, 20, 0.15);\nINSERT INTO `order_items` VALUES (10701, 76, 18.00, 35, 0.15);\nINSERT INTO `order_items` VALUES (10702, 3, 10.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10702, 76, 18.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10703, 2, 19.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10703, 59, 55.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (10703, 73, 15.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (10704, 4, 22.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10704, 24, 4.50, 35, 0.00);\nINSERT INTO `order_items` VALUES (10704, 48, 12.75, 24, 0.00);\nINSERT INTO `order_items` VALUES (10705, 31, 12.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10705, 32, 32.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10706, 16, 17.45, 20, 0.00);\nINSERT INTO `order_items` VALUES (10706, 43, 46.00, 24, 0.00);\nINSERT INTO `order_items` VALUES (10706, 59, 55.00, 8, 0.00);\nINSERT INTO `order_items` VALUES (10707, 55, 24.00, 21, 0.00);\nINSERT INTO `order_items` VALUES (10707, 57, 19.50, 40, 0.00);\nINSERT INTO `order_items` VALUES (10707, 70, 15.00, 28, 0.15);\nINSERT INTO `order_items` VALUES (10708, 5, 21.35, 4, 0.00);\nINSERT INTO `order_items` VALUES (10708, 36, 19.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10709, 8, 40.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10709, 51, 53.00, 28, 0.00);\nINSERT INTO `order_items` VALUES (10709, 60, 34.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10710, 19, 9.20, 5, 0.00);\nINSERT INTO `order_items` VALUES (10710, 47, 9.50, 5, 0.00);\nINSERT INTO `order_items` VALUES (10711, 19, 9.20, 12, 0.00);\nINSERT INTO `order_items` VALUES (10711, 41, 9.65, 42, 0.00);\nINSERT INTO `order_items` VALUES (10711, 53, 32.80, 120, 0.00);\nINSERT INTO `order_items` VALUES (10712, 53, 32.80, 3, 0.05);\nINSERT INTO `order_items` VALUES (10712, 56, 38.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10713, 10, 31.00, 18, 0.00);\nINSERT INTO `order_items` VALUES (10713, 26, 31.23, 30, 0.00);\nINSERT INTO `order_items` VALUES (10713, 45, 9.50, 110, 0.00);\nINSERT INTO `order_items` VALUES (10713, 46, 12.00, 24, 0.00);\nINSERT INTO `order_items` VALUES (10714, 2, 19.00, 30, 0.25);\nINSERT INTO `order_items` VALUES (10714, 17, 39.00, 27, 0.25);\nINSERT INTO `order_items` VALUES (10714, 47, 9.50, 50, 0.25);\nINSERT INTO `order_items` VALUES (10714, 56, 38.00, 18, 0.25);\nINSERT INTO `order_items` VALUES (10714, 58, 13.25, 12, 0.25);\nINSERT INTO `order_items` VALUES (10715, 10, 31.00, 21, 0.00);\nINSERT INTO `order_items` VALUES (10715, 71, 21.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10716, 21, 10.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10716, 51, 53.00, 7, 0.00);\nINSERT INTO `order_items` VALUES (10716, 61, 28.50, 10, 0.00);\nINSERT INTO `order_items` VALUES (10717, 21, 10.00, 32, 0.05);\nINSERT INTO `order_items` VALUES (10717, 54, 7.45, 15, 0.00);\nINSERT INTO `order_items` VALUES (10717, 69, 36.00, 25, 0.05);\nINSERT INTO `order_items` VALUES (10718, 12, 38.00, 36, 0.00);\nINSERT INTO `order_items` VALUES (10718, 16, 17.45, 20, 0.00);\nINSERT INTO `order_items` VALUES (10718, 36, 19.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10718, 62, 49.30, 20, 0.00);\nINSERT INTO `order_items` VALUES (10719, 18, 62.50, 12, 0.25);\nINSERT INTO `order_items` VALUES (10719, 30, 25.89, 3, 0.25);\nINSERT INTO `order_items` VALUES (10719, 54, 7.45, 40, 0.25);\nINSERT INTO `order_items` VALUES (10720, 35, 18.00, 21, 0.00);\nINSERT INTO `order_items` VALUES (10720, 71, 21.50, 8, 0.00);\nINSERT INTO `order_items` VALUES (10721, 44, 19.45, 50, 0.05);\nINSERT INTO `order_items` VALUES (10722, 2, 19.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (10722, 31, 12.50, 50, 0.00);\nINSERT INTO `order_items` VALUES (10722, 68, 12.50, 45, 0.00);\nINSERT INTO `order_items` VALUES (10722, 75, 7.75, 42, 0.00);\nINSERT INTO `order_items` VALUES (10723, 26, 31.23, 15, 0.00);\nINSERT INTO `order_items` VALUES (10724, 10, 31.00, 16, 0.00);\nINSERT INTO `order_items` VALUES (10724, 61, 28.50, 5, 0.00);\nINSERT INTO `order_items` VALUES (10725, 41, 9.65, 12, 0.00);\nINSERT INTO `order_items` VALUES (10725, 52, 7.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10725, 55, 24.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10726, 4, 22.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10726, 11, 21.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10727, 17, 39.00, 20, 0.05);\nINSERT INTO `order_items` VALUES (10727, 56, 38.00, 10, 0.05);\nINSERT INTO `order_items` VALUES (10727, 59, 55.00, 10, 0.05);\nINSERT INTO `order_items` VALUES (10728, 30, 25.89, 15, 0.00);\nINSERT INTO `order_items` VALUES (10728, 40, 18.40, 6, 0.00);\nINSERT INTO `order_items` VALUES (10728, 55, 24.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10728, 60, 34.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10729, 1, 18.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10729, 21, 10.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10729, 50, 16.25, 40, 0.00);\nINSERT INTO `order_items` VALUES (10730, 16, 17.45, 15, 0.05);\nINSERT INTO `order_items` VALUES (10730, 31, 12.50, 3, 0.05);\nINSERT INTO `order_items` VALUES (10730, 65, 21.05, 10, 0.05);\nINSERT INTO `order_items` VALUES (10731, 21, 10.00, 40, 0.05);\nINSERT INTO `order_items` VALUES (10731, 51, 53.00, 30, 0.05);\nINSERT INTO `order_items` VALUES (10732, 76, 18.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10733, 14, 23.25, 16, 0.00);\nINSERT INTO `order_items` VALUES (10733, 28, 45.60, 20, 0.00);\nINSERT INTO `order_items` VALUES (10733, 52, 7.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10734, 6, 25.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10734, 30, 25.89, 15, 0.00);\nINSERT INTO `order_items` VALUES (10734, 76, 18.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10735, 61, 28.50, 20, 0.10);\nINSERT INTO `order_items` VALUES (10735, 77, 13.00, 2, 0.10);\nINSERT INTO `order_items` VALUES (10736, 65, 21.05, 40, 0.00);\nINSERT INTO `order_items` VALUES (10736, 75, 7.75, 20, 0.00);\nINSERT INTO `order_items` VALUES (10737, 13, 6.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10737, 41, 9.65, 12, 0.00);\nINSERT INTO `order_items` VALUES (10738, 16, 17.45, 3, 0.00);\nINSERT INTO `order_items` VALUES (10739, 36, 19.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10739, 52, 7.00, 18, 0.00);\nINSERT INTO `order_items` VALUES (10740, 28, 45.60, 5, 0.20);\nINSERT INTO `order_items` VALUES (10740, 35, 18.00, 35, 0.20);\nINSERT INTO `order_items` VALUES (10740, 45, 9.50, 40, 0.20);\nINSERT INTO `order_items` VALUES (10740, 56, 38.00, 14, 0.20);\nINSERT INTO `order_items` VALUES (10741, 2, 19.00, 15, 0.20);\nINSERT INTO `order_items` VALUES (10742, 3, 10.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10742, 60, 34.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10742, 72, 34.80, 35, 0.00);\nINSERT INTO `order_items` VALUES (10743, 46, 12.00, 28, 0.05);\nINSERT INTO `order_items` VALUES (10744, 40, 18.40, 50, 0.20);\nINSERT INTO `order_items` VALUES (10745, 18, 62.50, 24, 0.00);\nINSERT INTO `order_items` VALUES (10745, 44, 19.45, 16, 0.00);\nINSERT INTO `order_items` VALUES (10745, 59, 55.00, 45, 0.00);\nINSERT INTO `order_items` VALUES (10745, 72, 34.80, 7, 0.00);\nINSERT INTO `order_items` VALUES (10746, 13, 6.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10746, 42, 14.00, 28, 0.00);\nINSERT INTO `order_items` VALUES (10746, 62, 49.30, 9, 0.00);\nINSERT INTO `order_items` VALUES (10746, 69, 36.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10747, 31, 12.50, 8, 0.00);\nINSERT INTO `order_items` VALUES (10747, 41, 9.65, 35, 0.00);\nINSERT INTO `order_items` VALUES (10747, 63, 43.90, 9, 0.00);\nINSERT INTO `order_items` VALUES (10747, 69, 36.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10748, 23, 9.00, 44, 0.00);\nINSERT INTO `order_items` VALUES (10748, 40, 18.40, 40, 0.00);\nINSERT INTO `order_items` VALUES (10748, 56, 38.00, 28, 0.00);\nINSERT INTO `order_items` VALUES (10749, 56, 38.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10749, 59, 55.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10749, 76, 18.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10750, 14, 23.25, 5, 0.15);\nINSERT INTO `order_items` VALUES (10750, 45, 9.50, 40, 0.15);\nINSERT INTO `order_items` VALUES (10750, 59, 55.00, 25, 0.15);\nINSERT INTO `order_items` VALUES (10751, 26, 31.23, 12, 0.10);\nINSERT INTO `order_items` VALUES (10751, 30, 25.89, 30, 0.00);\nINSERT INTO `order_items` VALUES (10751, 50, 16.25, 20, 0.10);\nINSERT INTO `order_items` VALUES (10751, 73, 15.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10752, 1, 18.00, 8, 0.00);\nINSERT INTO `order_items` VALUES (10752, 69, 36.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (10753, 45, 9.50, 4, 0.00);\nINSERT INTO `order_items` VALUES (10753, 74, 10.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10754, 40, 18.40, 3, 0.00);\nINSERT INTO `order_items` VALUES (10755, 47, 9.50, 30, 0.25);\nINSERT INTO `order_items` VALUES (10755, 56, 38.00, 30, 0.25);\nINSERT INTO `order_items` VALUES (10755, 57, 19.50, 14, 0.25);\nINSERT INTO `order_items` VALUES (10755, 69, 36.00, 25, 0.25);\nINSERT INTO `order_items` VALUES (10756, 18, 62.50, 21, 0.20);\nINSERT INTO `order_items` VALUES (10756, 36, 19.00, 20, 0.20);\nINSERT INTO `order_items` VALUES (10756, 68, 12.50, 6, 0.20);\nINSERT INTO `order_items` VALUES (10756, 69, 36.00, 20, 0.20);\nINSERT INTO `order_items` VALUES (10757, 34, 14.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10757, 59, 55.00, 7, 0.00);\nINSERT INTO `order_items` VALUES (10757, 62, 49.30, 30, 0.00);\nINSERT INTO `order_items` VALUES (10757, 64, 33.25, 24, 0.00);\nINSERT INTO `order_items` VALUES (10758, 26, 31.23, 20, 0.00);\nINSERT INTO `order_items` VALUES (10758, 52, 7.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10758, 70, 15.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10759, 32, 32.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10760, 25, 14.00, 12, 0.25);\nINSERT INTO `order_items` VALUES (10760, 27, 43.90, 40, 0.00);\nINSERT INTO `order_items` VALUES (10760, 43, 46.00, 30, 0.25);\nINSERT INTO `order_items` VALUES (10761, 25, 14.00, 35, 0.25);\nINSERT INTO `order_items` VALUES (10761, 75, 7.75, 18, 0.00);\nINSERT INTO `order_items` VALUES (10762, 39, 18.00, 16, 0.00);\nINSERT INTO `order_items` VALUES (10762, 47, 9.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10762, 51, 53.00, 28, 0.00);\nINSERT INTO `order_items` VALUES (10762, 56, 38.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10763, 21, 10.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10763, 22, 21.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10763, 24, 4.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10764, 3, 10.00, 20, 0.10);\nINSERT INTO `order_items` VALUES (10764, 39, 18.00, 130, 0.10);\nINSERT INTO `order_items` VALUES (10765, 65, 21.05, 80, 0.10);\nINSERT INTO `order_items` VALUES (10766, 2, 19.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10766, 7, 30.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (10766, 68, 12.50, 40, 0.00);\nINSERT INTO `order_items` VALUES (10767, 42, 14.00, 2, 0.00);\nINSERT INTO `order_items` VALUES (10768, 22, 21.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10768, 31, 12.50, 50, 0.00);\nINSERT INTO `order_items` VALUES (10768, 60, 34.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10768, 71, 21.50, 12, 0.00);\nINSERT INTO `order_items` VALUES (10769, 41, 9.65, 30, 0.05);\nINSERT INTO `order_items` VALUES (10769, 52, 7.00, 15, 0.05);\nINSERT INTO `order_items` VALUES (10769, 61, 28.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10769, 62, 49.30, 15, 0.00);\nINSERT INTO `order_items` VALUES (10770, 11, 21.00, 15, 0.25);\nINSERT INTO `order_items` VALUES (10771, 71, 21.50, 16, 0.00);\nINSERT INTO `order_items` VALUES (10772, 29, 123.79, 18, 0.00);\nINSERT INTO `order_items` VALUES (10772, 59, 55.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10773, 17, 39.00, 33, 0.00);\nINSERT INTO `order_items` VALUES (10773, 31, 12.50, 70, 0.20);\nINSERT INTO `order_items` VALUES (10773, 75, 7.75, 7, 0.20);\nINSERT INTO `order_items` VALUES (10774, 31, 12.50, 2, 0.25);\nINSERT INTO `order_items` VALUES (10774, 66, 17.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10775, 10, 31.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10775, 67, 14.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (10776, 31, 12.50, 16, 0.05);\nINSERT INTO `order_items` VALUES (10776, 42, 14.00, 12, 0.05);\nINSERT INTO `order_items` VALUES (10776, 45, 9.50, 27, 0.05);\nINSERT INTO `order_items` VALUES (10776, 51, 53.00, 120, 0.05);\nINSERT INTO `order_items` VALUES (10777, 42, 14.00, 20, 0.20);\nINSERT INTO `order_items` VALUES (10778, 41, 9.65, 10, 0.00);\nINSERT INTO `order_items` VALUES (10779, 16, 17.45, 20, 0.00);\nINSERT INTO `order_items` VALUES (10779, 62, 49.30, 20, 0.00);\nINSERT INTO `order_items` VALUES (10780, 70, 15.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (10780, 77, 13.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10781, 54, 7.45, 3, 0.20);\nINSERT INTO `order_items` VALUES (10781, 56, 38.00, 20, 0.20);\nINSERT INTO `order_items` VALUES (10781, 74, 10.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (10782, 31, 12.50, 1, 0.00);\nINSERT INTO `order_items` VALUES (10783, 31, 12.50, 10, 0.00);\nINSERT INTO `order_items` VALUES (10783, 38, 263.50, 5, 0.00);\nINSERT INTO `order_items` VALUES (10784, 36, 19.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10784, 39, 18.00, 2, 0.15);\nINSERT INTO `order_items` VALUES (10784, 72, 34.80, 30, 0.15);\nINSERT INTO `order_items` VALUES (10785, 10, 31.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10785, 75, 7.75, 10, 0.00);\nINSERT INTO `order_items` VALUES (10786, 8, 40.00, 30, 0.20);\nINSERT INTO `order_items` VALUES (10786, 30, 25.89, 15, 0.20);\nINSERT INTO `order_items` VALUES (10786, 75, 7.75, 42, 0.20);\nINSERT INTO `order_items` VALUES (10787, 2, 19.00, 15, 0.05);\nINSERT INTO `order_items` VALUES (10787, 29, 123.79, 20, 0.05);\nINSERT INTO `order_items` VALUES (10788, 19, 9.20, 50, 0.05);\nINSERT INTO `order_items` VALUES (10788, 75, 7.75, 40, 0.05);\nINSERT INTO `order_items` VALUES (10789, 18, 62.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10789, 35, 18.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10789, 63, 43.90, 30, 0.00);\nINSERT INTO `order_items` VALUES (10789, 68, 12.50, 18, 0.00);\nINSERT INTO `order_items` VALUES (10790, 7, 30.00, 3, 0.15);\nINSERT INTO `order_items` VALUES (10790, 56, 38.00, 20, 0.15);\nINSERT INTO `order_items` VALUES (10791, 29, 123.79, 14, 0.05);\nINSERT INTO `order_items` VALUES (10791, 41, 9.65, 20, 0.05);\nINSERT INTO `order_items` VALUES (10792, 2, 19.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10792, 54, 7.45, 3, 0.00);\nINSERT INTO `order_items` VALUES (10792, 68, 12.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (10793, 41, 9.65, 14, 0.00);\nINSERT INTO `order_items` VALUES (10793, 52, 7.00, 8, 0.00);\nINSERT INTO `order_items` VALUES (10794, 14, 23.25, 15, 0.20);\nINSERT INTO `order_items` VALUES (10794, 54, 7.45, 6, 0.20);\nINSERT INTO `order_items` VALUES (10795, 16, 17.45, 65, 0.00);\nINSERT INTO `order_items` VALUES (10795, 17, 39.00, 35, 0.25);\nINSERT INTO `order_items` VALUES (10796, 26, 31.23, 21, 0.20);\nINSERT INTO `order_items` VALUES (10796, 44, 19.45, 10, 0.00);\nINSERT INTO `order_items` VALUES (10796, 64, 33.25, 35, 0.20);\nINSERT INTO `order_items` VALUES (10796, 69, 36.00, 24, 0.20);\nINSERT INTO `order_items` VALUES (10797, 11, 21.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10798, 62, 49.30, 2, 0.00);\nINSERT INTO `order_items` VALUES (10798, 72, 34.80, 10, 0.00);\nINSERT INTO `order_items` VALUES (10799, 13, 6.00, 20, 0.15);\nINSERT INTO `order_items` VALUES (10799, 24, 4.50, 20, 0.15);\nINSERT INTO `order_items` VALUES (10799, 59, 55.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10800, 11, 21.00, 50, 0.10);\nINSERT INTO `order_items` VALUES (10800, 51, 53.00, 10, 0.10);\nINSERT INTO `order_items` VALUES (10800, 54, 7.45, 7, 0.10);\nINSERT INTO `order_items` VALUES (10801, 17, 39.00, 40, 0.25);\nINSERT INTO `order_items` VALUES (10801, 29, 123.79, 20, 0.25);\nINSERT INTO `order_items` VALUES (10802, 30, 25.89, 25, 0.25);\nINSERT INTO `order_items` VALUES (10802, 51, 53.00, 30, 0.25);\nINSERT INTO `order_items` VALUES (10802, 55, 24.00, 60, 0.25);\nINSERT INTO `order_items` VALUES (10802, 62, 49.30, 5, 0.25);\nINSERT INTO `order_items` VALUES (10803, 19, 9.20, 24, 0.05);\nINSERT INTO `order_items` VALUES (10803, 25, 14.00, 15, 0.05);\nINSERT INTO `order_items` VALUES (10803, 59, 55.00, 15, 0.05);\nINSERT INTO `order_items` VALUES (10804, 10, 31.00, 36, 0.00);\nINSERT INTO `order_items` VALUES (10804, 28, 45.60, 24, 0.00);\nINSERT INTO `order_items` VALUES (10804, 49, 20.00, 4, 0.15);\nINSERT INTO `order_items` VALUES (10805, 34, 14.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10805, 38, 263.50, 10, 0.00);\nINSERT INTO `order_items` VALUES (10806, 2, 19.00, 20, 0.25);\nINSERT INTO `order_items` VALUES (10806, 65, 21.05, 2, 0.00);\nINSERT INTO `order_items` VALUES (10806, 74, 10.00, 15, 0.25);\nINSERT INTO `order_items` VALUES (10807, 40, 18.40, 1, 0.00);\nINSERT INTO `order_items` VALUES (10808, 56, 38.00, 20, 0.15);\nINSERT INTO `order_items` VALUES (10808, 76, 18.00, 50, 0.15);\nINSERT INTO `order_items` VALUES (10809, 52, 7.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10810, 13, 6.00, 7, 0.00);\nINSERT INTO `order_items` VALUES (10810, 25, 14.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10810, 70, 15.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10811, 19, 9.20, 15, 0.00);\nINSERT INTO `order_items` VALUES (10811, 23, 9.00, 18, 0.00);\nINSERT INTO `order_items` VALUES (10811, 40, 18.40, 30, 0.00);\nINSERT INTO `order_items` VALUES (10812, 31, 12.50, 16, 0.10);\nINSERT INTO `order_items` VALUES (10812, 72, 34.80, 40, 0.10);\nINSERT INTO `order_items` VALUES (10812, 77, 13.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10813, 2, 19.00, 12, 0.20);\nINSERT INTO `order_items` VALUES (10813, 46, 12.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (10814, 41, 9.65, 20, 0.00);\nINSERT INTO `order_items` VALUES (10814, 43, 46.00, 20, 0.15);\nINSERT INTO `order_items` VALUES (10814, 48, 12.75, 8, 0.15);\nINSERT INTO `order_items` VALUES (10814, 61, 28.50, 30, 0.15);\nINSERT INTO `order_items` VALUES (10815, 33, 2.50, 16, 0.00);\nINSERT INTO `order_items` VALUES (10816, 38, 263.50, 30, 0.05);\nINSERT INTO `order_items` VALUES (10816, 62, 49.30, 20, 0.05);\nINSERT INTO `order_items` VALUES (10817, 26, 31.23, 40, 0.15);\nINSERT INTO `order_items` VALUES (10817, 38, 263.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10817, 40, 18.40, 60, 0.15);\nINSERT INTO `order_items` VALUES (10817, 62, 49.30, 25, 0.15);\nINSERT INTO `order_items` VALUES (10818, 32, 32.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10818, 41, 9.65, 20, 0.00);\nINSERT INTO `order_items` VALUES (10819, 43, 46.00, 7, 0.00);\nINSERT INTO `order_items` VALUES (10819, 75, 7.75, 20, 0.00);\nINSERT INTO `order_items` VALUES (10820, 56, 38.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10821, 35, 18.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10821, 51, 53.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10822, 62, 49.30, 3, 0.00);\nINSERT INTO `order_items` VALUES (10822, 70, 15.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10823, 11, 21.00, 20, 0.10);\nINSERT INTO `order_items` VALUES (10823, 57, 19.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (10823, 59, 55.00, 40, 0.10);\nINSERT INTO `order_items` VALUES (10823, 77, 13.00, 15, 0.10);\nINSERT INTO `order_items` VALUES (10824, 41, 9.65, 12, 0.00);\nINSERT INTO `order_items` VALUES (10824, 70, 15.00, 9, 0.00);\nINSERT INTO `order_items` VALUES (10825, 26, 31.23, 12, 0.00);\nINSERT INTO `order_items` VALUES (10825, 53, 32.80, 20, 0.00);\nINSERT INTO `order_items` VALUES (10826, 31, 12.50, 35, 0.00);\nINSERT INTO `order_items` VALUES (10826, 57, 19.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (10827, 10, 31.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10827, 39, 18.00, 21, 0.00);\nINSERT INTO `order_items` VALUES (10828, 20, 81.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10828, 38, 263.50, 2, 0.00);\nINSERT INTO `order_items` VALUES (10829, 2, 19.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10829, 8, 40.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10829, 13, 6.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10829, 60, 34.00, 21, 0.00);\nINSERT INTO `order_items` VALUES (10830, 6, 25.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10830, 39, 18.00, 28, 0.00);\nINSERT INTO `order_items` VALUES (10830, 60, 34.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10830, 68, 12.50, 24, 0.00);\nINSERT INTO `order_items` VALUES (10831, 19, 9.20, 2, 0.00);\nINSERT INTO `order_items` VALUES (10831, 35, 18.00, 8, 0.00);\nINSERT INTO `order_items` VALUES (10831, 38, 263.50, 8, 0.00);\nINSERT INTO `order_items` VALUES (10831, 43, 46.00, 9, 0.00);\nINSERT INTO `order_items` VALUES (10832, 13, 6.00, 3, 0.20);\nINSERT INTO `order_items` VALUES (10832, 25, 14.00, 10, 0.20);\nINSERT INTO `order_items` VALUES (10832, 44, 19.45, 16, 0.20);\nINSERT INTO `order_items` VALUES (10832, 64, 33.25, 3, 0.00);\nINSERT INTO `order_items` VALUES (10833, 7, 30.00, 20, 0.10);\nINSERT INTO `order_items` VALUES (10833, 31, 12.50, 9, 0.10);\nINSERT INTO `order_items` VALUES (10833, 53, 32.80, 9, 0.10);\nINSERT INTO `order_items` VALUES (10834, 29, 123.79, 8, 0.05);\nINSERT INTO `order_items` VALUES (10834, 30, 25.89, 20, 0.05);\nINSERT INTO `order_items` VALUES (10835, 59, 55.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10835, 77, 13.00, 2, 0.20);\nINSERT INTO `order_items` VALUES (10836, 22, 21.00, 52, 0.00);\nINSERT INTO `order_items` VALUES (10836, 35, 18.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10836, 57, 19.50, 24, 0.00);\nINSERT INTO `order_items` VALUES (10836, 60, 34.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10836, 64, 33.25, 30, 0.00);\nINSERT INTO `order_items` VALUES (10837, 13, 6.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10837, 40, 18.40, 25, 0.00);\nINSERT INTO `order_items` VALUES (10837, 47, 9.50, 40, 0.25);\nINSERT INTO `order_items` VALUES (10837, 76, 18.00, 21, 0.25);\nINSERT INTO `order_items` VALUES (10838, 1, 18.00, 4, 0.25);\nINSERT INTO `order_items` VALUES (10838, 18, 62.50, 25, 0.25);\nINSERT INTO `order_items` VALUES (10838, 36, 19.00, 50, 0.25);\nINSERT INTO `order_items` VALUES (10839, 58, 13.25, 30, 0.10);\nINSERT INTO `order_items` VALUES (10839, 72, 34.80, 15, 0.10);\nINSERT INTO `order_items` VALUES (10840, 25, 14.00, 6, 0.20);\nINSERT INTO `order_items` VALUES (10840, 39, 18.00, 10, 0.20);\nINSERT INTO `order_items` VALUES (10841, 10, 31.00, 16, 0.00);\nINSERT INTO `order_items` VALUES (10841, 56, 38.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10841, 59, 55.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10841, 77, 13.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10842, 11, 21.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10842, 43, 46.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10842, 68, 12.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10842, 70, 15.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10843, 51, 53.00, 4, 0.25);\nINSERT INTO `order_items` VALUES (10844, 22, 21.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (10845, 23, 9.00, 70, 0.10);\nINSERT INTO `order_items` VALUES (10845, 35, 18.00, 25, 0.10);\nINSERT INTO `order_items` VALUES (10845, 42, 14.00, 42, 0.10);\nINSERT INTO `order_items` VALUES (10845, 58, 13.25, 60, 0.10);\nINSERT INTO `order_items` VALUES (10845, 64, 33.25, 48, 0.00);\nINSERT INTO `order_items` VALUES (10846, 4, 22.00, 21, 0.00);\nINSERT INTO `order_items` VALUES (10846, 70, 15.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10846, 74, 10.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10847, 1, 18.00, 80, 0.20);\nINSERT INTO `order_items` VALUES (10847, 19, 9.20, 12, 0.20);\nINSERT INTO `order_items` VALUES (10847, 37, 26.00, 60, 0.20);\nINSERT INTO `order_items` VALUES (10847, 45, 9.50, 36, 0.20);\nINSERT INTO `order_items` VALUES (10847, 60, 34.00, 45, 0.20);\nINSERT INTO `order_items` VALUES (10847, 71, 21.50, 55, 0.20);\nINSERT INTO `order_items` VALUES (10848, 5, 21.35, 30, 0.00);\nINSERT INTO `order_items` VALUES (10848, 9, 97.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (10849, 3, 10.00, 49, 0.00);\nINSERT INTO `order_items` VALUES (10849, 26, 31.23, 18, 0.15);\nINSERT INTO `order_items` VALUES (10850, 25, 14.00, 20, 0.15);\nINSERT INTO `order_items` VALUES (10850, 33, 2.50, 4, 0.15);\nINSERT INTO `order_items` VALUES (10850, 70, 15.00, 30, 0.15);\nINSERT INTO `order_items` VALUES (10851, 2, 19.00, 5, 0.05);\nINSERT INTO `order_items` VALUES (10851, 25, 14.00, 10, 0.05);\nINSERT INTO `order_items` VALUES (10851, 57, 19.50, 10, 0.05);\nINSERT INTO `order_items` VALUES (10851, 59, 55.00, 42, 0.05);\nINSERT INTO `order_items` VALUES (10852, 2, 19.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10852, 17, 39.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10852, 62, 49.30, 50, 0.00);\nINSERT INTO `order_items` VALUES (10853, 18, 62.50, 10, 0.00);\nINSERT INTO `order_items` VALUES (10854, 10, 31.00, 100, 0.15);\nINSERT INTO `order_items` VALUES (10854, 13, 6.00, 65, 0.15);\nINSERT INTO `order_items` VALUES (10855, 16, 17.45, 50, 0.00);\nINSERT INTO `order_items` VALUES (10855, 31, 12.50, 14, 0.00);\nINSERT INTO `order_items` VALUES (10855, 56, 38.00, 24, 0.00);\nINSERT INTO `order_items` VALUES (10855, 65, 21.05, 15, 0.15);\nINSERT INTO `order_items` VALUES (10856, 2, 19.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10856, 42, 14.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10857, 3, 10.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10857, 26, 31.23, 35, 0.25);\nINSERT INTO `order_items` VALUES (10857, 29, 123.79, 10, 0.25);\nINSERT INTO `order_items` VALUES (10858, 7, 30.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10858, 27, 43.90, 10, 0.00);\nINSERT INTO `order_items` VALUES (10858, 70, 15.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10859, 24, 4.50, 40, 0.25);\nINSERT INTO `order_items` VALUES (10859, 54, 7.45, 35, 0.25);\nINSERT INTO `order_items` VALUES (10859, 64, 33.25, 30, 0.25);\nINSERT INTO `order_items` VALUES (10860, 51, 53.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (10860, 76, 18.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10861, 17, 39.00, 42, 0.00);\nINSERT INTO `order_items` VALUES (10861, 18, 62.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10861, 21, 10.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10861, 33, 2.50, 35, 0.00);\nINSERT INTO `order_items` VALUES (10861, 62, 49.30, 3, 0.00);\nINSERT INTO `order_items` VALUES (10862, 11, 21.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10862, 52, 7.00, 8, 0.00);\nINSERT INTO `order_items` VALUES (10863, 1, 18.00, 20, 0.15);\nINSERT INTO `order_items` VALUES (10863, 58, 13.25, 12, 0.15);\nINSERT INTO `order_items` VALUES (10864, 35, 18.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10864, 67, 14.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10865, 38, 263.50, 60, 0.05);\nINSERT INTO `order_items` VALUES (10865, 39, 18.00, 80, 0.05);\nINSERT INTO `order_items` VALUES (10866, 2, 19.00, 21, 0.25);\nINSERT INTO `order_items` VALUES (10866, 24, 4.50, 6, 0.25);\nINSERT INTO `order_items` VALUES (10866, 30, 25.89, 40, 0.25);\nINSERT INTO `order_items` VALUES (10867, 53, 32.80, 3, 0.00);\nINSERT INTO `order_items` VALUES (10868, 26, 31.23, 20, 0.00);\nINSERT INTO `order_items` VALUES (10868, 35, 18.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10868, 49, 20.00, 42, 0.10);\nINSERT INTO `order_items` VALUES (10869, 1, 18.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10869, 11, 21.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10869, 23, 9.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10869, 68, 12.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10870, 35, 18.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (10870, 51, 53.00, 2, 0.00);\nINSERT INTO `order_items` VALUES (10871, 6, 25.00, 50, 0.05);\nINSERT INTO `order_items` VALUES (10871, 16, 17.45, 12, 0.05);\nINSERT INTO `order_items` VALUES (10871, 17, 39.00, 16, 0.05);\nINSERT INTO `order_items` VALUES (10872, 55, 24.00, 10, 0.05);\nINSERT INTO `order_items` VALUES (10872, 62, 49.30, 20, 0.05);\nINSERT INTO `order_items` VALUES (10872, 64, 33.25, 15, 0.05);\nINSERT INTO `order_items` VALUES (10872, 65, 21.05, 21, 0.05);\nINSERT INTO `order_items` VALUES (10873, 21, 10.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10873, 28, 45.60, 3, 0.00);\nINSERT INTO `order_items` VALUES (10874, 10, 31.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10875, 19, 9.20, 25, 0.00);\nINSERT INTO `order_items` VALUES (10875, 47, 9.50, 21, 0.10);\nINSERT INTO `order_items` VALUES (10875, 49, 20.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10876, 46, 12.00, 21, 0.00);\nINSERT INTO `order_items` VALUES (10876, 64, 33.25, 20, 0.00);\nINSERT INTO `order_items` VALUES (10877, 16, 17.45, 30, 0.25);\nINSERT INTO `order_items` VALUES (10877, 18, 62.50, 25, 0.00);\nINSERT INTO `order_items` VALUES (10878, 20, 81.00, 20, 0.05);\nINSERT INTO `order_items` VALUES (10879, 40, 18.40, 12, 0.00);\nINSERT INTO `order_items` VALUES (10879, 65, 21.05, 10, 0.00);\nINSERT INTO `order_items` VALUES (10879, 76, 18.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10880, 23, 9.00, 30, 0.20);\nINSERT INTO `order_items` VALUES (10880, 61, 28.50, 30, 0.20);\nINSERT INTO `order_items` VALUES (10880, 70, 15.00, 50, 0.20);\nINSERT INTO `order_items` VALUES (10881, 73, 15.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10882, 42, 14.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10882, 49, 20.00, 20, 0.15);\nINSERT INTO `order_items` VALUES (10882, 54, 7.45, 32, 0.15);\nINSERT INTO `order_items` VALUES (10883, 24, 4.50, 8, 0.00);\nINSERT INTO `order_items` VALUES (10884, 21, 10.00, 40, 0.05);\nINSERT INTO `order_items` VALUES (10884, 56, 38.00, 21, 0.05);\nINSERT INTO `order_items` VALUES (10884, 65, 21.05, 12, 0.05);\nINSERT INTO `order_items` VALUES (10885, 2, 19.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10885, 24, 4.50, 12, 0.00);\nINSERT INTO `order_items` VALUES (10885, 70, 15.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10885, 77, 13.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10886, 10, 31.00, 70, 0.00);\nINSERT INTO `order_items` VALUES (10886, 31, 12.50, 35, 0.00);\nINSERT INTO `order_items` VALUES (10886, 77, 13.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10887, 25, 14.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10888, 2, 19.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10888, 68, 12.50, 18, 0.00);\nINSERT INTO `order_items` VALUES (10889, 11, 21.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10889, 38, 263.50, 40, 0.00);\nINSERT INTO `order_items` VALUES (10890, 17, 39.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10890, 34, 14.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10890, 41, 9.65, 14, 0.00);\nINSERT INTO `order_items` VALUES (10891, 30, 25.89, 15, 0.05);\nINSERT INTO `order_items` VALUES (10892, 59, 55.00, 40, 0.05);\nINSERT INTO `order_items` VALUES (10893, 8, 40.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10893, 24, 4.50, 10, 0.00);\nINSERT INTO `order_items` VALUES (10893, 29, 123.79, 24, 0.00);\nINSERT INTO `order_items` VALUES (10893, 30, 25.89, 35, 0.00);\nINSERT INTO `order_items` VALUES (10893, 36, 19.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10894, 13, 6.00, 28, 0.05);\nINSERT INTO `order_items` VALUES (10894, 69, 36.00, 50, 0.05);\nINSERT INTO `order_items` VALUES (10894, 75, 7.75, 120, 0.05);\nINSERT INTO `order_items` VALUES (10895, 24, 4.50, 110, 0.00);\nINSERT INTO `order_items` VALUES (10895, 39, 18.00, 45, 0.00);\nINSERT INTO `order_items` VALUES (10895, 40, 18.40, 91, 0.00);\nINSERT INTO `order_items` VALUES (10895, 60, 34.00, 100, 0.00);\nINSERT INTO `order_items` VALUES (10896, 45, 9.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (10896, 56, 38.00, 16, 0.00);\nINSERT INTO `order_items` VALUES (10897, 29, 123.79, 80, 0.00);\nINSERT INTO `order_items` VALUES (10897, 30, 25.89, 36, 0.00);\nINSERT INTO `order_items` VALUES (10898, 13, 6.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10899, 39, 18.00, 8, 0.15);\nINSERT INTO `order_items` VALUES (10900, 70, 15.00, 3, 0.25);\nINSERT INTO `order_items` VALUES (10901, 41, 9.65, 30, 0.00);\nINSERT INTO `order_items` VALUES (10901, 71, 21.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10902, 55, 24.00, 30, 0.15);\nINSERT INTO `order_items` VALUES (10902, 62, 49.30, 6, 0.15);\nINSERT INTO `order_items` VALUES (10903, 13, 6.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10903, 65, 21.05, 21, 0.00);\nINSERT INTO `order_items` VALUES (10903, 68, 12.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10904, 58, 13.25, 15, 0.00);\nINSERT INTO `order_items` VALUES (10904, 62, 49.30, 35, 0.00);\nINSERT INTO `order_items` VALUES (10905, 1, 18.00, 20, 0.05);\nINSERT INTO `order_items` VALUES (10906, 61, 28.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (10907, 75, 7.75, 14, 0.00);\nINSERT INTO `order_items` VALUES (10908, 7, 30.00, 20, 0.05);\nINSERT INTO `order_items` VALUES (10908, 52, 7.00, 14, 0.05);\nINSERT INTO `order_items` VALUES (10909, 7, 30.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10909, 16, 17.45, 15, 0.00);\nINSERT INTO `order_items` VALUES (10909, 41, 9.65, 5, 0.00);\nINSERT INTO `order_items` VALUES (10910, 19, 9.20, 12, 0.00);\nINSERT INTO `order_items` VALUES (10910, 49, 20.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10910, 61, 28.50, 5, 0.00);\nINSERT INTO `order_items` VALUES (10911, 1, 18.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10911, 17, 39.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10911, 67, 14.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10912, 11, 21.00, 40, 0.25);\nINSERT INTO `order_items` VALUES (10912, 29, 123.79, 60, 0.25);\nINSERT INTO `order_items` VALUES (10913, 4, 22.00, 30, 0.25);\nINSERT INTO `order_items` VALUES (10913, 33, 2.50, 40, 0.25);\nINSERT INTO `order_items` VALUES (10913, 58, 13.25, 15, 0.00);\nINSERT INTO `order_items` VALUES (10914, 71, 21.50, 25, 0.00);\nINSERT INTO `order_items` VALUES (10915, 17, 39.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10915, 33, 2.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10915, 54, 7.45, 10, 0.00);\nINSERT INTO `order_items` VALUES (10916, 16, 17.45, 6, 0.00);\nINSERT INTO `order_items` VALUES (10916, 32, 32.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10916, 57, 19.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10917, 30, 25.89, 1, 0.00);\nINSERT INTO `order_items` VALUES (10917, 60, 34.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10918, 1, 18.00, 60, 0.25);\nINSERT INTO `order_items` VALUES (10918, 60, 34.00, 25, 0.25);\nINSERT INTO `order_items` VALUES (10919, 16, 17.45, 24, 0.00);\nINSERT INTO `order_items` VALUES (10919, 25, 14.00, 24, 0.00);\nINSERT INTO `order_items` VALUES (10919, 40, 18.40, 20, 0.00);\nINSERT INTO `order_items` VALUES (10920, 50, 16.25, 24, 0.00);\nINSERT INTO `order_items` VALUES (10921, 35, 18.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10921, 63, 43.90, 40, 0.00);\nINSERT INTO `order_items` VALUES (10922, 17, 39.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10922, 24, 4.50, 35, 0.00);\nINSERT INTO `order_items` VALUES (10923, 42, 14.00, 10, 0.20);\nINSERT INTO `order_items` VALUES (10923, 43, 46.00, 10, 0.20);\nINSERT INTO `order_items` VALUES (10923, 67, 14.00, 24, 0.20);\nINSERT INTO `order_items` VALUES (10924, 10, 31.00, 20, 0.10);\nINSERT INTO `order_items` VALUES (10924, 28, 45.60, 30, 0.10);\nINSERT INTO `order_items` VALUES (10924, 75, 7.75, 6, 0.00);\nINSERT INTO `order_items` VALUES (10925, 36, 19.00, 25, 0.15);\nINSERT INTO `order_items` VALUES (10925, 52, 7.00, 12, 0.15);\nINSERT INTO `order_items` VALUES (10926, 11, 21.00, 2, 0.00);\nINSERT INTO `order_items` VALUES (10926, 13, 6.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10926, 19, 9.20, 7, 0.00);\nINSERT INTO `order_items` VALUES (10926, 72, 34.80, 10, 0.00);\nINSERT INTO `order_items` VALUES (10927, 20, 81.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10927, 52, 7.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10927, 76, 18.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10928, 47, 9.50, 5, 0.00);\nINSERT INTO `order_items` VALUES (10928, 76, 18.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10929, 21, 10.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10929, 75, 7.75, 49, 0.00);\nINSERT INTO `order_items` VALUES (10929, 77, 13.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10930, 21, 10.00, 36, 0.00);\nINSERT INTO `order_items` VALUES (10930, 27, 43.90, 25, 0.00);\nINSERT INTO `order_items` VALUES (10930, 55, 24.00, 25, 0.20);\nINSERT INTO `order_items` VALUES (10930, 58, 13.25, 30, 0.20);\nINSERT INTO `order_items` VALUES (10931, 13, 6.00, 42, 0.15);\nINSERT INTO `order_items` VALUES (10931, 57, 19.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10932, 16, 17.45, 30, 0.10);\nINSERT INTO `order_items` VALUES (10932, 62, 49.30, 14, 0.10);\nINSERT INTO `order_items` VALUES (10932, 72, 34.80, 16, 0.00);\nINSERT INTO `order_items` VALUES (10932, 75, 7.75, 20, 0.10);\nINSERT INTO `order_items` VALUES (10933, 53, 32.80, 2, 0.00);\nINSERT INTO `order_items` VALUES (10933, 61, 28.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10934, 6, 25.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10935, 1, 18.00, 21, 0.00);\nINSERT INTO `order_items` VALUES (10935, 18, 62.50, 4, 0.25);\nINSERT INTO `order_items` VALUES (10935, 23, 9.00, 8, 0.25);\nINSERT INTO `order_items` VALUES (10936, 36, 19.00, 30, 0.20);\nINSERT INTO `order_items` VALUES (10937, 28, 45.60, 8, 0.00);\nINSERT INTO `order_items` VALUES (10937, 34, 14.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10938, 13, 6.00, 20, 0.25);\nINSERT INTO `order_items` VALUES (10938, 43, 46.00, 24, 0.25);\nINSERT INTO `order_items` VALUES (10938, 60, 34.00, 49, 0.25);\nINSERT INTO `order_items` VALUES (10938, 71, 21.50, 35, 0.25);\nINSERT INTO `order_items` VALUES (10939, 2, 19.00, 10, 0.15);\nINSERT INTO `order_items` VALUES (10939, 67, 14.00, 40, 0.15);\nINSERT INTO `order_items` VALUES (10940, 7, 30.00, 8, 0.00);\nINSERT INTO `order_items` VALUES (10940, 13, 6.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10941, 31, 12.50, 44, 0.25);\nINSERT INTO `order_items` VALUES (10941, 62, 49.30, 30, 0.25);\nINSERT INTO `order_items` VALUES (10941, 68, 12.50, 80, 0.25);\nINSERT INTO `order_items` VALUES (10941, 72, 34.80, 50, 0.00);\nINSERT INTO `order_items` VALUES (10942, 49, 20.00, 28, 0.00);\nINSERT INTO `order_items` VALUES (10943, 13, 6.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10943, 22, 21.00, 21, 0.00);\nINSERT INTO `order_items` VALUES (10943, 46, 12.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10944, 11, 21.00, 5, 0.25);\nINSERT INTO `order_items` VALUES (10944, 44, 19.45, 18, 0.25);\nINSERT INTO `order_items` VALUES (10944, 56, 38.00, 18, 0.00);\nINSERT INTO `order_items` VALUES (10945, 13, 6.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10945, 31, 12.50, 10, 0.00);\nINSERT INTO `order_items` VALUES (10946, 10, 31.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (10946, 24, 4.50, 25, 0.00);\nINSERT INTO `order_items` VALUES (10946, 77, 13.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10947, 59, 55.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10948, 50, 16.25, 9, 0.00);\nINSERT INTO `order_items` VALUES (10948, 51, 53.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10948, 55, 24.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10949, 6, 25.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10949, 10, 31.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10949, 17, 39.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10949, 62, 49.30, 60, 0.00);\nINSERT INTO `order_items` VALUES (10950, 4, 22.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (10951, 33, 2.50, 15, 0.05);\nINSERT INTO `order_items` VALUES (10951, 41, 9.65, 6, 0.05);\nINSERT INTO `order_items` VALUES (10951, 75, 7.75, 50, 0.05);\nINSERT INTO `order_items` VALUES (10952, 6, 25.00, 16, 0.05);\nINSERT INTO `order_items` VALUES (10952, 28, 45.60, 2, 0.00);\nINSERT INTO `order_items` VALUES (10953, 20, 81.00, 50, 0.05);\nINSERT INTO `order_items` VALUES (10953, 31, 12.50, 50, 0.05);\nINSERT INTO `order_items` VALUES (10954, 16, 17.45, 28, 0.15);\nINSERT INTO `order_items` VALUES (10954, 31, 12.50, 25, 0.15);\nINSERT INTO `order_items` VALUES (10954, 45, 9.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10954, 60, 34.00, 24, 0.15);\nINSERT INTO `order_items` VALUES (10955, 75, 7.75, 12, 0.20);\nINSERT INTO `order_items` VALUES (10956, 21, 10.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (10956, 47, 9.50, 14, 0.00);\nINSERT INTO `order_items` VALUES (10956, 51, 53.00, 8, 0.00);\nINSERT INTO `order_items` VALUES (10957, 30, 25.89, 30, 0.00);\nINSERT INTO `order_items` VALUES (10957, 35, 18.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10957, 64, 33.25, 8, 0.00);\nINSERT INTO `order_items` VALUES (10958, 5, 21.35, 20, 0.00);\nINSERT INTO `order_items` VALUES (10958, 7, 30.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10958, 72, 34.80, 5, 0.00);\nINSERT INTO `order_items` VALUES (10959, 75, 7.75, 20, 0.15);\nINSERT INTO `order_items` VALUES (10960, 24, 4.50, 10, 0.25);\nINSERT INTO `order_items` VALUES (10960, 41, 9.65, 24, 0.00);\nINSERT INTO `order_items` VALUES (10961, 52, 7.00, 6, 0.05);\nINSERT INTO `order_items` VALUES (10961, 76, 18.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10962, 7, 30.00, 45, 0.00);\nINSERT INTO `order_items` VALUES (10962, 13, 6.00, 77, 0.00);\nINSERT INTO `order_items` VALUES (10962, 53, 32.80, 20, 0.00);\nINSERT INTO `order_items` VALUES (10962, 69, 36.00, 9, 0.00);\nINSERT INTO `order_items` VALUES (10962, 76, 18.00, 44, 0.00);\nINSERT INTO `order_items` VALUES (10963, 60, 34.00, 2, 0.15);\nINSERT INTO `order_items` VALUES (10964, 18, 62.50, 6, 0.00);\nINSERT INTO `order_items` VALUES (10964, 38, 263.50, 5, 0.00);\nINSERT INTO `order_items` VALUES (10964, 69, 36.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10965, 51, 53.00, 16, 0.00);\nINSERT INTO `order_items` VALUES (10966, 37, 26.00, 8, 0.00);\nINSERT INTO `order_items` VALUES (10966, 56, 38.00, 12, 0.15);\nINSERT INTO `order_items` VALUES (10966, 62, 49.30, 12, 0.15);\nINSERT INTO `order_items` VALUES (10967, 19, 9.20, 12, 0.00);\nINSERT INTO `order_items` VALUES (10967, 49, 20.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10968, 12, 38.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10968, 24, 4.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10968, 64, 33.25, 4, 0.00);\nINSERT INTO `order_items` VALUES (10969, 46, 12.00, 9, 0.00);\nINSERT INTO `order_items` VALUES (10970, 52, 7.00, 40, 0.20);\nINSERT INTO `order_items` VALUES (10971, 29, 123.79, 14, 0.00);\nINSERT INTO `order_items` VALUES (10972, 17, 39.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10972, 33, 2.50, 7, 0.00);\nINSERT INTO `order_items` VALUES (10973, 26, 31.23, 5, 0.00);\nINSERT INTO `order_items` VALUES (10973, 41, 9.65, 6, 0.00);\nINSERT INTO `order_items` VALUES (10973, 75, 7.75, 10, 0.00);\nINSERT INTO `order_items` VALUES (10974, 63, 43.90, 10, 0.00);\nINSERT INTO `order_items` VALUES (10975, 8, 40.00, 16, 0.00);\nINSERT INTO `order_items` VALUES (10975, 75, 7.75, 10, 0.00);\nINSERT INTO `order_items` VALUES (10976, 28, 45.60, 20, 0.00);\nINSERT INTO `order_items` VALUES (10977, 39, 18.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10977, 47, 9.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (10977, 51, 53.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10977, 63, 43.90, 20, 0.00);\nINSERT INTO `order_items` VALUES (10978, 8, 40.00, 20, 0.15);\nINSERT INTO `order_items` VALUES (10978, 21, 10.00, 40, 0.15);\nINSERT INTO `order_items` VALUES (10978, 40, 18.40, 10, 0.00);\nINSERT INTO `order_items` VALUES (10978, 44, 19.45, 6, 0.15);\nINSERT INTO `order_items` VALUES (10979, 7, 30.00, 18, 0.00);\nINSERT INTO `order_items` VALUES (10979, 12, 38.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10979, 24, 4.50, 80, 0.00);\nINSERT INTO `order_items` VALUES (10979, 27, 43.90, 30, 0.00);\nINSERT INTO `order_items` VALUES (10979, 31, 12.50, 24, 0.00);\nINSERT INTO `order_items` VALUES (10979, 63, 43.90, 35, 0.00);\nINSERT INTO `order_items` VALUES (10980, 75, 7.75, 40, 0.20);\nINSERT INTO `order_items` VALUES (10981, 38, 263.50, 60, 0.00);\nINSERT INTO `order_items` VALUES (10982, 7, 30.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10982, 43, 46.00, 9, 0.00);\nINSERT INTO `order_items` VALUES (10983, 13, 6.00, 84, 0.15);\nINSERT INTO `order_items` VALUES (10983, 57, 19.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (10984, 16, 17.45, 55, 0.00);\nINSERT INTO `order_items` VALUES (10984, 24, 4.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (10984, 36, 19.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10985, 16, 17.45, 36, 0.10);\nINSERT INTO `order_items` VALUES (10985, 18, 62.50, 8, 0.10);\nINSERT INTO `order_items` VALUES (10985, 32, 32.00, 35, 0.10);\nINSERT INTO `order_items` VALUES (10986, 11, 21.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (10986, 20, 81.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10986, 76, 18.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (10986, 77, 13.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10987, 7, 30.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10987, 43, 46.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (10987, 72, 34.80, 20, 0.00);\nINSERT INTO `order_items` VALUES (10988, 7, 30.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (10988, 62, 49.30, 40, 0.10);\nINSERT INTO `order_items` VALUES (10989, 6, 25.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10989, 11, 21.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (10989, 41, 9.65, 4, 0.00);\nINSERT INTO `order_items` VALUES (10990, 21, 10.00, 65, 0.00);\nINSERT INTO `order_items` VALUES (10990, 34, 14.00, 60, 0.15);\nINSERT INTO `order_items` VALUES (10990, 55, 24.00, 65, 0.15);\nINSERT INTO `order_items` VALUES (10990, 61, 28.50, 66, 0.15);\nINSERT INTO `order_items` VALUES (10991, 2, 19.00, 50, 0.20);\nINSERT INTO `order_items` VALUES (10991, 70, 15.00, 20, 0.20);\nINSERT INTO `order_items` VALUES (10991, 76, 18.00, 90, 0.20);\nINSERT INTO `order_items` VALUES (10992, 72, 34.80, 2, 0.00);\nINSERT INTO `order_items` VALUES (10993, 29, 123.79, 50, 0.25);\nINSERT INTO `order_items` VALUES (10993, 41, 9.65, 35, 0.25);\nINSERT INTO `order_items` VALUES (10994, 59, 55.00, 18, 0.05);\nINSERT INTO `order_items` VALUES (10995, 51, 53.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10995, 60, 34.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (10996, 42, 14.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (10997, 32, 32.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (10997, 46, 12.00, 20, 0.25);\nINSERT INTO `order_items` VALUES (10997, 52, 7.00, 20, 0.25);\nINSERT INTO `order_items` VALUES (10998, 24, 4.50, 12, 0.00);\nINSERT INTO `order_items` VALUES (10998, 61, 28.50, 7, 0.00);\nINSERT INTO `order_items` VALUES (10998, 74, 10.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (10998, 75, 7.75, 30, 0.00);\nINSERT INTO `order_items` VALUES (10999, 41, 9.65, 20, 0.05);\nINSERT INTO `order_items` VALUES (10999, 51, 53.00, 15, 0.05);\nINSERT INTO `order_items` VALUES (10999, 77, 13.00, 21, 0.05);\nINSERT INTO `order_items` VALUES (11000, 4, 22.00, 25, 0.25);\nINSERT INTO `order_items` VALUES (11000, 24, 4.50, 30, 0.25);\nINSERT INTO `order_items` VALUES (11000, 77, 13.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (11001, 7, 30.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (11001, 22, 21.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (11001, 46, 12.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (11001, 55, 24.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (11002, 13, 6.00, 56, 0.00);\nINSERT INTO `order_items` VALUES (11002, 35, 18.00, 15, 0.15);\nINSERT INTO `order_items` VALUES (11002, 42, 14.00, 24, 0.15);\nINSERT INTO `order_items` VALUES (11002, 55, 24.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (11003, 1, 18.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (11003, 40, 18.40, 10, 0.00);\nINSERT INTO `order_items` VALUES (11003, 52, 7.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (11004, 26, 31.23, 6, 0.00);\nINSERT INTO `order_items` VALUES (11004, 76, 18.00, 6, 0.00);\nINSERT INTO `order_items` VALUES (11005, 1, 18.00, 2, 0.00);\nINSERT INTO `order_items` VALUES (11005, 59, 55.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (11006, 1, 18.00, 8, 0.00);\nINSERT INTO `order_items` VALUES (11006, 29, 123.79, 2, 0.25);\nINSERT INTO `order_items` VALUES (11007, 8, 40.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (11007, 29, 123.79, 10, 0.00);\nINSERT INTO `order_items` VALUES (11007, 42, 14.00, 14, 0.00);\nINSERT INTO `order_items` VALUES (11008, 28, 45.60, 70, 0.05);\nINSERT INTO `order_items` VALUES (11008, 34, 14.00, 90, 0.05);\nINSERT INTO `order_items` VALUES (11008, 71, 21.50, 21, 0.00);\nINSERT INTO `order_items` VALUES (11009, 24, 4.50, 12, 0.00);\nINSERT INTO `order_items` VALUES (11009, 36, 19.00, 18, 0.25);\nINSERT INTO `order_items` VALUES (11009, 60, 34.00, 9, 0.00);\nINSERT INTO `order_items` VALUES (11010, 7, 30.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (11010, 24, 4.50, 10, 0.00);\nINSERT INTO `order_items` VALUES (11011, 58, 13.25, 40, 0.05);\nINSERT INTO `order_items` VALUES (11011, 71, 21.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (11012, 19, 9.20, 50, 0.05);\nINSERT INTO `order_items` VALUES (11012, 60, 34.00, 36, 0.05);\nINSERT INTO `order_items` VALUES (11012, 71, 21.50, 60, 0.05);\nINSERT INTO `order_items` VALUES (11013, 23, 9.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (11013, 42, 14.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (11013, 45, 9.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (11013, 68, 12.50, 2, 0.00);\nINSERT INTO `order_items` VALUES (11014, 41, 9.65, 28, 0.10);\nINSERT INTO `order_items` VALUES (11015, 30, 25.89, 15, 0.00);\nINSERT INTO `order_items` VALUES (11015, 77, 13.00, 18, 0.00);\nINSERT INTO `order_items` VALUES (11016, 31, 12.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (11016, 36, 19.00, 16, 0.00);\nINSERT INTO `order_items` VALUES (11017, 3, 10.00, 25, 0.00);\nINSERT INTO `order_items` VALUES (11017, 59, 55.00, 110, 0.00);\nINSERT INTO `order_items` VALUES (11017, 70, 15.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (11018, 12, 38.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (11018, 18, 62.50, 10, 0.00);\nINSERT INTO `order_items` VALUES (11018, 56, 38.00, 5, 0.00);\nINSERT INTO `order_items` VALUES (11019, 46, 12.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (11019, 49, 20.00, 2, 0.00);\nINSERT INTO `order_items` VALUES (11020, 10, 31.00, 24, 0.15);\nINSERT INTO `order_items` VALUES (11021, 2, 19.00, 11, 0.25);\nINSERT INTO `order_items` VALUES (11021, 20, 81.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (11021, 26, 31.23, 63, 0.00);\nINSERT INTO `order_items` VALUES (11021, 51, 53.00, 44, 0.25);\nINSERT INTO `order_items` VALUES (11021, 72, 34.80, 35, 0.00);\nINSERT INTO `order_items` VALUES (11022, 19, 9.20, 35, 0.00);\nINSERT INTO `order_items` VALUES (11022, 69, 36.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (11023, 7, 30.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (11023, 43, 46.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (11024, 26, 31.23, 12, 0.00);\nINSERT INTO `order_items` VALUES (11024, 33, 2.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (11024, 65, 21.05, 21, 0.00);\nINSERT INTO `order_items` VALUES (11024, 71, 21.50, 50, 0.00);\nINSERT INTO `order_items` VALUES (11025, 1, 18.00, 10, 0.10);\nINSERT INTO `order_items` VALUES (11025, 13, 6.00, 20, 0.10);\nINSERT INTO `order_items` VALUES (11026, 18, 62.50, 8, 0.00);\nINSERT INTO `order_items` VALUES (11026, 51, 53.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (11027, 24, 4.50, 30, 0.25);\nINSERT INTO `order_items` VALUES (11027, 62, 49.30, 21, 0.25);\nINSERT INTO `order_items` VALUES (11028, 55, 24.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (11028, 59, 55.00, 24, 0.00);\nINSERT INTO `order_items` VALUES (11029, 56, 38.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (11029, 63, 43.90, 12, 0.00);\nINSERT INTO `order_items` VALUES (11030, 2, 19.00, 100, 0.25);\nINSERT INTO `order_items` VALUES (11030, 5, 21.35, 70, 0.00);\nINSERT INTO `order_items` VALUES (11030, 29, 123.79, 60, 0.25);\nINSERT INTO `order_items` VALUES (11030, 59, 55.00, 100, 0.25);\nINSERT INTO `order_items` VALUES (11031, 1, 18.00, 45, 0.00);\nINSERT INTO `order_items` VALUES (11031, 13, 6.00, 80, 0.00);\nINSERT INTO `order_items` VALUES (11031, 24, 4.50, 21, 0.00);\nINSERT INTO `order_items` VALUES (11031, 64, 33.25, 20, 0.00);\nINSERT INTO `order_items` VALUES (11031, 71, 21.50, 16, 0.00);\nINSERT INTO `order_items` VALUES (11032, 36, 19.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (11032, 38, 263.50, 25, 0.00);\nINSERT INTO `order_items` VALUES (11032, 59, 55.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (11033, 53, 32.80, 70, 0.10);\nINSERT INTO `order_items` VALUES (11033, 69, 36.00, 36, 0.10);\nINSERT INTO `order_items` VALUES (11034, 21, 10.00, 15, 0.10);\nINSERT INTO `order_items` VALUES (11034, 44, 19.45, 12, 0.00);\nINSERT INTO `order_items` VALUES (11034, 61, 28.50, 6, 0.00);\nINSERT INTO `order_items` VALUES (11035, 1, 18.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (11035, 35, 18.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (11035, 42, 14.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (11035, 54, 7.45, 10, 0.00);\nINSERT INTO `order_items` VALUES (11036, 13, 6.00, 7, 0.00);\nINSERT INTO `order_items` VALUES (11036, 59, 55.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (11037, 70, 15.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (11038, 40, 18.40, 5, 0.20);\nINSERT INTO `order_items` VALUES (11038, 52, 7.00, 2, 0.00);\nINSERT INTO `order_items` VALUES (11038, 71, 21.50, 30, 0.00);\nINSERT INTO `order_items` VALUES (11039, 28, 45.60, 20, 0.00);\nINSERT INTO `order_items` VALUES (11039, 35, 18.00, 24, 0.00);\nINSERT INTO `order_items` VALUES (11039, 49, 20.00, 60, 0.00);\nINSERT INTO `order_items` VALUES (11039, 57, 19.50, 28, 0.00);\nINSERT INTO `order_items` VALUES (11040, 21, 10.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (11041, 2, 19.00, 30, 0.20);\nINSERT INTO `order_items` VALUES (11041, 63, 43.90, 30, 0.00);\nINSERT INTO `order_items` VALUES (11042, 44, 19.45, 15, 0.00);\nINSERT INTO `order_items` VALUES (11042, 61, 28.50, 4, 0.00);\nINSERT INTO `order_items` VALUES (11043, 11, 21.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (11044, 62, 49.30, 12, 0.00);\nINSERT INTO `order_items` VALUES (11045, 33, 2.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (11045, 51, 53.00, 24, 0.00);\nINSERT INTO `order_items` VALUES (11046, 12, 38.00, 20, 0.05);\nINSERT INTO `order_items` VALUES (11046, 32, 32.00, 15, 0.05);\nINSERT INTO `order_items` VALUES (11046, 35, 18.00, 18, 0.05);\nINSERT INTO `order_items` VALUES (11047, 1, 18.00, 25, 0.25);\nINSERT INTO `order_items` VALUES (11047, 5, 21.35, 30, 0.25);\nINSERT INTO `order_items` VALUES (11048, 68, 12.50, 42, 0.00);\nINSERT INTO `order_items` VALUES (11049, 2, 19.00, 10, 0.20);\nINSERT INTO `order_items` VALUES (11049, 12, 38.00, 4, 0.20);\nINSERT INTO `order_items` VALUES (11050, 76, 18.00, 50, 0.10);\nINSERT INTO `order_items` VALUES (11051, 24, 4.50, 10, 0.20);\nINSERT INTO `order_items` VALUES (11052, 43, 46.00, 30, 0.20);\nINSERT INTO `order_items` VALUES (11052, 61, 28.50, 10, 0.20);\nINSERT INTO `order_items` VALUES (11053, 18, 62.50, 35, 0.20);\nINSERT INTO `order_items` VALUES (11053, 32, 32.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (11053, 64, 33.25, 25, 0.20);\nINSERT INTO `order_items` VALUES (11054, 33, 2.50, 10, 0.00);\nINSERT INTO `order_items` VALUES (11054, 67, 14.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (11055, 24, 4.50, 15, 0.00);\nINSERT INTO `order_items` VALUES (11055, 25, 14.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (11055, 51, 53.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (11055, 57, 19.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (11056, 7, 30.00, 40, 0.00);\nINSERT INTO `order_items` VALUES (11056, 55, 24.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (11056, 60, 34.00, 50, 0.00);\nINSERT INTO `order_items` VALUES (11057, 70, 15.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (11058, 21, 10.00, 3, 0.00);\nINSERT INTO `order_items` VALUES (11058, 60, 34.00, 21, 0.00);\nINSERT INTO `order_items` VALUES (11058, 61, 28.50, 4, 0.00);\nINSERT INTO `order_items` VALUES (11059, 13, 6.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (11059, 17, 39.00, 12, 0.00);\nINSERT INTO `order_items` VALUES (11059, 60, 34.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (11060, 60, 34.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (11060, 77, 13.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (11061, 60, 34.00, 15, 0.00);\nINSERT INTO `order_items` VALUES (11062, 53, 32.80, 10, 0.20);\nINSERT INTO `order_items` VALUES (11062, 70, 15.00, 12, 0.20);\nINSERT INTO `order_items` VALUES (11063, 34, 14.00, 30, 0.00);\nINSERT INTO `order_items` VALUES (11063, 40, 18.40, 40, 0.10);\nINSERT INTO `order_items` VALUES (11063, 41, 9.65, 30, 0.10);\nINSERT INTO `order_items` VALUES (11064, 17, 39.00, 77, 0.10);\nINSERT INTO `order_items` VALUES (11064, 41, 9.65, 12, 0.00);\nINSERT INTO `order_items` VALUES (11064, 53, 32.80, 25, 0.10);\nINSERT INTO `order_items` VALUES (11064, 55, 24.00, 4, 0.10);\nINSERT INTO `order_items` VALUES (11064, 68, 12.50, 55, 0.00);\nINSERT INTO `order_items` VALUES (11065, 30, 25.89, 4, 0.25);\nINSERT INTO `order_items` VALUES (11065, 54, 7.45, 20, 0.25);\nINSERT INTO `order_items` VALUES (11066, 16, 17.45, 3, 0.00);\nINSERT INTO `order_items` VALUES (11066, 19, 9.20, 42, 0.00);\nINSERT INTO `order_items` VALUES (11066, 34, 14.00, 35, 0.00);\nINSERT INTO `order_items` VALUES (11067, 41, 9.65, 9, 0.00);\nINSERT INTO `order_items` VALUES (11068, 28, 45.60, 8, 0.15);\nINSERT INTO `order_items` VALUES (11068, 43, 46.00, 36, 0.15);\nINSERT INTO `order_items` VALUES (11068, 77, 13.00, 28, 0.15);\nINSERT INTO `order_items` VALUES (11069, 39, 18.00, 20, 0.00);\nINSERT INTO `order_items` VALUES (11070, 1, 18.00, 40, 0.15);\nINSERT INTO `order_items` VALUES (11070, 2, 19.00, 20, 0.15);\nINSERT INTO `order_items` VALUES (11070, 16, 17.45, 30, 0.15);\nINSERT INTO `order_items` VALUES (11070, 31, 12.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (11071, 7, 30.00, 15, 0.05);\nINSERT INTO `order_items` VALUES (11071, 13, 6.00, 10, 0.05);\nINSERT INTO `order_items` VALUES (11072, 2, 19.00, 8, 0.00);\nINSERT INTO `order_items` VALUES (11072, 41, 9.65, 40, 0.00);\nINSERT INTO `order_items` VALUES (11072, 50, 16.25, 22, 0.00);\nINSERT INTO `order_items` VALUES (11072, 64, 33.25, 130, 0.00);\nINSERT INTO `order_items` VALUES (11073, 11, 21.00, 10, 0.00);\nINSERT INTO `order_items` VALUES (11073, 24, 4.50, 20, 0.00);\nINSERT INTO `order_items` VALUES (11074, 16, 17.45, 14, 0.05);\nINSERT INTO `order_items` VALUES (11075, 2, 19.00, 10, 0.15);\nINSERT INTO `order_items` VALUES (11075, 46, 12.00, 30, 0.15);\nINSERT INTO `order_items` VALUES (11075, 76, 18.00, 2, 0.15);\nINSERT INTO `order_items` VALUES (11076, 6, 25.00, 20, 0.25);\nINSERT INTO `order_items` VALUES (11076, 14, 23.25, 20, 0.25);\nINSERT INTO `order_items` VALUES (11076, 19, 9.20, 10, 0.25);\nINSERT INTO `order_items` VALUES (11077, 2, 19.00, 24, 0.20);\nINSERT INTO `order_items` VALUES (11077, 3, 10.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (11077, 4, 22.00, 1, 0.00);\nINSERT INTO `order_items` VALUES (11077, 6, 25.00, 1, 0.02);\nINSERT INTO `order_items` VALUES (11077, 7, 30.00, 1, 0.05);\nINSERT INTO `order_items` VALUES (11077, 8, 40.00, 2, 0.10);\nINSERT INTO `order_items` VALUES (11077, 10, 31.00, 1, 0.00);\nINSERT INTO `order_items` VALUES (11077, 12, 38.00, 2, 0.05);\nINSERT INTO `order_items` VALUES (11077, 13, 6.00, 4, 0.00);\nINSERT INTO `order_items` VALUES (11077, 14, 23.25, 1, 0.03);\nINSERT INTO `order_items` VALUES (11077, 16, 17.45, 2, 0.03);\nINSERT INTO `order_items` VALUES (11077, 20, 81.00, 1, 0.04);\nINSERT INTO `order_items` VALUES (11077, 23, 9.00, 2, 0.00);\nINSERT INTO `order_items` VALUES (11077, 32, 32.00, 1, 0.00);\nINSERT INTO `order_items` VALUES (11077, 39, 18.00, 2, 0.05);\nINSERT INTO `order_items` VALUES (11077, 41, 9.65, 3, 0.00);\nINSERT INTO `order_items` VALUES (11077, 46, 12.00, 3, 0.02);\nINSERT INTO `order_items` VALUES (11077, 52, 7.00, 2, 0.00);\nINSERT INTO `order_items` VALUES (11077, 55, 24.00, 2, 0.00);\nINSERT INTO `order_items` VALUES (11077, 60, 34.00, 2, 0.06);\nINSERT INTO `order_items` VALUES (11077, 64, 33.25, 2, 0.03);\nINSERT INTO `order_items` VALUES (11077, 66, 17.00, 1, 0.00);\nINSERT INTO `order_items` VALUES (11077, 73, 15.00, 2, 0.01);\nINSERT INTO `order_items` VALUES (11077, 75, 7.75, 4, 0.00);\nINSERT INTO `order_items` VALUES (11077, 77, 13.00, 2, 0.00);\nCOMMIT;\n\n-- ----------------------------\n-- Table structure for orders\n-- ----------------------------\nDROP TABLE IF EXISTS `orders`;\nCREATE TABLE `orders` (\n  `order_id` int NOT NULL,\n  `customer_id` varchar(5) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `employee_id` int DEFAULT NULL,\n  `order_date` datetime DEFAULT NULL,\n  `shipped_date` datetime DEFAULT NULL,\n  `ship_via` int DEFAULT NULL,\n  `freight` decimal(10,2) DEFAULT NULL,\n  `ship_address` varchar(60) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `ship_city` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `ship_region` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `ship_postal_code` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `ship_country` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  PRIMARY KEY (`order_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;\n\n-- ----------------------------\n-- Records of orders\n-- ----------------------------\nBEGIN;\nINSERT INTO `orders` VALUES (10248, 'VINET', 5, '2016-07-04 00:00:00', '2016-07-16 00:00:00', 3, 32.38, '59 rue de l\\'\\'Abbaye', 'Reims', NULL, '51100', 'France');\nINSERT INTO `orders` VALUES (10249, 'TOMSP', 6, '2016-07-05 00:00:00', '2016-07-10 00:00:00', 1, 11.61, 'Luisenstr. 48', 'Münster', NULL, '44087', 'Germany');\nINSERT INTO `orders` VALUES (10250, 'HANAR', 4, '2016-07-08 00:00:00', '2016-07-12 00:00:00', 2, 65.83, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (10251, 'VICTE', 3, '2016-07-08 00:00:00', '2016-07-15 00:00:00', 1, 41.34, '2-rue du Commerce', 'Lyo', NULL, '69004', 'France');\nINSERT INTO `orders` VALUES (10252, 'SUPRD', 4, '2016-07-09 00:00:00', '2016-07-11 00:00:00', 2, 51.30, 'Boulevard Tirou-255', 'Charleroi', NULL, 'B-6000', 'Belgium');\nINSERT INTO `orders` VALUES (10253, 'HANAR', 3, '2016-07-10 00:00:00', '2016-07-16 00:00:00', 2, 58.17, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (10254, 'CHOPS', 5, '2016-07-11 00:00:00', '2016-07-23 00:00:00', 2, 22.98, 'Hauptstr. 31', 'Ber', NULL, '3012', 'Switzerland');\nINSERT INTO `orders` VALUES (10255, 'RICSU', 9, '2016-07-12 00:00:00', '2016-07-15 00:00:00', 3, 148.33, 'Starenweg 5', 'Genève', NULL, '1204', 'Switzerland');\nINSERT INTO `orders` VALUES (10256, 'WELLI', 3, '2016-07-15 00:00:00', '2016-07-17 00:00:00', 2, 13.97, 'Rua do Mercado-12', 'Resende', 'SP', '08737-363', 'Brazil');\nINSERT INTO `orders` VALUES (10257, 'HILAA', 4, '2016-07-16 00:00:00', '2016-07-22 00:00:00', 3, 81.91, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10258, 'ERNSH', 1, '2016-07-17 00:00:00', '2016-07-23 00:00:00', 1, 140.51, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10259, 'CENTC', 4, '2016-07-18 00:00:00', '2016-07-25 00:00:00', 3, 3.25, 'Sierras de Granada 9993', 'México D.F.', NULL, '05022', 'Mexico');\nINSERT INTO `orders` VALUES (10260, 'OTTIK', 4, '2016-07-19 00:00:00', '2016-07-29 00:00:00', 1, 55.09, 'Mehrheimerstr. 369', 'Köl', NULL, '50739', 'Germany');\nINSERT INTO `orders` VALUES (10261, 'QUEDE', 10, '2016-07-19 00:00:00', '2016-07-30 00:00:00', 2, 3.05, 'Rua da Panificadora-12', 'Rio de Janeiro', 'RJ', '02389-673', 'Brazil');\nINSERT INTO `orders` VALUES (10262, 'RATTC', 8, '2016-07-22 00:00:00', '2016-07-25 00:00:00', 3, 48.29, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10263, 'ERNSH', 9, '2016-07-23 00:00:00', '2016-07-31 00:00:00', 3, 146.06, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10264, 'FOLKO', 6, '2016-07-24 00:00:00', '2016-08-23 00:00:00', 3, 3.67, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10265, 'BLONP', 2, '2016-07-25 00:00:00', '2016-08-12 00:00:00', 1, 55.28, '24-place Kléber', 'Strasbourg', NULL, '67000', 'France');\nINSERT INTO `orders` VALUES (10266, 'WARTH', 3, '2016-07-26 00:00:00', '2016-07-31 00:00:00', 3, 25.73, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10267, 'FRANK', 4, '2016-07-29 00:00:00', '2016-08-06 00:00:00', 1, 208.58, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10268, 'GROSR', 8, '2016-07-30 00:00:00', '2016-08-02 00:00:00', 3, 66.29, '5ª Ave. Los Palos Grandes', 'Caracas', 'DF', '1081', 'Venezuela');\nINSERT INTO `orders` VALUES (10269, 'WHITC', 5, '2016-07-31 00:00:00', '2016-08-09 00:00:00', 1, 4.56, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (10270, 'WARTH', 1, '2016-08-01 00:00:00', '2016-08-02 00:00:00', 1, 136.54, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10271, 'SPLIR', 6, '2016-08-01 00:00:00', '2016-08-30 00:00:00', 2, 4.54, 'P.O. Box 555', 'Lander', 'WY', '82520', 'USA');\nINSERT INTO `orders` VALUES (10272, 'RATTC', 6, '2016-08-02 00:00:00', '2016-08-06 00:00:00', 2, 98.03, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10273, 'QUICK', 3, '2016-08-05 00:00:00', '2016-08-12 00:00:00', 3, 76.07, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10274, 'VINET', 6, '2016-08-06 00:00:00', '2016-08-16 00:00:00', 1, 6.01, '59 rue de l\\'\\'Abbaye', 'Reims', NULL, '51100', 'France');\nINSERT INTO `orders` VALUES (10275, 'MAGAA', 1, '2016-08-07 00:00:00', '2016-08-09 00:00:00', 1, 26.93, 'Via Ludovico il Moro 22', 'Bergamo', NULL, '24100', 'Italy');\nINSERT INTO `orders` VALUES (10276, 'TORTU', 8, '2016-08-08 00:00:00', '2016-08-14 00:00:00', 3, 13.84, 'Avda. Azteca 123', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10277, 'MORGK', 2, '2016-08-09 00:00:00', '2016-08-13 00:00:00', 3, 125.77, 'Heerstr. 22', 'Leipzig', NULL, '04179', 'Germany');\nINSERT INTO `orders` VALUES (10278, 'BERGS', 8, '2016-08-12 00:00:00', '2016-08-16 00:00:00', 2, 92.69, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10279, 'LEHMS', 8, '2016-08-13 00:00:00', '2016-08-16 00:00:00', 2, 25.83, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10280, 'BERGS', 2, '2016-08-14 00:00:00', '2016-09-12 00:00:00', 1, 8.98, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10281, 'ROMEY', 4, '2016-08-14 00:00:00', '2016-08-21 00:00:00', 1, 2.94, 'Gran Vía-1', 'Madrid', NULL, '28001', 'Spain');\nINSERT INTO `orders` VALUES (10282, 'ROMEY', 4, '2016-08-15 00:00:00', '2016-08-21 00:00:00', 1, 12.69, 'Gran Vía-1', 'Madrid', NULL, '28001', 'Spain');\nINSERT INTO `orders` VALUES (10283, 'LILAS', 3, '2016-08-16 00:00:00', '2016-08-23 00:00:00', 3, 84.81, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (10284, 'LEHMS', 4, '2016-08-19 00:00:00', '2016-08-27 00:00:00', 1, 76.56, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10285, 'QUICK', 1, '2016-08-20 00:00:00', '2016-08-26 00:00:00', 2, 76.83, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10286, 'QUICK', 8, '2016-08-21 00:00:00', '2016-08-30 00:00:00', 3, 229.24, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10287, 'RICAR', 8, '2016-08-22 00:00:00', '2016-08-28 00:00:00', 3, 12.76, 'Av. Copacabana-267', 'Rio de Janeiro', 'RJ', '02389-890', 'Brazil');\nINSERT INTO `orders` VALUES (10288, 'REGGC', 4, '2016-08-23 00:00:00', '2016-09-03 00:00:00', 1, 7.45, 'Strada Provinciale 124', 'Reggio Emilia', NULL, '42100', 'Italy');\nINSERT INTO `orders` VALUES (10289, 'BSBEV', 7, '2016-08-26 00:00:00', '2016-08-28 00:00:00', 3, 22.77, 'Fauntleroy Circus', 'Londo', NULL, 'EC2 5NT', 'UK');\nINSERT INTO `orders` VALUES (10290, 'COMMI', 8, '2016-08-27 00:00:00', '2016-09-03 00:00:00', 1, 79.70, 'Av. dos Lusíadas-23', 'Sao Paulo', 'SP', '05432-043', 'Brazil');\nINSERT INTO `orders` VALUES (10291, 'QUEDE', 6, '2016-08-27 00:00:00', '2016-09-04 00:00:00', 2, 6.40, 'Rua da Panificadora-12', 'Rio de Janeiro', 'RJ', '02389-673', 'Brazil');\nINSERT INTO `orders` VALUES (10292, 'TRADH', 1, '2016-08-28 00:00:00', '2016-09-02 00:00:00', 2, 1.35, 'Av. Inês de Castro-414', 'Sao Paulo', 'SP', '05634-030', 'Brazil');\nINSERT INTO `orders` VALUES (10293, 'TORTU', 1, '2016-08-29 00:00:00', '2016-09-11 00:00:00', 3, 21.18, 'Avda. Azteca 123', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10294, 'RATTC', 4, '2016-08-30 00:00:00', '2016-09-05 00:00:00', 2, 147.26, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10295, 'VINET', 2, '2016-09-02 00:00:00', '2016-09-10 00:00:00', 2, 1.15, '59 rue de l\\'\\'Abbaye', 'Reims', NULL, '51100', 'France');\nINSERT INTO `orders` VALUES (10296, 'LILAS', 6, '2016-09-03 00:00:00', '2016-09-11 00:00:00', 1, 0.12, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (10297, 'BLONP', 5, '2016-09-04 00:00:00', '2016-09-10 00:00:00', 2, 5.74, '24-place Kléber', 'Strasbourg', NULL, '67000', 'France');\nINSERT INTO `orders` VALUES (10298, 'HUNGO', 6, '2016-09-05 00:00:00', '2016-09-11 00:00:00', 2, 168.22, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10299, 'RICAR', 4, '2016-09-06 00:00:00', '2016-09-13 00:00:00', 2, 29.76, 'Av. Copacabana-267', 'Rio de Janeiro', 'RJ', '02389-890', 'Brazil');\nINSERT INTO `orders` VALUES (10300, 'MAGAA', 2, '2016-09-09 00:00:00', '2016-09-18 00:00:00', 2, 17.68, 'Via Ludovico il Moro 22', 'Bergamo', NULL, '24100', 'Italy');\nINSERT INTO `orders` VALUES (10301, 'WANDK', 8, '2016-09-09 00:00:00', '2016-09-17 00:00:00', 2, 45.08, 'Adenauerallee 900', 'Stuttgart', NULL, '70563', 'Germany');\nINSERT INTO `orders` VALUES (10302, 'SUPRD', 4, '2016-09-10 00:00:00', '2016-10-09 00:00:00', 2, 6.27, 'Boulevard Tirou-255', 'Charleroi', NULL, 'B-6000', 'Belgium');\nINSERT INTO `orders` VALUES (10303, 'GODOS', 7, '2016-09-11 00:00:00', '2016-09-18 00:00:00', 2, 107.83, 'C/ Romero-33', 'Sevilla', NULL, '41101', 'Spain');\nINSERT INTO `orders` VALUES (10304, 'TORTU', 1, '2016-09-12 00:00:00', '2016-09-17 00:00:00', 2, 63.79, 'Avda. Azteca 123', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10305, 'OLDWO', 8, '2016-09-13 00:00:00', '2016-10-09 00:00:00', 3, 257.62, '2743 Bering St.', 'Anchorage', 'AK', '99508', 'USA');\nINSERT INTO `orders` VALUES (10306, 'ROMEY', 1, '2016-09-16 00:00:00', '2016-09-23 00:00:00', 3, 7.56, 'Gran Vía-1', 'Madrid', NULL, '28001', 'Spain');\nINSERT INTO `orders` VALUES (10307, 'LONEP', 2, '2016-09-17 00:00:00', '2016-09-25 00:00:00', 2, 0.56, '89 Chiaroscuro Rd.', 'Portland', 'OR', '97219', 'USA');\nINSERT INTO `orders` VALUES (10308, 'ANATR', 7, '2016-09-18 00:00:00', '2016-09-24 00:00:00', 3, 1.61, 'Avda. de la Constitución 2222', 'México D.F.', NULL, '05021', 'Mexico');\nINSERT INTO `orders` VALUES (10309, 'HUNGO', 3, '2016-09-19 00:00:00', '2016-10-23 00:00:00', 1, 47.30, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10310, 'THEBI', 8, '2016-09-20 00:00:00', '2016-09-27 00:00:00', 2, 17.52, '89 Jefferson Way Suite 2', 'Portland', 'OR', '97201', 'USA');\nINSERT INTO `orders` VALUES (10311, 'DUMO', 1, '2016-09-20 00:00:00', '2016-09-26 00:00:00', 3, 24.69, '67-rue des Cinquante Otages', 'Nantes', NULL, '44000', 'France');\nINSERT INTO `orders` VALUES (10312, 'WANDK', 2, '2016-09-23 00:00:00', '2016-10-03 00:00:00', 2, 40.26, 'Adenauerallee 900', 'Stuttgart', NULL, '70563', 'Germany');\nINSERT INTO `orders` VALUES (10313, 'QUICK', 2, '2016-09-24 00:00:00', '2016-10-04 00:00:00', 2, 1.96, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10314, 'RATTC', 1, '2016-09-25 00:00:00', '2016-10-04 00:00:00', 2, 74.16, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10315, 'ISLAT', 4, '2016-09-26 00:00:00', '2016-10-03 00:00:00', 2, 41.76, 'Garden House Crowther Way', 'Cowes', 'Isle of Wight', 'PO31 7PJ', 'UK');\nINSERT INTO `orders` VALUES (10316, 'RATTC', 1, '2016-09-27 00:00:00', '2016-10-08 00:00:00', 3, 150.15, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10317, 'LONEP', 6, '2016-09-30 00:00:00', '2016-10-10 00:00:00', 1, 12.69, '89 Chiaroscuro Rd.', 'Portland', 'OR', '97219', 'USA');\nINSERT INTO `orders` VALUES (10318, 'ISLAT', 8, '2016-10-01 00:00:00', '2016-10-04 00:00:00', 2, 4.73, 'Garden House Crowther Way', 'Cowes', 'Isle of Wight', 'PO31 7PJ', 'UK');\nINSERT INTO `orders` VALUES (10319, 'TORTU', 7, '2016-10-02 00:00:00', '2016-10-11 00:00:00', 3, 64.50, 'Avda. Azteca 123', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10320, 'WARTH', 5, '2016-10-03 00:00:00', '2016-10-18 00:00:00', 3, 34.57, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10321, 'ISLAT', 3, '2016-10-03 00:00:00', '2016-10-11 00:00:00', 2, 3.43, 'Garden House Crowther Way', 'Cowes', 'Isle of Wight', 'PO31 7PJ', 'UK');\nINSERT INTO `orders` VALUES (10322, 'PERIC', 7, '2016-10-04 00:00:00', '2016-10-23 00:00:00', 3, 0.40, 'Calle Dr. Jorge Cash 321', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10323, 'KOENE', 4, '2016-10-07 00:00:00', '2016-10-14 00:00:00', 1, 4.88, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (10324, 'SAVEA', 9, '2016-10-08 00:00:00', '2016-10-10 00:00:00', 1, 214.27, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10325, 'KOENE', 1, '2016-10-09 00:00:00', '2016-10-14 00:00:00', 3, 64.86, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (10326, 'BOLID', 4, '2016-10-10 00:00:00', '2016-10-14 00:00:00', 2, 77.92, 'C/ Araquil-67', 'Madrid', NULL, '28023', 'Spain');\nINSERT INTO `orders` VALUES (10327, 'FOLKO', 2, '2016-10-11 00:00:00', '2016-10-14 00:00:00', 1, 63.36, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10328, 'FURIB', 4, '2016-10-14 00:00:00', '2016-10-17 00:00:00', 3, 87.03, 'Jardim das rosas n. 32', 'Lisboa', NULL, '1675', 'Portugal');\nINSERT INTO `orders` VALUES (10329, 'SPLIR', 4, '2016-10-15 00:00:00', '2016-10-23 00:00:00', 2, 191.67, 'P.O. Box 555', 'Lander', 'WY', '82520', 'USA');\nINSERT INTO `orders` VALUES (10330, 'LILAS', 3, '2016-10-16 00:00:00', '2016-10-28 00:00:00', 1, 12.75, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (10331, 'BONAP', 9, '2016-10-16 00:00:00', '2016-10-21 00:00:00', 1, 10.19, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10332, 'MEREP', 3, '2016-10-17 00:00:00', '2016-10-21 00:00:00', 2, 52.84, '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `orders` VALUES (10333, 'WARTH', 5, '2016-10-18 00:00:00', '2016-10-25 00:00:00', 3, 0.59, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10334, 'VICTE', 8, '2016-10-21 00:00:00', '2016-10-28 00:00:00', 2, 8.56, '2-rue du Commerce', 'Lyo', NULL, '69004', 'France');\nINSERT INTO `orders` VALUES (10335, 'HUNGO', 7, '2016-10-22 00:00:00', '2016-10-24 00:00:00', 2, 42.11, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10336, 'PRINI', 7, '2016-10-23 00:00:00', '2016-10-25 00:00:00', 2, 15.51, 'Estrada da saúde n. 58', 'Lisboa', NULL, '1756', 'Portugal');\nINSERT INTO `orders` VALUES (10337, 'FRANK', 4, '2016-10-24 00:00:00', '2016-10-29 00:00:00', 3, 108.26, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10338, 'OLDWO', 4, '2016-10-25 00:00:00', '2016-10-29 00:00:00', 3, 84.21, '2743 Bering St.', 'Anchorage', 'AK', '99508', 'USA');\nINSERT INTO `orders` VALUES (10339, 'MEREP', 2, '2016-10-28 00:00:00', '2016-11-04 00:00:00', 2, 15.66, '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `orders` VALUES (10340, 'BONAP', 1, '2016-10-29 00:00:00', '2016-11-08 00:00:00', 3, 166.31, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10341, 'SIMOB', 7, '2016-10-29 00:00:00', '2016-11-05 00:00:00', 3, 26.78, 'Vinbæltet 34', 'Kobenhav', NULL, '1734', 'Denmark');\nINSERT INTO `orders` VALUES (10342, 'FRANK', 4, '2016-10-30 00:00:00', '2016-11-04 00:00:00', 2, 54.83, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10343, 'LEHMS', 4, '2016-10-31 00:00:00', '2016-11-06 00:00:00', 1, 110.37, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10344, 'WHITC', 4, '2016-11-01 00:00:00', '2016-11-05 00:00:00', 2, 23.29, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (10345, 'QUICK', 2, '2016-11-04 00:00:00', '2016-11-11 00:00:00', 2, 249.06, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10346, 'RATTC', 3, '2016-11-05 00:00:00', '2016-11-08 00:00:00', 3, 142.08, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10347, 'FAMIA', 4, '2016-11-06 00:00:00', '2016-11-08 00:00:00', 3, 3.10, 'Rua Orós-92', 'Sao Paulo', 'SP', '05442-030', 'Brazil');\nINSERT INTO `orders` VALUES (10348, 'WANDK', 4, '2016-11-07 00:00:00', '2016-11-15 00:00:00', 2, 0.78, 'Adenauerallee 900', 'Stuttgart', NULL, '70563', 'Germany');\nINSERT INTO `orders` VALUES (10349, 'SPLIR', 7, '2016-11-08 00:00:00', '2016-11-15 00:00:00', 1, 8.63, 'P.O. Box 555', 'Lander', 'WY', '82520', 'USA');\nINSERT INTO `orders` VALUES (10350, 'LAMAI', 6, '2016-11-11 00:00:00', '2016-12-03 00:00:00', 2, 64.19, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (10351, 'ERNSH', 1, '2016-11-11 00:00:00', '2016-11-20 00:00:00', 1, 162.33, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10352, 'FURIB', 3, '2016-11-12 00:00:00', '2016-11-18 00:00:00', 3, 1.30, 'Jardim das rosas n. 32', 'Lisboa', NULL, '1675', 'Portugal');\nINSERT INTO `orders` VALUES (10353, 'PICCO', 7, '2016-11-13 00:00:00', '2016-11-25 00:00:00', 3, 360.63, 'Geislweg 14', 'Salzburg', NULL, '5020', 'Austria');\nINSERT INTO `orders` VALUES (10354, 'PERIC', 8, '2016-11-14 00:00:00', '2016-11-20 00:00:00', 3, 53.80, 'Calle Dr. Jorge Cash 321', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10355, 'AROUT', 6, '2016-11-15 00:00:00', '2016-11-20 00:00:00', 1, 41.95, 'Brook Farm Stratford St. Mary', 'Colchester', 'Essex', 'CO7 6JX', 'UK');\nINSERT INTO `orders` VALUES (10356, 'WANDK', 6, '2016-11-18 00:00:00', '2016-11-27 00:00:00', 2, 36.71, 'Adenauerallee 900', 'Stuttgart', NULL, '70563', 'Germany');\nINSERT INTO `orders` VALUES (10357, 'LILAS', 1, '2016-11-19 00:00:00', '2016-12-02 00:00:00', 3, 34.88, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (10358, 'LAMAI', 5, '2016-11-20 00:00:00', '2016-11-27 00:00:00', 1, 19.64, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (10359, 'SEVES', 5, '2016-11-21 00:00:00', '2016-11-26 00:00:00', 3, 288.43, '90 Wadhurst Rd.', 'Londo', NULL, 'OX15 4NB', 'UK');\nINSERT INTO `orders` VALUES (10360, 'BLONP', 4, '2016-11-22 00:00:00', '2016-12-02 00:00:00', 3, 131.70, '24-place Kléber', 'Strasbourg', NULL, '67000', 'France');\nINSERT INTO `orders` VALUES (10361, 'QUICK', 1, '2016-11-22 00:00:00', '2016-12-03 00:00:00', 2, 183.17, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10362, 'BONAP', 3, '2016-11-25 00:00:00', '2016-11-28 00:00:00', 1, 96.04, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10363, 'DRACD', 4, '2016-11-26 00:00:00', '2016-12-04 00:00:00', 3, 30.54, 'Walserweg 21', 'Aache', NULL, '52066', 'Germany');\nINSERT INTO `orders` VALUES (10364, 'EASTC', 1, '2016-11-26 00:00:00', '2016-12-04 00:00:00', 1, 71.97, '35 King George', 'Londo', NULL, 'WX3 6FW', 'UK');\nINSERT INTO `orders` VALUES (10365, 'ANTO', 3, '2016-11-27 00:00:00', '2016-12-02 00:00:00', 2, 22.00, 'Mataderos  2312', 'México D.F.', NULL, '05023', 'Mexico');\nINSERT INTO `orders` VALUES (10366, 'GALED', 8, '2016-11-28 00:00:00', '2016-12-30 00:00:00', 2, 10.14, 'Rambla de Cataluña-23', 'Barcelona', NULL, '8022', 'Spain');\nINSERT INTO `orders` VALUES (10367, 'VAFFE', 7, '2016-11-28 00:00:00', '2016-12-02 00:00:00', 3, 13.55, 'Smagsloget 45', 'Århus', NULL, '8200', 'Denmark');\nINSERT INTO `orders` VALUES (10368, 'ERNSH', 2, '2016-11-29 00:00:00', '2016-12-02 00:00:00', 2, 101.95, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10369, 'SPLIR', 8, '2016-12-02 00:00:00', '2016-12-09 00:00:00', 2, 195.68, 'P.O. Box 555', 'Lander', 'WY', '82520', 'USA');\nINSERT INTO `orders` VALUES (10370, 'CHOPS', 6, '2016-12-03 00:00:00', '2016-12-27 00:00:00', 2, 1.17, 'Hauptstr. 31', 'Ber', NULL, '3012', 'Switzerland');\nINSERT INTO `orders` VALUES (10371, 'LAMAI', 1, '2016-12-03 00:00:00', '2016-12-24 00:00:00', 1, 0.45, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (10372, 'QUEE', 5, '2016-12-04 00:00:00', '2016-12-09 00:00:00', 2, 890.78, 'Alameda dos Canàrios-891', 'Sao Paulo', 'SP', '05487-020', 'Brazil');\nINSERT INTO `orders` VALUES (10373, 'HUNGO', 4, '2016-12-05 00:00:00', '2016-12-11 00:00:00', 3, 124.12, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10374, 'WOLZA', 1, '2016-12-05 00:00:00', '2016-12-09 00:00:00', 3, 3.94, 'ul. Filtrowa 68', 'Warszawa', NULL, '01-012', 'Poland');\nINSERT INTO `orders` VALUES (10375, 'HUNGC', 3, '2016-12-06 00:00:00', '2016-12-09 00:00:00', 2, 20.12, 'City Center Plaza 516 Main St.', 'Elgi', 'OR', '97827', 'USA');\nINSERT INTO `orders` VALUES (10376, 'MEREP', 1, '2016-12-09 00:00:00', '2016-12-13 00:00:00', 2, 20.39, '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `orders` VALUES (10377, 'SEVES', 1, '2016-12-09 00:00:00', '2016-12-13 00:00:00', 3, 22.21, '90 Wadhurst Rd.', 'Londo', NULL, 'OX15 4NB', 'UK');\nINSERT INTO `orders` VALUES (10378, 'FOLKO', 5, '2016-12-10 00:00:00', '2016-12-19 00:00:00', 3, 5.44, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10379, 'QUEDE', 2, '2016-12-11 00:00:00', '2016-12-13 00:00:00', 1, 45.03, 'Rua da Panificadora-12', 'Rio de Janeiro', 'RJ', '02389-673', 'Brazil');\nINSERT INTO `orders` VALUES (10380, 'HUNGO', 8, '2016-12-12 00:00:00', '2017-01-16 00:00:00', 3, 35.03, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10381, 'LILAS', 3, '2016-12-12 00:00:00', '2016-12-13 00:00:00', 3, 7.99, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (10382, 'ERNSH', 4, '2016-12-13 00:00:00', '2016-12-16 00:00:00', 1, 94.77, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10383, 'AROUT', 8, '2016-12-16 00:00:00', '2016-12-18 00:00:00', 3, 34.24, 'Brook Farm Stratford St. Mary', 'Colchester', 'Essex', 'CO7 6JX', 'UK');\nINSERT INTO `orders` VALUES (10384, 'BERGS', 3, '2016-12-16 00:00:00', '2016-12-20 00:00:00', 3, 168.64, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10385, 'SPLIR', 1, '2016-12-17 00:00:00', '2016-12-23 00:00:00', 2, 30.96, 'P.O. Box 555', 'Lander', 'WY', '82520', 'USA');\nINSERT INTO `orders` VALUES (10386, 'FAMIA', 9, '2016-12-18 00:00:00', '2016-12-25 00:00:00', 3, 13.99, 'Rua Orós-92', 'Sao Paulo', 'SP', '05442-030', 'Brazil');\nINSERT INTO `orders` VALUES (10387, 'SANTG', 1, '2016-12-18 00:00:00', '2016-12-20 00:00:00', 2, 93.63, 'Erling Skakkes gate 78', 'Staver', NULL, '4110', 'Norway');\nINSERT INTO `orders` VALUES (10388, 'SEVES', 2, '2016-12-19 00:00:00', '2016-12-20 00:00:00', 1, 34.86, '90 Wadhurst Rd.', 'Londo', NULL, 'OX15 4NB', 'UK');\nINSERT INTO `orders` VALUES (10389, 'BOTTM', 4, '2016-12-20 00:00:00', '2016-12-24 00:00:00', 2, 47.42, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (10390, 'ERNSH', 6, '2016-12-23 00:00:00', '2016-12-26 00:00:00', 1, 126.38, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10391, 'DRACD', 3, '2016-12-23 00:00:00', '2016-12-31 00:00:00', 3, 5.45, 'Walserweg 21', 'Aache', NULL, '52066', 'Germany');\nINSERT INTO `orders` VALUES (10392, 'PICCO', 2, '2016-12-24 00:00:00', '2017-01-01 00:00:00', 3, 122.46, 'Geislweg 14', 'Salzburg', NULL, '5020', 'Austria');\nINSERT INTO `orders` VALUES (10393, 'SAVEA', 1, '2016-12-25 00:00:00', '2017-01-03 00:00:00', 3, 126.56, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10394, 'HUNGC', 1, '2016-12-25 00:00:00', '2017-01-03 00:00:00', 3, 30.34, 'City Center Plaza 516 Main St.', 'Elgi', 'OR', '97827', 'USA');\nINSERT INTO `orders` VALUES (10395, 'HILAA', 6, '2016-12-26 00:00:00', '2017-01-03 00:00:00', 1, 184.41, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10396, 'FRANK', 1, '2016-12-27 00:00:00', '2017-01-06 00:00:00', 3, 135.35, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10397, 'PRINI', 5, '2016-12-27 00:00:00', '2017-01-02 00:00:00', 1, 60.26, 'Estrada da saúde n. 58', 'Lisboa', NULL, '1756', 'Portugal');\nINSERT INTO `orders` VALUES (10398, 'SAVEA', 2, '2016-12-30 00:00:00', '2017-01-09 00:00:00', 3, 89.16, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10399, 'VAFFE', 8, '2016-12-31 00:00:00', '2017-01-08 00:00:00', 3, 27.36, 'Smagsloget 45', 'Århus', NULL, '8200', 'Denmark');\nINSERT INTO `orders` VALUES (10400, 'EASTC', 1, '2017-01-01 00:00:00', '2017-01-16 00:00:00', 3, 83.93, '35 King George', 'Londo', NULL, 'WX3 6FW', 'UK');\nINSERT INTO `orders` VALUES (10401, 'RATTC', 1, '2017-01-01 00:00:00', '2017-01-10 00:00:00', 1, 12.51, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10402, 'ERNSH', 8, '2017-01-02 00:00:00', '2017-01-10 00:00:00', 2, 67.88, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10403, 'ERNSH', 4, '2017-01-03 00:00:00', '2017-01-09 00:00:00', 3, 73.79, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10404, 'MAGAA', 2, '2017-01-03 00:00:00', '2017-01-08 00:00:00', 1, 155.97, 'Via Ludovico il Moro 22', 'Bergamo', NULL, '24100', 'Italy');\nINSERT INTO `orders` VALUES (10405, 'LINOD', 1, '2017-01-06 00:00:00', '2017-01-22 00:00:00', 1, 34.82, 'Ave. 5 de Mayo Porlamar', 'I. de Margarita', 'Nueva Esparta', '4980', 'Venezuela');\nINSERT INTO `orders` VALUES (10406, 'QUEE', 7, '2017-01-07 00:00:00', '2017-01-13 00:00:00', 1, 108.04, 'Alameda dos Canàrios-891', 'Sao Paulo', 'SP', '05487-020', 'Brazil');\nINSERT INTO `orders` VALUES (10407, 'OTTIK', 2, '2017-01-07 00:00:00', '2017-01-30 00:00:00', 2, 91.48, 'Mehrheimerstr. 369', 'Köl', NULL, '50739', 'Germany');\nINSERT INTO `orders` VALUES (10408, 'FOLIG', 8, '2017-01-08 00:00:00', '2017-01-14 00:00:00', 1, 11.26, '184-chaussée de Tournai', 'Lille', NULL, '59000', 'France');\nINSERT INTO `orders` VALUES (10409, 'OCEA', 3, '2017-01-09 00:00:00', '2017-01-14 00:00:00', 1, 29.83, 'Ing. Gustavo Moncada 8585 Piso 20-A', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10410, 'BOTTM', 3, '2017-01-10 00:00:00', '2017-01-15 00:00:00', 3, 2.40, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (10411, 'BOTTM', 9, '2017-01-10 00:00:00', '2017-01-21 00:00:00', 3, 23.65, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (10412, 'WARTH', 8, '2017-01-13 00:00:00', '2017-01-15 00:00:00', 2, 3.77, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10413, 'LAMAI', 3, '2017-01-14 00:00:00', '2017-01-16 00:00:00', 2, 95.66, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (10414, 'FAMIA', 2, '2017-01-14 00:00:00', '2017-01-17 00:00:00', 3, 21.48, 'Rua Orós-92', 'Sao Paulo', 'SP', '05442-030', 'Brazil');\nINSERT INTO `orders` VALUES (10415, 'HUNGC', 3, '2017-01-15 00:00:00', '2017-01-24 00:00:00', 1, 0.20, 'City Center Plaza 516 Main St.', 'Elgi', 'OR', '97827', 'USA');\nINSERT INTO `orders` VALUES (10416, 'WARTH', 8, '2017-01-16 00:00:00', '2017-01-27 00:00:00', 3, 22.72, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10417, 'SIMOB', 4, '2017-01-16 00:00:00', '2017-01-28 00:00:00', 3, 70.29, 'Vinbæltet 34', 'Kobenhav', NULL, '1734', 'Denmark');\nINSERT INTO `orders` VALUES (10418, 'QUICK', 4, '2017-01-17 00:00:00', '2017-01-24 00:00:00', 1, 17.55, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10419, 'RICSU', 4, '2017-01-20 00:00:00', '2017-01-30 00:00:00', 2, 137.35, 'Starenweg 5', 'Genève', NULL, '1204', 'Switzerland');\nINSERT INTO `orders` VALUES (10420, 'WELLI', 3, '2017-01-21 00:00:00', '2017-01-27 00:00:00', 1, 44.12, 'Rua do Mercado-12', 'Resende', 'SP', '08737-363', 'Brazil');\nINSERT INTO `orders` VALUES (10421, 'QUEDE', 8, '2017-01-21 00:00:00', '2017-01-27 00:00:00', 1, 99.23, 'Rua da Panificadora-12', 'Rio de Janeiro', 'RJ', '02389-673', 'Brazil');\nINSERT INTO `orders` VALUES (10422, 'FRANS', 2, '2017-01-22 00:00:00', '2017-01-31 00:00:00', 1, 3.02, 'Via Monte Bianco 34', 'Torino', NULL, '10100', 'Italy');\nINSERT INTO `orders` VALUES (10423, 'GOURL', 6, '2017-01-23 00:00:00', '2017-02-24 00:00:00', 3, 24.50, 'Av. Brasil-442', 'Campinas', 'SP', '04876-786', 'Brazil');\nINSERT INTO `orders` VALUES (10424, 'MEREP', 7, '2017-01-23 00:00:00', '2017-01-27 00:00:00', 2, 370.61, '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `orders` VALUES (10425, 'LAMAI', 6, '2017-01-24 00:00:00', '2017-02-14 00:00:00', 2, 7.93, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (10426, 'GALED', 4, '2017-01-27 00:00:00', '2017-02-06 00:00:00', 1, 18.69, 'Rambla de Cataluña-23', 'Barcelona', NULL, '8022', 'Spain');\nINSERT INTO `orders` VALUES (10427, 'PICCO', 4, '2017-01-27 00:00:00', '2017-03-03 00:00:00', 2, 31.29, 'Geislweg 14', 'Salzburg', NULL, '5020', 'Austria');\nINSERT INTO `orders` VALUES (10428, 'REGGC', 7, '2017-01-28 00:00:00', '2017-02-04 00:00:00', 1, 11.09, 'Strada Provinciale 124', 'Reggio Emilia', NULL, '42100', 'Italy');\nINSERT INTO `orders` VALUES (10429, 'HUNGO', 3, '2017-01-29 00:00:00', '2017-02-07 00:00:00', 2, 56.63, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10430, 'ERNSH', 4, '2017-01-30 00:00:00', '2017-02-03 00:00:00', 1, 458.78, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10431, 'BOTTM', 4, '2017-01-30 00:00:00', '2017-02-07 00:00:00', 2, 44.17, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (10432, 'SPLIR', 3, '2017-01-31 00:00:00', '2017-02-07 00:00:00', 2, 4.34, 'P.O. Box 555', 'Lander', 'WY', '82520', 'USA');\nINSERT INTO `orders` VALUES (10433, 'PRINI', 3, '2017-02-03 00:00:00', '2017-03-04 00:00:00', 3, 73.83, 'Estrada da saúde n. 58', 'Lisboa', NULL, '1756', 'Portugal');\nINSERT INTO `orders` VALUES (10434, 'FOLKO', 3, '2017-02-03 00:00:00', '2017-02-13 00:00:00', 2, 17.92, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10435, 'CONSH', 8, '2017-02-04 00:00:00', '2017-02-07 00:00:00', 2, 9.21, 'Berkeley Gardens 12  Brewery', 'Londo', NULL, 'WX1 6LT', 'UK');\nINSERT INTO `orders` VALUES (10436, 'BLONP', 3, '2017-02-05 00:00:00', '2017-02-11 00:00:00', 2, 156.66, '24-place Kléber', 'Strasbourg', NULL, '67000', 'France');\nINSERT INTO `orders` VALUES (10437, 'WARTH', 8, '2017-02-05 00:00:00', '2017-02-12 00:00:00', 1, 19.97, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10438, 'TOMSP', 3, '2017-02-06 00:00:00', '2017-02-14 00:00:00', 2, 8.24, 'Luisenstr. 48', 'Münster', NULL, '44087', 'Germany');\nINSERT INTO `orders` VALUES (10439, 'MEREP', 6, '2017-02-07 00:00:00', '2017-02-10 00:00:00', 3, 4.07, '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `orders` VALUES (10440, 'SAVEA', 4, '2017-02-10 00:00:00', '2017-02-28 00:00:00', 2, 86.53, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10441, 'OLDWO', 3, '2017-02-10 00:00:00', '2017-03-14 00:00:00', 2, 73.02, '2743 Bering St.', 'Anchorage', 'AK', '99508', 'USA');\nINSERT INTO `orders` VALUES (10442, 'ERNSH', 3, '2017-02-11 00:00:00', '2017-02-18 00:00:00', 2, 47.94, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10443, 'REGGC', 8, '2017-02-12 00:00:00', '2017-02-14 00:00:00', 1, 13.95, 'Strada Provinciale 124', 'Reggio Emilia', NULL, '42100', 'Italy');\nINSERT INTO `orders` VALUES (10444, 'BERGS', 3, '2017-02-12 00:00:00', '2017-02-21 00:00:00', 3, 3.50, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10445, 'BERGS', 3, '2017-02-13 00:00:00', '2017-02-20 00:00:00', 1, 9.30, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10446, 'TOMSP', 6, '2017-02-14 00:00:00', '2017-02-19 00:00:00', 1, 14.68, 'Luisenstr. 48', 'Münster', NULL, '44087', 'Germany');\nINSERT INTO `orders` VALUES (10447, 'RICAR', 4, '2017-02-14 00:00:00', '2017-03-07 00:00:00', 2, 68.66, 'Av. Copacabana-267', 'Rio de Janeiro', 'RJ', '02389-890', 'Brazil');\nINSERT INTO `orders` VALUES (10448, 'RANCH', 4, '2017-02-17 00:00:00', '2017-02-24 00:00:00', 2, 38.82, 'Av. del Libertador 900', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10449, 'BLONP', 3, '2017-02-18 00:00:00', '2017-02-27 00:00:00', 2, 53.30, '24-place Kléber', 'Strasbourg', NULL, '67000', 'France');\nINSERT INTO `orders` VALUES (10450, 'VICTE', 8, '2017-02-19 00:00:00', '2017-03-11 00:00:00', 2, 7.23, '2-rue du Commerce', 'Lyo', NULL, '69004', 'France');\nINSERT INTO `orders` VALUES (10451, 'QUICK', 4, '2017-02-19 00:00:00', '2017-03-12 00:00:00', 3, 189.09, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10452, 'SAVEA', 8, '2017-02-20 00:00:00', '2017-02-26 00:00:00', 1, 140.26, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10453, 'AROUT', 1, '2017-02-21 00:00:00', '2017-02-26 00:00:00', 2, 25.36, 'Brook Farm Stratford St. Mary', 'Colchester', 'Essex', 'CO7 6JX', 'UK');\nINSERT INTO `orders` VALUES (10454, 'LAMAI', 4, '2017-02-21 00:00:00', '2017-02-25 00:00:00', 3, 2.74, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (10455, 'WARTH', 8, '2017-02-24 00:00:00', '2017-03-03 00:00:00', 2, 180.45, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10456, 'KOENE', 8, '2017-02-25 00:00:00', '2017-02-28 00:00:00', 2, 8.12, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (10457, 'KOENE', 2, '2017-02-25 00:00:00', '2017-03-03 00:00:00', 1, 11.57, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (10458, 'SUPRD', 7, '2017-02-26 00:00:00', '2017-03-04 00:00:00', 3, 147.06, 'Boulevard Tirou-255', 'Charleroi', NULL, 'B-6000', 'Belgium');\nINSERT INTO `orders` VALUES (10459, 'VICTE', 4, '2017-02-27 00:00:00', '2017-02-28 00:00:00', 2, 25.09, '2-rue du Commerce', 'Lyo', NULL, '69004', 'France');\nINSERT INTO `orders` VALUES (10460, 'FOLKO', 8, '2017-02-28 00:00:00', '2017-03-03 00:00:00', 1, 16.27, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10461, 'LILAS', 1, '2017-02-28 00:00:00', '2017-03-05 00:00:00', 3, 148.61, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (10462, 'CONSH', 2, '2017-03-03 00:00:00', '2017-03-18 00:00:00', 1, 6.17, 'Berkeley Gardens 12  Brewery', 'Londo', NULL, 'WX1 6LT', 'UK');\nINSERT INTO `orders` VALUES (10463, 'SUPRD', 5, '2017-03-04 00:00:00', '2017-03-06 00:00:00', 3, 14.78, 'Boulevard Tirou-255', 'Charleroi', NULL, 'B-6000', 'Belgium');\nINSERT INTO `orders` VALUES (10464, 'FURIB', 4, '2017-03-04 00:00:00', '2017-03-14 00:00:00', 2, 89.00, 'Jardim das rosas n. 32', 'Lisboa', NULL, '1675', 'Portugal');\nINSERT INTO `orders` VALUES (10465, 'VAFFE', 1, '2017-03-05 00:00:00', '2017-03-14 00:00:00', 3, 145.04, 'Smagsloget 45', 'Århus', NULL, '8200', 'Denmark');\nINSERT INTO `orders` VALUES (10466, 'COMMI', 4, '2017-03-06 00:00:00', '2017-03-13 00:00:00', 1, 11.93, 'Av. dos Lusíadas-23', 'Sao Paulo', 'SP', '05432-043', 'Brazil');\nINSERT INTO `orders` VALUES (10467, 'MAGAA', 8, '2017-03-06 00:00:00', '2017-03-11 00:00:00', 2, 4.93, 'Via Ludovico il Moro 22', 'Bergamo', NULL, '24100', 'Italy');\nINSERT INTO `orders` VALUES (10468, 'KOENE', 3, '2017-03-07 00:00:00', '2017-03-12 00:00:00', 3, 44.12, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (10469, 'WHITC', 1, '2017-03-10 00:00:00', '2017-03-14 00:00:00', 1, 60.18, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (10470, 'BONAP', 4, '2017-03-11 00:00:00', '2017-03-14 00:00:00', 2, 64.56, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10471, 'BSBEV', 2, '2017-03-11 00:00:00', '2017-03-18 00:00:00', 3, 45.59, 'Fauntleroy Circus', 'Londo', NULL, 'EC2 5NT', 'UK');\nINSERT INTO `orders` VALUES (10472, 'SEVES', 8, '2017-03-12 00:00:00', '2017-03-19 00:00:00', 1, 4.20, '90 Wadhurst Rd.', 'Londo', NULL, 'OX15 4NB', 'UK');\nINSERT INTO `orders` VALUES (10473, 'ISLAT', 1, '2017-03-13 00:00:00', '2017-03-21 00:00:00', 3, 16.37, 'Garden House Crowther Way', 'Cowes', 'Isle of Wight', 'PO31 7PJ', 'UK');\nINSERT INTO `orders` VALUES (10474, 'PERIC', 5, '2017-03-13 00:00:00', '2017-03-21 00:00:00', 2, 83.49, 'Calle Dr. Jorge Cash 321', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10475, 'SUPRD', 9, '2017-03-14 00:00:00', '2017-04-04 00:00:00', 1, 68.52, 'Boulevard Tirou-255', 'Charleroi', NULL, 'B-6000', 'Belgium');\nINSERT INTO `orders` VALUES (10476, 'HILAA', 8, '2017-03-17 00:00:00', '2017-03-24 00:00:00', 3, 4.41, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10477, 'PRINI', 5, '2017-03-17 00:00:00', '2017-03-25 00:00:00', 2, 13.02, 'Estrada da saúde n. 58', 'Lisboa', NULL, '1756', 'Portugal');\nINSERT INTO `orders` VALUES (10478, 'VICTE', 2, '2017-03-18 00:00:00', '2017-03-26 00:00:00', 3, 4.81, '2-rue du Commerce', 'Lyo', NULL, '69004', 'France');\nINSERT INTO `orders` VALUES (10479, 'RATTC', 3, '2017-03-19 00:00:00', '2017-03-21 00:00:00', 3, 708.95, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10480, 'FOLIG', 6, '2017-03-20 00:00:00', '2017-03-24 00:00:00', 2, 1.35, '184-chaussée de Tournai', 'Lille', NULL, '59000', 'France');\nINSERT INTO `orders` VALUES (10481, 'RICAR', 8, '2017-03-20 00:00:00', '2017-03-25 00:00:00', 2, 64.33, 'Av. Copacabana-267', 'Rio de Janeiro', 'RJ', '02389-890', 'Brazil');\nINSERT INTO `orders` VALUES (10482, 'LAZYK', 1, '2017-03-21 00:00:00', '2017-04-10 00:00:00', 3, 7.48, '12 Orchestra Terrace', 'Walla Walla', 'WA', '99362', 'USA');\nINSERT INTO `orders` VALUES (10483, 'WHITC', 7, '2017-03-24 00:00:00', '2017-04-25 00:00:00', 2, 15.28, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (10484, 'BSBEV', 3, '2017-03-24 00:00:00', '2017-04-01 00:00:00', 3, 6.88, 'Fauntleroy Circus', 'Londo', NULL, 'EC2 5NT', 'UK');\nINSERT INTO `orders` VALUES (10485, 'LINOD', 4, '2017-03-25 00:00:00', '2017-03-31 00:00:00', 2, 64.45, 'Ave. 5 de Mayo Porlamar', 'I. de Margarita', 'Nueva Esparta', '4980', 'Venezuela');\nINSERT INTO `orders` VALUES (10486, 'HILAA', 1, '2017-03-26 00:00:00', '2017-04-02 00:00:00', 2, 30.53, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10487, 'QUEE', 2, '2017-03-26 00:00:00', '2017-03-28 00:00:00', 2, 71.07, 'Alameda dos Canàrios-891', 'Sao Paulo', 'SP', '05487-020', 'Brazil');\nINSERT INTO `orders` VALUES (10488, 'FRANK', 8, '2017-03-27 00:00:00', '2017-04-02 00:00:00', 2, 4.93, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10489, 'PICCO', 6, '2017-03-28 00:00:00', '2017-04-09 00:00:00', 2, 5.29, 'Geislweg 14', 'Salzburg', NULL, '5020', 'Austria');\nINSERT INTO `orders` VALUES (10490, 'HILAA', 7, '2017-03-31 00:00:00', '2017-04-03 00:00:00', 2, 210.19, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10491, 'FURIB', 8, '2017-03-31 00:00:00', '2017-04-08 00:00:00', 3, 16.96, 'Jardim das rosas n. 32', 'Lisboa', NULL, '1675', 'Portugal');\nINSERT INTO `orders` VALUES (10492, 'BOTTM', 3, '2017-04-01 00:00:00', '2017-04-11 00:00:00', 1, 62.89, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (10493, 'LAMAI', 4, '2017-04-02 00:00:00', '2017-04-10 00:00:00', 3, 10.64, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (10494, 'COMMI', 4, '2017-04-02 00:00:00', '2017-04-09 00:00:00', 2, 65.99, 'Av. dos Lusíadas-23', 'Sao Paulo', 'SP', '05432-043', 'Brazil');\nINSERT INTO `orders` VALUES (10495, 'LAUGB', 3, '2017-04-03 00:00:00', '2017-04-11 00:00:00', 3, 4.65, '2319 Elm St.', 'Vancouver', 'BC', 'V3F 2K1', 'Canada');\nINSERT INTO `orders` VALUES (10496, 'TRADH', 7, '2017-04-04 00:00:00', '2017-04-07 00:00:00', 2, 46.77, 'Av. Inês de Castro-414', 'Sao Paulo', 'SP', '05634-030', 'Brazil');\nINSERT INTO `orders` VALUES (10497, 'LEHMS', 7, '2017-04-04 00:00:00', '2017-04-07 00:00:00', 1, 36.21, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10498, 'HILAA', 8, '2017-04-07 00:00:00', '2017-04-11 00:00:00', 2, 29.75, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10499, 'LILAS', 4, '2017-04-08 00:00:00', '2017-04-16 00:00:00', 2, 102.02, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (10500, 'LAMAI', 6, '2017-04-09 00:00:00', '2017-04-17 00:00:00', 1, 42.68, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (10501, 'BLAUS', 9, '2017-04-09 00:00:00', '2017-04-16 00:00:00', 3, 8.85, 'Forsterstr. 57', 'Mannheim', NULL, '68306', 'Germany');\nINSERT INTO `orders` VALUES (10502, 'PERIC', 2, '2017-04-10 00:00:00', '2017-04-29 00:00:00', 1, 69.32, 'Calle Dr. Jorge Cash 321', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10503, 'HUNGO', 6, '2017-04-11 00:00:00', '2017-04-16 00:00:00', 2, 16.74, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10504, 'WHITC', 4, '2017-04-11 00:00:00', '2017-04-18 00:00:00', 3, 59.13, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (10505, 'MEREP', 3, '2017-04-14 00:00:00', '2017-04-21 00:00:00', 3, 7.13, '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `orders` VALUES (10506, 'KOENE', 9, '2017-04-15 00:00:00', '2017-05-02 00:00:00', 2, 21.19, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (10507, 'ANTO', 7, '2017-04-15 00:00:00', '2017-04-22 00:00:00', 1, 47.45, 'Mataderos  2312', 'México D.F.', NULL, '05023', 'Mexico');\nINSERT INTO `orders` VALUES (10508, 'OTTIK', 1, '2017-04-16 00:00:00', '2017-05-13 00:00:00', 2, 4.99, 'Mehrheimerstr. 369', 'Köl', NULL, '50739', 'Germany');\nINSERT INTO `orders` VALUES (10509, 'BLAUS', 4, '2017-04-17 00:00:00', '2017-04-29 00:00:00', 1, 0.15, 'Forsterstr. 57', 'Mannheim', NULL, '68306', 'Germany');\nINSERT INTO `orders` VALUES (10510, 'SAVEA', 6, '2017-04-18 00:00:00', '2017-04-28 00:00:00', 3, 367.63, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10511, 'BONAP', 4, '2017-04-18 00:00:00', '2017-04-21 00:00:00', 3, 350.64, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10512, 'FAMIA', 7, '2017-04-21 00:00:00', '2017-04-24 00:00:00', 2, 3.53, 'Rua Orós-92', 'Sao Paulo', 'SP', '05442-030', 'Brazil');\nINSERT INTO `orders` VALUES (10513, 'WANDK', 7, '2017-04-22 00:00:00', '2017-04-28 00:00:00', 1, 105.65, 'Adenauerallee 900', 'Stuttgart', NULL, '70563', 'Germany');\nINSERT INTO `orders` VALUES (10514, 'ERNSH', 3, '2017-04-22 00:00:00', '2017-05-16 00:00:00', 2, 789.95, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10515, 'QUICK', 2, '2017-04-23 00:00:00', '2017-05-23 00:00:00', 1, 204.47, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10516, 'HUNGO', 2, '2017-04-24 00:00:00', '2017-05-01 00:00:00', 3, 62.78, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10517, 'NORTS', 3, '2017-04-24 00:00:00', '2017-04-29 00:00:00', 3, 32.07, 'South House 300 Queensbridge', 'Londo', NULL, 'SW7 1RZ', 'UK');\nINSERT INTO `orders` VALUES (10518, 'TORTU', 4, '2017-04-25 00:00:00', '2017-05-05 00:00:00', 2, 218.15, 'Avda. Azteca 123', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10519, 'CHOPS', 6, '2017-04-28 00:00:00', '2017-05-01 00:00:00', 3, 91.76, 'Hauptstr. 31', 'Ber', NULL, '3012', 'Switzerland');\nINSERT INTO `orders` VALUES (10520, 'SANTG', 7, '2017-04-29 00:00:00', '2017-05-01 00:00:00', 1, 13.37, 'Erling Skakkes gate 78', 'Staver', NULL, '4110', 'Norway');\nINSERT INTO `orders` VALUES (10521, 'CACTU', 8, '2017-04-29 00:00:00', '2017-05-02 00:00:00', 2, 17.22, 'Cerrito 333', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10522, 'LEHMS', 4, '2017-04-30 00:00:00', '2017-05-06 00:00:00', 1, 45.33, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10523, 'SEVES', 7, '2017-05-01 00:00:00', '2017-05-30 00:00:00', 2, 77.63, '90 Wadhurst Rd.', 'Londo', NULL, 'OX15 4NB', 'UK');\nINSERT INTO `orders` VALUES (10524, 'BERGS', 1, '2017-05-01 00:00:00', '2017-05-07 00:00:00', 2, 244.79, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10525, 'BONAP', 1, '2017-05-02 00:00:00', '2017-05-23 00:00:00', 2, 11.06, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10526, 'WARTH', 4, '2017-05-05 00:00:00', '2017-05-15 00:00:00', 2, 58.59, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10527, 'QUICK', 7, '2017-05-05 00:00:00', '2017-05-07 00:00:00', 1, 41.90, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10528, 'GREAL', 6, '2017-05-06 00:00:00', '2017-05-09 00:00:00', 2, 3.35, '2732 Baker Blvd.', 'Eugene', 'OR', '97403', 'USA');\nINSERT INTO `orders` VALUES (10529, 'MAISD', 5, '2017-05-07 00:00:00', '2017-05-09 00:00:00', 2, 66.69, 'Rue Joseph-Bens 532', 'Bruxelles', NULL, 'B-1180', 'Belgium');\nINSERT INTO `orders` VALUES (10530, 'PICCO', 3, '2017-05-08 00:00:00', '2017-05-12 00:00:00', 2, 339.22, 'Geislweg 14', 'Salzburg', NULL, '5020', 'Austria');\nINSERT INTO `orders` VALUES (10531, 'OCEA', 7, '2017-05-08 00:00:00', '2017-05-19 00:00:00', 1, 8.12, 'Ing. Gustavo Moncada 8585 Piso 20-A', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10532, 'EASTC', 7, '2017-05-09 00:00:00', '2017-05-12 00:00:00', 3, 74.46, '35 King George', 'Londo', NULL, 'WX3 6FW', 'UK');\nINSERT INTO `orders` VALUES (10533, 'FOLKO', 8, '2017-05-12 00:00:00', '2017-05-22 00:00:00', 1, 188.04, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10534, 'LEHMS', 8, '2017-05-12 00:00:00', '2017-05-14 00:00:00', 2, 27.94, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10535, 'ANTO', 4, '2017-05-13 00:00:00', '2017-05-21 00:00:00', 1, 15.64, 'Mataderos  2312', 'México D.F.', NULL, '05023', 'Mexico');\nINSERT INTO `orders` VALUES (10536, 'LEHMS', 3, '2017-05-14 00:00:00', '2017-06-06 00:00:00', 2, 58.88, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10537, 'RICSU', 1, '2017-05-14 00:00:00', '2017-05-19 00:00:00', 1, 78.85, 'Starenweg 5', 'Genève', NULL, '1204', 'Switzerland');\nINSERT INTO `orders` VALUES (10538, 'BSBEV', 9, '2017-05-15 00:00:00', '2017-05-16 00:00:00', 3, 4.87, 'Fauntleroy Circus', 'Londo', NULL, 'EC2 5NT', 'UK');\nINSERT INTO `orders` VALUES (10539, 'BSBEV', 6, '2017-05-16 00:00:00', '2017-05-23 00:00:00', 3, 12.36, 'Fauntleroy Circus', 'Londo', NULL, 'EC2 5NT', 'UK');\nINSERT INTO `orders` VALUES (10540, 'QUICK', 3, '2017-05-19 00:00:00', '2017-06-13 00:00:00', 3, 1007.64, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10541, 'HANAR', 2, '2017-05-19 00:00:00', '2017-05-29 00:00:00', 1, 68.65, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (10542, 'KOENE', 1, '2017-05-20 00:00:00', '2017-05-26 00:00:00', 3, 10.95, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (10543, 'LILAS', 8, '2017-05-21 00:00:00', '2017-05-23 00:00:00', 2, 48.17, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (10544, 'LONEP', 4, '2017-05-21 00:00:00', '2017-05-30 00:00:00', 1, 24.91, '89 Chiaroscuro Rd.', 'Portland', 'OR', '97219', 'USA');\nINSERT INTO `orders` VALUES (10545, 'LAZYK', 8, '2017-05-22 00:00:00', '2017-06-26 00:00:00', 2, 11.92, '12 Orchestra Terrace', 'Walla Walla', 'WA', '99362', 'USA');\nINSERT INTO `orders` VALUES (10546, 'VICTE', 1, '2017-05-23 00:00:00', '2017-05-27 00:00:00', 3, 194.72, '2-rue du Commerce', 'Lyo', NULL, '69004', 'France');\nINSERT INTO `orders` VALUES (10547, 'SEVES', 3, '2017-05-23 00:00:00', '2017-06-02 00:00:00', 2, 178.43, '90 Wadhurst Rd.', 'Londo', NULL, 'OX15 4NB', 'UK');\nINSERT INTO `orders` VALUES (10548, 'TOMSP', 3, '2017-05-26 00:00:00', '2017-06-02 00:00:00', 2, 1.43, 'Luisenstr. 48', 'Münster', NULL, '44087', 'Germany');\nINSERT INTO `orders` VALUES (10549, 'QUICK', 5, '2017-05-27 00:00:00', '2017-05-30 00:00:00', 1, 171.24, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10550, 'GODOS', 7, '2017-05-28 00:00:00', '2017-06-06 00:00:00', 3, 4.32, 'C/ Romero-33', 'Sevilla', NULL, '41101', 'Spain');\nINSERT INTO `orders` VALUES (10551, 'FURIB', 4, '2017-05-28 00:00:00', '2017-06-06 00:00:00', 3, 72.95, 'Jardim das rosas n. 32', 'Lisboa', NULL, '1675', 'Portugal');\nINSERT INTO `orders` VALUES (10552, 'HILAA', 2, '2017-05-29 00:00:00', '2017-06-05 00:00:00', 1, 83.22, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10553, 'WARTH', 2, '2017-05-30 00:00:00', '2017-06-03 00:00:00', 2, 149.49, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10554, 'OTTIK', 4, '2017-05-30 00:00:00', '2017-06-05 00:00:00', 3, 120.97, 'Mehrheimerstr. 369', 'Köl', NULL, '50739', 'Germany');\nINSERT INTO `orders` VALUES (10555, 'SAVEA', 6, '2017-06-02 00:00:00', '2017-06-04 00:00:00', 3, 252.49, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10556, 'SIMOB', 2, '2017-06-03 00:00:00', '2017-06-13 00:00:00', 1, 9.80, 'Vinbæltet 34', 'Kobenhav', NULL, '1734', 'Denmark');\nINSERT INTO `orders` VALUES (10557, 'LEHMS', 9, '2017-06-03 00:00:00', '2017-06-06 00:00:00', 2, 96.72, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10558, 'AROUT', 1, '2017-06-04 00:00:00', '2017-06-10 00:00:00', 2, 72.97, 'Brook Farm Stratford St. Mary', 'Colchester', 'Essex', 'CO7 6JX', 'UK');\nINSERT INTO `orders` VALUES (10559, 'BLONP', 6, '2017-06-05 00:00:00', '2017-06-13 00:00:00', 1, 8.05, '24-place Kléber', 'Strasbourg', NULL, '67000', 'France');\nINSERT INTO `orders` VALUES (10560, 'FRANK', 8, '2017-06-06 00:00:00', '2017-06-09 00:00:00', 1, 36.65, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10561, 'FOLKO', 2, '2017-06-06 00:00:00', '2017-06-09 00:00:00', 2, 242.21, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10562, 'REGGC', 1, '2017-06-09 00:00:00', '2017-06-12 00:00:00', 1, 22.95, 'Strada Provinciale 124', 'Reggio Emilia', NULL, '42100', 'Italy');\nINSERT INTO `orders` VALUES (10563, 'RICAR', 2, '2017-06-10 00:00:00', '2017-06-24 00:00:00', 2, 60.43, 'Av. Copacabana-267', 'Rio de Janeiro', 'RJ', '02389-890', 'Brazil');\nINSERT INTO `orders` VALUES (10564, 'RATTC', 4, '2017-06-10 00:00:00', '2017-06-16 00:00:00', 3, 13.75, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10565, 'MEREP', 8, '2017-06-11 00:00:00', '2017-06-18 00:00:00', 2, 7.15, '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `orders` VALUES (10566, 'BLONP', 9, '2017-06-12 00:00:00', '2017-06-18 00:00:00', 1, 88.40, '24-place Kléber', 'Strasbourg', NULL, '67000', 'France');\nINSERT INTO `orders` VALUES (10567, 'HUNGO', 1, '2017-06-12 00:00:00', '2017-06-17 00:00:00', 1, 33.97, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10568, 'GALED', 3, '2017-06-13 00:00:00', '2017-07-09 00:00:00', 3, 6.54, 'Rambla de Cataluña-23', 'Barcelona', NULL, '8022', 'Spain');\nINSERT INTO `orders` VALUES (10569, 'RATTC', 5, '2017-06-16 00:00:00', '2017-07-11 00:00:00', 1, 58.98, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10570, 'MEREP', 3, '2017-06-17 00:00:00', '2017-06-19 00:00:00', 3, 188.99, '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `orders` VALUES (10571, 'ERNSH', 8, '2017-06-17 00:00:00', '2017-07-04 00:00:00', 3, 26.06, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10572, 'BERGS', 3, '2017-06-18 00:00:00', '2017-06-25 00:00:00', 2, 116.43, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10573, 'ANTO', 7, '2017-06-19 00:00:00', '2017-06-20 00:00:00', 3, 84.84, 'Mataderos  2312', 'México D.F.', NULL, '05023', 'Mexico');\nINSERT INTO `orders` VALUES (10574, 'TRAIH', 4, '2017-06-19 00:00:00', '2017-06-30 00:00:00', 2, 37.60, '722 DaVinci Blvd.', 'Kirkland', 'WA', '98034', 'USA');\nINSERT INTO `orders` VALUES (10575, 'MORGK', 5, '2017-06-20 00:00:00', '2017-06-30 00:00:00', 1, 127.34, 'Heerstr. 22', 'Leipzig', NULL, '04179', 'Germany');\nINSERT INTO `orders` VALUES (10576, 'TORTU', 3, '2017-06-23 00:00:00', '2017-06-30 00:00:00', 3, 18.56, 'Avda. Azteca 123', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10577, 'TRAIH', 9, '2017-06-23 00:00:00', '2017-06-30 00:00:00', 2, 25.41, '722 DaVinci Blvd.', 'Kirkland', 'WA', '98034', 'USA');\nINSERT INTO `orders` VALUES (10578, 'BSBEV', 4, '2017-06-24 00:00:00', '2017-07-25 00:00:00', 3, 29.60, 'Fauntleroy Circus', 'Londo', NULL, 'EC2 5NT', 'UK');\nINSERT INTO `orders` VALUES (10579, 'LETSS', 1, '2017-06-25 00:00:00', '2017-07-04 00:00:00', 2, 13.73, '87 Polk St. Suite 5', 'San Francisco', 'CA', '94117', 'USA');\nINSERT INTO `orders` VALUES (10580, 'OTTIK', 4, '2017-06-26 00:00:00', '2017-07-01 00:00:00', 3, 75.89, 'Mehrheimerstr. 369', 'Köl', NULL, '50739', 'Germany');\nINSERT INTO `orders` VALUES (10581, 'FAMIA', 3, '2017-06-26 00:00:00', '2017-07-02 00:00:00', 1, 3.01, 'Rua Orós-92', 'Sao Paulo', 'SP', '05442-030', 'Brazil');\nINSERT INTO `orders` VALUES (10582, 'BLAUS', 3, '2017-06-27 00:00:00', '2017-07-14 00:00:00', 2, 27.71, 'Forsterstr. 57', 'Mannheim', NULL, '68306', 'Germany');\nINSERT INTO `orders` VALUES (10583, 'WARTH', 2, '2017-06-30 00:00:00', '2017-07-04 00:00:00', 2, 7.28, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10584, 'BLONP', 4, '2017-06-30 00:00:00', '2017-07-04 00:00:00', 1, 59.14, '24-place Kléber', 'Strasbourg', NULL, '67000', 'France');\nINSERT INTO `orders` VALUES (10585, 'WELLI', 7, '2017-07-01 00:00:00', '2017-07-10 00:00:00', 1, 13.41, 'Rua do Mercado-12', 'Resende', 'SP', '08737-363', 'Brazil');\nINSERT INTO `orders` VALUES (10586, 'REGGC', 9, '2017-07-02 00:00:00', '2017-07-09 00:00:00', 1, 0.48, 'Strada Provinciale 124', 'Reggio Emilia', NULL, '42100', 'Italy');\nINSERT INTO `orders` VALUES (10587, 'QUEDE', 1, '2017-07-02 00:00:00', '2017-07-09 00:00:00', 1, 62.52, 'Rua da Panificadora-12', 'Rio de Janeiro', 'RJ', '02389-673', 'Brazil');\nINSERT INTO `orders` VALUES (10588, 'QUICK', 2, '2017-07-03 00:00:00', '2017-07-10 00:00:00', 3, 194.67, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10589, 'GREAL', 8, '2017-07-04 00:00:00', '2017-07-14 00:00:00', 2, 4.42, '2732 Baker Blvd.', 'Eugene', 'OR', '97403', 'USA');\nINSERT INTO `orders` VALUES (10590, 'MEREP', 4, '2017-07-07 00:00:00', '2017-07-14 00:00:00', 3, 44.77, '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `orders` VALUES (10591, 'VAFFE', 1, '2017-07-07 00:00:00', '2017-07-16 00:00:00', 1, 55.92, 'Smagsloget 45', 'Århus', NULL, '8200', 'Denmark');\nINSERT INTO `orders` VALUES (10592, 'LEHMS', 3, '2017-07-08 00:00:00', '2017-07-16 00:00:00', 1, 32.10, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10593, 'LEHMS', 7, '2017-07-09 00:00:00', '2017-08-13 00:00:00', 2, 174.20, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10594, 'OLDWO', 3, '2017-07-09 00:00:00', '2017-07-16 00:00:00', 2, 5.24, '2743 Bering St.', 'Anchorage', 'AK', '99508', 'USA');\nINSERT INTO `orders` VALUES (10595, 'ERNSH', 2, '2017-07-10 00:00:00', '2017-07-14 00:00:00', 1, 96.78, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10596, 'WHITC', 8, '2017-07-11 00:00:00', '2017-08-12 00:00:00', 1, 16.34, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (10597, 'PICCO', 7, '2017-07-11 00:00:00', '2017-07-18 00:00:00', 3, 35.12, 'Geislweg 14', 'Salzburg', NULL, '5020', 'Austria');\nINSERT INTO `orders` VALUES (10598, 'RATTC', 1, '2017-07-14 00:00:00', '2017-07-18 00:00:00', 3, 44.42, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10599, 'BSBEV', 6, '2017-07-15 00:00:00', '2017-07-21 00:00:00', 3, 29.98, 'Fauntleroy Circus', 'Londo', NULL, 'EC2 5NT', 'UK');\nINSERT INTO `orders` VALUES (10600, 'HUNGC', 4, '2017-07-16 00:00:00', '2017-07-21 00:00:00', 1, 45.13, 'City Center Plaza 516 Main St.', 'Elgi', 'OR', '97827', 'USA');\nINSERT INTO `orders` VALUES (10601, 'HILAA', 7, '2017-07-16 00:00:00', '2017-07-22 00:00:00', 1, 58.30, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10602, 'VAFFE', 8, '2017-07-17 00:00:00', '2017-07-22 00:00:00', 2, 2.92, 'Smagsloget 45', 'Århus', NULL, '8200', 'Denmark');\nINSERT INTO `orders` VALUES (10603, 'SAVEA', 8, '2017-07-18 00:00:00', '2017-08-08 00:00:00', 2, 48.77, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10604, 'FURIB', 1, '2017-07-18 00:00:00', '2017-07-29 00:00:00', 1, 7.46, 'Jardim das rosas n. 32', 'Lisboa', NULL, '1675', 'Portugal');\nINSERT INTO `orders` VALUES (10605, 'MEREP', 1, '2017-07-21 00:00:00', '2017-07-29 00:00:00', 2, 379.13, '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `orders` VALUES (10606, 'TRADH', 4, '2017-07-22 00:00:00', '2017-07-31 00:00:00', 3, 79.40, 'Av. Inês de Castro-414', 'Sao Paulo', 'SP', '05634-030', 'Brazil');\nINSERT INTO `orders` VALUES (10607, 'SAVEA', 5, '2017-07-22 00:00:00', '2017-07-25 00:00:00', 1, 200.24, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10608, 'TOMSP', 4, '2017-07-23 00:00:00', '2017-08-01 00:00:00', 2, 27.79, 'Luisenstr. 48', 'Münster', NULL, '44087', 'Germany');\nINSERT INTO `orders` VALUES (10609, 'DUMO', 7, '2017-07-24 00:00:00', '2017-07-30 00:00:00', 2, 1.85, '67-rue des Cinquante Otages', 'Nantes', NULL, '44000', 'France');\nINSERT INTO `orders` VALUES (10610, 'LAMAI', 8, '2017-07-25 00:00:00', '2017-08-06 00:00:00', 1, 26.78, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (10611, 'WOLZA', 6, '2017-07-25 00:00:00', '2017-08-01 00:00:00', 2, 80.65, 'ul. Filtrowa 68', 'Warszawa', NULL, '01-012', 'Poland');\nINSERT INTO `orders` VALUES (10612, 'SAVEA', 1, '2017-07-28 00:00:00', '2017-08-01 00:00:00', 2, 544.08, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10613, 'HILAA', 4, '2017-07-29 00:00:00', '2017-08-01 00:00:00', 2, 8.11, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10614, 'BLAUS', 8, '2017-07-29 00:00:00', '2017-08-01 00:00:00', 3, 1.93, 'Forsterstr. 57', 'Mannheim', NULL, '68306', 'Germany');\nINSERT INTO `orders` VALUES (10615, 'WILMK', 2, '2017-07-30 00:00:00', '2017-08-06 00:00:00', 3, 0.75, 'Keskuskatu 45', 'Helsinki', NULL, '21240', 'Finland');\nINSERT INTO `orders` VALUES (10616, 'GREAL', 1, '2017-07-31 00:00:00', '2017-08-05 00:00:00', 2, 116.53, '2732 Baker Blvd.', 'Eugene', 'OR', '97403', 'USA');\nINSERT INTO `orders` VALUES (10617, 'GREAL', 4, '2017-07-31 00:00:00', '2017-08-04 00:00:00', 2, 18.53, '2732 Baker Blvd.', 'Eugene', 'OR', '97403', 'USA');\nINSERT INTO `orders` VALUES (10618, 'MEREP', 1, '2017-08-01 00:00:00', '2017-08-08 00:00:00', 1, 154.68, '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `orders` VALUES (10619, 'MEREP', 3, '2017-08-04 00:00:00', '2017-08-07 00:00:00', 3, 91.05, '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `orders` VALUES (10620, 'LAUGB', 2, '2017-08-05 00:00:00', '2017-08-14 00:00:00', 3, 0.94, '2319 Elm St.', 'Vancouver', 'BC', 'V3F 2K1', 'Canada');\nINSERT INTO `orders` VALUES (10621, 'ISLAT', 4, '2017-08-05 00:00:00', '2017-08-11 00:00:00', 2, 23.73, 'Garden House Crowther Way', 'Cowes', 'Isle of Wight', 'PO31 7PJ', 'UK');\nINSERT INTO `orders` VALUES (10622, 'RICAR', 4, '2017-08-06 00:00:00', '2017-08-11 00:00:00', 3, 50.97, 'Av. Copacabana-267', 'Rio de Janeiro', 'RJ', '02389-890', 'Brazil');\nINSERT INTO `orders` VALUES (10623, 'FRANK', 8, '2017-08-07 00:00:00', '2017-08-12 00:00:00', 2, 97.18, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10624, 'THECR', 4, '2017-08-07 00:00:00', '2017-08-19 00:00:00', 2, 94.80, '55 Grizzly Peak Rd.', 'Butte', 'MT', '59801', 'USA');\nINSERT INTO `orders` VALUES (10625, 'ANATR', 3, '2017-08-08 00:00:00', '2017-08-14 00:00:00', 1, 43.90, 'Avda. de la Constitución 2222', 'México D.F.', NULL, '05021', 'Mexico');\nINSERT INTO `orders` VALUES (10626, 'BERGS', 1, '2017-08-11 00:00:00', '2017-08-20 00:00:00', 2, 138.69, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10627, 'SAVEA', 8, '2017-08-11 00:00:00', '2017-08-21 00:00:00', 3, 107.46, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10628, 'BLONP', 4, '2017-08-12 00:00:00', '2017-08-20 00:00:00', 3, 30.36, '24-place Kléber', 'Strasbourg', NULL, '67000', 'France');\nINSERT INTO `orders` VALUES (10629, 'GODOS', 4, '2017-08-12 00:00:00', '2017-08-20 00:00:00', 3, 85.46, 'C/ Romero-33', 'Sevilla', NULL, '41101', 'Spain');\nINSERT INTO `orders` VALUES (10630, 'KOENE', 1, '2017-08-13 00:00:00', '2017-08-19 00:00:00', 2, 32.35, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (10631, 'LAMAI', 8, '2017-08-14 00:00:00', '2017-08-15 00:00:00', 1, 0.87, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (10632, 'WANDK', 8, '2017-08-14 00:00:00', '2017-08-19 00:00:00', 1, 41.38, 'Adenauerallee 900', 'Stuttgart', NULL, '70563', 'Germany');\nINSERT INTO `orders` VALUES (10633, 'ERNSH', 7, '2017-08-15 00:00:00', '2017-08-18 00:00:00', 3, 477.90, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10634, 'FOLIG', 4, '2017-08-15 00:00:00', '2017-08-21 00:00:00', 3, 487.38, '184-chaussée de Tournai', 'Lille', NULL, '59000', 'France');\nINSERT INTO `orders` VALUES (10635, 'MAGAA', 8, '2017-08-18 00:00:00', '2017-08-21 00:00:00', 3, 47.46, 'Via Ludovico il Moro 22', 'Bergamo', NULL, '24100', 'Italy');\nINSERT INTO `orders` VALUES (10636, 'WARTH', 4, '2017-08-19 00:00:00', '2017-08-26 00:00:00', 1, 1.15, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10637, 'QUEE', 6, '2017-08-19 00:00:00', '2017-08-26 00:00:00', 1, 201.29, 'Alameda dos Canàrios-891', 'Sao Paulo', 'SP', '05487-020', 'Brazil');\nINSERT INTO `orders` VALUES (10638, 'LINOD', 3, '2017-08-20 00:00:00', '2017-09-01 00:00:00', 1, 158.44, 'Ave. 5 de Mayo Porlamar', 'I. de Margarita', 'Nueva Esparta', '4980', 'Venezuela');\nINSERT INTO `orders` VALUES (10639, 'SANTG', 7, '2017-08-20 00:00:00', '2017-08-27 00:00:00', 3, 38.64, 'Erling Skakkes gate 78', 'Staver', NULL, '4110', 'Norway');\nINSERT INTO `orders` VALUES (10640, 'WANDK', 4, '2017-08-21 00:00:00', '2017-08-28 00:00:00', 1, 23.55, 'Adenauerallee 900', 'Stuttgart', NULL, '70563', 'Germany');\nINSERT INTO `orders` VALUES (10641, 'HILAA', 4, '2017-08-22 00:00:00', '2017-08-26 00:00:00', 2, 179.61, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10642, 'SIMOB', 7, '2017-08-22 00:00:00', '2017-09-05 00:00:00', 3, 41.89, 'Vinbæltet 34', 'Kobenhav', NULL, '1734', 'Denmark');\nINSERT INTO `orders` VALUES (10643, 'ALFKI', 6, '2017-08-25 00:00:00', '2017-09-02 00:00:00', 1, 29.46, 'Obere Str. 57', 'Berli', NULL, '12209', 'Germany');\nINSERT INTO `orders` VALUES (10644, 'WELLI', 3, '2017-08-25 00:00:00', '2017-09-01 00:00:00', 2, 0.14, 'Rua do Mercado-12', 'Resende', 'SP', '08737-363', 'Brazil');\nINSERT INTO `orders` VALUES (10645, 'HANAR', 4, '2017-08-26 00:00:00', '2017-09-02 00:00:00', 1, 12.41, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (10646, 'HUNGO', 9, '2017-08-27 00:00:00', '2017-09-03 00:00:00', 3, 142.33, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10647, 'QUEDE', 4, '2017-08-27 00:00:00', '2017-09-03 00:00:00', 2, 45.54, 'Rua da Panificadora-12', 'Rio de Janeiro', 'RJ', '02389-673', 'Brazil');\nINSERT INTO `orders` VALUES (10648, 'RICAR', 5, '2017-08-28 00:00:00', '2017-09-09 00:00:00', 2, 14.25, 'Av. Copacabana-267', 'Rio de Janeiro', 'RJ', '02389-890', 'Brazil');\nINSERT INTO `orders` VALUES (10649, 'MAISD', 5, '2017-08-28 00:00:00', '2017-08-29 00:00:00', 3, 6.20, 'Rue Joseph-Bens 532', 'Bruxelles', NULL, 'B-1180', 'Belgium');\nINSERT INTO `orders` VALUES (10650, 'FAMIA', 5, '2017-08-29 00:00:00', '2017-09-03 00:00:00', 3, 176.81, 'Rua Orós-92', 'Sao Paulo', 'SP', '05442-030', 'Brazil');\nINSERT INTO `orders` VALUES (10651, 'WANDK', 8, '2017-09-01 00:00:00', '2017-09-11 00:00:00', 2, 20.60, 'Adenauerallee 900', 'Stuttgart', NULL, '70563', 'Germany');\nINSERT INTO `orders` VALUES (10652, 'GOURL', 4, '2017-09-01 00:00:00', '2017-09-08 00:00:00', 2, 7.14, 'Av. Brasil-442', 'Campinas', 'SP', '04876-786', 'Brazil');\nINSERT INTO `orders` VALUES (10653, 'FRANK', 1, '2017-09-02 00:00:00', '2017-09-19 00:00:00', 1, 93.25, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10654, 'BERGS', 5, '2017-09-02 00:00:00', '2017-09-11 00:00:00', 1, 55.26, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10655, 'REGGC', 1, '2017-09-03 00:00:00', '2017-09-11 00:00:00', 2, 4.41, 'Strada Provinciale 124', 'Reggio Emilia', NULL, '42100', 'Italy');\nINSERT INTO `orders` VALUES (10656, 'GREAL', 6, '2017-09-04 00:00:00', '2017-09-10 00:00:00', 1, 57.15, '2732 Baker Blvd.', 'Eugene', 'OR', '97403', 'USA');\nINSERT INTO `orders` VALUES (10657, 'SAVEA', 2, '2017-09-04 00:00:00', '2017-09-15 00:00:00', 2, 352.69, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10658, 'QUICK', 4, '2017-09-05 00:00:00', '2017-09-08 00:00:00', 1, 364.15, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10659, 'QUEE', 7, '2017-09-05 00:00:00', '2017-09-10 00:00:00', 2, 105.81, 'Alameda dos Canàrios-891', 'Sao Paulo', 'SP', '05487-020', 'Brazil');\nINSERT INTO `orders` VALUES (10660, 'HUNGC', 8, '2017-09-08 00:00:00', '2017-10-15 00:00:00', 1, 111.29, 'City Center Plaza 516 Main St.', 'Elgi', 'OR', '97827', 'USA');\nINSERT INTO `orders` VALUES (10661, 'HUNGO', 7, '2017-09-09 00:00:00', '2017-09-15 00:00:00', 3, 17.55, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10662, 'LONEP', 3, '2017-09-09 00:00:00', '2017-09-18 00:00:00', 2, 1.28, '89 Chiaroscuro Rd.', 'Portland', 'OR', '97219', 'USA');\nINSERT INTO `orders` VALUES (10663, 'BONAP', 2, '2017-09-10 00:00:00', '2017-10-03 00:00:00', 2, 113.15, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10664, 'FURIB', 1, '2017-09-10 00:00:00', '2017-09-19 00:00:00', 3, 1.27, 'Jardim das rosas n. 32', 'Lisboa', NULL, '1675', 'Portugal');\nINSERT INTO `orders` VALUES (10665, 'LONEP', 1, '2017-09-11 00:00:00', '2017-09-17 00:00:00', 2, 26.31, '89 Chiaroscuro Rd.', 'Portland', 'OR', '97219', 'USA');\nINSERT INTO `orders` VALUES (10666, 'RICSU', 7, '2017-09-12 00:00:00', '2017-09-22 00:00:00', 2, 232.42, 'Starenweg 5', 'Genève', NULL, '1204', 'Switzerland');\nINSERT INTO `orders` VALUES (10667, 'ERNSH', 7, '2017-09-12 00:00:00', '2017-09-19 00:00:00', 1, 78.09, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10668, 'WANDK', 1, '2017-09-15 00:00:00', '2017-09-23 00:00:00', 2, 47.22, 'Adenauerallee 900', 'Stuttgart', NULL, '70563', 'Germany');\nINSERT INTO `orders` VALUES (10669, 'SIMOB', 2, '2017-09-15 00:00:00', '2017-09-22 00:00:00', 1, 24.39, 'Vinbæltet 34', 'Kobenhav', NULL, '1734', 'Denmark');\nINSERT INTO `orders` VALUES (10670, 'FRANK', 4, '2017-09-16 00:00:00', '2017-09-18 00:00:00', 1, 203.48, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10671, 'FRANR', 1, '2017-09-17 00:00:00', '2017-09-24 00:00:00', 1, 30.34, '54-rue Royale', 'Nantes', NULL, '44000', 'France');\nINSERT INTO `orders` VALUES (10672, 'BERGS', 9, '2017-09-17 00:00:00', '2017-09-26 00:00:00', 2, 95.75, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10673, 'WILMK', 2, '2017-09-18 00:00:00', '2017-09-19 00:00:00', 1, 22.76, 'Keskuskatu 45', 'Helsinki', NULL, '21240', 'Finland');\nINSERT INTO `orders` VALUES (10674, 'ISLAT', 4, '2017-09-18 00:00:00', '2017-09-30 00:00:00', 2, 0.90, 'Garden House Crowther Way', 'Cowes', 'Isle of Wight', 'PO31 7PJ', 'UK');\nINSERT INTO `orders` VALUES (10675, 'FRANK', 5, '2017-09-19 00:00:00', '2017-09-23 00:00:00', 2, 31.85, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10676, 'TORTU', 2, '2017-09-22 00:00:00', '2017-09-29 00:00:00', 2, 2.01, 'Avda. Azteca 123', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10677, 'ANTO', 1, '2017-09-22 00:00:00', '2017-09-26 00:00:00', 3, 4.03, 'Mataderos  2312', 'México D.F.', NULL, '05023', 'Mexico');\nINSERT INTO `orders` VALUES (10678, 'SAVEA', 7, '2017-09-23 00:00:00', '2017-10-16 00:00:00', 3, 388.98, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10679, 'BLONP', 8, '2017-09-23 00:00:00', '2017-09-30 00:00:00', 3, 27.94, '24-place Kléber', 'Strasbourg', NULL, '67000', 'France');\nINSERT INTO `orders` VALUES (10680, 'OLDWO', 1, '2017-09-24 00:00:00', '2017-09-26 00:00:00', 1, 26.61, '2743 Bering St.', 'Anchorage', 'AK', '99508', 'USA');\nINSERT INTO `orders` VALUES (10681, 'GREAL', 3, '2017-09-25 00:00:00', '2017-09-30 00:00:00', 3, 76.13, '2732 Baker Blvd.', 'Eugene', 'OR', '97403', 'USA');\nINSERT INTO `orders` VALUES (10682, 'ANTO', 3, '2017-09-25 00:00:00', '2017-10-01 00:00:00', 2, 36.13, 'Mataderos  2312', 'México D.F.', NULL, '05023', 'Mexico');\nINSERT INTO `orders` VALUES (10683, 'DUMO', 2, '2017-09-26 00:00:00', '2017-10-01 00:00:00', 1, 4.40, '67-rue des Cinquante Otages', 'Nantes', NULL, '44000', 'France');\nINSERT INTO `orders` VALUES (10684, 'OTTIK', 3, '2017-09-26 00:00:00', '2017-09-30 00:00:00', 1, 145.63, 'Mehrheimerstr. 369', 'Köl', NULL, '50739', 'Germany');\nINSERT INTO `orders` VALUES (10685, 'GOURL', 4, '2017-09-29 00:00:00', '2017-10-03 00:00:00', 2, 33.75, 'Av. Brasil-442', 'Campinas', 'SP', '04876-786', 'Brazil');\nINSERT INTO `orders` VALUES (10686, 'PICCO', 2, '2017-09-30 00:00:00', '2017-10-08 00:00:00', 1, 96.50, 'Geislweg 14', 'Salzburg', NULL, '5020', 'Austria');\nINSERT INTO `orders` VALUES (10687, 'HUNGO', 9, '2017-09-30 00:00:00', '2017-10-30 00:00:00', 2, 296.43, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10688, 'VAFFE', 4, '2017-10-01 00:00:00', '2017-10-07 00:00:00', 2, 299.09, 'Smagsloget 45', 'Århus', NULL, '8200', 'Denmark');\nINSERT INTO `orders` VALUES (10689, 'BERGS', 1, '2017-10-01 00:00:00', '2017-10-07 00:00:00', 2, 13.42, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10690, 'HANAR', 1, '2017-10-02 00:00:00', '2017-10-03 00:00:00', 1, 15.80, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (10691, 'QUICK', 2, '2017-10-03 00:00:00', '2017-10-22 00:00:00', 2, 810.05, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10692, 'ALFKI', 4, '2017-10-03 00:00:00', '2017-10-13 00:00:00', 2, 61.02, 'Obere Str. 57', 'Berli', NULL, '12209', 'Germany');\nINSERT INTO `orders` VALUES (10693, 'WHITC', 3, '2017-10-06 00:00:00', '2017-10-10 00:00:00', 3, 139.34, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (10694, 'QUICK', 8, '2017-10-06 00:00:00', '2017-10-09 00:00:00', 3, 398.36, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10695, 'WILMK', 7, '2017-10-07 00:00:00', '2017-10-14 00:00:00', 1, 16.72, 'Keskuskatu 45', 'Helsinki', NULL, '21240', 'Finland');\nINSERT INTO `orders` VALUES (10696, 'WHITC', 8, '2017-10-08 00:00:00', '2017-10-14 00:00:00', 3, 102.55, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (10697, 'LINOD', 3, '2017-10-08 00:00:00', '2017-10-14 00:00:00', 1, 45.52, 'Ave. 5 de Mayo Porlamar', 'I. de Margarita', 'Nueva Esparta', '4980', 'Venezuela');\nINSERT INTO `orders` VALUES (10698, 'ERNSH', 4, '2017-10-09 00:00:00', '2017-10-17 00:00:00', 1, 272.47, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10699, 'MORGK', 3, '2017-10-09 00:00:00', '2017-10-13 00:00:00', 3, 0.58, 'Heerstr. 22', 'Leipzig', NULL, '04179', 'Germany');\nINSERT INTO `orders` VALUES (10700, 'SAVEA', 3, '2017-10-10 00:00:00', '2017-10-16 00:00:00', 1, 65.10, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10701, 'HUNGO', 6, '2017-10-13 00:00:00', '2017-10-15 00:00:00', 3, 220.31, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10702, 'ALFKI', 4, '2017-10-13 00:00:00', '2017-10-21 00:00:00', 1, 23.94, 'Obere Str. 57', 'Berli', NULL, '12209', 'Germany');\nINSERT INTO `orders` VALUES (10703, 'FOLKO', 6, '2017-10-14 00:00:00', '2017-10-20 00:00:00', 2, 152.30, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10704, 'QUEE', 6, '2017-10-14 00:00:00', '2017-11-07 00:00:00', 1, 4.78, 'Alameda dos Canàrios-891', 'Sao Paulo', 'SP', '05487-020', 'Brazil');\nINSERT INTO `orders` VALUES (10705, 'HILAA', 9, '2017-10-15 00:00:00', '2017-11-18 00:00:00', 2, 3.52, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10706, 'OLDWO', 8, '2017-10-16 00:00:00', '2017-10-21 00:00:00', 3, 135.63, '2743 Bering St.', 'Anchorage', 'AK', '99508', 'USA');\nINSERT INTO `orders` VALUES (10707, 'AROUT', 4, '2017-10-16 00:00:00', '2017-10-23 00:00:00', 3, 21.74, 'Brook Farm Stratford St. Mary', 'Colchester', 'Essex', 'CO7 6JX', 'UK');\nINSERT INTO `orders` VALUES (10708, 'THEBI', 6, '2017-10-17 00:00:00', '2017-11-05 00:00:00', 2, 2.96, '89 Jefferson Way Suite 2', 'Portland', 'OR', '97201', 'USA');\nINSERT INTO `orders` VALUES (10709, 'GOURL', 1, '2017-10-17 00:00:00', '2017-11-20 00:00:00', 3, 210.80, 'Av. Brasil-442', 'Campinas', 'SP', '04876-786', 'Brazil');\nINSERT INTO `orders` VALUES (10710, 'FRANS', 1, '2017-10-20 00:00:00', '2017-10-23 00:00:00', 1, 4.98, 'Via Monte Bianco 34', 'Torino', NULL, '10100', 'Italy');\nINSERT INTO `orders` VALUES (10711, 'SAVEA', 5, '2017-10-21 00:00:00', '2017-10-29 00:00:00', 2, 52.41, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10712, 'HUNGO', 3, '2017-10-21 00:00:00', '2017-10-31 00:00:00', 1, 89.93, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10713, 'SAVEA', 1, '2017-10-22 00:00:00', '2017-10-24 00:00:00', 1, 167.05, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10714, 'SAVEA', 5, '2017-10-22 00:00:00', '2017-10-27 00:00:00', 3, 24.49, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10715, 'BONAP', 3, '2017-10-23 00:00:00', '2017-10-29 00:00:00', 1, 63.20, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10716, 'RANCH', 4, '2017-10-24 00:00:00', '2017-10-27 00:00:00', 2, 22.57, 'Av. del Libertador 900', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10717, 'FRANK', 1, '2017-10-24 00:00:00', '2017-10-29 00:00:00', 2, 59.25, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10718, 'KOENE', 1, '2017-10-27 00:00:00', '2017-10-29 00:00:00', 3, 170.88, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (10719, 'LETSS', 8, '2017-10-27 00:00:00', '2017-11-05 00:00:00', 2, 51.44, '87 Polk St. Suite 5', 'San Francisco', 'CA', '94117', 'USA');\nINSERT INTO `orders` VALUES (10720, 'QUEDE', 8, '2017-10-28 00:00:00', '2017-11-05 00:00:00', 2, 9.53, 'Rua da Panificadora-12', 'Rio de Janeiro', 'RJ', '02389-673', 'Brazil');\nINSERT INTO `orders` VALUES (10721, 'QUICK', 5, '2017-10-29 00:00:00', '2017-10-31 00:00:00', 3, 48.92, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10722, 'SAVEA', 8, '2017-10-29 00:00:00', '2017-11-04 00:00:00', 1, 74.58, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10723, 'WHITC', 3, '2017-10-30 00:00:00', '2017-11-25 00:00:00', 1, 21.72, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (10724, 'MEREP', 8, '2017-10-30 00:00:00', '2017-11-05 00:00:00', 2, 57.75, '43 rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `orders` VALUES (10725, 'FAMIA', 4, '2017-10-31 00:00:00', '2017-11-05 00:00:00', 3, 10.83, 'Rua Orós-92', 'Sao Paulo', 'SP', '05442-030', 'Brazil');\nINSERT INTO `orders` VALUES (10726, 'EASTC', 4, '2017-11-03 00:00:00', '2017-12-05 00:00:00', 1, 16.56, '35 King George', 'Londo', NULL, 'WX3 6FW', 'UK');\nINSERT INTO `orders` VALUES (10727, 'REGGC', 2, '2017-11-03 00:00:00', '2017-12-05 00:00:00', 1, 89.90, 'Strada Provinciale 124', 'Reggio Emilia', NULL, '42100', 'Italy');\nINSERT INTO `orders` VALUES (10728, 'QUEE', 4, '2017-11-04 00:00:00', '2017-11-11 00:00:00', 2, 58.33, 'Alameda dos Canàrios-891', 'Sao Paulo', 'SP', '05487-020', 'Brazil');\nINSERT INTO `orders` VALUES (10729, 'LINOD', 8, '2017-11-04 00:00:00', '2017-11-14 00:00:00', 3, 141.06, 'Ave. 5 de Mayo Porlamar', 'I. de Margarita', 'Nueva Esparta', '4980', 'Venezuela');\nINSERT INTO `orders` VALUES (10730, 'BONAP', 5, '2017-11-05 00:00:00', '2017-11-14 00:00:00', 1, 20.12, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10731, 'CHOPS', 7, '2017-11-06 00:00:00', '2017-11-14 00:00:00', 1, 96.65, 'Hauptstr. 31', 'Ber', NULL, '3012', 'Switzerland');\nINSERT INTO `orders` VALUES (10732, 'BONAP', 3, '2017-11-06 00:00:00', '2017-11-07 00:00:00', 1, 16.97, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10733, 'BERGS', 1, '2017-11-07 00:00:00', '2017-11-10 00:00:00', 3, 110.11, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10734, 'GOURL', 2, '2017-11-07 00:00:00', '2017-11-12 00:00:00', 3, 1.63, 'Av. Brasil-442', 'Campinas', 'SP', '04876-786', 'Brazil');\nINSERT INTO `orders` VALUES (10735, 'LETSS', 6, '2017-11-10 00:00:00', '2017-11-21 00:00:00', 2, 45.97, '87 Polk St. Suite 5', 'San Francisco', 'CA', '94117', 'USA');\nINSERT INTO `orders` VALUES (10736, 'HUNGO', 9, '2017-11-11 00:00:00', '2017-11-21 00:00:00', 2, 44.10, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10737, 'VINET', 2, '2017-11-11 00:00:00', '2017-11-18 00:00:00', 2, 7.79, '59 rue de l\\'\\'Abbaye', 'Reims', NULL, '51100', 'France');\nINSERT INTO `orders` VALUES (10738, 'SPECD', 2, '2017-11-12 00:00:00', '2017-11-18 00:00:00', 1, 2.91, '25-rue Lauristo', 'Paris', NULL, '75016', 'France');\nINSERT INTO `orders` VALUES (10739, 'VINET', 3, '2017-11-12 00:00:00', '2017-11-17 00:00:00', 3, 11.08, '59 rue de l\\'\\'Abbaye', 'Reims', NULL, '51100', 'France');\nINSERT INTO `orders` VALUES (10740, 'WHITC', 4, '2017-11-13 00:00:00', '2017-11-25 00:00:00', 2, 81.88, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (10741, 'AROUT', 4, '2017-11-14 00:00:00', '2017-11-18 00:00:00', 3, 10.96, 'Brook Farm Stratford St. Mary', 'Colchester', 'Essex', 'CO7 6JX', 'UK');\nINSERT INTO `orders` VALUES (10742, 'BOTTM', 3, '2017-11-14 00:00:00', '2017-11-18 00:00:00', 3, 243.73, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (10743, 'AROUT', 1, '2017-11-17 00:00:00', '2017-11-21 00:00:00', 2, 23.72, 'Brook Farm Stratford St. Mary', 'Colchester', 'Essex', 'CO7 6JX', 'UK');\nINSERT INTO `orders` VALUES (10744, 'VAFFE', 6, '2017-11-17 00:00:00', '2017-11-24 00:00:00', 1, 69.19, 'Smagsloget 45', 'Århus', NULL, '8200', 'Denmark');\nINSERT INTO `orders` VALUES (10745, 'QUICK', 9, '2017-11-18 00:00:00', '2017-11-27 00:00:00', 1, 3.52, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10746, 'CHOPS', 1, '2017-11-19 00:00:00', '2017-11-21 00:00:00', 3, 31.43, 'Hauptstr. 31', 'Ber', NULL, '3012', 'Switzerland');\nINSERT INTO `orders` VALUES (10747, 'PICCO', 6, '2017-11-19 00:00:00', '2017-11-26 00:00:00', 1, 117.33, 'Geislweg 14', 'Salzburg', NULL, '5020', 'Austria');\nINSERT INTO `orders` VALUES (10748, 'SAVEA', 3, '2017-11-20 00:00:00', '2017-11-28 00:00:00', 1, 232.55, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10749, 'ISLAT', 4, '2017-11-20 00:00:00', '2017-12-19 00:00:00', 2, 61.53, 'Garden House Crowther Way', 'Cowes', 'Isle of Wight', 'PO31 7PJ', 'UK');\nINSERT INTO `orders` VALUES (10750, 'WARTH', 9, '2017-11-21 00:00:00', '2017-11-24 00:00:00', 1, 79.30, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10751, 'RICSU', 3, '2017-11-24 00:00:00', '2017-12-03 00:00:00', 3, 130.79, 'Starenweg 5', 'Genève', NULL, '1204', 'Switzerland');\nINSERT INTO `orders` VALUES (10752, 'NORTS', 2, '2017-11-24 00:00:00', '2017-11-28 00:00:00', 3, 1.39, 'South House 300 Queensbridge', 'Londo', NULL, 'SW7 1RZ', 'UK');\nINSERT INTO `orders` VALUES (10753, 'FRANS', 3, '2017-11-25 00:00:00', '2017-11-27 00:00:00', 1, 7.70, 'Via Monte Bianco 34', 'Torino', NULL, '10100', 'Italy');\nINSERT INTO `orders` VALUES (10754, 'MAGAA', 6, '2017-11-25 00:00:00', '2017-11-27 00:00:00', 3, 2.38, 'Via Ludovico il Moro 22', 'Bergamo', NULL, '24100', 'Italy');\nINSERT INTO `orders` VALUES (10755, 'BONAP', 4, '2017-11-26 00:00:00', '2017-11-28 00:00:00', 2, 16.71, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10756, 'SPLIR', 8, '2017-11-27 00:00:00', '2017-12-02 00:00:00', 2, 73.21, 'P.O. Box 555', 'Lander', 'WY', '82520', 'USA');\nINSERT INTO `orders` VALUES (10757, 'SAVEA', 6, '2017-11-27 00:00:00', '2017-12-15 00:00:00', 1, 8.19, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10758, 'RICSU', 3, '2017-11-28 00:00:00', '2017-12-04 00:00:00', 3, 138.17, 'Starenweg 5', 'Genève', NULL, '1204', 'Switzerland');\nINSERT INTO `orders` VALUES (10759, 'ANATR', 3, '2017-11-28 00:00:00', '2017-12-12 00:00:00', 3, 11.99, 'Avda. de la Constitución 2222', 'México D.F.', NULL, '05021', 'Mexico');\nINSERT INTO `orders` VALUES (10760, 'MAISD', 4, '2017-12-01 00:00:00', '2017-12-10 00:00:00', 1, 155.64, 'Rue Joseph-Bens 532', 'Bruxelles', NULL, 'B-1180', 'Belgium');\nINSERT INTO `orders` VALUES (10761, 'RATTC', 5, '2017-12-02 00:00:00', '2017-12-08 00:00:00', 2, 18.66, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10762, 'FOLKO', 3, '2017-12-02 00:00:00', '2017-12-09 00:00:00', 1, 328.74, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10763, 'FOLIG', 3, '2017-12-03 00:00:00', '2017-12-08 00:00:00', 3, 37.35, '184-chaussée de Tournai', 'Lille', NULL, '59000', 'France');\nINSERT INTO `orders` VALUES (10764, 'ERNSH', 6, '2017-12-03 00:00:00', '2017-12-08 00:00:00', 3, 145.45, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10765, 'QUICK', 3, '2017-12-04 00:00:00', '2017-12-09 00:00:00', 3, 42.74, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10766, 'OTTIK', 4, '2017-12-05 00:00:00', '2017-12-09 00:00:00', 1, 157.55, 'Mehrheimerstr. 369', 'Köl', NULL, '50739', 'Germany');\nINSERT INTO `orders` VALUES (10767, 'SUPRD', 4, '2017-12-05 00:00:00', '2017-12-15 00:00:00', 3, 1.59, 'Boulevard Tirou-255', 'Charleroi', NULL, 'B-6000', 'Belgium');\nINSERT INTO `orders` VALUES (10768, 'AROUT', 3, '2017-12-08 00:00:00', '2017-12-15 00:00:00', 2, 146.32, 'Brook Farm Stratford St. Mary', 'Colchester', 'Essex', 'CO7 6JX', 'UK');\nINSERT INTO `orders` VALUES (10769, 'VAFFE', 3, '2017-12-08 00:00:00', '2017-12-12 00:00:00', 1, 65.06, 'Smagsloget 45', 'Århus', NULL, '8200', 'Denmark');\nINSERT INTO `orders` VALUES (10770, 'HANAR', 8, '2017-12-09 00:00:00', '2017-12-17 00:00:00', 3, 5.32, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (10771, 'ERNSH', 9, '2017-12-10 00:00:00', '2018-01-02 00:00:00', 2, 11.19, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10772, 'LEHMS', 3, '2017-12-10 00:00:00', '2017-12-19 00:00:00', 2, 91.28, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10773, 'ERNSH', 1, '2017-12-11 00:00:00', '2017-12-16 00:00:00', 3, 96.43, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10774, 'FOLKO', 4, '2017-12-11 00:00:00', '2017-12-12 00:00:00', 1, 48.20, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10775, 'THECR', 7, '2017-12-12 00:00:00', '2017-12-26 00:00:00', 1, 20.25, '55 Grizzly Peak Rd.', 'Butte', 'MT', '59801', 'USA');\nINSERT INTO `orders` VALUES (10776, 'ERNSH', 1, '2017-12-15 00:00:00', '2017-12-18 00:00:00', 3, 351.53, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10777, 'GOURL', 7, '2017-12-15 00:00:00', '2018-01-21 00:00:00', 2, 3.01, 'Av. Brasil-442', 'Campinas', 'SP', '04876-786', 'Brazil');\nINSERT INTO `orders` VALUES (10778, 'BERGS', 3, '2017-12-16 00:00:00', '2017-12-24 00:00:00', 1, 6.79, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10779, 'MORGK', 3, '2017-12-16 00:00:00', '2018-01-14 00:00:00', 2, 58.13, 'Heerstr. 22', 'Leipzig', NULL, '04179', 'Germany');\nINSERT INTO `orders` VALUES (10780, 'LILAS', 2, '2017-12-16 00:00:00', '2017-12-25 00:00:00', 1, 42.13, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (10781, 'WARTH', 2, '2017-12-17 00:00:00', '2017-12-19 00:00:00', 3, 73.16, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (10782, 'CACTU', 9, '2017-12-17 00:00:00', '2017-12-22 00:00:00', 3, 1.10, 'Cerrito 333', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10783, 'HANAR', 4, '2017-12-18 00:00:00', '2017-12-19 00:00:00', 2, 124.98, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (10784, 'MAGAA', 4, '2017-12-18 00:00:00', '2017-12-22 00:00:00', 3, 70.09, 'Via Ludovico il Moro 22', 'Bergamo', NULL, '24100', 'Italy');\nINSERT INTO `orders` VALUES (10785, 'GROSR', 1, '2017-12-18 00:00:00', '2017-12-24 00:00:00', 3, 1.51, '5ª Ave. Los Palos Grandes', 'Caracas', 'DF', '1081', 'Venezuela');\nINSERT INTO `orders` VALUES (10786, 'QUEE', 8, '2017-12-19 00:00:00', '2017-12-23 00:00:00', 1, 110.87, 'Alameda dos Canàrios-891', 'Sao Paulo', 'SP', '05487-020', 'Brazil');\nINSERT INTO `orders` VALUES (10787, 'LAMAI', 2, '2017-12-19 00:00:00', '2017-12-26 00:00:00', 1, 249.93, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (10788, 'QUICK', 1, '2017-12-22 00:00:00', '2018-01-19 00:00:00', 2, 42.70, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10789, 'FOLIG', 1, '2017-12-22 00:00:00', '2017-12-31 00:00:00', 2, 100.60, '184-chaussée de Tournai', 'Lille', NULL, '59000', 'France');\nINSERT INTO `orders` VALUES (10790, 'GOURL', 6, '2017-12-22 00:00:00', '2017-12-26 00:00:00', 1, 28.23, 'Av. Brasil-442', 'Campinas', 'SP', '04876-786', 'Brazil');\nINSERT INTO `orders` VALUES (10791, 'FRANK', 6, '2017-12-23 00:00:00', '2018-01-01 00:00:00', 2, 16.85, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10792, 'WOLZA', 1, '2017-12-23 00:00:00', '2017-12-31 00:00:00', 3, 23.79, 'ul. Filtrowa 68', 'Warszawa', NULL, '01-012', 'Poland');\nINSERT INTO `orders` VALUES (10793, 'AROUT', 3, '2017-12-24 00:00:00', '2018-01-08 00:00:00', 3, 4.52, 'Brook Farm Stratford St. Mary', 'Colchester', 'Essex', 'CO7 6JX', 'UK');\nINSERT INTO `orders` VALUES (10794, 'QUEDE', 6, '2017-12-24 00:00:00', '2018-01-02 00:00:00', 1, 21.49, 'Rua da Panificadora-12', 'Rio de Janeiro', 'RJ', '02389-673', 'Brazil');\nINSERT INTO `orders` VALUES (10795, 'ERNSH', 8, '2017-12-24 00:00:00', '2018-01-20 00:00:00', 2, 126.66, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10796, 'HILAA', 3, '2017-12-25 00:00:00', '2018-01-14 00:00:00', 1, 26.52, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10797, 'DRACD', 7, '2017-12-25 00:00:00', '2018-01-05 00:00:00', 2, 33.35, 'Walserweg 21', 'Aache', NULL, '52066', 'Germany');\nINSERT INTO `orders` VALUES (10798, 'ISLAT', 2, '2017-12-26 00:00:00', '2018-01-05 00:00:00', 1, 2.33, 'Garden House Crowther Way', 'Cowes', 'Isle of Wight', 'PO31 7PJ', 'UK');\nINSERT INTO `orders` VALUES (10799, 'KOENE', 9, '2017-12-26 00:00:00', '2018-01-05 00:00:00', 3, 30.76, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (10800, 'SEVES', 1, '2017-12-26 00:00:00', '2018-01-05 00:00:00', 3, 137.44, '90 Wadhurst Rd.', 'Londo', NULL, 'OX15 4NB', 'UK');\nINSERT INTO `orders` VALUES (10801, 'BOLID', 4, '2017-12-29 00:00:00', '2017-12-31 00:00:00', 2, 97.09, 'C/ Araquil-67', 'Madrid', NULL, '28023', 'Spain');\nINSERT INTO `orders` VALUES (10802, 'SIMOB', 4, '2017-12-29 00:00:00', '2018-01-02 00:00:00', 2, 257.26, 'Vinbæltet 34', 'Kobenhav', NULL, '1734', 'Denmark');\nINSERT INTO `orders` VALUES (10803, 'WELLI', 4, '2017-12-30 00:00:00', '2018-01-06 00:00:00', 1, 55.23, 'Rua do Mercado-12', 'Resende', 'SP', '08737-363', 'Brazil');\nINSERT INTO `orders` VALUES (10804, 'SEVES', 6, '2017-12-30 00:00:00', '2018-01-07 00:00:00', 2, 27.33, '90 Wadhurst Rd.', 'Londo', NULL, 'OX15 4NB', 'UK');\nINSERT INTO `orders` VALUES (10805, 'THEBI', 2, '2017-12-30 00:00:00', '2018-01-09 00:00:00', 3, 237.34, '89 Jefferson Way Suite 2', 'Portland', 'OR', '97201', 'USA');\nINSERT INTO `orders` VALUES (10806, 'VICTE', 3, '2017-12-31 00:00:00', '2018-01-05 00:00:00', 2, 22.11, '2-rue du Commerce', 'Lyo', NULL, '69004', 'France');\nINSERT INTO `orders` VALUES (10807, 'FRANS', 4, '2017-12-31 00:00:00', '2018-01-30 00:00:00', 1, 1.36, 'Via Monte Bianco 34', 'Torino', NULL, '10100', 'Italy');\nINSERT INTO `orders` VALUES (10808, 'OLDWO', 2, '2018-01-01 00:00:00', '2018-01-09 00:00:00', 3, 45.53, '2743 Bering St.', 'Anchorage', 'AK', '99508', 'USA');\nINSERT INTO `orders` VALUES (10809, 'WELLI', 7, '2018-01-01 00:00:00', '2018-01-07 00:00:00', 1, 4.87, 'Rua do Mercado-12', 'Resende', 'SP', '08737-363', 'Brazil');\nINSERT INTO `orders` VALUES (10810, 'LAUGB', 2, '2018-01-01 00:00:00', '2018-01-07 00:00:00', 3, 4.33, '2319 Elm St.', 'Vancouver', 'BC', 'V3F 2K1', 'Canada');\nINSERT INTO `orders` VALUES (10811, 'LINOD', 8, '2018-01-02 00:00:00', '2018-01-08 00:00:00', 1, 31.22, 'Ave. 5 de Mayo Porlamar', 'I. de Margarita', 'Nueva Esparta', '4980', 'Venezuela');\nINSERT INTO `orders` VALUES (10812, 'REGGC', 5, '2018-01-02 00:00:00', '2018-01-12 00:00:00', 1, 59.78, 'Strada Provinciale 124', 'Reggio Emilia', NULL, '42100', 'Italy');\nINSERT INTO `orders` VALUES (10813, 'RICAR', 1, '2018-01-05 00:00:00', '2018-01-09 00:00:00', 1, 47.38, 'Av. Copacabana-267', 'Rio de Janeiro', 'RJ', '02389-890', 'Brazil');\nINSERT INTO `orders` VALUES (10814, 'VICTE', 3, '2018-01-05 00:00:00', '2018-01-14 00:00:00', 3, 130.94, '2-rue du Commerce', 'Lyo', NULL, '69004', 'France');\nINSERT INTO `orders` VALUES (10815, 'SAVEA', 2, '2018-01-05 00:00:00', '2018-01-14 00:00:00', 3, 14.62, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10816, 'GREAL', 4, '2018-01-06 00:00:00', '2018-02-04 00:00:00', 2, 719.78, '2732 Baker Blvd.', 'Eugene', 'OR', '97403', 'USA');\nINSERT INTO `orders` VALUES (10817, 'KOENE', 3, '2018-01-06 00:00:00', '2018-01-13 00:00:00', 2, 306.07, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (10818, 'MAGAA', 7, '2018-01-07 00:00:00', '2018-01-12 00:00:00', 3, 65.48, 'Via Ludovico il Moro 22', 'Bergamo', NULL, '24100', 'Italy');\nINSERT INTO `orders` VALUES (10819, 'CACTU', 2, '2018-01-07 00:00:00', '2018-01-16 00:00:00', 3, 19.76, 'Cerrito 333', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10820, 'RATTC', 3, '2018-01-07 00:00:00', '2018-01-13 00:00:00', 2, 37.52, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10821, 'SPLIR', 1, '2018-01-08 00:00:00', '2018-01-15 00:00:00', 1, 36.68, 'P.O. Box 555', 'Lander', 'WY', '82520', 'USA');\nINSERT INTO `orders` VALUES (10822, 'TRAIH', 6, '2018-01-08 00:00:00', '2018-01-16 00:00:00', 3, 7.00, '722 DaVinci Blvd.', 'Kirkland', 'WA', '98034', 'USA');\nINSERT INTO `orders` VALUES (10823, 'LILAS', 5, '2018-01-09 00:00:00', '2018-01-13 00:00:00', 2, 163.97, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (10824, 'FOLKO', 8, '2018-01-09 00:00:00', '2018-01-30 00:00:00', 1, 1.23, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10825, 'DRACD', 1, '2018-01-09 00:00:00', '2018-01-14 00:00:00', 1, 79.25, 'Walserweg 21', 'Aache', NULL, '52066', 'Germany');\nINSERT INTO `orders` VALUES (10826, 'BLONP', 6, '2018-01-12 00:00:00', '2018-02-06 00:00:00', 1, 7.09, '24-place Kléber', 'Strasbourg', NULL, '67000', 'France');\nINSERT INTO `orders` VALUES (10827, 'BONAP', 1, '2018-01-12 00:00:00', '2018-02-06 00:00:00', 2, 63.54, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10828, 'RANCH', 9, '2018-01-13 00:00:00', '2018-02-04 00:00:00', 1, 90.85, 'Av. del Libertador 900', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10829, 'ISLAT', 9, '2018-01-13 00:00:00', '2018-01-23 00:00:00', 1, 154.72, 'Garden House Crowther Way', 'Cowes', 'Isle of Wight', 'PO31 7PJ', 'UK');\nINSERT INTO `orders` VALUES (10830, 'TRADH', 4, '2018-01-13 00:00:00', '2018-01-21 00:00:00', 2, 81.83, 'Av. Inês de Castro-414', 'Sao Paulo', 'SP', '05634-030', 'Brazil');\nINSERT INTO `orders` VALUES (10831, 'SANTG', 3, '2018-01-14 00:00:00', '2018-01-23 00:00:00', 2, 72.19, 'Erling Skakkes gate 78', 'Staver', NULL, '4110', 'Norway');\nINSERT INTO `orders` VALUES (10832, 'LAMAI', 2, '2018-01-14 00:00:00', '2018-01-19 00:00:00', 2, 43.26, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (10833, 'OTTIK', 6, '2018-01-15 00:00:00', '2018-01-23 00:00:00', 2, 71.49, 'Mehrheimerstr. 369', 'Köl', NULL, '50739', 'Germany');\nINSERT INTO `orders` VALUES (10834, 'TRADH', 1, '2018-01-15 00:00:00', '2018-01-19 00:00:00', 3, 29.78, 'Av. Inês de Castro-414', 'Sao Paulo', 'SP', '05634-030', 'Brazil');\nINSERT INTO `orders` VALUES (10835, 'ALFKI', 1, '2018-01-15 00:00:00', '2018-01-21 00:00:00', 3, 69.53, 'Obere Str. 57', 'Berli', NULL, '12209', 'Germany');\nINSERT INTO `orders` VALUES (10836, 'ERNSH', 7, '2018-01-16 00:00:00', '2018-01-21 00:00:00', 1, 411.88, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10837, 'BERGS', 9, '2018-01-16 00:00:00', '2018-01-23 00:00:00', 3, 13.32, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10838, 'LINOD', 3, '2018-01-19 00:00:00', '2018-01-23 00:00:00', 3, 59.28, 'Ave. 5 de Mayo Porlamar', 'I. de Margarita', 'Nueva Esparta', '4980', 'Venezuela');\nINSERT INTO `orders` VALUES (10839, 'TRADH', 3, '2018-01-19 00:00:00', '2018-01-22 00:00:00', 3, 35.43, 'Av. Inês de Castro-414', 'Sao Paulo', 'SP', '05634-030', 'Brazil');\nINSERT INTO `orders` VALUES (10840, 'LINOD', 4, '2018-01-19 00:00:00', '2018-02-16 00:00:00', 2, 2.71, 'Ave. 5 de Mayo Porlamar', 'I. de Margarita', 'Nueva Esparta', '4980', 'Venezuela');\nINSERT INTO `orders` VALUES (10841, 'SUPRD', 5, '2018-01-20 00:00:00', '2018-01-29 00:00:00', 2, 424.30, 'Boulevard Tirou-255', 'Charleroi', NULL, 'B-6000', 'Belgium');\nINSERT INTO `orders` VALUES (10842, 'TORTU', 1, '2018-01-20 00:00:00', '2018-01-29 00:00:00', 3, 54.42, 'Avda. Azteca 123', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10843, 'VICTE', 4, '2018-01-21 00:00:00', '2018-01-26 00:00:00', 2, 9.26, '2-rue du Commerce', 'Lyo', NULL, '69004', 'France');\nINSERT INTO `orders` VALUES (10844, 'PICCO', 8, '2018-01-21 00:00:00', '2018-01-26 00:00:00', 2, 25.22, 'Geislweg 14', 'Salzburg', NULL, '5020', 'Austria');\nINSERT INTO `orders` VALUES (10845, 'QUICK', 8, '2018-01-21 00:00:00', '2018-01-30 00:00:00', 1, 212.98, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10846, 'SUPRD', 2, '2018-01-22 00:00:00', '2018-01-23 00:00:00', 3, 56.46, 'Boulevard Tirou-255', 'Charleroi', NULL, 'B-6000', 'Belgium');\nINSERT INTO `orders` VALUES (10847, 'SAVEA', 4, '2018-01-22 00:00:00', '2018-02-10 00:00:00', 3, 487.57, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10848, 'CONSH', 7, '2018-01-23 00:00:00', '2018-01-29 00:00:00', 2, 38.24, 'Berkeley Gardens 12  Brewery', 'Londo', NULL, 'WX1 6LT', 'UK');\nINSERT INTO `orders` VALUES (10849, 'KOENE', 9, '2018-01-23 00:00:00', '2018-01-30 00:00:00', 2, 0.56, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (10850, 'VICTE', 1, '2018-01-23 00:00:00', '2018-01-30 00:00:00', 1, 49.19, '2-rue du Commerce', 'Lyo', NULL, '69004', 'France');\nINSERT INTO `orders` VALUES (10851, 'RICAR', 5, '2018-01-26 00:00:00', '2018-02-02 00:00:00', 1, 160.55, 'Av. Copacabana-267', 'Rio de Janeiro', 'RJ', '02389-890', 'Brazil');\nINSERT INTO `orders` VALUES (10852, 'RATTC', 8, '2018-01-26 00:00:00', '2018-01-30 00:00:00', 1, 174.05, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10853, 'BLAUS', 9, '2018-01-27 00:00:00', '2018-02-03 00:00:00', 2, 53.83, 'Forsterstr. 57', 'Mannheim', NULL, '68306', 'Germany');\nINSERT INTO `orders` VALUES (10854, 'ERNSH', 3, '2018-01-27 00:00:00', '2018-02-05 00:00:00', 2, 100.22, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10855, 'OLDWO', 3, '2018-01-27 00:00:00', '2018-02-04 00:00:00', 1, 170.97, '2743 Bering St.', 'Anchorage', 'AK', '99508', 'USA');\nINSERT INTO `orders` VALUES (10856, 'ANTO', 3, '2018-01-28 00:00:00', '2018-02-10 00:00:00', 2, 58.43, 'Mataderos  2312', 'México D.F.', NULL, '05023', 'Mexico');\nINSERT INTO `orders` VALUES (10857, 'BERGS', 8, '2018-01-28 00:00:00', '2018-02-06 00:00:00', 2, 188.85, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10858, 'LACOR', 2, '2018-01-29 00:00:00', '2018-02-03 00:00:00', 1, 52.51, '67-avenue de l\\'\\'Europe', 'Versailles', NULL, '78000', 'France');\nINSERT INTO `orders` VALUES (10859, 'FRANK', 1, '2018-01-29 00:00:00', '2018-02-02 00:00:00', 2, 76.10, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10860, 'FRANR', 3, '2018-01-29 00:00:00', '2018-02-04 00:00:00', 3, 19.26, '54-rue Royale', 'Nantes', NULL, '44000', 'France');\nINSERT INTO `orders` VALUES (10861, 'WHITC', 4, '2018-01-30 00:00:00', '2018-02-17 00:00:00', 2, 14.93, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (10862, 'LEHMS', 8, '2018-01-30 00:00:00', '2018-02-02 00:00:00', 2, 53.23, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10863, 'HILAA', 4, '2018-02-02 00:00:00', '2018-02-17 00:00:00', 2, 30.26, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10864, 'AROUT', 4, '2018-02-02 00:00:00', '2018-02-09 00:00:00', 2, 3.04, 'Brook Farm Stratford St. Mary', 'Colchester', 'Essex', 'CO7 6JX', 'UK');\nINSERT INTO `orders` VALUES (10865, 'QUICK', 2, '2018-02-02 00:00:00', '2018-02-12 00:00:00', 1, 348.14, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10866, 'BERGS', 5, '2018-02-03 00:00:00', '2018-02-12 00:00:00', 1, 109.11, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10867, 'LONEP', 6, '2018-02-03 00:00:00', '2018-02-11 00:00:00', 1, 1.93, '89 Chiaroscuro Rd.', 'Portland', 'OR', '97219', 'USA');\nINSERT INTO `orders` VALUES (10868, 'QUEE', 7, '2018-02-04 00:00:00', '2018-02-23 00:00:00', 2, 191.27, 'Alameda dos Canàrios-891', 'Sao Paulo', 'SP', '05487-020', 'Brazil');\nINSERT INTO `orders` VALUES (10869, 'SEVES', 5, '2018-02-04 00:00:00', '2018-02-09 00:00:00', 1, 143.28, '90 Wadhurst Rd.', 'Londo', NULL, 'OX15 4NB', 'UK');\nINSERT INTO `orders` VALUES (10870, 'WOLZA', 5, '2018-02-04 00:00:00', '2018-02-13 00:00:00', 3, 12.04, 'ul. Filtrowa 68', 'Warszawa', NULL, '01-012', 'Poland');\nINSERT INTO `orders` VALUES (10871, 'BONAP', 9, '2018-02-05 00:00:00', '2018-02-10 00:00:00', 2, 112.27, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10872, 'GODOS', 5, '2018-02-05 00:00:00', '2018-02-09 00:00:00', 2, 175.32, 'C/ Romero-33', 'Sevilla', NULL, '41101', 'Spain');\nINSERT INTO `orders` VALUES (10873, 'WILMK', 4, '2018-02-06 00:00:00', '2018-02-09 00:00:00', 1, 0.82, 'Keskuskatu 45', 'Helsinki', NULL, '21240', 'Finland');\nINSERT INTO `orders` VALUES (10874, 'GODOS', 5, '2018-02-06 00:00:00', '2018-02-11 00:00:00', 2, 19.58, 'C/ Romero-33', 'Sevilla', NULL, '41101', 'Spain');\nINSERT INTO `orders` VALUES (10875, 'BERGS', 4, '2018-02-06 00:00:00', '2018-03-03 00:00:00', 2, 32.37, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10876, 'BONAP', 7, '2018-02-09 00:00:00', '2018-02-12 00:00:00', 3, 60.42, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10877, 'RICAR', 1, '2018-02-09 00:00:00', '2018-02-19 00:00:00', 1, 38.06, 'Av. Copacabana-267', 'Rio de Janeiro', 'RJ', '02389-890', 'Brazil');\nINSERT INTO `orders` VALUES (10878, 'QUICK', 4, '2018-02-10 00:00:00', '2018-02-12 00:00:00', 1, 46.69, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10879, 'WILMK', 3, '2018-02-10 00:00:00', '2018-02-12 00:00:00', 3, 8.50, 'Keskuskatu 45', 'Helsinki', NULL, '21240', 'Finland');\nINSERT INTO `orders` VALUES (10880, 'FOLKO', 7, '2018-02-10 00:00:00', '2018-02-18 00:00:00', 1, 88.01, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10881, 'CACTU', 4, '2018-02-11 00:00:00', '2018-02-18 00:00:00', 1, 2.84, 'Cerrito 333', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10882, 'SAVEA', 4, '2018-02-11 00:00:00', '2018-02-20 00:00:00', 3, 23.10, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10883, 'LONEP', 8, '2018-02-12 00:00:00', '2018-02-20 00:00:00', 3, 0.53, '89 Chiaroscuro Rd.', 'Portland', 'OR', '97219', 'USA');\nINSERT INTO `orders` VALUES (10884, 'LETSS', 4, '2018-02-12 00:00:00', '2018-02-13 00:00:00', 2, 90.97, '87 Polk St. Suite 5', 'San Francisco', 'CA', '94117', 'USA');\nINSERT INTO `orders` VALUES (10885, 'SUPRD', 6, '2018-02-12 00:00:00', '2018-02-18 00:00:00', 3, 5.64, 'Boulevard Tirou-255', 'Charleroi', NULL, 'B-6000', 'Belgium');\nINSERT INTO `orders` VALUES (10886, 'HANAR', 1, '2018-02-13 00:00:00', '2018-03-02 00:00:00', 1, 4.99, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (10887, 'GALED', 8, '2018-02-13 00:00:00', '2018-02-16 00:00:00', 3, 1.25, 'Rambla de Cataluña-23', 'Barcelona', NULL, '8022', 'Spain');\nINSERT INTO `orders` VALUES (10888, 'GODOS', 1, '2018-02-16 00:00:00', '2018-02-23 00:00:00', 2, 51.87, 'C/ Romero-33', 'Sevilla', NULL, '41101', 'Spain');\nINSERT INTO `orders` VALUES (10889, 'RATTC', 9, '2018-02-16 00:00:00', '2018-02-23 00:00:00', 3, 280.61, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10890, 'DUMO', 7, '2018-02-16 00:00:00', '2018-02-18 00:00:00', 1, 32.76, '67-rue des Cinquante Otages', 'Nantes', NULL, '44000', 'France');\nINSERT INTO `orders` VALUES (10891, 'LEHMS', 7, '2018-02-17 00:00:00', '2018-02-19 00:00:00', 2, 20.37, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10892, 'MAISD', 4, '2018-02-17 00:00:00', '2018-02-19 00:00:00', 2, 120.27, 'Rue Joseph-Bens 532', 'Bruxelles', NULL, 'B-1180', 'Belgium');\nINSERT INTO `orders` VALUES (10893, 'KOENE', 9, '2018-02-18 00:00:00', '2018-02-20 00:00:00', 2, 77.78, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (10894, 'SAVEA', 1, '2018-02-18 00:00:00', '2018-02-20 00:00:00', 1, 116.13, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10895, 'ERNSH', 3, '2018-02-18 00:00:00', '2018-02-23 00:00:00', 1, 162.75, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10896, 'MAISD', 7, '2018-02-19 00:00:00', '2018-02-27 00:00:00', 3, 32.45, 'Rue Joseph-Bens 532', 'Bruxelles', NULL, 'B-1180', 'Belgium');\nINSERT INTO `orders` VALUES (10897, 'HUNGO', 3, '2018-02-19 00:00:00', '2018-02-25 00:00:00', 2, 603.54, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10898, 'OCEA', 4, '2018-02-20 00:00:00', '2018-03-06 00:00:00', 2, 1.27, 'Ing. Gustavo Moncada 8585 Piso 20-A', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10899, 'LILAS', 5, '2018-02-20 00:00:00', '2018-02-26 00:00:00', 3, 1.21, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (10900, 'WELLI', 1, '2018-02-20 00:00:00', '2018-03-04 00:00:00', 2, 1.66, 'Rua do Mercado-12', 'Resende', 'SP', '08737-363', 'Brazil');\nINSERT INTO `orders` VALUES (10901, 'HILAA', 4, '2018-02-23 00:00:00', '2018-02-26 00:00:00', 1, 62.09, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10902, 'FOLKO', 1, '2018-02-23 00:00:00', '2018-03-03 00:00:00', 1, 44.15, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10903, 'HANAR', 3, '2018-02-24 00:00:00', '2018-03-04 00:00:00', 3, 36.71, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (10904, 'WHITC', 3, '2018-02-24 00:00:00', '2018-02-27 00:00:00', 3, 162.95, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (10905, 'WELLI', 9, '2018-02-24 00:00:00', '2018-03-06 00:00:00', 2, 13.72, 'Rua do Mercado-12', 'Resende', 'SP', '08737-363', 'Brazil');\nINSERT INTO `orders` VALUES (10906, 'WOLZA', 4, '2018-02-25 00:00:00', '2018-03-03 00:00:00', 3, 26.29, 'ul. Filtrowa 68', 'Warszawa', NULL, '01-012', 'Poland');\nINSERT INTO `orders` VALUES (10907, 'SPECD', 6, '2018-02-25 00:00:00', '2018-02-27 00:00:00', 3, 9.19, '25-rue Lauristo', 'Paris', NULL, '75016', 'France');\nINSERT INTO `orders` VALUES (10908, 'REGGC', 4, '2018-02-26 00:00:00', '2018-03-06 00:00:00', 2, 32.96, 'Strada Provinciale 124', 'Reggio Emilia', NULL, '42100', 'Italy');\nINSERT INTO `orders` VALUES (10909, 'SANTG', 1, '2018-02-26 00:00:00', '2018-03-10 00:00:00', 2, 53.05, 'Erling Skakkes gate 78', 'Staver', NULL, '4110', 'Norway');\nINSERT INTO `orders` VALUES (10910, 'WILMK', 1, '2018-02-26 00:00:00', '2018-03-04 00:00:00', 3, 38.11, 'Keskuskatu 45', 'Helsinki', NULL, '21240', 'Finland');\nINSERT INTO `orders` VALUES (10911, 'GODOS', 3, '2018-02-26 00:00:00', '2018-03-05 00:00:00', 1, 38.19, 'C/ Romero-33', 'Sevilla', NULL, '41101', 'Spain');\nINSERT INTO `orders` VALUES (10912, 'HUNGO', 2, '2018-02-26 00:00:00', '2018-03-18 00:00:00', 2, 580.91, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10913, 'QUEE', 4, '2018-02-26 00:00:00', '2018-03-04 00:00:00', 1, 33.05, 'Alameda dos Canàrios-891', 'Sao Paulo', 'SP', '05487-020', 'Brazil');\nINSERT INTO `orders` VALUES (10914, 'QUEE', 6, '2018-02-27 00:00:00', '2018-03-02 00:00:00', 1, 21.19, 'Alameda dos Canàrios-891', 'Sao Paulo', 'SP', '05487-020', 'Brazil');\nINSERT INTO `orders` VALUES (10915, 'TORTU', 2, '2018-02-27 00:00:00', '2018-03-02 00:00:00', 2, 3.51, 'Avda. Azteca 123', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10916, 'RANCH', 1, '2018-02-27 00:00:00', '2018-03-09 00:00:00', 2, 63.77, 'Av. del Libertador 900', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10917, 'ROMEY', 4, '2018-03-02 00:00:00', '2018-03-11 00:00:00', 2, 8.29, 'Gran Vía-1', 'Madrid', NULL, '28001', 'Spain');\nINSERT INTO `orders` VALUES (10918, 'BOTTM', 3, '2018-03-02 00:00:00', '2018-03-11 00:00:00', 3, 48.83, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (10919, 'LINOD', 2, '2018-03-02 00:00:00', '2018-03-04 00:00:00', 2, 19.80, 'Ave. 5 de Mayo Porlamar', 'I. de Margarita', 'Nueva Esparta', '4980', 'Venezuela');\nINSERT INTO `orders` VALUES (10920, 'AROUT', 4, '2018-03-03 00:00:00', '2018-03-09 00:00:00', 2, 29.61, 'Brook Farm Stratford St. Mary', 'Colchester', 'Essex', 'CO7 6JX', 'UK');\nINSERT INTO `orders` VALUES (10921, 'VAFFE', 1, '2018-03-03 00:00:00', '2018-03-09 00:00:00', 1, 176.48, 'Smagsloget 45', 'Århus', NULL, '8200', 'Denmark');\nINSERT INTO `orders` VALUES (10922, 'HANAR', 5, '2018-03-03 00:00:00', '2018-03-05 00:00:00', 3, 62.74, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (10923, 'LAMAI', 7, '2018-03-03 00:00:00', '2018-03-13 00:00:00', 3, 68.26, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (10924, 'BERGS', 3, '2018-03-04 00:00:00', '2018-04-08 00:00:00', 2, 151.52, 'Berguvsvägen  8', 'Luleå', NULL, 'S-958 22', 'Sweden');\nINSERT INTO `orders` VALUES (10925, 'HANAR', 3, '2018-03-04 00:00:00', '2018-03-13 00:00:00', 1, 2.27, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (10926, 'ANATR', 4, '2018-03-04 00:00:00', '2018-03-11 00:00:00', 3, 39.92, 'Avda. de la Constitución 2222', 'México D.F.', NULL, '05021', 'Mexico');\nINSERT INTO `orders` VALUES (10927, 'LACOR', 4, '2018-03-05 00:00:00', '2018-04-08 00:00:00', 1, 19.79, '67-avenue de l\\'\\'Europe', 'Versailles', NULL, '78000', 'France');\nINSERT INTO `orders` VALUES (10928, 'GALED', 1, '2018-03-05 00:00:00', '2018-03-18 00:00:00', 1, 1.36, 'Rambla de Cataluña-23', 'Barcelona', NULL, '8022', 'Spain');\nINSERT INTO `orders` VALUES (10929, 'FRANK', 6, '2018-03-05 00:00:00', '2018-03-12 00:00:00', 1, 33.93, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (10930, 'SUPRD', 4, '2018-03-06 00:00:00', '2018-03-18 00:00:00', 3, 15.55, 'Boulevard Tirou-255', 'Charleroi', NULL, 'B-6000', 'Belgium');\nINSERT INTO `orders` VALUES (10931, 'RICSU', 4, '2018-03-06 00:00:00', '2018-03-19 00:00:00', 2, 13.60, 'Starenweg 5', 'Genève', NULL, '1204', 'Switzerland');\nINSERT INTO `orders` VALUES (10932, 'BONAP', 8, '2018-03-06 00:00:00', '2018-03-24 00:00:00', 1, 134.64, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10933, 'ISLAT', 6, '2018-03-06 00:00:00', '2018-03-16 00:00:00', 3, 54.15, 'Garden House Crowther Way', 'Cowes', 'Isle of Wight', 'PO31 7PJ', 'UK');\nINSERT INTO `orders` VALUES (10934, 'LEHMS', 3, '2018-03-09 00:00:00', '2018-03-12 00:00:00', 3, 32.01, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (10935, 'WELLI', 4, '2018-03-09 00:00:00', '2018-03-18 00:00:00', 3, 47.59, 'Rua do Mercado-12', 'Resende', 'SP', '08737-363', 'Brazil');\nINSERT INTO `orders` VALUES (10936, 'GREAL', 3, '2018-03-09 00:00:00', '2018-03-18 00:00:00', 2, 33.68, '2732 Baker Blvd.', 'Eugene', 'OR', '97403', 'USA');\nINSERT INTO `orders` VALUES (10937, 'CACTU', 7, '2018-03-10 00:00:00', '2018-03-13 00:00:00', 3, 31.51, 'Cerrito 333', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10938, 'QUICK', 3, '2018-03-10 00:00:00', '2018-03-16 00:00:00', 2, 31.89, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10939, 'MAGAA', 2, '2018-03-10 00:00:00', '2018-03-13 00:00:00', 2, 76.33, 'Via Ludovico il Moro 22', 'Bergamo', NULL, '24100', 'Italy');\nINSERT INTO `orders` VALUES (10940, 'BONAP', 8, '2018-03-11 00:00:00', '2018-03-23 00:00:00', 3, 19.77, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (10941, 'SAVEA', 7, '2018-03-11 00:00:00', '2018-03-20 00:00:00', 2, 400.81, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10942, 'REGGC', 9, '2018-03-11 00:00:00', '2018-03-18 00:00:00', 3, 17.95, 'Strada Provinciale 124', 'Reggio Emilia', NULL, '42100', 'Italy');\nINSERT INTO `orders` VALUES (10943, 'BSBEV', 4, '2018-03-11 00:00:00', '2018-03-19 00:00:00', 2, 2.17, 'Fauntleroy Circus', 'Londo', NULL, 'EC2 5NT', 'UK');\nINSERT INTO `orders` VALUES (10944, 'BOTTM', 6, '2018-03-12 00:00:00', '2018-03-13 00:00:00', 3, 52.92, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (10945, 'MORGK', 4, '2018-03-12 00:00:00', '2018-03-18 00:00:00', 1, 10.22, 'Heerstr. 22', 'Leipzig', NULL, '04179', 'Germany');\nINSERT INTO `orders` VALUES (10946, 'VAFFE', 1, '2018-03-12 00:00:00', '2018-03-19 00:00:00', 2, 27.20, 'Smagsloget 45', 'Århus', NULL, '8200', 'Denmark');\nINSERT INTO `orders` VALUES (10947, 'BSBEV', 3, '2018-03-13 00:00:00', '2018-03-16 00:00:00', 2, 3.26, 'Fauntleroy Circus', 'Londo', NULL, 'EC2 5NT', 'UK');\nINSERT INTO `orders` VALUES (10948, 'GODOS', 3, '2018-03-13 00:00:00', '2018-03-19 00:00:00', 3, 23.39, 'C/ Romero-33', 'Sevilla', NULL, '41101', 'Spain');\nINSERT INTO `orders` VALUES (10949, 'BOTTM', 2, '2018-03-13 00:00:00', '2018-03-17 00:00:00', 3, 74.44, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (10950, 'MAGAA', 1, '2018-03-16 00:00:00', '2018-03-23 00:00:00', 2, 2.50, 'Via Ludovico il Moro 22', 'Bergamo', NULL, '24100', 'Italy');\nINSERT INTO `orders` VALUES (10951, 'RICSU', 9, '2018-03-16 00:00:00', '2018-04-07 00:00:00', 2, 30.85, 'Starenweg 5', 'Genève', NULL, '1204', 'Switzerland');\nINSERT INTO `orders` VALUES (10952, 'ALFKI', 1, '2018-03-16 00:00:00', '2018-03-24 00:00:00', 1, 40.42, 'Obere Str. 57', 'Berli', NULL, '12209', 'Germany');\nINSERT INTO `orders` VALUES (10953, 'AROUT', 9, '2018-03-16 00:00:00', '2018-03-25 00:00:00', 2, 23.72, 'Brook Farm Stratford St. Mary', 'Colchester', 'Essex', 'CO7 6JX', 'UK');\nINSERT INTO `orders` VALUES (10954, 'LINOD', 5, '2018-03-17 00:00:00', '2018-03-20 00:00:00', 1, 27.91, 'Ave. 5 de Mayo Porlamar', 'I. de Margarita', 'Nueva Esparta', '4980', 'Venezuela');\nINSERT INTO `orders` VALUES (10955, 'FOLKO', 8, '2018-03-17 00:00:00', '2018-03-20 00:00:00', 2, 3.26, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10956, 'BLAUS', 6, '2018-03-17 00:00:00', '2018-03-20 00:00:00', 2, 44.65, 'Forsterstr. 57', 'Mannheim', NULL, '68306', 'Germany');\nINSERT INTO `orders` VALUES (10957, 'HILAA', 8, '2018-03-18 00:00:00', '2018-03-27 00:00:00', 3, 105.36, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10958, 'OCEA', 7, '2018-03-18 00:00:00', '2018-03-27 00:00:00', 2, 49.56, 'Ing. Gustavo Moncada 8585 Piso 20-A', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10959, 'GOURL', 6, '2018-03-18 00:00:00', '2018-03-23 00:00:00', 2, 4.98, 'Av. Brasil-442', 'Campinas', 'SP', '04876-786', 'Brazil');\nINSERT INTO `orders` VALUES (10960, 'HILAA', 3, '2018-03-19 00:00:00', '2018-04-08 00:00:00', 1, 2.08, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10961, 'QUEE', 8, '2018-03-19 00:00:00', '2018-03-30 00:00:00', 1, 104.47, 'Alameda dos Canàrios-891', 'Sao Paulo', 'SP', '05487-020', 'Brazil');\nINSERT INTO `orders` VALUES (10962, 'QUICK', 8, '2018-03-19 00:00:00', '2018-03-23 00:00:00', 2, 275.79, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10963, 'FURIB', 9, '2018-03-19 00:00:00', '2018-03-26 00:00:00', 3, 2.70, 'Jardim das rosas n. 32', 'Lisboa', NULL, '1675', 'Portugal');\nINSERT INTO `orders` VALUES (10964, 'SPECD', 3, '2018-03-20 00:00:00', '2018-03-24 00:00:00', 2, 87.38, '25-rue Lauristo', 'Paris', NULL, '75016', 'France');\nINSERT INTO `orders` VALUES (10965, 'OLDWO', 6, '2018-03-20 00:00:00', '2018-03-30 00:00:00', 3, 144.38, '2743 Bering St.', 'Anchorage', 'AK', '99508', 'USA');\nINSERT INTO `orders` VALUES (10966, 'CHOPS', 4, '2018-03-20 00:00:00', '2018-04-08 00:00:00', 1, 27.19, 'Hauptstr. 31', 'Ber', NULL, '3012', 'Switzerland');\nINSERT INTO `orders` VALUES (10967, 'TOMSP', 2, '2018-03-23 00:00:00', '2018-04-02 00:00:00', 2, 62.22, 'Luisenstr. 48', 'Münster', NULL, '44087', 'Germany');\nINSERT INTO `orders` VALUES (10968, 'ERNSH', 1, '2018-03-23 00:00:00', '2018-04-01 00:00:00', 3, 74.60, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10969, 'COMMI', 1, '2018-03-23 00:00:00', '2018-03-30 00:00:00', 2, 0.21, 'Av. dos Lusíadas-23', 'Sao Paulo', 'SP', '05432-043', 'Brazil');\nINSERT INTO `orders` VALUES (10970, 'BOLID', 9, '2018-03-24 00:00:00', '2018-04-24 00:00:00', 1, 16.16, 'C/ Araquil-67', 'Madrid', NULL, '28023', 'Spain');\nINSERT INTO `orders` VALUES (10971, 'FRANR', 2, '2018-03-24 00:00:00', '2018-04-02 00:00:00', 2, 121.82, '54-rue Royale', 'Nantes', NULL, '44000', 'France');\nINSERT INTO `orders` VALUES (10972, 'LACOR', 4, '2018-03-24 00:00:00', '2018-03-26 00:00:00', 2, 0.02, '67-avenue de l\\'\\'Europe', 'Versailles', NULL, '78000', 'France');\nINSERT INTO `orders` VALUES (10973, 'LACOR', 6, '2018-03-24 00:00:00', '2018-03-27 00:00:00', 2, 15.17, '67-avenue de l\\'\\'Europe', 'Versailles', NULL, '78000', 'France');\nINSERT INTO `orders` VALUES (10974, 'SPLIR', 3, '2018-03-25 00:00:00', '2018-04-03 00:00:00', 3, 12.96, 'P.O. Box 555', 'Lander', 'WY', '82520', 'USA');\nINSERT INTO `orders` VALUES (10975, 'BOTTM', 1, '2018-03-25 00:00:00', '2018-03-27 00:00:00', 3, 32.27, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (10976, 'HILAA', 1, '2018-03-25 00:00:00', '2018-04-03 00:00:00', 1, 37.97, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (10977, 'FOLKO', 8, '2018-03-26 00:00:00', '2018-04-10 00:00:00', 3, 208.50, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10978, 'MAISD', 9, '2018-03-26 00:00:00', '2018-04-23 00:00:00', 2, 32.82, 'Rue Joseph-Bens 532', 'Bruxelles', NULL, 'B-1180', 'Belgium');\nINSERT INTO `orders` VALUES (10979, 'ERNSH', 8, '2018-03-26 00:00:00', '2018-03-31 00:00:00', 2, 353.07, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10980, 'FOLKO', 4, '2018-03-27 00:00:00', '2018-04-17 00:00:00', 1, 1.26, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10981, 'HANAR', 1, '2018-03-27 00:00:00', '2018-04-02 00:00:00', 2, 193.37, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (10982, 'BOTTM', 2, '2018-03-27 00:00:00', '2018-04-08 00:00:00', 1, 14.01, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (10983, 'SAVEA', 2, '2018-03-27 00:00:00', '2018-04-06 00:00:00', 2, 657.54, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10984, 'SAVEA', 1, '2018-03-30 00:00:00', '2018-04-03 00:00:00', 3, 211.22, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (10985, 'HUNGO', 2, '2018-03-30 00:00:00', '2018-04-02 00:00:00', 1, 91.51, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (10986, 'OCEA', 8, '2018-03-30 00:00:00', '2018-04-21 00:00:00', 2, 217.86, 'Ing. Gustavo Moncada 8585 Piso 20-A', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (10987, 'EASTC', 8, '2018-03-31 00:00:00', '2018-04-06 00:00:00', 1, 185.48, '35 King George', 'Londo', NULL, 'WX3 6FW', 'UK');\nINSERT INTO `orders` VALUES (10988, 'RATTC', 3, '2018-03-31 00:00:00', '2018-04-10 00:00:00', 2, 61.14, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (10989, 'QUEDE', 2, '2018-03-31 00:00:00', '2018-04-02 00:00:00', 1, 34.76, 'Rua da Panificadora-12', 'Rio de Janeiro', 'RJ', '02389-673', 'Brazil');\nINSERT INTO `orders` VALUES (10990, 'ERNSH', 2, '2018-04-01 00:00:00', '2018-04-07 00:00:00', 3, 117.61, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (10991, 'QUICK', 1, '2018-04-01 00:00:00', '2018-04-07 00:00:00', 1, 38.51, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10992, 'THEBI', 1, '2018-04-01 00:00:00', '2018-04-03 00:00:00', 3, 4.27, '89 Jefferson Way Suite 2', 'Portland', 'OR', '97201', 'USA');\nINSERT INTO `orders` VALUES (10993, 'FOLKO', 7, '2018-04-01 00:00:00', '2018-04-10 00:00:00', 3, 8.81, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (10994, 'VAFFE', 2, '2018-04-02 00:00:00', '2018-04-09 00:00:00', 3, 65.53, 'Smagsloget 45', 'Århus', NULL, '8200', 'Denmark');\nINSERT INTO `orders` VALUES (10995, 'PERIC', 1, '2018-04-02 00:00:00', '2018-04-06 00:00:00', 3, 46.00, 'Calle Dr. Jorge Cash 321', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (10996, 'QUICK', 4, '2018-04-02 00:00:00', '2018-04-10 00:00:00', 2, 1.12, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (10997, 'LILAS', 8, '2018-04-03 00:00:00', '2018-04-13 00:00:00', 2, 73.91, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (10998, 'WOLZA', 8, '2018-04-03 00:00:00', '2018-04-17 00:00:00', 2, 20.31, 'ul. Filtrowa 68', 'Warszawa', NULL, '01-012', 'Poland');\nINSERT INTO `orders` VALUES (10999, 'OTTIK', 6, '2018-04-03 00:00:00', '2018-04-10 00:00:00', 2, 96.35, 'Mehrheimerstr. 369', 'Köl', NULL, '50739', 'Germany');\nINSERT INTO `orders` VALUES (11000, 'RATTC', 2, '2018-04-06 00:00:00', '2018-04-14 00:00:00', 3, 55.12, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nINSERT INTO `orders` VALUES (11001, 'FOLKO', 2, '2018-04-06 00:00:00', '2018-04-14 00:00:00', 2, 197.30, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (11002, 'SAVEA', 4, '2018-04-06 00:00:00', '2018-04-16 00:00:00', 1, 141.16, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (11003, 'THECR', 3, '2018-04-06 00:00:00', '2018-04-08 00:00:00', 3, 14.91, '55 Grizzly Peak Rd.', 'Butte', 'MT', '59801', 'USA');\nINSERT INTO `orders` VALUES (11004, 'MAISD', 3, '2018-04-07 00:00:00', '2018-04-20 00:00:00', 1, 44.84, 'Rue Joseph-Bens 532', 'Bruxelles', NULL, 'B-1180', 'Belgium');\nINSERT INTO `orders` VALUES (11005, 'WILMK', 2, '2018-04-07 00:00:00', '2018-04-10 00:00:00', 1, 0.75, 'Keskuskatu 45', 'Helsinki', NULL, '21240', 'Finland');\nINSERT INTO `orders` VALUES (11006, 'GREAL', 3, '2018-04-07 00:00:00', '2018-04-15 00:00:00', 2, 25.19, '2732 Baker Blvd.', 'Eugene', 'OR', '97403', 'USA');\nINSERT INTO `orders` VALUES (11007, 'PRINI', 8, '2018-04-08 00:00:00', '2018-04-13 00:00:00', 2, 202.24, 'Estrada da saúde n. 58', 'Lisboa', NULL, '1756', 'Portugal');\nINSERT INTO `orders` VALUES (11008, 'ERNSH', 7, '2018-04-08 00:00:00', NULL, 3, 79.46, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (11009, 'GODOS', 2, '2018-04-08 00:00:00', '2018-04-10 00:00:00', 1, 59.11, 'C/ Romero-33', 'Sevilla', NULL, '41101', 'Spain');\nINSERT INTO `orders` VALUES (11010, 'REGGC', 2, '2018-04-09 00:00:00', '2018-04-21 00:00:00', 2, 28.71, 'Strada Provinciale 124', 'Reggio Emilia', NULL, '42100', 'Italy');\nINSERT INTO `orders` VALUES (11011, 'ALFKI', 3, '2018-04-09 00:00:00', '2018-04-13 00:00:00', 1, 1.21, 'Obere Str. 57', 'Berli', NULL, '12209', 'Germany');\nINSERT INTO `orders` VALUES (11012, 'FRANK', 1, '2018-04-09 00:00:00', '2018-04-17 00:00:00', 3, 242.95, 'Berliner Platz 43', 'Münche', NULL, '80805', 'Germany');\nINSERT INTO `orders` VALUES (11013, 'ROMEY', 2, '2018-04-09 00:00:00', '2018-04-10 00:00:00', 1, 32.99, 'Gran Vía-1', 'Madrid', NULL, '28001', 'Spain');\nINSERT INTO `orders` VALUES (11014, 'LINOD', 2, '2018-04-10 00:00:00', '2018-04-15 00:00:00', 3, 23.60, 'Ave. 5 de Mayo Porlamar', 'I. de Margarita', 'Nueva Esparta', '4980', 'Venezuela');\nINSERT INTO `orders` VALUES (11015, 'SANTG', 2, '2018-04-10 00:00:00', '2018-04-20 00:00:00', 2, 4.62, 'Erling Skakkes gate 78', 'Staver', NULL, '4110', 'Norway');\nINSERT INTO `orders` VALUES (11016, 'AROUT', 9, '2018-04-10 00:00:00', '2018-04-13 00:00:00', 2, 33.80, 'Brook Farm Stratford St. Mary', 'Colchester', 'Essex', 'CO7 6JX', 'UK');\nINSERT INTO `orders` VALUES (11017, 'ERNSH', 9, '2018-04-13 00:00:00', '2018-04-20 00:00:00', 2, 754.26, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (11018, 'LONEP', 4, '2018-04-13 00:00:00', '2018-04-16 00:00:00', 2, 11.65, '89 Chiaroscuro Rd.', 'Portland', 'OR', '97219', 'USA');\nINSERT INTO `orders` VALUES (11019, 'RANCH', 6, '2018-04-13 00:00:00', NULL, 3, 3.17, 'Av. del Libertador 900', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (11020, 'OTTIK', 2, '2018-04-14 00:00:00', '2018-04-16 00:00:00', 2, 43.30, 'Mehrheimerstr. 369', 'Köl', NULL, '50739', 'Germany');\nINSERT INTO `orders` VALUES (11021, 'QUICK', 3, '2018-04-14 00:00:00', '2018-04-21 00:00:00', 1, 297.18, 'Taucherstraße 10', 'Cunewalde', NULL, '01307', 'Germany');\nINSERT INTO `orders` VALUES (11022, 'HANAR', 9, '2018-04-14 00:00:00', '2018-05-04 00:00:00', 2, 6.27, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (11023, 'BSBEV', 1, '2018-04-14 00:00:00', '2018-04-24 00:00:00', 2, 123.83, 'Fauntleroy Circus', 'Londo', NULL, 'EC2 5NT', 'UK');\nINSERT INTO `orders` VALUES (11024, 'EASTC', 4, '2018-04-15 00:00:00', '2018-04-20 00:00:00', 1, 74.36, '35 King George', 'Londo', NULL, 'WX3 6FW', 'UK');\nINSERT INTO `orders` VALUES (11025, 'WARTH', 6, '2018-04-15 00:00:00', '2018-04-24 00:00:00', 3, 29.17, 'Torikatu 38', 'Oulu', NULL, '90110', 'Finland');\nINSERT INTO `orders` VALUES (11026, 'FRANS', 4, '2018-04-15 00:00:00', '2018-04-28 00:00:00', 1, 47.09, 'Via Monte Bianco 34', 'Torino', NULL, '10100', 'Italy');\nINSERT INTO `orders` VALUES (11027, 'BOTTM', 1, '2018-04-16 00:00:00', '2018-04-20 00:00:00', 1, 52.52, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (11028, 'KOENE', 2, '2018-04-16 00:00:00', '2018-04-22 00:00:00', 1, 29.59, 'Maubelstr. 90', 'Brandenburg', NULL, '14776', 'Germany');\nINSERT INTO `orders` VALUES (11029, 'CHOPS', 4, '2018-04-16 00:00:00', '2018-04-27 00:00:00', 1, 47.84, 'Hauptstr. 31', 'Ber', NULL, '3012', 'Switzerland');\nINSERT INTO `orders` VALUES (11030, 'SAVEA', 7, '2018-04-17 00:00:00', '2018-04-27 00:00:00', 2, 830.75, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (11031, 'SAVEA', 6, '2018-04-17 00:00:00', '2018-04-24 00:00:00', 2, 227.22, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (11032, 'WHITC', 2, '2018-04-17 00:00:00', '2018-04-23 00:00:00', 3, 606.19, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (11033, 'RICSU', 7, '2018-04-17 00:00:00', '2018-04-23 00:00:00', 3, 84.74, 'Starenweg 5', 'Genève', NULL, '1204', 'Switzerland');\nINSERT INTO `orders` VALUES (11034, 'OLDWO', 8, '2018-04-20 00:00:00', '2018-04-27 00:00:00', 1, 40.32, '2743 Bering St.', 'Anchorage', 'AK', '99508', 'USA');\nINSERT INTO `orders` VALUES (11035, 'SUPRD', 2, '2018-04-20 00:00:00', '2018-04-24 00:00:00', 2, 0.17, 'Boulevard Tirou-255', 'Charleroi', NULL, 'B-6000', 'Belgium');\nINSERT INTO `orders` VALUES (11036, 'DRACD', 8, '2018-04-20 00:00:00', '2018-04-22 00:00:00', 3, 149.47, 'Walserweg 21', 'Aache', NULL, '52066', 'Germany');\nINSERT INTO `orders` VALUES (11037, 'GODOS', 7, '2018-04-21 00:00:00', '2018-04-27 00:00:00', 1, 3.20, 'C/ Romero-33', 'Sevilla', NULL, '41101', 'Spain');\nINSERT INTO `orders` VALUES (11038, 'SUPRD', 1, '2018-04-21 00:00:00', '2018-04-30 00:00:00', 2, 29.59, 'Boulevard Tirou-255', 'Charleroi', NULL, 'B-6000', 'Belgium');\nINSERT INTO `orders` VALUES (11039, 'LINOD', 1, '2018-04-21 00:00:00', NULL, 2, 65.00, 'Ave. 5 de Mayo Porlamar', 'I. de Margarita', 'Nueva Esparta', '4980', 'Venezuela');\nINSERT INTO `orders` VALUES (11040, 'GREAL', 4, '2018-04-22 00:00:00', NULL, 3, 18.84, '2732 Baker Blvd.', 'Eugene', 'OR', '97403', 'USA');\nINSERT INTO `orders` VALUES (11041, 'CHOPS', 3, '2018-04-22 00:00:00', '2018-04-28 00:00:00', 2, 48.22, 'Hauptstr. 31', 'Ber', NULL, '3012', 'Switzerland');\nINSERT INTO `orders` VALUES (11042, 'COMMI', 2, '2018-04-22 00:00:00', '2018-05-01 00:00:00', 1, 29.99, 'Av. dos Lusíadas-23', 'Sao Paulo', 'SP', '05432-043', 'Brazil');\nINSERT INTO `orders` VALUES (11043, 'SPECD', 5, '2018-04-22 00:00:00', '2018-04-29 00:00:00', 2, 8.80, '25-rue Lauristo', 'Paris', NULL, '75016', 'France');\nINSERT INTO `orders` VALUES (11044, 'WOLZA', 4, '2018-04-23 00:00:00', '2018-05-01 00:00:00', 1, 8.72, 'ul. Filtrowa 68', 'Warszawa', NULL, '01-012', 'Poland');\nINSERT INTO `orders` VALUES (11045, 'BOTTM', 6, '2018-04-23 00:00:00', NULL, 2, 70.58, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (11046, 'WANDK', 8, '2018-04-23 00:00:00', '2018-04-24 00:00:00', 2, 71.64, 'Adenauerallee 900', 'Stuttgart', NULL, '70563', 'Germany');\nINSERT INTO `orders` VALUES (11047, 'EASTC', 7, '2018-04-24 00:00:00', '2018-05-01 00:00:00', 3, 46.62, '35 King George', 'Londo', NULL, 'WX3 6FW', 'UK');\nINSERT INTO `orders` VALUES (11048, 'BOTTM', 7, '2018-04-24 00:00:00', '2018-04-30 00:00:00', 3, 24.12, '23 Tsawassen Blvd.', 'Tsawasse', 'BC', 'T2F 8M4', 'Canada');\nINSERT INTO `orders` VALUES (11049, 'GOURL', 3, '2018-04-24 00:00:00', '2018-05-04 00:00:00', 1, 8.34, 'Av. Brasil-442', 'Campinas', 'SP', '04876-786', 'Brazil');\nINSERT INTO `orders` VALUES (11050, 'FOLKO', 8, '2018-04-27 00:00:00', '2018-05-05 00:00:00', 2, 59.41, 'Åkergatan 24', 'Bräcke', NULL, 'S-844 67', 'Sweden');\nINSERT INTO `orders` VALUES (11051, 'LAMAI', 7, '2018-04-27 00:00:00', NULL, 3, 2.79, '1 rue Alsace-Lorraine', 'Toulouse', NULL, '31000', 'France');\nINSERT INTO `orders` VALUES (11052, 'HANAR', 3, '2018-04-27 00:00:00', '2018-05-01 00:00:00', 1, 67.26, 'Rua do Paço-67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil');\nINSERT INTO `orders` VALUES (11053, 'PICCO', 2, '2018-04-27 00:00:00', '2018-04-29 00:00:00', 2, 53.05, 'Geislweg 14', 'Salzburg', NULL, '5020', 'Austria');\nINSERT INTO `orders` VALUES (11054, 'CACTU', 8, '2018-04-28 00:00:00', NULL, 1, 0.33, 'Cerrito 333', 'Buenos Aires', NULL, '1010', 'Argentina');\nINSERT INTO `orders` VALUES (11055, 'HILAA', 7, '2018-04-28 00:00:00', '2018-05-05 00:00:00', 2, 120.92, 'Carrera 22 con Ave. Carlos Soublette #8-35', 'San Cristóbal', 'Táchira', '5022', 'Venezuela');\nINSERT INTO `orders` VALUES (11056, 'EASTC', 8, '2018-04-28 00:00:00', '2018-05-01 00:00:00', 2, 278.96, '35 King George', 'Londo', NULL, 'WX3 6FW', 'UK');\nINSERT INTO `orders` VALUES (11057, 'NORTS', 3, '2018-04-29 00:00:00', '2018-05-01 00:00:00', 3, 4.13, 'South House 300 Queensbridge', 'Londo', NULL, 'SW7 1RZ', 'UK');\nINSERT INTO `orders` VALUES (11058, 'BLAUS', 9, '2018-04-29 00:00:00', NULL, 3, 31.14, 'Forsterstr. 57', 'Mannheim', NULL, '68306', 'Germany');\nINSERT INTO `orders` VALUES (11059, 'RICAR', 2, '2018-04-29 00:00:00', NULL, 2, 85.80, 'Av. Copacabana-267', 'Rio de Janeiro', 'RJ', '02389-890', 'Brazil');\nINSERT INTO `orders` VALUES (11060, 'FRANS', 2, '2018-04-30 00:00:00', '2018-05-04 00:00:00', 2, 10.98, 'Via Monte Bianco 34', 'Torino', NULL, '10100', 'Italy');\nINSERT INTO `orders` VALUES (11061, 'GREAL', 4, '2018-04-30 00:00:00', NULL, 3, 14.01, '2732 Baker Blvd.', 'Eugene', 'OR', '97403', 'USA');\nINSERT INTO `orders` VALUES (11062, 'REGGC', 4, '2018-04-30 00:00:00', NULL, 2, 29.93, 'Strada Provinciale 124', 'Reggio Emilia', NULL, '42100', 'Italy');\nINSERT INTO `orders` VALUES (11063, 'HUNGO', 3, '2018-04-30 00:00:00', '2018-05-06 00:00:00', 2, 81.73, '8 Johnstown Road', 'Cork', 'Co. Cork', NULL, 'Ireland');\nINSERT INTO `orders` VALUES (11064, 'SAVEA', 1, '2018-05-01 00:00:00', '2018-05-04 00:00:00', 1, 30.09, '187 Suffolk Ln.', 'Boise', 'ID', '83720', 'USA');\nINSERT INTO `orders` VALUES (11065, 'LILAS', 8, '2018-05-01 00:00:00', NULL, 1, 12.91, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (11066, 'WHITC', 7, '2018-05-01 00:00:00', '2018-05-04 00:00:00', 2, 44.72, '1029 - 12th Ave. S.', 'Seattle', 'WA', '98124', 'USA');\nINSERT INTO `orders` VALUES (11067, 'DRACD', 1, '2018-05-04 00:00:00', '2018-05-06 00:00:00', 2, 7.98, 'Walserweg 21', 'Aache', NULL, '52066', 'Germany');\nINSERT INTO `orders` VALUES (11068, 'QUEE', 8, '2018-05-04 00:00:00', NULL, 2, 81.75, 'Alameda dos Canàrios-891', 'Sao Paulo', 'SP', '05487-020', 'Brazil');\nINSERT INTO `orders` VALUES (11069, 'TORTU', 1, '2018-05-04 00:00:00', '2018-05-06 00:00:00', 2, 15.67, 'Avda. Azteca 123', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (11070, 'LEHMS', 2, '2018-05-05 00:00:00', NULL, 1, 136.00, 'Magazinweg 7', 'Frankfurt a.M.', NULL, '60528', 'Germany');\nINSERT INTO `orders` VALUES (11071, 'LILAS', 1, '2018-05-05 00:00:00', NULL, 1, 0.93, 'Carrera 52 con Ave. Bolívar #65-98 Llano Largo', 'Barquisimeto', 'Lara', '3508', 'Venezuela');\nINSERT INTO `orders` VALUES (11072, 'ERNSH', 4, '2018-05-05 00:00:00', NULL, 2, 258.64, 'Kirchgasse 6', 'Graz', NULL, '8010', 'Austria');\nINSERT INTO `orders` VALUES (11073, 'PERIC', 2, '2018-05-05 00:00:00', NULL, 2, 24.95, 'Calle Dr. Jorge Cash 321', 'México D.F.', NULL, '05033', 'Mexico');\nINSERT INTO `orders` VALUES (11074, 'SIMOB', 7, '2018-05-06 00:00:00', NULL, 2, 18.44, 'Vinbæltet 34', 'Kobenhav', NULL, '1734', 'Denmark');\nINSERT INTO `orders` VALUES (11075, 'RICSU', 8, '2018-05-06 00:00:00', NULL, 2, 6.19, 'Starenweg 5', 'Genève', NULL, '1204', 'Switzerland');\nINSERT INTO `orders` VALUES (11076, 'BONAP', 4, '2018-05-06 00:00:00', NULL, 2, 38.28, '12-rue des Bouchers', 'Marseille', NULL, '13008', 'France');\nINSERT INTO `orders` VALUES (11077, 'RATTC', 1, '2018-05-06 00:00:00', NULL, 2, 8.53, '2817 Milton Dr.', 'Albuquerque', 'NM', '87110', 'USA');\nCOMMIT;\n\n-- ----------------------------\n-- Table structure for products\n-- ----------------------------\nDROP TABLE IF EXISTS `products`;\nCREATE TABLE `products` (\n  `product_id` int NOT NULL,\n  `product_name` varchar(40) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `supplier_id` int DEFAULT NULL,\n  `category_id` int DEFAULT NULL,\n  `quantity_per_unit` varchar(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `unit_price` decimal(10,2) DEFAULT NULL,\n  `units_in_stock` smallint DEFAULT NULL,\n  `units_on_order` smallint DEFAULT NULL,\n  `discontinued` bit(1) DEFAULT NULL,\n  PRIMARY KEY (`product_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;\n\n-- ----------------------------\n-- Records of products\n-- ----------------------------\nBEGIN;\nINSERT INTO `products` VALUES (1, 'Chai', 1, 1, '10 boxes x 20 bags', 18.00, 39, 0, b'0');\nINSERT INTO `products` VALUES (2, 'Chang', 1, 1, '24 - 12 oz bottles', 19.00, 17, 40, b'0');\nINSERT INTO `products` VALUES (3, 'Aniseed Syrup', 1, 2, '12 - 550 ml bottles', 10.00, 13, 70, b'0');\nINSERT INTO `products` VALUES (4, 'Chef Anton\\'s Cajun Seasoning', 2, 2, '48 - 6 oz jars', 22.00, 53, 0, b'0');\nINSERT INTO `products` VALUES (5, 'Chef Anton\\'s Gumbo Mix', 2, 2, '36 boxes', 21.35, 0, 0, b'1');\nINSERT INTO `products` VALUES (6, 'Grandma\\'s Boysenberry Spread', 3, 2, '12 - 8 oz jars', 25.00, 120, 0, b'0');\nINSERT INTO `products` VALUES (7, 'Uncle Bob\\'s Organic Dried Pears', 3, 7, '12 - 1 lb pkgs.', 30.00, 15, 0, b'0');\nINSERT INTO `products` VALUES (8, 'Northwoods Cranberry Sauce', 3, 2, '12 - 12 oz jars', 40.00, 6, 0, b'0');\nINSERT INTO `products` VALUES (9, 'Mishi Kobe Niku', 4, 6, '18 - 500 g pkgs.', 97.00, 29, 0, b'1');\nINSERT INTO `products` VALUES (10, 'Ikura', 4, 8, '12 - 200 ml jars', 31.00, 31, 0, b'0');\nINSERT INTO `products` VALUES (11, 'Queso Cabrales', 5, 4, '1 kg pkg.', 21.00, 22, 30, b'0');\nINSERT INTO `products` VALUES (12, 'Queso Manchego La Pastora', 5, 4, '10 - 500 g pkgs.', 38.00, 86, 0, b'0');\nINSERT INTO `products` VALUES (13, 'Konbu', 6, 8, '2 kg box', 6.00, 24, 0, b'0');\nINSERT INTO `products` VALUES (14, 'Tofu', 6, 7, '40 - 100 g pkgs.', 23.25, 35, 0, b'0');\nINSERT INTO `products` VALUES (15, 'Genen Shouyu', 6, 2, '24 - 250 ml bottles', 15.50, 39, 0, b'0');\nINSERT INTO `products` VALUES (16, 'Pavlova', 7, 3, '32 - 500 g boxes', 17.45, 29, 0, b'0');\nINSERT INTO `products` VALUES (17, 'Alice Mutton', 7, 6, '20 - 1 kg tins', 39.00, 0, 0, b'1');\nINSERT INTO `products` VALUES (18, 'Carnarvon Tigers', 7, 8, '16 kg pkg.', 62.50, 42, 0, b'0');\nINSERT INTO `products` VALUES (19, 'Teatime Chocolate Biscuits', 8, 3, '10 boxes x 12 pieces', 9.20, 25, 0, b'0');\nINSERT INTO `products` VALUES (20, 'Sir Rodney\\'s Marmalade', 8, 3, '30 gift boxes', 81.00, 40, 0, b'0');\nINSERT INTO `products` VALUES (21, 'Sir Rodney\\'s Scones', 8, 3, '24 pkgs. x 4 pieces', 10.00, 3, 40, b'0');\nINSERT INTO `products` VALUES (22, 'Gustaf\\'s Knäckebröd', 9, 5, '24 - 500 g pkgs.', 21.00, 104, 0, b'0');\nINSERT INTO `products` VALUES (23, 'Tunnbröd', 9, 5, '12 - 250 g pkgs.', 9.00, 61, 0, b'0');\nINSERT INTO `products` VALUES (24, 'Guaraná Fantástica', 10, 1, '12 - 355 ml cans', 4.50, 20, 0, b'1');\nINSERT INTO `products` VALUES (25, 'NuNuCa Nuß-Nougat-Creme', 11, 3, '20 - 450 g glasses', 14.00, 76, 0, b'0');\nINSERT INTO `products` VALUES (26, 'Gumbär Gummibärchen', 11, 3, '100 - 250 g bags', 31.23, 15, 0, b'0');\nINSERT INTO `products` VALUES (27, 'Schoggi Schokolade', 11, 3, '100 - 100 g pieces', 43.90, 49, 0, b'0');\nINSERT INTO `products` VALUES (28, 'Rössle Sauerkraut', 12, 7, '25 - 825 g cans', 45.60, 26, 0, b'1');\nINSERT INTO `products` VALUES (29, 'Thüringer Rostbratwurst', 12, 6, '50 bags x 30 sausgs.', 123.79, 0, 0, b'1');\nINSERT INTO `products` VALUES (30, 'Nord-Ost Matjeshering', 13, 8, '10 - 200 g glasses', 25.89, 10, 0, b'0');\nINSERT INTO `products` VALUES (31, 'Gorgonzola Telino', 14, 4, '12 - 100 g pkgs', 12.50, 0, 70, b'0');\nINSERT INTO `products` VALUES (32, 'Mascarpone Fabioli', 14, 4, '24 - 200 g pkgs.', 32.00, 9, 40, b'0');\nINSERT INTO `products` VALUES (33, 'Geitost', 16, 4, '500 g', 2.50, 112, 0, b'0');\nINSERT INTO `products` VALUES (34, 'Sasquatch Ale', 16, 1, '24 - 12 oz bottles', 14.00, 111, 0, b'0');\nINSERT INTO `products` VALUES (35, 'Steeleye Stout', 16, 1, '24 - 12 oz bottles', 18.00, 20, 0, b'0');\nINSERT INTO `products` VALUES (36, 'Inlagd Sill', 17, 8, '24 - 250 g jars', 19.00, 112, 0, b'0');\nINSERT INTO `products` VALUES (37, 'Gravad lax', 17, 8, '12 - 500 g pkgs.', 26.00, 11, 50, b'0');\nINSERT INTO `products` VALUES (38, 'Côte de Blaye', 18, 1, '12 - 75 cl bottles', 263.50, 17, 0, b'0');\nINSERT INTO `products` VALUES (39, 'Chartreuse verte', 18, 1, '750 cc per bottle', 18.00, 69, 0, b'0');\nINSERT INTO `products` VALUES (40, 'Boston Crab Meat', 19, 8, '24 - 4 oz tins', 18.40, 123, 0, b'0');\nINSERT INTO `products` VALUES (41, 'Jack\\'s New England Clam Chowder', 19, 8, '12 - 12 oz cans', 9.65, 85, 0, b'0');\nINSERT INTO `products` VALUES (42, 'Singaporean Hokkien Fried Mee', 20, 5, '32 - 1 kg pkgs.', 14.00, 26, 0, b'1');\nINSERT INTO `products` VALUES (43, 'Ipoh Coffee', 20, 1, '16 - 500 g tins', 46.00, 17, 10, b'0');\nINSERT INTO `products` VALUES (44, 'Gula Malacca', 20, 2, '20 - 2 kg bags', 19.45, 27, 0, b'0');\nINSERT INTO `products` VALUES (45, 'Rogede sild', 21, 8, '1k pkg.', 9.50, 5, 70, b'0');\nINSERT INTO `products` VALUES (46, 'Spegesild', 21, 8, '4 - 450 g glasses', 12.00, 95, 0, b'0');\nINSERT INTO `products` VALUES (47, 'Zaanse koeken', 22, 3, '10 - 4 oz boxes', 9.50, 36, 0, b'0');\nINSERT INTO `products` VALUES (48, 'Chocolade', 22, 3, '10 pkgs.', 12.75, 15, 70, b'0');\nINSERT INTO `products` VALUES (49, 'Maxilaku', 23, 3, '24 - 50 g pkgs.', 20.00, 10, 60, b'0');\nINSERT INTO `products` VALUES (50, 'Valkoinen suklaa', 23, 3, '12 - 100 g bars', 16.25, 65, 0, b'0');\nINSERT INTO `products` VALUES (51, 'Manjimup Dried Apples', 24, 7, '50 - 300 g pkgs.', 53.00, 20, 0, b'0');\nINSERT INTO `products` VALUES (52, 'Filo Mix', 24, 5, '16 - 2 kg boxes', 7.00, 38, 0, b'0');\nINSERT INTO `products` VALUES (53, 'Perth Pasties', 24, 6, '48 pieces', 32.80, 0, 0, b'1');\nINSERT INTO `products` VALUES (54, 'Tourtière', 25, 6, '16 pies', 7.45, 21, 0, b'0');\nINSERT INTO `products` VALUES (55, 'Pâté chinois', 25, 6, '24 boxes x 2 pies', 24.00, 115, 0, b'0');\nINSERT INTO `products` VALUES (56, 'Gnocchi di nonna Alice', 26, 5, '24 - 250 g pkgs.', 38.00, 21, 10, b'0');\nINSERT INTO `products` VALUES (57, 'Ravioli Angelo', 26, 5, '24 - 250 g pkgs.', 19.50, 36, 0, b'0');\nINSERT INTO `products` VALUES (58, 'Escargots de Bourgogne', 27, 8, '24 pieces', 13.25, 62, 0, b'0');\nINSERT INTO `products` VALUES (59, 'Raclette Courdavault', 28, 4, '5 kg pkg.', 55.00, 79, 0, b'0');\nINSERT INTO `products` VALUES (60, 'Camembert Pierrot', 28, 4, '15 - 300 g rounds', 34.00, 19, 0, b'0');\nINSERT INTO `products` VALUES (61, 'Sirop d\\'érable', 29, 2, '24 - 500 ml bottles', 28.50, 113, 0, b'0');\nINSERT INTO `products` VALUES (62, 'Tarte au sucre', 29, 3, '48 pies', 49.30, 17, 0, b'0');\nINSERT INTO `products` VALUES (63, 'Vegie-spread', 7, 2, '15 - 625 g jars', 43.90, 24, 0, b'0');\nINSERT INTO `products` VALUES (64, 'Wimmers gute Semmelknödel', 12, 5, '20 bags x 4 pieces', 33.25, 22, 80, b'0');\nINSERT INTO `products` VALUES (65, 'Louisiana Fiery Hot Pepper Sauce', 2, 2, '32 - 8 oz bottles', 21.05, 76, 0, b'0');\nINSERT INTO `products` VALUES (66, 'Louisiana Hot Spiced Okra', 2, 2, '24 - 8 oz jars', 17.00, 4, 100, b'0');\nINSERT INTO `products` VALUES (67, 'Laughing Lumberjack Lager', 16, 1, '24 - 12 oz bottles', 14.00, 52, 0, b'0');\nINSERT INTO `products` VALUES (68, 'Scottish Longbreads', 8, 3, '10 boxes x 8 pieces', 12.50, 6, 10, b'0');\nINSERT INTO `products` VALUES (69, 'Gudbrandsdalsost', 16, 4, '10 kg pkg.', 36.00, 26, 0, b'0');\nINSERT INTO `products` VALUES (70, 'Outback Lager', 7, 1, '24 - 355 ml bottles', 15.00, 15, 10, b'0');\nINSERT INTO `products` VALUES (71, 'Flotemysost', 16, 4, '10 - 500 g pkgs.', 21.50, 26, 0, b'0');\nINSERT INTO `products` VALUES (72, 'Mozzarella di Giovanni', 14, 4, '24 - 200 g pkgs.', 34.80, 14, 0, b'0');\nINSERT INTO `products` VALUES (73, 'Röd Kaviar', 17, 8, '24 - 150 g jars', 15.00, 101, 0, b'0');\nINSERT INTO `products` VALUES (74, 'Longlife Tofu', 4, 7, '5 kg pkg.', 10.00, 4, 20, b'0');\nINSERT INTO `products` VALUES (75, 'Rhönbräu Klosterbier', 12, 1, '24 - 0.5 l bottles', 7.75, 125, 0, b'0');\nINSERT INTO `products` VALUES (76, 'Lakkalikööri', 23, 1, '500 ml', 18.00, 57, 0, b'0');\nINSERT INTO `products` VALUES (77, 'Original Frankfurter grüne Soße', 12, 2, '12 boxes', 13.00, 32, 0, b'0');\nCOMMIT;\n\n-- ----------------------------\n-- Table structure for suppliers\n-- ----------------------------\nDROP TABLE IF EXISTS `suppliers`;\nCREATE TABLE `suppliers` (\n  `supplier_id` int NOT NULL,\n  `company_name` varchar(40) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `address` varchar(60) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `city` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `region` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `postal_code` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  `country` varchar(15) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,\n  PRIMARY KEY (`supplier_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;\n\n-- ----------------------------\n-- Records of suppliers\n-- ----------------------------\nBEGIN;\nINSERT INTO `suppliers` VALUES (1, 'Exotic Liquids', '49 Gilbert St.', 'London', NULL, 'EC1 4SD', 'UK');\nINSERT INTO `suppliers` VALUES (2, 'New Orleans Cajun Delights', 'P.O. Box 78934', 'New Orleans', 'LA', '70117', 'USA');\nINSERT INTO `suppliers` VALUES (3, 'Grandma Kelly\\'s Homestead', '707 Oxford Rd.', 'Ann Arbor', 'MI', '48104', 'USA');\nINSERT INTO `suppliers` VALUES (4, 'Tokyo Traders', '9-8 Sekimai Musashino-shi', 'Tokyo', NULL, '100', 'Japan');\nINSERT INTO `suppliers` VALUES (5, 'Cooperativa de Quesos \\'Las Cabras\\'', 'Calle del Rosal 4', 'Oviedo', 'Asturias', '33007', 'Spain');\nINSERT INTO `suppliers` VALUES (6, 'Mayumi\\'s', '92 Setsuko Chuo-ku', 'Osaka', NULL, '545', 'Japan');\nINSERT INTO `suppliers` VALUES (7, 'Pavlova, Ltd.', '74 Rose St. Moonie Ponds', 'Melbourne', 'Victoria', '3058', 'Australia');\nINSERT INTO `suppliers` VALUES (8, 'Specialty Biscuits, Ltd.', '29 King\\'s Way', 'Manchester', NULL, 'M14 GSD', 'UK');\nINSERT INTO `suppliers` VALUES (9, 'PB Knäckebröd AB', 'Kaloadagatan 13', 'Göteborg', NULL, 'S-345 67', 'Sweden');\nINSERT INTO `suppliers` VALUES (10, 'Refrescos Americanas LTDA', 'Av. das Americanas 12.890', 'Sao Paulo', NULL, '5442', 'Brazil');\nINSERT INTO `suppliers` VALUES (11, 'Heli Süßwaren GmbH & Co. KG', 'Tiergartenstraße 5', 'Berlin', NULL, '10785', 'Germany');\nINSERT INTO `suppliers` VALUES (12, 'Plutzer Lebensmittelgroßmärkte AG', 'Bogenallee 51', 'Frankfurt', NULL, '60439', 'Germany');\nINSERT INTO `suppliers` VALUES (13, 'Nord-Ost-Fisch Handelsgesellschaft mbH', 'Frahmredder 112a', 'Cuxhaven', NULL, '27478', 'Germany');\nINSERT INTO `suppliers` VALUES (14, 'Formaggi Fortini s.r.l.', 'Viale Dante, 75', 'Ravenna', NULL, '48100', 'Italy');\nINSERT INTO `suppliers` VALUES (15, 'Norske Meierier', 'Hatlevegen 5', 'Sandvika', NULL, '1320', 'Norway');\nINSERT INTO `suppliers` VALUES (16, 'Bigfoot Breweries', '3400 - 8th Avenue Suite 210', 'Bend', 'OR', '97101', 'USA');\nINSERT INTO `suppliers` VALUES (17, 'Svensk Sjöföda AB', 'Brovallavägen 231', 'Stockholm', NULL, 'S-123 45', 'Sweden');\nINSERT INTO `suppliers` VALUES (18, 'Aux joyeux ecclésiastiques', '203, Rue des Francs-Bourgeois', 'Paris', NULL, '75004', 'France');\nINSERT INTO `suppliers` VALUES (19, 'New England Seafood Cannery', 'Order Processing Dept. 2100 Paul Revere Blvd.', 'Boston', 'MA', '2134', 'USA');\nINSERT INTO `suppliers` VALUES (20, 'Leka Trading', '471 Serangoon Loop, Suite #402', 'Singapore', NULL, '512', 'Singapore');\nINSERT INTO `suppliers` VALUES (21, 'Lyngbysild', 'Lyngbysild Fiskebakken 10', 'Lyngby', NULL, '2800', 'Denmark');\nINSERT INTO `suppliers` VALUES (22, 'Zaanse Snoepfabriek', 'Verkoop Rijnweg 22', 'Zaandam', NULL, '9999 ZZ', 'Netherlands');\nINSERT INTO `suppliers` VALUES (23, 'Karkki Oy', 'Valtakatu 12', 'Lappeenranta', NULL, '53120', 'Finland');\nINSERT INTO `suppliers` VALUES (24, 'G\\'day, Mate', '170 Prince Edward Parade Hunter\\'s Hill', 'Sydney', 'NSW', '2042', 'Australia');\nINSERT INTO `suppliers` VALUES (25, 'Ma Maison', '2960 Rue St. Laurent', 'Montréal', 'Québec', 'H1J 1C3', 'Canada');\nINSERT INTO `suppliers` VALUES (26, 'Pasta Buttini s.r.l.', 'Via dei Gelsomini, 153', 'Salerno', NULL, '84100', 'Italy');\nINSERT INTO `suppliers` VALUES (27, 'Escargots Nouveaux', '22, rue H. Voiron', 'Montceau', NULL, '71300', 'France');\nINSERT INTO `suppliers` VALUES (28, 'Gai pâturage', 'Bat. B 3, rue des Alpes', 'Annecy', NULL, '74000', 'France');\nINSERT INTO `suppliers` VALUES (29, 'Forêts d\\'érables', '148 rue Chasseur', 'Ste-Hyacinthe', 'Québec', 'J2S 7S8', 'Canada');\nCOMMIT;\n\nSET FOREIGN_KEY_CHECKS = 1;\n\n```\n\n## 十三、总结\n![数据库.png](https://s2.loli.net/2024/03/15/gaYtT2urKIR4yHL.png)\n![SQL基础内容.png](https://s2.loli.net/2024/03/15/ylTcCPkJtwmxoVY.png)","tags":["数据操作","SQL","数据库"],"categories":["大数据"]},{"title":"Typecho创建","url":"/post/typechocreate.html","content":"在写完Halo博客搭建后，决定再记录一下主站typecho博客的搭建过程。typecho是一款轻量化博客程序，系统内存占用少，性能良好，搭建方便，操作简单。在多年前就是口碑良好的博客程序。~~遗憾的是在2017年就已经停止更新了~~（似乎又恢复更新了），并且缺点是所有插件需要自己安装，主题切换不保存设置数据，且不支持在博客页面编辑主题信息，编写文章时没有预览功能等。但是非常节省内存资源，加上宝塔面板占用才200-300M，相比之下Halo就需要800M左右的空间来保证运行，在[Haxio][1]白嫖的Kvm的机器内存非常(~~没~~)好用(~~钱~~)，只是内存只有可怜的450M，用来做typecho再合适不过（随便玩玩，随时寄），毕竟是原生IP，只是用来做节点有点浪费。\n注意，虚拟化方式为Openvz的vps**建议**先开启tun，以hax为例（*hax账号注册需要tg账号，搜索HAX_bot得到id，在登录页面输入id后，bot会发送一串校验码，复制到登录页内重置密码即可，这里不过多赘述*），登录后点击**Poweroff & Restart VPS**\n![tun.png][2]\n点击Enable TUN，然后在终端输入 cat /dev/net/tun，显示in bad state或者Finalshell显示文件处于错误的描述阶段就表示开启成功（halo博客文中已提及）\n# 安装宝塔面板\n请保证是纯净的系统，未安装任何环境\n```\nyum install -y wget && wget -O install.sh http://download.bt.cn/install/install_6.0.sh && sh install.sh\n```\ntypecho博客之所以简单在于基本只需要这一行代码即可完成博客部署\n具体步骤[Halo文中已经写过][3]\n安装LNMP套件，PHP版本请选择7.2（typecho最高支持7.2）![LNMP套件.png][4]\n# 一键部署\n在软件商店-宝塔插件内安装宝塔一键部署源码\n![一键部署源码.png][5]\n点击设置，选择博客，点击typecho一键部署\n![一键部署源码设置.png][6]\n输入域名之后很快，会弹出MySQL的账号和密码,复制好保存备用（halo博客使用的是H2 Database，所以LNMP套件可以不安装MySQL及其相关）\n![域名部署.png][7]\n点击网站，在创建好的域名后点击设置，设置伪静态，选择typecho模板并保存\n![伪静态.png][8]\n# 主题和插件上传\n保存完点击网站目录-usr-themes，上传自己喜欢的主题，网站目录-usr-plugins上传插件。这里提供两个typecho主题和插件的下载网站[1站][10]和[2站][11]，建议上传压缩包上传后解压，不然上传速度很慢\n![主题上传.png][9]\n使用域名访问博客并进行初始化，输入之前保存的数据库信息，设置后台访问的账号密码，安装成功\n![typecho初始化.png][12]\n![安装成功.png][13]\n进入主页即可撰写文章，更换主题，安装插件\n![博客主页.png][14]\n这里提供一个有众多[live2d看板娘][15]模型的网站，推荐的其他插件有代码高亮，动态线条聚合等，需要数学公式的请在footer.php中手动添加mathjax（或Katex），具体方式自行搜索\n```\n<script type=\"text/x-mathjax-config\">\n    MathJax.Hub.Config({\n      extensions: [\"tex2jax.js\"],\n      jax: [\"input/TeX\", \"output/HTML-CSS\"],\n      tex2jax: {\n        inlineMath:  [ [\"$\", \"$\"],  [\"\\(\",\"\\)\"] ],\n        displayMath: [ [\"$$\",\"$$\"], [\"\\[\",\"\\]\"] ],\n        processEscapes: true\n      },\n      \"HTML-CSS\": { availableFonts: [\"TeX\"] }\n    });\n  </script>\n  <script type=\"text/javascript\"\n     src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n  </script>\n```\n# 开启ssl\n详情请见[Halo][17]\nlets encrypt申请失败的话可以自行去阿里云/腾讯云申请后粘贴到其他证书内\n# 关于开启代理后的问题\n开启cf代理的目的是使只有IPv6地址的服务器能够被纯IPv4访问\n[cf代理开启方式][16]\ntypecho在开启代理后请不要在宝塔面板打开强制https，第二点是打开代理后博客后台可能会出现无法登录的情况，点登录后仍然返回登录界面，因为本地没有开启强制https导致cf cdn重定向错误无法登录typecho后台\n这时候需要在网站目录的config.inc.php的代码注释过后（大约第9-10行）加入\n```\ndefine('__TYPECHO_SECURE__',true);\n```\n\n</br>\n更多功能还请读者自行探索，文章若有错误还望大佬评论区告知谢谢\n\n[1]:https://hax.co.id/create-vps/\n[2]: https://s2.loli.net/2024/03/15/Y5mX6WuEOMt8cF4.png\n[3]:https://blog.icjlu.eu.org/post/halocreate.html\n[4]:https://s2.loli.net/2024/03/15/cUGb2MkhZoiVSQO.png\n[5]:https://s2.loli.net/2024/03/15/ok3buY2rLvtScU5.png\n[6]:https://s2.loli.net/2024/03/15/UKMGBaCTe6osJqb.png\n[7]:https://s2.loli.net/2024/03/15/TumMf3S7k1qYNIh.png\n[8]:https://s2.loli.net/2024/03/15/XPSMFwkOfZzxjHT.png\n[9]:https://s2.loli.net/2024/03/15/hfqKUeFMlJQi84s.png\n[10]:https://typecho.me/page-2.html\n[11]:https://store.ijkxs.com/ztmb/typecho/typecho_themes/page/4?price_type=1\n[12]:https://s2.loli.net/2024/03/15/j39DozG1sYJX7fO.png\n[13]:https://s2.loli.net/2024/03/15/qslgN8OuyZh7Sow.png\n[14]:https://s2.loli.net/2024/03/15/8w1dAiehEN4ORzU.png\n[15]:https://mx.paul.ren\n[16]:https://blog.icjlu.eu.org/post/halocreate.html\n[17]:https://blog.icjlu.eu.org/post/halocreate.html","tags":["blog","nginx","vps"],"categories":["旧日"]},{"title":"Halo创建","url":"/post/halocreate.html","content":"\n本文将对VPS使用Docker容器搭建Halo博客的一般方式作简述（小白的逐步操作），大致分为\n\n1. 安装Docker引擎\n2.  创建容器\n3.  拉取Halo镜像\n4.  安装nginx并配置反向代理\n5.  开启SSL\n6.  创建，美化博客页面\n\n \n\n搭建Halo博客需要VPS服务器一台（最低配置要求1C1G，docker本身占用就接近400M的Ram，至于核心一般来说1核就够了），域名1个，~~搭建完就吃灰的决心~~。\n\n~~如果购买的是虚拟化方式为Openvz的服务器请先前往运营商处开启tun，然后在终端输入 cat /dev/net/tun，显示in bad state或者Finalshell显示文件处于错误的描述阶段就表示开启成功了，不过应该没人买Ovz的机器，除了像我这样从Hax白嫖的~~\n\n首先使用Finalshell/Xshell或者命令行（ssh root@）连接上购买服务器的IP地址\n\n# 依赖安装与配置\n\n## 安装Docker引擎\n\n参考：[Docker官方文档][2]\n\n![docker官方文档][1]\n\n*常见系统的安装都有，本文只介绍最简单的安装过程，可选步骤请移步官方文档*\n\n1.安装utils包\n\n```\nyum install -y yum-utils\n```\n\n2.设置仓库\n\n```\nyum-config-manager \\\n\n    --add-repo \\\n\n    https://download.docker.com/linux/centos/docker-ce.repo\n```\n\n3.安装docker引擎\n\n```\nyum install docker-ce docker-ce-cli containerd.io\n```\n\n4.启动docker\n\nsystemctl start docker\n\nsystemctl enable docker.service//设置docker开机自启动\n\ndocker自启动的设置可选择不执行，博主的服务器在执行自启动后nginx会出现异常导致网站无法正常访问，如果执行后无法使用域名访问博客可以关闭自启动（enable改为disable)reboot可解决\n\n*5.拉取测试镜像(可选)\n\n```\ndocker run hello-world//拉取hello-world测试docker是否正常运行，一般都是正常，可以不用操作\n```\n\n安装过程出现的询问操作输入y即可，第三步安装引擎时有个指纹校对可以对比一下，一般都是吻合的\n\n```\n060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35\n```\n\n## 使用 Docker 部署 Halo\n\n参考：[官方文档][3]\n\n安装完毕就可以使用docker部署halo了，按照官方文档操作\n\n1.创建工作目录\n\n```\nmkdir ~/.halo && cd ~/.halo\n```\n\n2.下载示例配置文件到工作目录\n\n```\nwget https://dl.halo.run/config/application-template.yaml -O ./application.yaml\n```\n\n*3.编辑配置文件，配置数据库或者端口等，如需配置请参考官方文档(可选)\n\n```\nvim application.yaml\n```\n\n4.拉取最新的 Halo 镜像\n\n```\ndocker pull halohub/halo:1.4.17//截至本文发布halo的最新版本为1.4.17，访客可自行前往官网查询最新版本或者将版本号改为latest\n```\n\n\n\n```\n纯IPv6机器请先修改DNS否则无法解析\n\necho \"nameserver 2a00:1098:2b::1\" > /etc/resolv.conf\n```\n\n\n\n5.创建容器\n\n```\ndocker run -it -d --name halo -p 8090:8090 -v ~/.halo:/root/.halo --restart=unless-stopped halohub/halo:1.4.17//注意版本号\n```\n\n*对创建容器的部分代码作解释*\n\n第一个8090表示本地的端口映射到第二个halo上的8090端口，第一个可以更改为任意没有被占用的端口，第二个不可更改。更改端口可以在一台服务器上安装多个halo博客，阿里云/腾讯云等开启了安全组的云服务器商请先在服务商控制面板处开启端口放行80，443等常用端口以及halo映射的端口\n\n```\n-it： 开启输入功能并连接伪终端\n\n-d： 后台运行容器\n\n-name： 为容器指定一个名称\n\n-p： 端口映射，格式为 主机(宿主)端口:容器端口 ，可在 application.yaml 配置。\n\n-v： 工作目录映射。形式为：-v 宿主机路径:/root/.halo，后者不能修改。\n\n-restart： 建议设置为 unless-stopped，在 Docker 启动的时候自动启动 Halo 容器。其它设置：\n\n no\t       不自动重启容器. (默认value)\n\n on-failure    容器发生error而退出(容器退出状态不为0)重启容器\n\n unless-stopped \t在容器已经stop掉或Docker stoped/restarted的时候才重启容器\n\n always     在容器已经stop掉或Docker stoped/restarted的时候才重启容器\n\n完成后等待片刻（finalshell中cpu占有降低时），halo博客就部署完成了，此时就可以使用http://ip:端口号 的形式即可看到安装引导界面，不过建议配置好反向代理后再初始化博客。\n```\n\n \n\n# 安装nginx并配置反向代理\n\n## 源码安装\n\n方法1使用的是源码安装nginx，目录/etc/nginx如果有需要LNMP套件的可以使用以下代码安装\n\n```\nwget http://soft.vpser.net/lnmp/lnmp1.8.tar.gz -cO lnmp1.8.tar.gz && tar zxf lnmp1.8.tar.gz && cd lnmp1.8 && ./install.sh lnmp\n```\n\n```\n安装目录\n\nNginx 目录: /usr/local/nginx/\n\nMySQL 目录 : /usr/local/mysql/\n\nMySQL数据库所在目录：/usr/local/mysql/var/\n\nPHP目录 : /usr/local/php/\n\n默认网站目录 : /home/wwwroot/default/\n\nNginx日志目录：/home/wwwlogs/\n\nLNMP软件配置文件路径\n\nNginx主配置(默认虚拟主机)文件：/usr/local/nginx/conf/nginx.conf\n\n添加的虚拟主机配置文件：/usr/local/nginx/conf/vhost/域名.conf\n\nMySQL配置文件：/etc/my.cnf\n\nPHP配置文件：/usr/local/php/etc/php.ini\n\nphp-fpm配置文件：/usr/local/php/etc/php-fpm.conf\n\n\\#重启服务让配置生效\n\nlnmp {nginx|mysql|mariadb|php-fpm|pureftpd} restart\n\n\\#或者直接重启LNMP：\n\nlnmp restart\n```\n\n1.添加 Nginx 源\n\n```\nrpm -Uvh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm\n```\n\n2.安装 Nginx（CentOS）\n\n```\nyum install -y nginx\n```\n\n3.启动 Nginx\n\n```\nsystemctl start nginx.service\n```\n\n4.设置开机自启 Nginx\n\n```\nsystemctl enable nginx.service\n```\n\nUbuntu系统nginx安装方式\n\n```\nsudo update\n\nsudo apt install nginx\n```\n\n5.下载 Halo 官方的 Nginx 配置模板到本地\n\n```\ncurl -o /etc/nginx/conf.d/halo.conf --create-dirs https://dl.halo.run/config/nginx.conf\n```\n\nnginx若出现启动失败，通常是80端口被占用，查看与80相关的端口\n\n```\nnetstat -lnp|grep 80\n\n\\# 命令无法使用请先输入下面代码安装\n\nyum -y install net-tools\n```\n\n在找到80端口的占用后杀死对应的进程号，如果仍然启动失败可尝试多杀几次\n\n```\nkill -9 进程号\n\nsystemctl restart nginx//重启nginx\n```\n\n\n\n如果使用yum拉取镜像安装nginx，nginx一般安装在/usr/local/nginx/conf/nginx.conf文件夹中，宝塔面板则是在/www/server/panel/vhost/nginx/conf/nginx.conf使用下面的代码无法直接配置nginx，而是会创建一个新的目录存放halo.conf，需要建立软连接（请自行搜索方法）或在nginx安装目录中找到nginx.conf，在http{}中添加\n\n```\ninclude /etc/nginx/conf.d/halo.conf\n```\n\n或者其他自定义的路径，保证正确即可\n\n6.使用vi/vim编辑halo.conf应用nginx配置，或者使用finalshell等其他工具对文件进行编辑\n\n```\nvim /etc/nginx/conf.d/halo.conf//如果vim提示命令不存在可使用vi,配置完毕后按下esc键输入 :wq 退出并保存\n```\n\n模板文件打开后格式为\n\n```\nupstream halo {\n\n  server 127.0.0.1:8090;//更改为你的服务器ip以及设置的端口\n\n}\n\nserver {\n\n  listen 80;\n\n  listen [::]:80;\n\n  server_name xxx.xx;//你的域名\n\n  client_max_body_size 1024m;\n\n  location / {\n\n    proxy_pass http://halo;\n\n    proxy_set_header HOST $host;\n\n    proxy_set_header X-Forwarded-Proto $scheme;\n\n    proxy_set_header X-Real-IP $remote_addr;\n\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n  }\n\n}\n```\n\n \n\n配置完后使用nginx检查是否含有错误\n\n```\nnginx -t\n```\n\n出现successfully时，表示配置文件无误，重新载入nginx即可使用域名访问博客\n\n```\nnginx -s reload\n```\n\n至此，源码安装的方式部署完成。\n\n## 使用宝塔面板安装nginx\n\n方法2是使用宝塔帮助安装web服务器，优点是可视化，操作简单，首先安装宝塔面板\n\n```\nyum install -y wget && wget -O install.sh http://download.bt.cn/install/install_6.0.sh && sh install.sh\n```\n\n期间出现的询问都输入y\n\n安装完毕后会提示默认端口8888和用户名密码，没有弹出的话输入bt default\n\n```\n外网面板地址: http://*****:****/*****\n\n内网面板地址: http://***.**.**.**:****/*****\n\n*以下仅为初始默认账户密码，若无法登录请执行bt命令重置账户/密码登录\n\nusername: ******\n\npassword: ****\n```\n\n \n\n此时访问外网面板登录会提示绑定宝塔账号，博主个人不太接受这种强制绑定的方式（不介意的跳过下面这步），~~所以在网上搜集了解除的方法。目前宝塔面板最新版为7.8，暂时还没有破解方式，现在的思路是降级到7.7。~~\n\n**最新消息，使用破解版宝塔面板7.8的服务器都将被查封，并且拉黑IP，即该服务器将永远无法安装宝塔面板，读者请量力而行，7.7暂时安全**\n\n```\ncurl -sSO https://raw.githubusercontent.com/zhucaidan/btpanel-v7.7.0/main/install/install_panel.sh && bash install_panel.sh\n\nsed -i \"s|bind_user == 'True'|bind_user == 'XXXX'|\"/www/server/panel/BTPanel/static/js/index.js\n\nrm -f /www/server/panel/data/bind.pl\n```\n\n此时访问已不再提示登录，并在首页弹出Linux套件安装，选择LNMP推荐的（nginx-php-mysql-apache）一键安装即可，经过漫长的等待（约20-30min）依赖环境都安装完毕。\n\n\n\n点击网站添加站点，填上主域名（不可泛解析），次域名（选填），网站备注\n\n![bt][4]\n\n然后点击设置，选择反向代理，根据面板的提示键入信息即可完成反向代理\n\n![创建反向代理][5]\n\n或者选择配置文件，按照方法1中配置的方式，在配置文件49-61使用ctrl+/注释掉，然后在62行{}添加相应的信息（使用面板的反向代理只能反代一个halo博客，添加新的反向代理会覆盖之前的配置--貌似）\n\n使用宝塔辅助nginx反代配置完成\n\n```\n location / {\n\n  proxy_pass http://127.0.0.1:8090/;\n\n  rewrite ^/(.*)$ /$1 break;\n\n  proxy_redirect off;\n\n  proxy_set_header Host $host;\n\n  proxy_set_header X-Forwarded-Proto $scheme;\n\n  proxy_set_header X-Real-IP $remote_addr;\n\n  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n  proxy_set_header Upgrade-Insecure-Requests 1;\n\n  proxy_set_header X-Forwarded-Proto https;\n\n}\n```\n\n# 开启SSL，启用https访问\n\n配置完反向代理后，已经可以使用域名访问博客，但浏览器显示的是网站不安全，因为没有受信任的证书，此时是http明文与主机传输数据，需要申请ssl证书上传并验证通过才能启用https。\n\nssl证书可以在阿里云、腾讯云，Cloudflare，acme.sh、certbot申请，\n\n其中阿里云和腾讯云免费申请的是1年有效的亚洲诚信颁发的证书，Cloudflare免费申请的是一年有效的边缘证书或最高15年有效的cf自签名证书，acme.sh和certbot免费申请的是3个月Let's Encrypt证书（可自动续期，但可能失败），有需要也可以在这些平台购买付费证书，安全性更高，并且有专人帮你安装（价格不菲）\n\n\n\n如果上一步使用的是宝塔面板辅助安装的，可以直接在网站页面点击ssl部署，选中域名一键申请，宝塔就会自动申请证书并帮你完成部署，再点击右上角的强制https就实现了https访问，此时网站已变成受信任状态（如果在DNS服务商处已经开启了强制https请不要点击，会导致重定向次数过多无法正常访问），或者已经拥有其他平台的证书，点击其他证书，把公钥和私钥内容粘贴进去即可\n\n![lets-encrypt][6]\n\n阿里云和腾讯云请在控制台搜索ssl申请证书，关于其他平台证书的申请方式请自行搜索，本文只介绍证书的导入和安装，其中cf的自签名证书只会显示一次，没有保存就找不到了，证书的格式为.pem，腾讯云的为.crt（貌似也有pem），密钥格式为.key\n\n证书下载到本地后，使用FTP上传到服务器（不知道怎么使用的自行搜索）或者使用Finalshell进行上传，上传完成后打开之前配置的halo.conf，启用ssl，打开443端口监听\n\n```\nupstream halo {\n\n  server 127.0.0.1:8090;\n\n}\n\nserver {\n\n  listen 80;\n\n  listen [::]:80;\n\n  listen 443 ssl;\n\n  server_name ****.**;//多个域名请加 , 后继续输入\n\n  client_max_body_size 1024m;\n\nssl_certificate /crt/certificate.pem;//证书上传的存放路径\n\nssl_certificate_key /crt/privatekey.key;//密钥上传的存放路径\n\nssl_session_timeout 5m;\n\nssl_protocols TLSv1 TLSv1.1 TLSv1.2;//启用的tls版本，建议不要开启tls v1，存在漏洞，最新版本为v1.3\n\nssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;//加密方式\n\nssl_prefer_server_ciphers on;//开启加密\n\n  location / {\n\n     proxy_pass http://halo;\n\n     proxy_set_header HOST $host;\n\n     proxy_set_header X-Forwarded-Proto $scheme;\n\n     proxy_set_header X-Real-IP $remote_addr;\n\n     proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n  }\n\n}\n```\n\n检查规则，重新加载nginx\n\n```\nnginx -t\n\nnginx -s reload\n```\n\n检查ssl是否正常开启，出现ssl xxx的就代表开启成功\n\n```\necho|openssl s_client -connect 127.0.0.1:443 -servername sslconfigure.certqa.cn 2>/dev/null\n```\n\n如果没有请检查防火墙是否拦截，宝塔面板用户请进入安全页面放行443端口\n\n```\nfirewall-cmd --state//检查防火墙开启状态\n\nfirewall-cmd –zone=public –add-port=443/tcp –permanent//放行443端口\n```\n\n完成以上步骤，就可以使用https访问博客了\n\n### *IPV6 Only的服务器如何能让IPV4 Only的网络访问\n\n一些廉价服务器只提供IPV6的公网地址（IPV4公网地址太少了得加钱），导致只有IPV4网络的用户无法访问。而IPV 4 to 6的隧道部署又相对较为繁琐，这里博主采用cf的CDN代理来解决\n\n![cf代理][7]\n\n打开[cloudflare][8]，添加站点,将cf提供的两个地址填入域名注册商的名称服务器，等待生效后打开添加的站点，点击DNS输入IP地址以及解析形式，小云朵代理状态选择开启\n\n![cf ssl证书设置][9]\n\n打开始终使用https（宝塔面板的记得关闭），最低tls版本选择1.1，打开随机加密，此时只有IPV4的网络经过cf代理也能成功访问博客（貌似不上传证书和配置ssl，只打开代理也能实现https访问，感兴趣的读者可自行尝试），但服务器仍然无法访问仅IPV4的资源，需要IPV 6 to 4隧道/NAT地址转换或者安装warp以实现，这里不再赘述。\n\n \n\n# 博客美化\n\n使用 域名/admin 访问博客，完成初始化操作并登录后台\n\n![halo登录][10]\n\n![halo面板][11]\n\n打开面板后可以看到各种博客数据，非常简洁，而且面板样式也很简约但又没有过分固化，个人是挺喜欢的，非常适合只想安心写博客的朋友，不过默认的网站外观不太好看，可以前往Halo官方的[主题仓库][12]选择自己喜欢的外观，点击面板的外观页面，点击安装选择安装包安装或远程安装（推荐安装包安装），~~本人使用的是大佬移植Wordpress的Sakura主题，如有使用该主题的，~~博客外观设置可以参考[LIlGG的操作指南][13]\n\n![halo外观][14]\n\n外观设置完毕后可以在页面栏选择新建页面用于在博客内分栏展示，在外观的菜单栏中可以添加独立页面的小图标，Sakura主题支持Font Awesome图标，各图标样式可以[点击查看][17]和[Font Awesome v6][19]，另外可以对图标增加的动态效果代码可以[查看][18]。具体使用方法实示例\n\n```\nfa fa-bank faa-tada//银行图标，放大旋转特效\n```\n\n ![font awesome动态特效][15]\n\n然后点击用户栏，设置个人资料包括用户名，昵称，邮箱，以及更改密码都在这个页面\n\n最后点击系统栏-博客设置添加网站的logo和favicon（浏览器标签页图标）还有页脚信息，可用于添加统计代码（访客数量，网站运行时间等，但貌似只能添加一个）如有需要添加api服务的可以点击高级选项进行设置\n\n[自建的一言api][20]\n\n![博客设置][16]\n\n仍然有改造主题需要的可以点击外观栏的主题编辑进行修改][16]\n\n 一般对footer和header进行更改即可，具体方式和更多有趣的内容还请自行探索\n\n\n\n以上就是halo博客从创建到美化的全过程了，本人小白，折腾这个博客也是花了不少时间，故理清流程后将其记录，如本文有错漏之处，还请大佬可以在评论区留言谢谢!\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n[1]: https://s2.loli.net/2024/03/15/3imgwh74HxETj6S.png\n[2]: https://docs.docker.com/engine/install/centos/\n[3]: https://docs.halo.run/getting-started/install/docker/\n[4]: https://s2.loli.net/2024/03/15/LcqzPkjlWD8Zar9.png\n[5]: https://s2.loli.net/2024/03/15/3kX45sWq7IEU82N.png\n[6]: https://s2.loli.net/2024/03/15/kizmlBZqnUHN6Qw.png\n[7]: https://s2.loli.net/2024/03/15/pgVao6rilPOYvsQ.png\n[8]: https://dash.cloudflare.com/\n[9]: https://s2.loli.net/2024/03/15/QMOJte7yj5NCUgh.png\n[10]: https://s2.loli.net/2024/03/15/dXnB4ATQacojS9P.png\n[11]: https://s2.loli.net/2024/03/15/wmrUS2CTIuYJb1H.png\n[12]: https://halo.run/themes.html\n[13]: https://lixingyong.com/2021/01/05/halo%E4%B8%BB%E9%A2%98sakura%E9%A3%9F%E7%94%A8%E8%AF%B4%E6%98%8E\n[14]: https://s2.loli.net/2024/03/15/3iA95eEzjRyISfW.png\n[15]: https://s2.loli.net/2024/03/15/bIpgQX286mKCeV3.png\n[16]: https://s2.loli.net/2024/03/15/ZqfTQiO8H29pwjA.png\n[17]: https://www.runoob.com/font-awesome/fontawesome-reference.html\n[18]: https://www.51qianduan.com/article/view/4111.html\n\n[19]: https://fontawesome.com/icons\n[20]: https://weus.cjlus.eu.org/hitokoto-api/?format=js&amp;amp;charset=utf-8\n\n","tags":["blog","nginx","vps"],"categories":["旧日"]},{"title":"数字跑表","url":"/post/4a12443.html","content":"\n# 一、课程设计的地位与任务\n《系统设计与仿真课程设计》是电子信息、通信工程专业安排的必修的一门电子电路综合技能训练课程。通过本课程的学习，使同学们掌握常用电子元器件的应用，熟练掌握模拟集成电路、数字集成电路、单片机集成电路的设计方法与应用；理解中规模、大规模集成电路的可靠性设计的概念和方法，学会电子产品的系统设计方法，为学习智能仪器等后续课程和专业技术工作打下良好的基础。\n# 二、课程设计的基本内容和要求\n## 第一部分： EDA技术仿真\n用Verilog HDL语言设计如下数字电路，并仿真验证：\n### 1. 多人表决器\n设计1个多人表决器，同意为1，不同意为0，同意者过半则表决通过，指示灯亮，否则指示灯灭。表决人数和描述方式自行选择。\n```properties\nmodule vote7(\ninput [7:1] vote,\noutput reg pass);\nreg [2:0] sum;\ninteger i;\nalways@(vote)\nbegin sum=0;\nfor(i=1;i<=7;i=i+1)\nif(vote[i]) sum=sum+1;\nif(sum[2]) pass=1;\nelse pass=0;\nend\nendmodule\n```\n7人表决器，大于4人通过(0100)\n激励文件\n```scala\nmodule tb_vote7();\nreg [7:1] vote;\nwire pass;\nvote7 i1(\n.pass(pass),\n.vote(vote));\ninitial begin\nvote=7'b1110001;\n#50 vote=7'b1100000;\n#50 vote=7'b1101101;  \n#50 $finish;\nend\nendmodule\n```\n\n\n### 2. 流水灯控制器\n流水灯控制器包含三个输入端口：时钟端，使能端和清零端。\n采用有限状态机实现流水灯控制器，控制LED灯实现多种花型.\n1. 从左到右依次逐个点亮，全灭；\n2. 从两边往中间逐个亮，全灭；\n3. 循环执行上诉过程。\n4. 学生选定题目后，查找相关资料，熟悉课程题目的方向和设计要求与具体基本指标，确定可行的方案。首先进行在仿真软件，得出正确合理的仿真结果；然后进行下载和调试，最后运行其实现的功能。在基本的功能上，学生可以自我扩展电路功能，创新设计效果，完善电路实现功能。\n```properties\nmodule flow(clk,clr,led,rst);\ninput clk,clr,rst;\noutput reg [7:0] led;\ninteger i;\nalways@(posedge clk)\nbegin \nif(!rst) begin led<=8'h00;end\nif(!clr) begin led<=8'h80;i<=4'b0000;end\nelse\nbegin case(i)\n4'b0000:begin led<=8'h80;i=4'b0001;end\n4'b0001:begin led<=8'h40;i=4'b0010;end\n4'b0010:begin led<=8'h20;i=4'b0011;end\n4'b0011:begin led<=8'h10;i=4'b0100;end\n4'b0100:begin led<=8'h08;i=4'b0101;end\n4'b0101:begin led<=8'h04;i=4'b0110;end\n4'b0110:begin led<=8'h02;i=4'b0111;end\n4'b0111:begin led<=8'h01;i=4'b1000;end\n4'b1000:begin led<=8'h00;i=4'b1001;end\n4'b1001:begin led<=8'h81;i=4'b1010;end\n4'b1010:begin led<=8'h42;i=4'b1011;end\n4'b1011:begin led<=8'h24;i=4'b1100;end\n4'b1100:begin led<=8'h18;i=4'b1101;end\n4'b1101:begin led<=8'h00;i=4'b0000;end\nendcase\nend\nend\nendmodule\n```\n这里使用16进制表示灯的花型，使用顺序编码编号状态，状态编码也可采用格雷码等实现，花型可采用一位热码编码、约翰逊编码，8421BCD等实现\n激励文件\n```scala\nmodule tb_flow();\nparameter DELY=20;\nreg clk;\nreg clr;\nreg rst;\nwire[7:0] led;\nflow i1(\n    .clk(clk),\n    .clr(clr),\n    .rst(rst),\n    .led(led));\ninitial begin\nclk=1'b0;\nclr=1'b0;\nrst=1'b1;\n#(DELY*2) clr=1'b1;\nend\nalways begin\n#(DELY/2) clk=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\x7eclk;\nend\nendmodule\n```\n## 第二部分：综合设计\n综合设计分二部分的内容：CPLD/FPGA仿真设计。综合题目有5个，学生可以自行选择其中一个题目进行，也可以自己拟订题目，但必须征得指导老师的同意方能进行。学生选定题目后，查找相关资料，熟悉课程题目的方向和设计要求与具体基本指标，确定可行的方案。在基本的功能上，学生可以自我扩展电路功能，创新设计效果，完善电路实现功能。\n### 1、 基于Verilog HDL数字频率计的设计\n**技术要求：**\n1) 频率测量范围：     10hz—1Mhz\n2) 测量分辨率：       1hz\n3) 测量误差：         ±1\n4) 测量显示：         6位数码管显示\n   **设计任务：**\n1) 说明设计具体思路。\n2) 画出系统模块框图。\n3) 画出系统顶层原理图。\n4) 按设计技术要求编写程序。\n5) 画出系统功能仿真波形图。\n6) 设计出硬件实现电路图，下载测试。\n完成课程设计报告一份。\n### 2、 基于Verilog HDL数字交通灯的设计\n**技术要求：**\n交通灯的基本工作状态：\n1) (主干道)绿灯：车辆前行；\n2)  (次干道）红灯：禁止通行；\n3)  (主干道)黄灯：过渡状态；\n4)  (主干道)红灯：禁止车辆通行；\n5) (次干道)绿灯：车辆前行。\n● 注：红黄绿等均为前行方向的信号指示灯。\n    **设计任务：**\n1) 说明设计具体思路。\n2) 画出系统模块框图。\n3) 画出系统顶层原理图。\n4) 按设计技术要求编写程序。\n5) 画出系统功能仿真波形图。\n6) 设计出硬件实现电路图，下载测试。\n完成课程设计报告一份。\n### 3、 基于Verilog HDL数字钟的设计\n**技术要求：**\n1) 该时钟具有校准时间、闹铃、整点报时等功能。\n2) 秒表至少有3个输入端，分别为时钟输入、校准信号、复位按键，也可以考虑一些扩展功能。\n3) 秒、分钟信号、小时采用BCD码计数方式。\n    **设计任务：**\n1) 说明设计具体思路。\n2) 画出系统模块框图。\n3) 画出系统顶层原理图。\n4) 按设计技术要求编写程序。\n5) 画出系统功能仿真波形图。\n6) 设计出硬件实现电路图，下载测试。\n完成课程设计报告一份。\n### 4、 基于Verilog HDL数字跑表的设计\n设计任务：设计一个以0.01s为基准计时信号的实用数字式跑表\n**技术要求：**\n1) 跑表计时显示范围0.01s-59min59.99s，计时精度为10ms。\n2) 具有清零、启动计时、暂停计时功能。\n3) 时钟源误差不超过0.01s。\n    **设计任务：**\n1) 说明设计具体思路。\n2) 画出系统模块框图。\n3) 画出系统顶层原理图。\n4) 按设计技术要求编写程序。\n5) 画出系统功能仿真波形图。\n6) 设计出硬件实现电路图，下载测试。\n完成课程设计报告一份。\n### 5、 基于Verilog HDL 汽车尾灯控制器的设计\n设计任务：汽车尾灯控制器\n**技术要求：**\n1) 正常行驶时，指示灯不亮；\n2) 刹车时，指示灯亮；\n3) 左转时，左侧的一盏灯闪烁，亮1s，灭1s；\n4) 右转时，右侧的一盏灯闪烁，亮1s，灭1s；\n5) 发生故障和事故时，双侧的灯都闪烁，亮0.5s，灭0.5s；\n**设计任务：**\n1) 说明设计具体思路。\n2) 画出系统模块框图。\n3) 画出系统顶层原理图。\n4) 按设计技术要求编写程序。\n5) 画出系统功能仿真波形图。\n6) 设计出硬件实现电路图，下载测试。\n完成课程设计报告一份。\n</br>\n这里我选择的是数字跑表设计\n在完成基本功能后添加了从当前时间开始倒计时，60秒倒计时，每计时1分钟短暂蜂鸣，倒计时结束持续蜂鸣功能\n\n```properties\n\n`timescale 1ns / 1ps\n//////////////////////////////////////////////////////////////////////////////////\n\nmodule chronograph(\ninput   clk,pause,reset,reversal,cnt,\n    output  reg[3:0] bai1,bai2,miao1,miao2,fen1,fen2,buzzer=0);//buzzer蜂鸣不用4位寄存器，懒得另外写了  \nalways @(posedge clk, posedge reset)//百分秒计时\nif(!reversal)\n    begin\n        if(reset)begin bai1<=0;bai2<=0; end  //复位信号               //else if(pause);//begin bai1<=bai1;a<=bai1;end\n        else if(!pause)\n            begin   if(bai2==9&&bai1==9) begin bai2<=0;bai1<=0;miao1<=miao1+1; end   //百分秒计满后秒进位\n                    else begin\n                        if(bai1==9) begin bai1<=0;bai2<=bai2+1;end  //百分秒第一位进位\n                        else begin bai1<=bai1+1;end                     \n                        end\n            end\n    end\nelse if(reversal)  //倒计时\nbegin\n        if(reset)begin bai1<=0;bai2<=0; end//复位\n        else if(!pause&&cnt==0)//从当前时间倒计时\n            begin   if(bai2==0&&bai1==0&&miao1>0) begin bai2<=9;bai1<=9;miao1<=miao1-1; end\n                     else if(bai2==0&&bai1==0&&miao1==0&&miao2>0)begin miao1<=9;bai1<=9;bai2<=9;miao2<=miao2-1;end//代码有瑕疵，其实还有别的情况，但是懒得改了，功能基本完成\n                    else begin//同正常计时的逆向\n                        if(bai1==0&&bai2>0) begin bai1<=9;bai2<=bai2-1;end\n                        else if(bai2==0&&bai1==0&&miao1==0);\n                        else begin bai1<=bai1-1;end                     \n                        end\n            end   \n            else if(!pause&&cnt)\n            begin fen2<=0;fen1<=0;miao2<=6;miao1<=0;bai2<=0;bai1<=0;end\nend\nelse if(reset)begin bai1<=0;bai2<=0; end\nalways @(bai1,bai2,pause,reset)//秒计时，基本和百分秒相同\nif(!reversal)                           \n    begin\n        if(reset)begin miao1<=0;miao2<=0;end                        //else if(pause);//begin miao1<=miao1;end\n        else if(!pause)\n            begin   if(miao2==5&&miao1>9) begin miao2<=0;miao1<=0;fen1<=fen1+1;  end\n                    else begin\n                        if(miao1>9) begin miao1<=0;miao2<=miao2+1;end\n                        end\n                        if(miao1==9&&miao2==5&&bai1==9&&bai2==9) buzzer<=1;//在每次计时到59秒99时短暂蜂鸣\n                        else buzzer<=0;\n            end           \n    end\nelse if(reversal)                           \n    begin\n        if(reset)begin miao1<=0;miao2<=0;end\n        else if(!pause&&cnt==0)\n            begin   if(miao2==0&&miao1==0&&(fen1>0||fen2>0)) begin miao2<=5;miao1<=9; bai2<=9;bai1<=9;fen1<=fen1-1;  end\n                    else begin\n                        if(miao1==0&&miao2>0) begin miao1<=9;miao2<=miao2-1;end\n                        if(miao1==0&&miao2==0&&bai1==0&&bai2==0) buzzer<=1;//倒计时结束后持续蜂鸣，可能还要加上分也等于0？\n                        else buzzer<=0;\n                        end\n            end\n            else if(!pause&&cnt)\n            begin fen2<=0;fen1<=0;miao2<=6;miao1<=0;bai2<=0;bai1<=0;end//cnt信号表示进行60秒倒计时\n    end \nelse if(reset)begin miao1<=0;miao2<=0;end\nalways @(miao1,miao2,pause,reset)//分计时\nif(!reversal)     \n    begin\n        if(reset)\n            begin fen1<=0;fen2<=0;end                                    //else if(pause);//begin fen1<=fen1;end\n        else if(!pause)\n            begin   if(fen2==5&&fen1>9)begin fen2<=0;fen1<=0;end\n                    else begin\n                        if(fen1>9)begin  fen1<=0; fen2<=fen2+1;end\n                        end\n            end\n    end\nelse if(reversal)   \n    begin\n        if(reset)begin fen1<=0;fen2<=0;end\n        else if(!pause&&cnt==0)\n            begin if(fen1==0&&fen2>0)begin  fen1<=9;miao2<=5;miao1<=9; bai2<=9;bai1<=9;fen2<=fen2-1;end                       \n            end\n    end\n    else if(!pause&&cnt)\n            begin fen2<=0;fen1<=0;miao2<=6;miao1<=0;bai2<=0;bai1<=0;end\nelse if(reset) begin fen1<=0;fen2<=0;end\nendmodule\n```\n激励文件\n```scala\n\n`timescale 1ns / 1ps\n//////////////////////////////////////////////////////////////////////////////////\n\nmodule tb_chronograph();\nreg clk,pause,reset,reversal,cnt;\nwire [3:0] bai1,bai2,miao1,miao2,fen1,fen2,buzzer;\nchronograph i1(\n        .clk(clk),\n        .pause(pause),\n        .reset(reset),\n        .bai1(bai1),\n        .bai2(bai2),\n        .miao1(miao1),\n        .miao2(miao2),\n        .fen1(fen1),\n        .fen2(fen2),\n        .reversal(reversal),\n        .cnt(cnt),\n        .buzzer(buzzer)\n        );\ninitial begin\n    clk = 1;reset = 1;pause = 0;reversal=0;cnt=0;\n#1;reset = 0;\n#5;pause = \\x7epause;//时延可以设置为相同，之前以为这个数字是连续的正常时间才把间隔越搞越大，实际上就是时间间隔\n#10;pause = \\x7epause;\n#15;pause = \\x7epause;\n#20;pause = \\x7epause;\n#3000;reset=0;reversal=1;\n#7000;reversal=0;\n#15000;reset=0;reversal=1;cnt=1;\n#15010;cnt=0;\nend\nalways begin\n    #1 clk=\\x7eclk;end\nendmodule\n```\n# 仿真波形图\n![基础计时 重置时间和暂停功能.png](https://s2.loli.net/2024/03/14/ibQhaA9zUZkmWvM.png)\n<center>基础计时 重置时间和暂停功能</center>\n\n![从当前时间倒计时.png](https://s2.loli.net/2024/03/14/WDcRoqsUp28yhSX.png)\n<center>从当前时间倒计时</center>\n\n![正常计时至59秒99时短暂蜂鸣.png](https://s2.loli.net/2024/03/14/agVpfnDhKreTN9d.png)\n<center>正常计时至59秒99时短暂蜂鸣</center>\n\n![倒计时状态下计时结束持续蜂鸣.png](https://s2.loli.net/2024/03/14/thYGd2mrEgvyRaq.png)\n<center>倒计时状态下计时结束持续蜂鸣</center>\n\n![60秒信号停止输入且倒计时信号继续输入开始从60秒倒计时.png](https://s2.loli.net/2024/03/14/E51xcfZLkOpzla4.png)\n<center>60秒信号停止输入且倒计时信号继续输入开始从60秒倒计时</center>\n\n![取消倒计时后正常计时停止蜂鸣.png](https://s2.loli.net/2024/03/14/8gxTL1Q45qydCsj.png)\n<center>取消倒计时后正常计时停止蜂鸣</center>\n\n![倒计时和60秒信号同时触发60秒倒计时_未设置上升沿触发导致不同步_.png](https://s2.loli.net/2024/03/14/LwbBEJiGO5gYlX4.png)\n<center>倒计时和60秒信号同时触发60秒倒计时未设置上升沿触发导致不同步</center>\n\n![整体情况.png](https://s2.loli.net/2024/03/14/c5ZiM1tvTLnGbUP.png)\n<center>整体情况</center>\n\n一次比较简单的课程设计，主要考察Verilog HDL的基础运用，时间原因未设计编译码模块并连接开发板测试实际效果，文章如有错误还望指出！","tags":["电子","Verilog"],"categories":["旧日"]},{"title":"小记数字图像处理","url":"/post/fbbe638c.html","content":"\n# 数字图像处理第3章图像增强\n~~若数学公式加载失败，请移步[主站](https://yxcnb.ml/index.php/archives/77/)~~\n\n## γ校正\n非线性部件的输人-输出特性，都是一个能够反映各自特性的幂函数，即如果输人的光信号强度为L,输出的电信号强度为I,则输入、输出之间的关系满足\n\n$I = c · L^γ$\n\n\nc为放大倍数（常数），γ为幂函数的指数，用于衡量非线性部件的转换特性，称为**幂律转换特性**，又称γ特性，对非线性关系的校正称为**γ校正**\n<br/>\n*对比度计算公式*\n\n\n\n$C=\\sum_{\\delta}\\delta(i,j)^2P_\\delta(i,j)$\n\n\n计算方式有四近邻或八近邻，略\n\n## 线性对比度展宽\n线性对比度展宽处理，实际上是图像灰度值的线性映射。假设处理后图像与处理前图像的量化级数相同，即处理前后图像的灰度分布范围均为[0,255],则如果需要进行对比度展宽,从原理上说，只能通过抑制非重要信息的对比度来腾出空间给重要信息进行对比度的展宽。\n设原图像的灰度为 f(i,j),处理后图像的灰度为g(i, j),设原图重要景物灰度在[fa，fb]范围内，处理后灰度分布在[ga，gb]内，α<1,γ<1,表示对非重要景物的抑制，β>1表示重要景物的对比度展宽增强。\n对比度线性展宽计算公式\n\n$$\ng(i,j) =\n\\begin{cases}\n\\alpha f(i,j),  & 0\\le f(i,j)\\lt f_a \\\\[2ex]\n\\beta(f(i,j)-f_a)+g_a, & f_a\\le f(i,j)\\lt f_b \\\\[2ex]\n\\gamma(f(i,j)-f_b)+g_b, &f_b\\le f(i,j)\\lt 255\n\\end{cases}\n$$\n\n(i=1,2,…,m;j=1,2,…,n)\n其中，$\\alpha =\\frac{g_a}{f_a},\\beta =\\frac{g_b-g_a}{f_b-f_a},\\gamma =\\frac{255-g_b}{255-g_b}$，图像的大小为m*n\n\n当得到一张矩阵形式的灰度图像时，若要进行线性对比度展宽，需先画出灰度直方图，确认原图重要景物的灰度分布范围fa，fb，根据需要确认处理后的灰度范围ga，gb，代入公式进行计算\n\n## 灰级窗与灰级窗切片\n灰级窗是将灰度值在一定范围内的目标进行对比度增强，使范围内像素映射到另一范围，使其达到分离图像区域（切片）以及高亮（映射）的效果，灰级窗映射计算公式\n\n\n$$\ng(i,j) =\n\\begin{cases}\n0,  & 0\\le f(i,j)\\lt f_a \\\\[2ex]\n\\beta(f(i,j)-f_a), & f_b\\le f(i,j)\\lt f_a \\\\[2ex]\n0, &f_b\\le f(i,j)\\lt 255\n\\end{cases}\n$$\n\n\n(i=1,2,…,m;j=1,2,…,n)\n其中，$\\beta =\\frac{255}{f_b-f_a}$，图像的大小为m*n\n灰级窗切片计算公式\n\n\n$$\ng(i,j) =\n\\begin{cases}\n0,  & 0\\le f(i,j)\\lt f_a \\\\[2ex]\n255, & f_a\\le f(i,j)\\lt f_b \\\\[2ex]\n0, &f_b\\le f(i,j)\\lt 255\n\\end{cases}\n$$\n\n\n(i=1,2,…,m;j=1,2,…,n)，图像的大小为m*n\n## 动态范围调整\n\n### 线性动态范围调整\n线性动态范围是先进行亮暗限幅，即将图像中黑的像素值调大,由0调整到a，白的像素值调小，由255调整到b。然后将区域[a,b]进行线性映射到[0,255]范围内。使一部分较暗的像素点以及较亮的像素点进入饱和，中间部分的像素值因为可以进行对比度扩展，而使得其细节部分看的更加清楚，结果是目标区域的像素得到增强，两边区域的细节丢失。线性动态范围调整公式\n\n\n$$\ng(i,j) =\n\\begin{cases}\n0,  & f(i,j)\\lt f_a \\\\[2ex]\n\\frac{255}{b-a}[f(i,j)-a], & f_a\\le f(i,j)\\lt f_b \\\\[2ex]\n255, &f(i,j)\\gt f_b\n\\end{cases}\n$$\n\n\n(i=1,2,…,m;j=1,2,…,n)，图像的大小为m*n,[a,b]为灰度变化范围\n### 非线性动态范围调整\n非线性动态范围调整的作用是抑制高亮度区域，扩展低亮度区域，一定程度解决了景物中高亮度区的信号掩盖暗区信号问题。\n非线性动态范围调整的计算公式\ng(i,j)=c · lg(1+f(i,j))&emsp;(i=1,2,…,m;j=1,2,…,n)\n首先计算$\\frac{灰度变化范围}{lg(灰度变化范围+1)}$，再计算g(i,j)\n## 直方图均衡化\n对图像中像素个数多的灰度值进行展宽，对像素个数多的灰度值进行进行归并，设f(i,j),g(i,j)(i=1,2,…,M;j=1,2,…,N)分别为原图像和处理后图像图像的灰度变化范围为[0，255]，方法如下\n①求原图$[f(i,j)]_{M*N}$的灰度直方图，设用256维的向量$h_f$表示\n②由$h_f$求原图的灰度分布概率，记作$p_f$,则\n\n\n$$\np_f(i)=\\frac{1}{N_f} · h_f(i), i=0,1,2,…,255\n$$\n\n\n$N_f$=M*N,为图像的总像素个数\n③计算图像各个灰度值的累计分布概率，记作$p_a$，则\n\n\n$$\np_a(i)=\\sum_{k=0}^i p_f(k), i=0,1,2,…,255\np_a(0)=0\n$$\n\n\n④进行直方图均衡化计算处理后像素值g(i,j)=255 · $p_a$(k)\n\n## 同态滤波\nf(x,y)=i(x,y) · r(x,y)\n两边取对数得lnf(x,y)=lni(x,y)+lnr(x,y)\n两边进行傅里叶变换得F(u,v)=I(u,v)+R(u,v)\n用频域滤波函数H(u,v)进行滤波得H(u,v)F(u,v)=H(u,v)I(u,v)+H(u,v)R(u,v)，$H_f(u,v)=H_i(u,v)+H_r(u,v)$\n反变换到空域得$h_f(x,y)=h_i(x,y)+h_r(x,y)$\n取指数得同态滤波图像\ng(x,y)=exp|$h_f(x,y)$|=exp|$h_i(x,y)$|=exp|$h_r(x,y)$|\n## [伪彩色](https://baike.baidu.com/item/%E4%BC%AA%E5%BD%A9%E8%89%B2/3429626)\n以上为数字图像处理（科学出版社）第3章给出的图像增强方法，附习题\n![数字图像处理例题.png](https://s2.loli.net/2024/03/14/NyVFMt3L1jJ8OkS.png)","tags":["图像处理","电子"],"categories":["旧日"]},{"title":"以太网和IP","url":"/post/ab626e9a.html","content":"摘要：局域网技术的概述，IP基本原理以及IP子网划分\n\n> 本期内容较为杂乱且基础，故列出以下大致目录 \n>  - 早期以太网技术\n>   - 全双工与半双工\n>   - MDI与MDIX\n>   - CSMA/CD\n>   - 以太网流量控制\n>  - 现代以太网技术\n>   - WLAN技术\n>   - CSMA/CA\n>  - 广域网基本原理\n>   - 常见接口\n>  - IP基本原理\n\n![局域网技术 目前仅以太网仍在使用][1]\n**早期以太网技术**\n\n|   名称   |   速率  |  介质类型  | 最大线缆长度 |\n|:--------:|:-------:|:----------:|:------------:|\n|  10BASE5 | 10 Mbps | 粗同轴电缆 |     500m     |\n|  10BASE2 | 10 Mbps | 细同轴电缆 |     200m     |\n| 10BASE-T | 10 Mbps |   双绞线   |     100m     |\n\n以10BASE5为例，10表示传输速率最高为10Mbps，5表示最大线缆长度为500m，仍可使用中继器将其延长，但最大长度不超过2000m。*10BASE-T为常见的网线*\n![RJ-45接头即水晶头][2]\n集线器和中继器的工作方式都为[半双工][3]\n光纤的工作方式为[全双工][4]\n半双工指在同一时间两端只能发送或接受信号，全双工则能同时收发信号并且不会产生冲突。\n[**MDI和MDIX**][5]\n\n|                           | 主机网卡(MDI) | 路由器以太口(MDI) | 交换机/集线器接入口(MDIX) | 交换机/集线器级连口（MDI） |\n|:-------------------------:|:-------------:|:-----------------:|:-------------------------:|:--------------------------:|\n|       主机网卡(MDI)       |     交叉线    |       交叉线      |           直连线          |             N/A            |\n|     路由器以太口(MDI)     |     交叉线    |       交叉线      |           直连线          |             N/A            |\n| 交换机/集线器接入口(MDIX) |     直连线    |       直连线      |           交叉线          |           直连线           |\n| 交换机/集线器级连口(MDI)  |      N/A      |        N/A        |           直连线          |           交叉线           |\n同类接口互连用交叉线，异类接口互连用直连线\n\n[**CSMA/CD**][6]\n目的：解决总线型拓扑结构中半双工的收发冲突\n工作机制：载波侦听->空闲->抢占->检测冲突->随即退避->退避期满，继续发送\n缺点：延迟高\n\n----------\n数据的发送方式：[单播][7]，[组播][8]，广播\n数据链路层的以太网流量控制（防止传输速率太快导致数据丢失）方式：在半双工线路上采用**背压式流控**，接收方反向发送电压信号制造冲突，使发送方停止发送：在全双工线路上采用**802.3 PAUSE流控**接收方向保留组播地址01-80-C2-00-00-01发送PAUSE帧，通知发送方停止发送![流控][9]\n\n----------\n## 现代以太网技术 ##\n现代以太网采用交换机取代了中继器和集线器进行以太网拓扑，隔离冲突域，避免冲突域过大，进一步扩大物理连接范围，提高以太网带宽利用率，增加吞吐量，适应不同的速率和不同的双工状况。\n**WLAN技术**![802.11b/g工作频段划分图][10]\n无线覆盖原则：蜂窝式覆盖。任意相邻区域使用无频率交叉的频道，如1、6、11频道；适当调整发射功率，避免跨区域同频干扰；蜂窝式无线覆盖实现无交叉频率重复使用\n<br />\n[CSMA/CA][11]（载波侦听多点接入／避让机制）\n![CSMA/CA][12]\n无线网络典型部署：热点覆盖、办公地点无线互联\n\n----------\n\n## 广域网基本原理 ##\n目的：局域网主要完成工作站、终端、服务器等在较小物理范围内的互联，只能解决局部的资源共享；广域网可以使相距遥远的局域网互相连接起来，远距离传输数据、语音、视频等，实现大范围的资源共享\n<br />\n广域网连接方式：专线方式、电路交换方式、分组交换方式\n**接口线缆**\nV.24和V.35均为串行接口\nG口（以太网口）默认数据链路层协议802.3，S口（串口）默认数据链路层协议PPP。根据不同物理层介质，数据链路层选择不同的协议。\n*以下接口线缆非仅广域网中使用*\n![V.24接口线缆（支持同/异步）][13]\n![V.35接口线缆（支持同步）][14]\n![其他常见接口线缆][15]\n\n----------\n\n----------\n\n----------\n## IP基本原理 ##\n\n**IP相关协议（网络层）**：[ICMP][16]、[IGMP][17]、[***ARP***][18]、[***RARP***][19]\nIP的作用：标识节点和链路 ①用唯一的IP地址标识每一个节点②用唯一的IP网络号标识每一个链路；\n寻址和转发①确定节点所在网络的位置，进而确定节点所在的位置②IP路由器选择适当的路径将IP包转发到目的节点；\n适应各种数据链路 ①根据链路的MTU对IP包进行分片和重组 ②为了通过实际的数据链路传递信息，须建立IP地 址到数据链路层地址的映射\n<br />\nIP网络由多个网段构成，每个网段对应一个链路 ，路由器负责将网段连接起来，适配链路层 协议，在网络之间转发数据包\n<br />\n网络号用于区分不同的IP网络、主机号用于标识该网络内的一个IP节点\n![IP头格式][20]\n版本（Version）：用于标识封装是IPv4/IPv6\n头长度（Internet Header Length,IHL）：描述数据包头的内容长度\n总长度（Total Length）：数据包总长度，字段长16Bit，数据包最长为65535B\n标识（Identification）：标识某个分片来自于哪个数据包\n标志（Flags）：标识数据包是否允许分片\nFragment Offset：分片偏移，用于描述分片在数据包中的位置\n生存时间（Time to Live,TTL）：该数据包允许经过的最多路由器数量（每经过一个路由器值-1，0时丢弃）\n协议（Protocol）：标识上层协议TCP,6/UDP,17（协议号）\n头校验和（Header Checksum）：用于检查包头完整性\n源地址Source Address和目的地址Destination Address：标识数据包的源节点和目的节点IP地址\n![IP地址自然分类][21]\nA类IP地址：1.0.0.0~126.255.255.255（127为回环测试，127.0.0.1通常表示本机，0.0.0.0通常用于路由器指定默认路由），每个A类网络有2^24个A类IP地址，2^24-2个可用主机数\nB类IP地址：128.0.0.0~191.255.255.255，每个B类网络有2^16个B类IP地址，2^16-2个可用主机数\nC类IP地址：192.0.0.0~223.255.255.255，每个C类网络有2^8个C类IP地址，2^8-2个可用主机数\nD类IP地址：第一个八位段1110开头，取值224~239，通常为组播地址\nE类IP地址：11110开头，保留用于研究\n网段（网络地址）：主机号全为0；网段广播（广播地址）：主机号全为1\nARP：将IP解析为MAC，RARP为反向ARP解析\n![主机单播IP包发送][22]\n若目的地址所处网络号与本机所处网络司号相同，则目的处于直连网段；\n①处于同一网段，主机可以与其直接通信，此时主机首先解析目的主机IP地址所对应的硬件地址，随即将IP包以此硬件地址为目的地址封装成帧，由直接连结此网段的接口发送给目的主机\n②如果属于不同网段，则主机需要将IP包交给网关去处理，此时主机根据网关的IP地址解析其物理地址，随即将IP包以此硬件地址为目的地址封装成帧，由直连此网段的接口发送给网关\n![路由器单播IP包转发][23]\n路由器收到IP包首先检查IP包的目的地址是不是自己，是的话就接收此包并将其解封装所得数据交给上层协议处理，如果目的IP不是自己\n①处于同一个直连网段，可以与其直接通信，此时路由器首先解析目的IP地址所对应的硬件地址，随即将IP包以此硬件地址为目的地址封装成帧，由此直接连接此网段的接口发给目的主机\n②如果处于不同网段，则需要交给下一跳路由器处理，此时根据路由器上面的路由表查出下一跳的IP地址，解析出一下跳的硬件地址，随即将IP包以此硬件地址为目的地址封装成帧，由此直接连接此网段的接口发给下一跳的路由器\n![主机接收IP包][24]\n\n----------\n\nIP子网划分\n------\n子网划分方法：在主机号中划分出子网号，达到在自然分类中再次划分主机的目的\n![IP地址与子网掩码][25]\n得到一个IP地址首先判断在自然分类中他的网络号的位数，再通过给出的位数相减得到子网号位数；得到一个16进制子网掩码首先将其转换为二进制，再判断子网号位数，用自然分类得出网络地址和广播地址的方式就能得出子网划分后的地址的网络地址/广播地址。\n![根据主机地址数划分子网][26]\n可用主机数：2^（主机位数）-2  *//此时的主机位数同自然分类中的主机位数-子网号位数*（在告知主机数和IP时，用2^（主机位数）-2>=主机数，来算出主机位数和子网位数即可得出子网掩码）\n![根据子网掩码数计算子网数][27]\n![根据子网数划分子网][28]\n可用子网数：2^（子网位数）（在告知子网数和IP时，用2^（子网位数）>=子网数，来算出子网位数即可得出子网掩码）\n可用主机范围：网络地址+1~广播地址-1\n**VLSM和CIDR**\n子网划分的局限性 ：无法实现把网络划分为不同大小的子网，常常会浪费许多主机地址 ，使用VLSM(Variable Length Subnet Mask，可变长子网掩码）可以允许使用多个子网掩码划分子网，使组织的IP地址空间得到更有效的利用\nCIDR(Classless Inter-Domain Routing, 无类域间路由） 消除了自然分类地址和子网划分的界限、将网络前缀相同的连续IP地址组成CIDR地址块、支持强化地址汇聚\n*题目示例*\n***基于CIDR划分子网***\n 1. 请根据10.0.0.0/8划分4个子网，并给出每个子网的网络地址、广播地址、可用IP地址范围和子网掩码。 \n    2^M>=4,M>=2\n    8+2=10位，255.192.0.0\n    10.0.0.0  10.63.255.255   10.0.0.1~10.63.255.254\n    10.64.0.0  10.127.255.255   10.64.0.1~10.127.255.254\n    10.128.0.0  10.191.255.255   10.128.0.1~10.191.255.254\n    10.192.0.0  10.255.255.255   10.192.0.1~10.255.255.254\n<br />\n 2. 请根据172.16.96.0/19划分4个子网，并给出每个子网的网络地址、广播地址、可用IP地址范围和子网掩码。 \n    2^M>=4,M>=2\n    子网掩码：19+2=21；255.255.248.0\n    172.16.96.0  172.16.103.255  172.16.96.1~172.16.103.254\n    172.16.104.0  172.16.111.255  172.16.104.1~172.16.111.254\n    172.16.112.0  172.16.119.255   172.16.112.1~172.16.119.254\n    172.16.120.0  172.16.127.255   172.16.120.1~172.16.127.254\n<br />\n 3. 请根据IP地址为100.100.100.100/11，计算该IP地址所属网段的网络地址、广播地址、可用IP地址范围和子网掩码。\n    100.011 00000.0.0=100.96.0.0\n    100.011 11111.255.255=100.127.255.255 \n    可用IP地址范围：100.96.0.1~100.127.255.254\n    255.224.0.0\n<br />\n 4. 请根据IP地址为200.200.200.200/27，计算该IP地址所属网段的网络地址、广播地址、可用IP地址范围和子网掩码。\n    200.200.200.110 11111\n    200.200.200.192  200.200.200.223\n    200.200.200.193~200.200.200.222\n    255.255.255.224\n\n----------\n\n----------\n\n----------\n***基于VLSM划分子网***\n\n 1. 某公司有A、B、C、D四个部门，计算机数量分别是100台、55台、29台、20台。该公司拟通过192.168.1.0/24划分子网，请给出每个子网的网络地址、广播地址、可用IP地址范围和子网掩码。\n    A：2^n-2>=100,n>=7,32-7=25  \n    192.168.1.0 0000000:\n    192.168.1.0  192.168.1.127   192.168.1.1~192.168.1.126 \n    B；2^n-2>=55,n>=6;32-6=26\n    192.168.1.1 0 000000:\n    192.168.1.128  192.168.1.191  192.168.1.129~192.168.1.190 \n    C:2^n-2>=29,n>=5;32-5=27\n    192.168.1.110 00000:\n    192.168.1.192 192.168.1.223  192.168.1.193~192.168.1.222 \n    D:2^n-2>=20,n>=5;32-5=27\n    192.168.1.111 00000:\n    192.168.1.224  192.168.1.255  192.168.1.225~192.168.1.254\n<br />\n 2. 某公司向运营商（ISP）申请到200.200.200.160/27的网络地址，数据中心有10台服务器，5个公网IP用作NAT（网络地址转换），其他IP用作网络设备之间提供点对点服务。请划分子网，并给出每个子网的网络地址、广播地址、可用IP地址范围和子网掩码。\n\n----------\n***地址聚合***\n\n 1. 某企业分配给产品部的IP地址块为192.168.31.192/26，分配给市场部的IP地址块为192.168.31.160/27，分配给财务部的IP地址块为192.168.31.128/27，那么这三个地址块经过聚合后的地址为（C  ）   \n    A、192.168.31.0/25                B、192.168.31.0/26 \n    C、192.168.31.128/25              D、192.168.31.128/26\n    比较，相同的部分均为192.168.31，总共24位相同，最后一组换成二进制再比较：  \n    192.168.31.11000000\n    192.168.31.10100000\n    192.168.31.10000000 \n    比较得出，总共25位相同，那么，聚合后的IP（网络前缀）就为192.168.31.10000000，将10000000转为十进制为128，聚合后的IP就是192.168.31.128。可直接写成192.168.31.128/25。\n    因为有25位相同，也以，子网掩码网络号就是25位，主机号剩下7位，网络号全为1，主机号全为0，即11111111.11111111.11111111.10000000，转换为十进制，255.255.255.128。\n<br />\n 2. 有４条路由：172.18.129.0/24, 172.18.130.0/24, 172.18.132.0/24, 172.18.133.0/24,如果进行路由会聚，能覆盖这４条路由的地址是（A ）。  \n    A．172.18.128.0/21                B. 172.18.128.0/22  \n    C.172.18.130.0/22                 D. 172.18.132.0/23 \n    首先从左到右开始，把不同的那个ip数字换算成二进制，\n    即 129 二进制 1000 0001 130 二进制 1000 0010 132 二进制 1000 0100 133 二进制 1000 0101\n    这四个数的前五位相同都是10000，所以加上前面的172.18这两部分相同的位数，网络号就是8+8+5=21。把共同的保留下来，其他全部为0，就是路由汇聚的地址。10000000转换回十进制就是128。所以，路由汇聚的ip地址就是172.18.128.0，最终就是172.18.128.0/21。\n<br />\n 3. 为缩小路由表，请根据192.168.20.0/24、192.168.21.0/24、192.168.22.0/24、192.168.23.0/24等4个子网进行地址聚合，求出超网地址。（不同的号位为0）\n    192.168.20.0/24 192.168.00010100.0\n    192.168.21.0/24 192.168.00010101.0\n    192.168.22.0/24 192.168.00010110.0\n    192.168.23.0/24 192.168.00010111.0 \n    故可得超网地址为：192.168.20.0/22\n\n[1]: https://s2.loli.net/2024/03/15/QA6kdFPHURLEpw1.png\n[2]: https://s2.loli.net/2024/03/15/5k69vt18PcbzTLu.png\n[3]: https://baike.baidu.com/item/%E5%8D%8A%E5%8F%8C%E5%B7%A5/309852?fr=aladdin\n[4]: https://baike.baidu.com/item/%E5%85%A8%E5%8F%8C%E5%B7%A5/310007?fr=aladdin\n[5]: https://zh.wikipedia.org/wiki/%E4%BB%8B%E8%B4%A8%E7%9B%B8%E5%85%B3%E6%8E%A5%E5%8F%A3\n[6]: https://baike.baidu.com/item/CSMA/CD/986847\n[7]: https://baike.baidu.com/item/%E5%8D%95%E6%92%AD/8946201?fr=aladdin\n[8]: https://baike.baidu.com/item/%E7%BB%84%E6%92%AD/8946116?fr=aladdin\n[9]: https://s2.loli.net/2024/03/15/VUwd6M7lOAPzQNx.png\n[10]: https://s2.loli.net/2024/03/15/Ep1SsxglMiZ3bvf.png\n[11]: https://baike.baidu.com/item/CSMA%2FCA/10898090?fr=aladdin\n[12]: https://s2.loli.net/2024/03/15/cgqF2HTuWoKdUmw.png\n[13]: https://s2.loli.net/2024/03/15/G4lXMKjag2I5bTP.png\n[14]: https://s2.loli.net/2024/03/15/xiZEnrW5FvDdKJM.png\n[15]: https://s2.loli.net/2024/03/15/nu9rX3L2bfESsKN.png\n[16]: https://baike.baidu.com/item/ICMP/572452\n[17]: https://baike.baidu.com/item/Internet%E7%BB%84%E7%AE%A1%E7%90%86%E5%8D%8F%E8%AE%AE?fromtitle=IGMP&fromid=610474\n[18]: https://baike.baidu.com/item/ARP/609343\n[19]: https://baike.baidu.com/item/%E5%8F%8D%E5%90%91%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2%E5%8D%8F%E8%AE%AE?fromtitle=RARP&fromid=610685\n[20]: https://s2.loli.net/2024/03/15/J5VUdthC73kMlHg.png\n[21]: https://s2.loli.net/2024/03/15/7qtn8lPuw3EyXHx.png\n[22]: https://s2.loli.net/2024/03/15/CSRKGJdz4IDWhVZ.png\n[23]: https://s2.loli.net/2024/03/15/tEMpceUq2XKVkxL.png\n[24]: https://s2.loli.net/2024/03/15/9yquQawFd5AULfR.png\n[25]: https://s2.loli.net/2024/03/15/FV7hIClTjxiDwYs.png\n[26]: https://s2.loli.net/2024/03/15/AOdpElL56UzW8eb.png\n[27]: https://s2.loli.net/2024/03/15/r2gmklVTa9wfWpi.png\n[28]: https://s2.loli.net/2024/03/15/gOEQTU4ycXpdisJ.png","tags":["通信","IP","路由"],"categories":["旧日"]},{"title":"OSI和TCPIP","url":"/post/b66e59b1.html","content":"摘要：OSI模型的7层结构及对应功能，TCP/IP模型的分层结构和OSI模型的对比\n\n> *开放式系统互联模型（Open System Interconnection Model，缩写：OSI；简称为OSI模型）是一种概念模型，由国际标准化组织（ISO）提出，一个试图使各种计算机在世界范围内互连为网络的标准框架。定义于ISO/IEC 7498-1。*\n> *该模型将通信系统中的数据流划分为七个层，从分布式应用程序数据的最高层表示到跨通信介质传输数据的物理实现。每个中间层为其上一层提供功能，其自身功能则由其下一层提供。功能的类别通过标准的通信协议在软件中实现。*\n> *开放式系统互联模型的开发始于上世纪70年代后期，用以支持各种计算机联网方法的出现。在上世纪80年代，该模型成为国际标准化组织（ISO）开放系统互连小组的工作产品。-------------------------维基百科*\n\n\n</br>\n\n\n**OSI七层参考模型有以下优点**\n\n 1. 开放的标准化接口\n 2. 多厂商兼容性\n 3. 易于理解、学习和更新协议标准\n 4. 实现模块化工程，降低开发实现的复杂度\n 5. 便于故障排除\n\nOSI参考模型\n7    应用层：(*数据名*)应用层协议数据单元APDU（Application Protocol Data Unit）\n6    表示层：表示层协议数据单元PPDU（Presentation Protocol Data Unit）\n5    会话层：会话层协议数据单元SPDU（Session Protocol Data Unit）\n4    传输层：      段  Segment\n3    网络层：      数据包 Packet\n2    数据链路层：  帧 Frame\n1    物理层：      比特流 Bit\n\n## 物理层 ##\n介质：同轴电缆，双绞线，光纤，串行电缆，电磁波等\n局域网接口线缆标准：10Base-T、100Base-Tx/Fx、1000Base-T、1000Base-Sx/Lx\n广域网接口线缆标准：RS-232(EIA/TIA-232)、V.24、V.35\n常见设备：中继器（局域网），集线器（局域网），调制解调器（广域网）\n\n## 数据链路层 ##\n主要功能：①帧同步（编帧和识别帧）②数据链路的建立，维持和释放③传输资源控制④流量控制⑤差错控制⑥寻址⑦标识上层数据\nIEEE 802标准：\n\n - 802.1描述局域网需要解决的问题（802.1d描述生成树协议）\n - 802.2 LLC子层标准制定\n - 802.3 MAC子层标准制定（如解决总线型拓扑的半双工单点故障的技术CSMA/CD）\n - 802.4 令牌总线标准制定\n - 802.5 令牌环网标准制定\n - 802.11 无线局域网标准制定\n*我国应用最广的LAN标准是基于IEEE802.3的以太网标准*\n广域网数据链路层标准：HDLC（高级数据链路控制）、PPP（点到点协议）、X.25、帧中继协议等\n常见设备：交换机\n\n## 网络层 ##\n主要功能：编址、路由选择、拥塞控制、异种网络互连\n主要协议：路由协议（RIP，OSPF，IS-IS，IGRP，EIGRP，BGP协议等）和可路由协议（IP，IPX协议等）\n![路由协议和可路由协议][1]\n\n\n面向连接的服务：适合可靠性要求高的应用。特点①通信前建立连接，通信完成后断开连接②有序传递③应答确认④差错重传\n无连接的服务：适合对延迟敏感的应用。特点①尽力而为的服务②无需建立连接③无序列号机制，无确认机制，无重传机制\n## 传输层 ##\n主要功能：负责创建端到端的通信连接、差错校验和重传、流量控制。\n主要协议：TCP、UDP、SPX协议等。\n## 会话层 ##\n利用传输层提供的端到端服务，向表示层或会话用户提供会话服务。\n## 表示层 ##\n转换应用层的信息，对数据进行加密和压缩。\n## 应用层 ##\n对软件提供接口，实现用户与应用程序交互。\n\n----------\n## TCP/IP模型 ##\n\n> *TCP/IP参考模型是一个抽象的分层模型，这个模型中，所有的TCP/IP系列网络协议都归类到4个抽象的“层”中。每一抽象层创建在低一层提供的服务上，并且为高一层提供服务。 完成一些特定的任务需要众多的协议协同工作，这些协议分布在参考模型的不同层中的，因此有时称它们为一个协议栈。 TCP/IP参考模型为TCP/IP协议栈订身制作。其中IP协议只关心如何使得数据能够跨越本地网络边界的问题，而不关心如何利用传输媒体，数据如何传输。整个TCP/IP协议栈则负责解决数据如何通过许许多多个点对点通路（一个点对点通路，也称为一“跳”, 1 hop）顺利传输，由此不同的网络成员能够在许多“跳”的基础上创建相互的数据通路。 如想分析更普遍的网络通信问题，ISO的OSI模型也能起更好的帮助作用。---------------------维基百科*\nTCP/IP模型\n4 应用层：融合了会话层和表示层---主要协议：Telnet，FTP，TFTP，SMTP，SNMP，HTTP等\n3 传输层：提供端到端连接---主要协议：TCP，UDP\n2 网络层：使主机能正确将信息发送至任何网络的目标---主要协议：IP，ICMP，IGMP\n1 网络接口层：主要技术：以太网，FDDI，令牌环，SLIP，HDLC，PPP，X.25，帧中继，ATM\n其中传输层协议的主要作用：\n\n 1. 提供面向连接和无连接的服务\n 2. 维护连接状态\n 3. 对应用层数据进行分段和封装\n 4. 实现多路复用\n 5. 可靠的传输数据\n 6. 执行流量控制\n![][2]\n##OSI参考模型和TCP/IP模型对比##\n![][3]\n\n*以上为个人的粗浅认识，如有不正确之处，还望大佬指正谢谢*\n\n\n[1]: https://s2.loli.net/2024/03/15/XHkK6Bo1iIUASxe.png\n[2]: https://s2.loli.net/2024/03/15/E8cdIkbzGlrq3j7.gif\n[3]: https://s2.loli.net/2024/03/15/2iA4PEJKao9cUgR.jpg\n","tags":["网络模型","通信"],"categories":["旧日"]},{"title":"5G网络架构和组网部署","url":"/post/7570f815.html","content":"## 5G网络架构的演进趋势 ##\n\n> 5G移动通信系统包括5GC（5G Core Network，5G核心网）和NG-RAN（Next Generation Radio Access Network，5G无线接入网）。\n> 5G核心网与5G接入网通过NG接口连接，实现控制面和用户面功能;\n> 5G无线接入网之间通过Xn接口连接，实现控制面和用户面功能。\n\n![5G移动通信系统整体架构][1]\n图中gNB为5G基站的名称，g代表generation，NB代表NodeB，so gNB is （next）generation NodeB。\n5G NR：New Radio，指5G的无线空口技术\nng-eNB：next generation eNodeB。在option4系列非独立组网架构下（NSA），4G基站必须升级支持eLTE，和5G核心网对接，这种升级后的4G基站就叫ng-eNB。\n<br />\nEvolved Node B，即演进型Node B简称eNB，LTE中基站的名称，相比现有3G中的Node B，集成了部分RNC的功能，减少了通信时协议的层次。\neNB的功能包括：RRM功能；IP头压缩及用户数据流加密；UE附着时的MME选择；寻呼信息的调度传输；广播信息的调度传输；以及设置和提供eNB的测量等。\n<br />\nNode B是3G移动基站的称呼，它是通过标准的Iub接口与RNC互连，通过Uu接口与UE进行通信，主要完成Uu接口物理层协议和Iub接口协议的处理，相当于一个无线收发信器。\n一般，Node B主要由控制子系统、传输子系统、射频子系统、中频/基带子系统、天馈子系统等部分组成。\n<br />\n**网元**\n[UPF][2]：用户面功能，实现用户数据处理\n[SMF][3]/[AMF][4]：控制面功能，实现接入管理\n\n\n  [1]: https://s2.loli.net/2024/03/15/fC2xwoZENAIPU95.png\n  [2]: https://baike.baidu.com/item/UPF/13973820?fr=aladdin\n  [3]: https://baike.baidu.com/item/smf/22360829#viewPageContent\n  [4]: https://baike.baidu.com/item/AMF/3337707","tags":["基站","网络基础"],"categories":["旧日"]}]