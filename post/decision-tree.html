<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>决策树学习笔记 | Stay hungry. Stay foolish.</title><meta name="author" content="Yuxico"><meta name="copyright" content="Yuxico"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#FFF5EE"><meta name="description" content="决策树学习笔记 1. 什么是决策树？ 决策树（Decision Tree）是一种基本的分类与回归方法。它是一种监督学习算法，其模型呈树形结构，可以看作是基于特征对实例进行分类或回归的过程。  结构:  根节点 (Root Node): 包含样本全集。 内部节点 (Internal Node): 代表一个特征或属性的测试。 分支 (Branch) &#x2F; 边 (Edge): 代表测试的输出（特征的某个值">
<meta property="og:type" content="article">
<meta property="og:title" content="决策树学习笔记">
<meta property="og:url" content="https://blog.icjlu.eu.org/post/decision-tree.html">
<meta property="og:site_name" content="Stay hungry. Stay foolish.">
<meta property="og:description" content="决策树学习笔记 1. 什么是决策树？ 决策树（Decision Tree）是一种基本的分类与回归方法。它是一种监督学习算法，其模型呈树形结构，可以看作是基于特征对实例进行分类或回归的过程。  结构:  根节点 (Root Node): 包含样本全集。 内部节点 (Internal Node): 代表一个特征或属性的测试。 分支 (Branch) &#x2F; 边 (Edge): 代表测试的输出（特征的某个值">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://e3f49eaa46b57.cdn.sohucs.com/2025/5/27/21/30/MTAwMTIyXzE3NDgzNTI2MzI1MjY=.jpeg">
<meta property="article:published_time" content="2025-05-27T12:51:00.000Z">
<meta property="article:modified_time" content="2025-05-27T14:09:51.154Z">
<meta property="article:author" content="Yuxico">
<meta property="article:tag" content="python">
<meta property="article:tag" content="决策树">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://e3f49eaa46b57.cdn.sohucs.com/2025/5/27/21/30/MTAwMTIyXzE3NDgzNTI2MzI1MjY=.jpeg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "决策树学习笔记",
  "url": "https://blog.icjlu.eu.org/post/decision-tree.html",
  "image": "https://e3f49eaa46b57.cdn.sohucs.com/2025/5/27/21/30/MTAwMTIyXzE3NDgzNTI2MzI1MjY=.jpeg",
  "datePublished": "2025-05-27T12:51:00.000Z",
  "dateModified": "2025-05-27T14:09:51.154Z",
  "author": [
    {
      "@type": "Person",
      "name": "Yuxico",
      "url": "https://blog.icjlu.eu.org/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="https://blog.icjlu.eu.org/post/decision-tree.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/font-awesome/6.7.2/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#3E2B2D')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#FFF5EE')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const mediaQueryDark = window.matchMedia('(prefers-color-scheme: dark)')
          const mediaQueryLight = window.matchMedia('(prefers-color-scheme: light)')

          if (theme === undefined) {
            if (mediaQueryLight.matches) activateLightMode()
            else if (mediaQueryDark.matches) activateDarkMode()
            else {
              const hour = new Date().getHours()
              const isNight = hour <= 7 || hour >= 21
              isNight ? activateDarkMode() : activateLightMode()
            }
            mediaQueryDark.addEventListener('change', () => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else {
            theme === 'light' ? activateLightMode() : activateDarkMode()
          }
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":true,"top_n_per_article":2,"unescape":true,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":500,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Yuxico","link":"链接: ","source":"来源: Stay hungry. Stay foolish.","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#FF7D4D","bgDark":"#3E2B2D","position":"bottom-center"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '决策树学习笔记',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><!--– 仅在 AI 翻译页面加载 translate.css--><!--– 在这里手动插入 AI 摘要的样式表--><link rel="stylesheet" href="/hexo-ai-summaries/gemini.css"><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Stay hungry. Stay foolish." type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/54/MTAwMTIyXzE3NDQ1NTI0NDMwMzk=.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">78</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">62</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-compass"></i><span> 页面</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tag"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder"></i><span> 分类</span></a></li><li><a class="site-page child" href="/translate/"><i class="fa-fw fas fa-language"></i><span> 私人翻译</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url(https://e3f49eaa46b57.cdn.sohucs.com/2025/5/27/21/30/MTAwMTIyXzE3NDgzNTI2MzI1MjY=.jpeg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/42/MTAwMTIyXzE3NDQ1NTE3NTYyMjk=.png" alt="Logo"><span class="site-name">Stay hungry. Stay foolish.</span></a><a class="nav-page-title" href="/"><span class="site-name">决策树学习笔记</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-compass"></i><span> 页面</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tag"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder"></i><span> 分类</span></a></li><li><a class="site-page child" href="/translate/"><i class="fa-fw fas fa-language"></i><span> 私人翻译</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">决策树学习笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-05-27T12:51:00.000Z" title="发表于 2025-05-27 20:51:00">2025-05-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-05-27T14:09:51.154Z" title="更新于 2025-05-27 22:09:51">2025-05-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">7.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>26分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><!-- body 开头或你希望触发按钮出现的地方--><div class="post-gemini-ai">
  <div class="ai-summary-trigger-button">
    <!-- 熊猫 1：将 src 替换为你的实际图像路径或保留占位符 -->
    <img src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://e3f49eaa46b57.cdn.sohucs.com/2025/5/7/21/39/MTAwMTIyXzE3NDY2MjUxOTYzMDY=.png" alt="" class="panda-button-img">
    <span>点击获取AI摘要</span>
  </div>
  <!-- 摘要卡将由 JavaScript 插入此处 -->
</div>
<div id="post-outdate-notice" data="{&quot;limitDay&quot;:365,&quot;messagePrev&quot;:&quot;距离上次更新已经过去&quot;,&quot;messageNext&quot;:&quot;天了，内容可能已经过时，请注意甄别内容呀！&quot;,&quot;postUpdate&quot;:&quot;2025-05-27 22:09:51&quot;}" hidden></div><h1>决策树学习笔记</h1>
<h2 id="1-什么是决策树？">1. 什么是决策树？</h2>
<p>决策树（Decision Tree）是一种基本的分类与回归方法。它是一种监督学习算法，其模型呈树形结构，可以看作是基于特征对实例进行分类或回归的过程。</p>
<ul>
<li><strong>结构:</strong>
<ul>
<li><strong>根节点 (Root Node):</strong> 包含样本全集。</li>
<li><strong>内部节点 (Internal Node):</strong> 代表一个特征或属性的测试。</li>
<li><strong>分支 (Branch) / 边 (Edge):</strong> 代表测试的输出（特征的某个值或范围）。</li>
<li><strong>叶节点 (Leaf Node) / 终端节点 (Terminal Node):</strong> 代表最终的决策结果（类别或数值）。</li>
</ul>
</li>
<li><strong>目标:</strong> 生成一棵泛化能力强，即处理未见示例能力强的决策树。</li>
<li><strong>决策过程:</strong> 从根节点开始，根据实例的特征值，沿着树的分支向下移动，直到到达叶节点，该叶节点的类别或值即为预测结果。</li>
</ul>
<h2 id="2-决策树学习原理">2. 决策树学习原理</h2>
<p>决策树学习的本质是从训练数据中归纳出一组分类规则，或者说是由训练数据集估计条件概率模型。其核心思想是 <strong>“分而治之” (Divide and Conquer)</strong>。</p>
<p>学习过程是一个 <strong>递归地选择最优特征</strong>，并根据该特征对训练数据进行分割，使得各个子数据集有一个最好的分类的过程。</p>
<h3 id="2-1-学习步骤概览">2.1 学习步骤概览</h3>
<ol>
<li><strong>开始:</strong> 构建根节点，所有训练数据都放在根节点。</li>
<li><strong>特征选择:</strong> 选择一个最优特征，按照该特征将训练数据集分割成子集，使得各个子集在当前条件下有最好的分类。</li>
<li><strong>生成子节点:</strong> 如果某个子集已能够被基本正确分类（达到停止条件），则构建叶节点，并将这些子集分到所对应的叶节点中去。</li>
<li><strong>递归:</strong> 如果子集不能被基本正确分类，则对这些子集选择新的最优特征，继续对其进行分割，构建相应的节点。</li>
<li><strong>结束:</strong> 递归地进行步骤 2-4，直到所有训练数据子集都被基本正确分类，或者没有合适的特征为止。</li>
</ol>
<h3 id="2-2-如何选择最优特征？——-划分选择">2.2 如何选择最优特征？—— 划分选择</h3>
<p>选择最优特征是决策树学习的关键。目标是选择一个特征进行划分后，各子集的“纯度” (Purity) 最高。纯度越高，意味着子集中的样本尽可能属于同一类别。</p>
<p>常用的衡量纯度的指标有：</p>
<h4 id="a-信息熵-Information-Entropy">a) 信息熵 (Information Entropy)</h4>
<p>熵是度量随机变量不确定性的指标。熵越大，随机变量的不确定性就越大，纯度越低。</p>
<p>假设当前样本集合 <code>D</code> 中第 <code>k</code> 类样本所占的比例为 <code>p_k</code> (k=1, 2, …, |Y|，|Y|是类别总数)，则 <code>D</code> 的信息熵定义为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">E</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">t</mi></mrow><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi mathvariant="normal">∣</mi><mi>Y</mi><mi mathvariant="normal">∣</mi></mrow></munderover><msub><mi>p</mi><mi>k</mi></msub><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{Ent}(D) = - \sum_{k=1}^{|Y|} p_k \log_2(p_k)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathrm">Ent</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.2631em;vertical-align:-1.3021em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.961em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.386em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">Y</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<ul>
<li><code>Ent(D)</code> 的值越小，<code>D</code> 的纯度越高。</li>
</ul>
<h4 id="b-信息增益-Information-Gain-ID3-算法">b) 信息增益 (Information Gain) - ID3 算法</h4>
<p>信息增益表示得知特征 <code>A</code> 的信息而使得数据集 <code>D</code> 的不确定性减少的程度。选择信息增益最大的特征作为划分特征。</p>
<p>假设用离散特征 <code>A</code> 对样本集 <code>D</code> 进行划分，<code>A</code> 有 <code>V</code> 个可能的取值 <code>&#123;a¹, a², ..., aᵛ&#125;</code>。若使用 <code>A</code> 来对 <code>D</code> 进行划分，则会产生 <code>V</code> 个分支节点，其中第 <code>v</code> 个分支节点包含了 <code>D</code> 中所有在特征 <code>A</code> 上取值为 <code>aᵛ</code> 的样本，记为 <code>Dᵛ</code>。</p>
<p>我们可以计算出用特征 <code>A</code> 对 <code>D</code> 进行划分所获得的“信息增益”：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Gain</mtext><mo stretchy="false">(</mo><mi>D</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>Ent</mtext><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>v</mi><mo>=</mo><mn>1</mn></mrow><mi>V</mi></munderover><mfrac><mrow><mi mathvariant="normal">∣</mi><msup><mi>D</mi><mi>v</mi></msup><mi mathvariant="normal">∣</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mi>D</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><mtext>Ent</mtext><mo stretchy="false">(</mo><msup><mi>D</mi><mi>v</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text {Gain}(D, a) = \text {Ent}(D) - \sum_{v=1}^{V} \frac{|D^v|}{|D|} \text {Ent}(D^v)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Gain</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Ent</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord text"><span class="mord">Ent</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7144em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<ul>
<li><code>|Dᵛ| / |D|</code> 是分支 <code>v</code> 的权重，样本数越多的分支节点影响越大。</li>
<li><code>Ent(Dᵛ)</code> 是分支节点 <code>v</code> 的信息熵。</li>
<li><strong>ID3 算法</strong> 就是以信息增益为准则来选择划分属性的决策树算法。</li>
</ul>
<p><strong>缺点:</strong> 信息增益准则对可取值数目较多的特征有所偏好（例如，如果一个特征是 ID，那么每个样本一个取值，划分出的每个子集纯度都是最高的，信息增益会很大，但这没有泛化能力）。</p>
<h4 id="c-增益率-Gain-Ratio-C4-5-算法">c) 增益率 (Gain Ratio) - C4.5 算法</h4>
<p>为了减少信息增益对多取值特征的偏好，<strong>C4.5 算法</strong> 使用“增益率”来选择最优划分特征。</p>
<p>增益率定义为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">G</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">_</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi></mrow><mo stretchy="false">(</mo><mi>D</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mrow><mi mathvariant="normal">G</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow><mo stretchy="false">(</mo><mi>D</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><mrow><mi>I</mi><mi>V</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\mathrm{Gain\_ratio}(D, A) = \frac{\mathrm{Gain}(D, A)}{IV(A)}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathrm">Gain_ratio</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">Gain</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>其中 <code>IV(A)</code> 称为特征 <code>A</code> 的“固有值” (Intrinsic Value)：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>I</mi><mi>V</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>v</mi><mo>=</mo><mn>1</mn></mrow><mi>V</mi></munderover><mfrac><mrow><mi mathvariant="normal">∣</mi><msup><mi>D</mi><mi>v</mi></msup><mi mathvariant="normal">∣</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mi>D</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mrow><mo fence="true">(</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><msup><mi>D</mi><mi>v</mi></msup><mi mathvariant="normal">∣</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mi>D</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">IV(A) = - \sum_{v=1}^{V} \frac{|D^v|}{|D|} \log_2 \left( \frac{|D^v|}{|D|} \right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></p>
<ul>
<li>特征 <code>A</code> 的可能取值数目越多（即 <code>V</code> 越大），<code>IV(A)</code> 的值通常会越大。</li>
</ul>
<p><strong>注意:</strong> 增益率准则对可取值数目较少的特征有所偏好。因此 C4.5 算法并非直接选择增益率最大的特征，而是使用一个启发式：<strong>先从候选划分特征中找出信息增益高于平均水平的特征，再从中选择增益率最高的。</strong></p>
<h4 id="d-基尼指数-Gini-Index-CART-算法">d) 基尼指数 (Gini Index) - CART 算法</h4>
<p><strong>CART (Classification and Regression Tree)</strong> 算法使用“基尼指数”来选择划分属性。</p>
<p>数据集 <code>D</code> 的纯度也可以用基尼值来度量：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mi>i</mi><mi>n</mi><mi>i</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi mathvariant="normal">∣</mi><mi>Y</mi><mi mathvariant="normal">∣</mi></mrow></munderover><munder><mo>∑</mo><mrow><msup><mi>k</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo mathvariant="normal">≠</mo><mi>k</mi></mrow></munder><msub><mi>p</mi><mi>k</mi></msub><msub><mi>p</mi><msup><mi>k</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><mo>=</mo><mn>1</mn><mo>−</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi mathvariant="normal">∣</mi><mi>Y</mi><mi mathvariant="normal">∣</mi></mrow></munderover><msubsup><mi>p</mi><mi>k</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">Gini(D) = \sum_{k=1}^{|Y|} \sum_{k&#x27; \neq k} p_k p_{k&#x27;} = 1 - \sum_{k=1}^{|Y|} p_k^2
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">ini</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.3992em;vertical-align:-1.4382em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.961em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.386em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">Y</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord mtight"><span class="mrel mtight"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4382em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:3.2631em;vertical-align:-1.3021em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.961em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.386em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.22222em;">Y</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li><code>Gini(D)</code> 反映了从数据集 <code>D</code> 中随机抽取两个样本，其类别标记不一致的概率。</li>
<li><code>Gini(D)</code> 越小，数据集 <code>D</code> 的纯度越高。</li>
</ul>
<p>特征 <code>A</code> 的基尼指数定义为 (假设 <code>A</code> 是离散特征，有 <code>V</code> 个取值)：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mi>i</mi><mi>n</mi><mi>i</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>x</mi><mo stretchy="false">(</mo><mi>D</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>v</mi><mo>=</mo><mn>1</mn></mrow><mi>V</mi></munderover><mfrac><mrow><mi mathvariant="normal">∣</mi><msup><mi>D</mi><mi>v</mi></msup><mi mathvariant="normal">∣</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mi>D</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><mo>⋅</mo><mi>G</mi><mi>i</mi><mi>n</mi><mi>i</mi><mo stretchy="false">(</mo><msup><mi>D</mi><mi>v</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Gini\_index(D, A) = \sum_{v=1}^{V} \frac{|D^v|}{|D|} \cdot Gini(D^v)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">ini</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">in</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">ini</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7144em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<ul>
<li>选择那个使得划分后基尼指数最小的特征作为最优划分特征，即 <code>A_* = arg min_&#123;A&#125; Gini_index(D, A)</code>。</li>
</ul>
<p><strong>特点:</strong> CART 生成的是 <strong>二叉树</strong>。对于连续特征，它会尝试所有可能的二分点；对于离散特征，它也会找出最优的二分组合。</p>
<h4 id="2-2-1-连续特征的处理">2.2.1 连续特征的处理</h4>
<p>在决策树中，特征可以是离散的（类别型）或连续的。对于连续特征，决策树的算法需要确定一个<strong>分割点</strong>，即根据特征值的大小将数据划分为两部分。</p>
<ul>
<li>
<p>对于连续特征 (A)，先对所有样本按该特征值排序，记排序后的不同取值为</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>v</mi><mi>m</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{v_1, v_2, \dots, v_m\}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span></p>
</li>
<li>
<p>决策树在构建过程中会选择一个合适的分割点 <code>t</code>（即 <code>A ≤ t</code>）来将数据分为两部分</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>v</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>v</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mtext>之间取中点</mtext><mo stretchy="false">(</mo><mi>t</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>v</mi><mi>i</mi></msub><mo>+</mo><msub><mi>v</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">(v_i, v_{i+1}) \text{之间取中点} (t = (v_i + v_{i+1})/2),
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord text"><span class="mord cjk_fallback">之间取中点</span></span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">/2</span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>将数据分为</mtext><mo stretchy="false">(</mo><mi>A</mi><mo>≤</mo><mi>t</mi><mo stretchy="false">)</mo><mtext>和</mtext><mo stretchy="false">(</mo><mi>A</mi><mo>&gt;</mo><mi>t</mi><mo stretchy="false">)</mo><mtext>两部分。</mtext></mrow><annotation encoding="application/x-tex">\text{将数据分为} (A \le t) \text{和} (A &gt; t) \text{两部分}。
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord cjk_fallback">将数据分为</span></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mord text"><span class="mord cjk_fallback">和</span></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mord text"><span class="mord cjk_fallback">两部分</span></span><span class="mord cjk_fallback">。</span></span></span></span></span></p>
</li>
<li>
<p>选择 <code>t</code> 的方法通常是通过计算划分后的纯度指标（如信息增益、增益率、基尼指数或其他标准），选出最优的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>t</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">t^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span>。</p>
</li>
</ul>
<h4 id="2-2-2-线搜索-Line-Search-过程">2.2.2 线搜索 (Line Search) 过程</h4>
<p>线搜索（Line Search）是一种通过遍历所有可能的分割点来寻找最优分割点的过程。对于每个连续特征，我们会按照其特征值进行排序，然后计算每个分割点的纯度（例如信息增益或基尼指数），并选择使得纯度最大化的分割点。</p>
<h4 id="2-2-2-二类分类中三种纯度度量的关系">2.2.2 二类分类中三种纯度度量的关系</h4>
<ul>
<li>
<p><strong>基尼指数</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>i</mi><mi>n</mi><mi>i</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn><mi>p</mi><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Gini(p) = 2p(1-p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">ini</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span></p>
<blockquote>
<p>其中 <code>p</code> 和 <code>1-p</code> 分别是属于两个类别的样本的比例。当 <code>p</code> 或 <code>1-p</code> 趋近于 0 时，基尼指数会接近 0，说明数据集非常纯净。</p>
</blockquote>
</li>
<li>
<p><strong>熵</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>n</mi><mi>t</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>p</mi><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mi>p</mi><mo>−</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false">)</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Ent(p) = -p\log_2 p - (1-p)\log_2(1-p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9386em;vertical-align:-0.2441em;"></span><span class="mord">−</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span></p>
<blockquote>
<p>同样，当 <code>p</code> 或 <code>1-p</code> 为 0 或 1 时，熵的值接近 0，表明数据集是纯净的。</p>
</blockquote>
</li>
<li>
<p><strong>分类误差率</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>r</mi><mi>r</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>p</mi><mo separator="true">,</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Err(p) = 1 - \max(p,1-p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.02778em;">rr</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span></p>
<blockquote>
<p>它的特点是非常直观，但对于不平衡数据（例如，一个类别占大多数）可能会给出较差的评估。</p>
</blockquote>
</li>
</ul>
<p>熵和基尼指数都能很好地衡量不确定性，二者通常产生相似的结果。</p>
<p>分类误差率通常不会作为选择特征的标准，因为它在纯度较高时变化较小，无法敏感地反映数据的变化。</p>
<p>对二分类问题，三者随 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">p\in[0,1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span> 的曲线关系为</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>E</mi><mi>r</mi><mi>r</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>≤</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>E</mi><mi>n</mi><mi>t</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>≤</mo><mi>G</mi><mi>i</mi><mi>n</mi><mi>i</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mspace width="1em"/><mi mathvariant="normal">∀</mi><mtext> </mtext><mi>p</mi><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">Err(p)\le \frac{1}{2}Ent(p)\le Gini(p)\quad\forall\,p,
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.02778em;">rr</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0074em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">ini</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:1em;"></span><span class="mord">∀</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mpunct">,</span></span></span></span></span></p>
<p><img src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://s2.loli.net/2025/05/26/OLmJ9Qo5fykwA8e.png" alt="二分类三种纯度度量"></p>
<h3 id="2-3-停止条件">2.3 停止条件</h3>
<p>递归划分过程何时停止？</p>
<ol>
<li><strong>当前节点包含的样本全属于同一类别:</strong> 无需划分，该节点成为叶节点。</li>
<li><strong>当前属性集为空，或者所有样本在所有属性上取值相同:</strong> 无法划分，将该节点标记为叶节点，类别设定为该节点所含样本最多的类别（或根据具体问题定义）。</li>
<li><strong>当前节点包含的样本集合为空:</strong> 不能划分，标记为叶节点，类别设定为其父节点所含样本最多的类别。</li>
</ol>
<h3 id="2-4-缺失值的处理">2.4 缺失值的处理</h3>
<p>在决策树学习中，处理缺失值是一个需要解决的问题。不同的算法有不同的处理方式。</p>
<h4 id="2-4-1-在算法层面如何处理缺失值">2.4.1 在算法层面如何处理缺失值</h4>
<p>有几种常见的方法来处理缺失值：</p>
<ul>
<li>
<p><strong>数据插补：</strong> 在训练决策树之前，将缺失的值使用该特征的均值、中位数或众数进行填充。</p>
<blockquote>
<p><strong>注意：</strong> scikit-learn 的决策树实现<strong>不内置</strong>对缺失值的处理，需要用户在训练前进行预处理（如使用 <code>SimpleImputer</code>）。</p>
</blockquote>
</li>
<li>
<p><strong>忽略样本：</strong> 直接忽略包含缺失值的样本。如果缺失值不多，这可能是一个简单有效的方案，但如果缺失样本较多，可能丢失大量信息。</p>
</li>
<li>
<p><strong>基于树的缺失值处理方法（某些算法支持）：</strong> 一些决策树实现（如 C4.5）允许在划分时处理缺失值。</p>
<ul>
<li><strong>计算纯度时：</strong> 仅使用该特征上非缺失的样本子集来计算信息增益（或其他纯度指标）。</li>
<li><strong>划分样本时：</strong> 对于在当前划分特征上有缺失值的样本，可以采用以下策略分配到子节点：
<ul>
<li>将其分配到最有可能的分支（例如，根据已知值样本在各分支的比例）。</li>
<li>将其分配到多个子节点，并赋予不同的权重。例如，如果一个样本在该特征上缺失，且已知值样本根据该特征分成了 A、B 两个分支，已知值样本中 70%去了 A，30%去了 B，那么可以将这个缺失值样本以 0.7 的权重分到 A 分支，以 0.3 的权重分到 B 分支。</li>
<li>将“缺失”本身视为一个独立的特征取值或分支。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="2-4-2-如何选择划分特征（当特征有缺失值时）">2.4.2 如何选择划分特征（当特征有缺失值时）</h4>
<p>当考虑用一个有缺失值的特征进行划分时，传统的纯度计算方法需要调整：</p>
<ul>
<li><strong>计算缺失值的概率：</strong> 可以在计算纯度指标时，对特征的缺失值情况进行惩罚。例如，C4.5 在计算增益率时会考虑样本在当前特征上已知值的比例。</li>
<li><strong>调整纯度计算：</strong> 只使用该特征上非缺失值的样本来计算纯度（如信息增益、基尼指数）。计算信息增益时，通常会乘以一个系数，这个系数等于当前节点中该特征非缺失样本的比例。</li>
</ul>
<h3 id="2-5-处理过拟合-剪枝与-Bagging">2.5 处理过拟合 (剪枝与 Bagging)</h3>
<p>为了防止决策树 <strong>过拟合 (Overfitting)</strong>，即模型在训练数据上表现很好，但在新数据上表现差，需要进行剪枝。过拟合通常是因为树生长得过于复杂，学习了训练数据中过多的噪声或特性。</p>
<h4 id="a-预剪枝-Pre-pruning">a) 预剪枝 (Pre-pruning)</h4>
<p>在决策树生成过程中，对每个节点在划分前先进行估计。若当前节点的划分不能带来决策树泛化性能提升（例如，在验证集上精度下降），则停止划分并将当前节点标记为叶节点。</p>
<ul>
<li><strong>优点:</strong> 降低过拟合风险，减少训练时间和测试时间开销。</li>
<li><strong>缺点:</strong> 基于“贪心”本质，可能带来欠拟合风险（有些划分暂时看可能不优，但后续划分可能显著提升性能）。</li>
</ul>
<p>常用判断条件：</p>
<ul>
<li>节点内样本数量小于阈值 (<code>min_samples_split</code>, <code>min_samples_leaf</code>)。</li>
<li>树的深度达到预设值 (<code>max_depth</code>)。</li>
<li>划分后信息增益（或其他指标）的提升小于阈值。</li>
<li>划分后在独立的验证集上精度下降。</li>
</ul>
<h4 id="b-后剪枝-Post-pruning">b) 后剪枝 (Post-pruning)</h4>
<p>先从训练集生成一棵完整的决策树，然后自底向上地对非叶节点进行考察。若将该节点对应的子树替换为叶节点能带来决策树泛化性能提升，则将该子树替换为叶节点。</p>
<ul>
<li><strong>优点:</strong> 通常比预剪枝保留了更多分支，欠拟合风险小，泛化性能往往优于预剪枝决策树。</li>
<li><strong>缺点:</strong> 训练时间开销比未剪枝和预剪枝决策树都要大得多。</li>
</ul>
<p>常用方法：</p>
<ul>
<li><strong>降低错误剪枝 (Reduced Error Pruning, REP):</strong> 使用验证集，将子树替换为叶节点后，如果验证集错误率降低或不变，则剪枝。</li>
<li><strong>代价复杂度剪枝 (Cost Complexity Pruning, CCP):</strong> 定义损失函数=经验熵+正则化项（树的复杂度），通过调整正则化系数 <code>α</code> (ccp_alpha) 来权衡模型复杂度和拟合度，生成一系列树，最后通过交叉验证选择最优子树。Scikit-learn 中常用此方法。</li>
</ul>
<h4 id="c-Bagging-Bootstrap-Aggregating">c) Bagging (Bootstrap Aggregating)</h4>
<p>除了传统的预剪枝和后剪枝，我们还可以使用 Bagging (Bootstrap Aggregating) 技术来处理过拟合。Bagging 是通过从原始训练集中进行有放回抽样（Bootstrap），生成多个不同的训练集，然后基于每个训练集独立地训练一棵决策树，并将它们的预测结果进行集成（例如，分类任务投票，回归任务平均）来减少过拟合风险。</p>
<ul>
<li><strong>思想：</strong> 对训练集做多次有放回抽样，训练多棵决策树，将其预测结果取平均（回归）或投票（分类）。</li>
<li><strong>优点：</strong> 显著降低高方差，缓解单棵树过拟合；增强了模型的稳定性；并行化简单。</li>
<li><strong>缺点：</strong> 牺牲了模型的解释性（因为是多个树的集成）。</li>
<li><strong>常用实现：</strong> <code>sklearn.ensemble.BaggingClassifier</code>（分类）和 <code>sklearn.ensemble.BaggingRegressor</code>（回归），以及特别针对决策树的 <strong>随机森林（Random Forest）</strong> (<code>sklearn.ensemble.RandomForestClassifier</code>/<code>Regressor</code>)。随机森林在 Bagging 的基础上进一步引入了特征随机性（在每个节点划分时只考虑特征的一个随机子集），进一步提升了性能和鲁棒性。。</li>
</ul>
<h4 id="2-6-二叉树和多叉树">2.6 二叉树和多叉树</h4>
<h5 id="2-6-1-二叉树与多叉树的区别">2.6.1 二叉树与多叉树的区别</h5>
<ul>
<li><strong>二叉树</strong>：每个节点最多有两个子节点（通常表示为左右子节点），即每个决策都只能有两个结果。CART 算法生成的树通常是二叉树。</li>
<li><strong>多叉树</strong>：每个节点可以有多个子节点，表示每次决策有多个选择。ID3 和 C4.5 算法可以生成多叉树（对于离散特征，每个取值对应一个分支）。</li>
</ul>
<h5 id="2-6-2-选择二叉树还是多叉树">2.6.2 选择二叉树还是多叉树</h5>
<ul>
<li><strong>二叉树</strong> 在算法实现上通常更简单，且对计算机资源的消耗更少。许多库（包括 scikit-learn）默认或只支持二叉树。</li>
<li><strong>多叉树</strong> 能处理更多的选择，但计算复杂度较高。对于离散特征，多叉划分虽然直观，但在某些情况下（如特征取值非常多）可能不够灵活。二叉树可以通过多次二分裂来模拟多叉分裂。</li>
</ul>
<h4 id="2-7-二分类和多分类">2.7 二分类和多分类</h4>
<h5 id="2-7-1-二分类">2.7.1 二分类</h5>
<p>决策树在二分类问题中，通过划分使得子节点的样本尽可能只属于两个类别中的一个。可以使用信息增益、增益率或基尼指数作为纯度标准。常见的二分类问题如癌症检测、垃圾邮件分类等。</p>
<h5 id="2-7-2-多分类">2.7.2 多分类</h5>
<p>对于多分类问题，决策树会通过逐步划分的方式将样本集划分成多个子集。对于每个子集，决策树会重复上述过程，直到所有的样本被完全分类。可以使用 <strong>一对一</strong> 或 <strong>一对多</strong> 的方法来构建多分类树。纯度计算方法（信息熵、基尼指数等）自然地扩展到多类别情况。</p>
<h2 id="3-决策树的优缺点">3. 决策树的优缺点</h2>
<h3 id="3-1-优点">3.1 优点</h3>
<ul>
<li><strong>易于理解和解释:</strong> 可以可视化，符合人类的直观思维。</li>
<li><strong>数据预处理要求低:</strong> 不需要数据归一化或标准化（但处理缺失值仍需注意）。可以同时处理数值型和类别型数据（不同算法支持度不同）。</li>
<li><strong>能够处理多输出问题。</strong></li>
<li><strong>计算复杂度相对较低:</strong> 预测阶段的复杂度是 O(log₂m)，m 是样本数。</li>
<li><strong>可以验证模型:</strong> 使用统计测试来验证模型的可靠性。</li>
<li><strong>鲁棒性:</strong> 对于缺失值不敏感（某些算法如 C4.5 可以处理，但 scikit-learn 需要预处理）。</li>
</ul>
<h3 id="3-2-缺点">3.2 缺点</h3>
<ul>
<li><strong>容易过拟合:</strong> 尤其是在数据有噪声或样本量不足时，可能生成过于复杂的树。需要剪枝或集成方法来缓解。</li>
<li><strong>不稳定性:</strong> 数据微小的变动可能导致生成完全不同的树。可以通过集成方法（如随机森林）改善。</li>
<li><strong>最优决策树学习是 NP 难问题:</strong> 实际算法通常采用启发式方法（如贪心算法），只能得到局部最优解。</li>
<li><strong>可能创建有偏的树:</strong> 如果某些类别的样本数量远多于其他类别，生成的树可能会偏向于这些数量多的类别。建议先平衡数据集。</li>
<li><strong>对线性关系表达能力弱:</strong> 对于变量间存在复杂线性关系的问题，决策树可能需要很深的树才能拟合。</li>
</ul>
<hr>
<h2 id="4-使用-Scikit-learn-实现决策树-Iris-数据集示例">4. 使用 Scikit-learn 实现决策树 (Iris 数据集示例)</h2>
<p>我们将使用经典的 Iris (鸢尾花) 数据集来演示如何用 Python 的 Scikit-learn 库构建决策树分类器。</p>
<p><strong>目标:</strong> 根据鸢尾花的花萼长度 (Sepal Length)、花萼宽度 (Sepal Width)、花瓣长度 (Petal Length)、花瓣宽度 (Petal Width) 这四个特征来预测鸢尾花的种类 (Setosa, Versicolour, Virginica)。</p>
<h3 id="4-0-决策树在-Scikit-learn-中的主要参数、属性与方法">4.0 决策树在 Scikit-learn 中的主要参数、属性与方法</h3>
<p>在 Scikit-learn 中，<code>DecisionTreeClassifier</code> 和 <code>DecisionTreeRegressor</code> 类提供了多种超参数来调整决策树的构建方式。</p>
<ul>
<li><strong>参数（<code>DecisionTreeClassifier</code>/<code>DecisionTreeRegressor</code>）</strong>
<ul>
<li><code>criterion</code>：用于划分的标准。<br>
分类树可选 <code>'gini'</code>（基尼指数）或 <code>'entropy'</code>（信息增益）。<br>
回归树可选 <code>'mse'</code> (均方误差, 已废弃, 推荐使用 <code>'squared_error'</code>)，<code>'friedman_mse'</code> 或 <code>'mae'</code> (平均绝对误差)。<br>
默认是分类树 <code>'gini'</code>，回归树 <code>'squared_error'</code>。</li>
<li><code>splitter</code>：划分策略。<code>'best'</code> 表示选择最好的特征进行划分（默认）。<br>
<code>'random'</code> 表示随机选择部分特征后再从中选择最好的进行划分（随机森林常用）适用于样本量非常大的情况。</li>
<li><code>max_depth</code>: 决策树的最大深度。控制树的复杂度，避免过拟合（预剪枝）。默认 <code>None</code>，表示不限制深度。</li>
<li><code>min_samples_split</code>：内部节点再划分所需最小样本数。<br>
较高的值有助于避免过拟合（预剪枝）。可以是整数或小数（表示比例）。默认是 2。</li>
<li><code>min_samples_leaf</code>：叶子节点最少样本数。<br>
一个分割点只有在左右分支都满足这个最少样本数条件时，才能进行划分（预剪枝）。可以是整数或小数。默认是 1。</li>
<li><code>min_weight_fraction_leaf</code>：叶子节点最小的样本权重和，小于这个值会和兄弟节点一起被剪枝，默认为0不考虑权重，当较多样本有缺失值或样本分布类别偏差很大需要考虑</li>
<li><code>max_features</code>：每次分割考虑的最大特征数（随机森林常用）。<br>
可以是整数、浮点数（比例）、<code>&quot;auto&quot;</code>/<code>&quot;sqrt&quot;</code> (等于 <code>sqrt(n_features)</code>)、<code>&quot;log2&quot;</code> (等于 <code>log2(n_features)</code>) 或 <code>None</code> (考虑所有特征)。</li>
<li><code>max_leaf_nodes</code>：最大叶子节点数，可以防止过拟合，默认None</li>
<li><code>min_impurity_decrease</code>：分裂所减小的不纯度小于等于该值才会分裂</li>
<li><code>min_impurity_split</code>：建树时候早停的基尼不纯度阈值，限制决策树的增长</li>
<li><code>class_weight</code>：类别样重，指定样本各类别的权重</li>
<li><code>ccp_alpha</code>：代价复杂度剪枝参数（后剪枝）。取值越大，剪枝越强。默认是 0.0 (不剪枝)。</li>
</ul>
</li>
<li><strong>重要属性 (训练后可用)</strong>
<ul>
<li><code>feature_importances_</code>: 一个 numpy 数组，表示每个特征的重要性评分（总和为 1）。重要性基于该特征在树中降低纯度（信息增益或基尼不纯度）的总量。</li>
<li><code>tree_</code>：底层的 <code>_tree.Tree</code> 对象，包含了树结构的详细信息（节点索引、左右子节点、特征索引、阈值、不纯度等）。</li>
<li><code>n_features_in_</code>: 训练时输入的特征数量。</li>
<li><code>classes_</code>: <u>分类树</u>独有，训练期间遇到的类标签数组。</li>
<li><code>n_classes_</code>: <u>分类树</u>独有，类别的数量。、</li>
<li><code>n_outputs_</code>: 模型输出的数量（对于多输出问题）。</li>
<li><code>n_node_samples_</code>: 每个节点中的训练样本数量数组。</li>
</ul>
</li>
<li><strong>常用方法</strong>
<ul>
<li><code>.fit(X, y)</code>：使用训练数据 <code>X</code> 和目标变量 <code>y</code> 训练决策树模型。</li>
<li><code>.predict(X)</code>：对新数据 <code>X</code> 进行预测。分类树返回类别标签，回归树返回预测值。</li>
<li><code>.predict_proba(X)</code>：<u>分类树</u>独有，预测每个样本属于各个类别的概率。</li>
<li><code>.score(X, y)</code>：返回模型的评估分数。分类树返回在 <code>(X, y)</code> 上的准确率，回归树返回 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>R</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">R^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 分数。</li>
<li><code>apply(X)</code>: 返回每个样本所属的叶节点索引。</li>
<li><code>get_params([deep])</code>: 获取模型的超参数。</li>
<li><code>set_params(**params)</code>: 设置模型的超参数。</li>
<li><code>export_text(decision_tree[, …])</code>、将决策树导出为文本规则表示。</li>
<li><code>plot_tree(decision_tree[, …])</code>：将决策树可视化（需要 Matplotlib）。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-1-导入所需库">4.1 导入所需库</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, plot_tree, export_text</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, classification_report, confusion_matrix</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 注意：Scikit-learn &gt;= 0.20 版本需要</span></span><br><span class="line"><span class="comment"># from sklearn.impute import SimpleImputer</span></span><br></pre></td></tr></table></figure>
<h3 id="4-2-加载和准备数据">4.2 加载和准备数据</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载 Iris 数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data  <span class="comment"># 特征数据 (numpy array)</span></span><br><span class="line">y = iris.target <span class="comment"># 目标标签 (numpy array)</span></span><br><span class="line">feature_names = iris.feature_names <span class="comment"># 特征名称</span></span><br><span class="line">target_names = iris.target_names   <span class="comment"># 类别名称</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># （可选）处理缺失值示例 (如果数据有缺失值)</span></span><br><span class="line"><span class="comment"># 例如，使用均值填充</span></span><br><span class="line"><span class="comment"># imputer = SimpleImputer(missing_values=np.nan, strategy=&#x27;mean&#x27;)</span></span><br><span class="line"><span class="comment"># X_imputed = imputer.fit_transform(X)</span></span><br><span class="line"><span class="comment"># X = X_imputed # 使用填充后的数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># （可选）将数据转换为 Pandas DataFrame 以便查看</span></span><br><span class="line"><span class="comment"># df = pd.DataFrame(X, columns=feature_names)</span></span><br><span class="line"><span class="comment"># df[&#x27;species&#x27;] = y</span></span><br><span class="line"><span class="comment"># df[&#x27;species_name&#x27;] = df[&#x27;species&#x27;].map(&#123;0: target_names[0], 1: target_names[1], 2: target_names[2]&#125;)</span></span><br><span class="line"><span class="comment"># print(df.head())</span></span><br><span class="line"><span class="comment"># print(df[&#x27;species_name&#x27;].value_counts())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割数据集为训练集和测试集</span></span><br><span class="line"><span class="comment"># random_state 保证每次分割结果一致，便于复现</span></span><br><span class="line"><span class="comment"># stratify=y 保证训练集和测试集中各类样本的比例与原始数据集一致 (重要!)</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>, stratify=y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练集大小: <span class="subst">&#123;X_train.shape[<span class="number">0</span>]&#125;</span> samples&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试集大小: <span class="subst">&#123;X_test.shape[<span class="number">0</span>]&#125;</span> samples&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="4-3-创建和训练决策树模型">4.3 创建和训练决策树模型</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建决策树分类器实例</span></span><br><span class="line"><span class="comment"># criterion=&#x27;gini&#x27;: 使用基尼指数作为划分标准 (默认)</span></span><br><span class="line"><span class="comment"># criterion=&#x27;entropy&#x27;: 使用信息增益作为划分标准</span></span><br><span class="line"><span class="comment"># max_depth: 树的最大深度 (预剪枝参数)</span></span><br><span class="line"><span class="comment"># min_samples_split: 内部节点再划分所需最小样本数 (预剪枝参数)</span></span><br><span class="line"><span class="comment"># min_samples_leaf: 叶子节点最少样本数 (预剪枝参数)</span></span><br><span class="line"><span class="comment"># ccp_alpha: 代价复杂度剪枝的参数 (后剪枝相关)</span></span><br><span class="line">dt_classifier = DecisionTreeClassifier(criterion=<span class="string">&#x27;gini&#x27;</span>, max_depth=<span class="literal">None</span>, random_state=<span class="number">42</span>) <span class="comment"># 先不加预剪枝</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用训练数据训练模型</span></span><br><span class="line">dt_classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;决策树模型训练完成!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看特征重要性 (属性示例)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n特征重要性:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> name, importance <span class="keyword">in</span> <span class="built_in">zip</span>(feature_names, dt_classifier.feature_importances_):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span>: <span class="subst">&#123;importance:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="4-4-模型预测与评估">4.4 模型预测与评估</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用训练好的模型对测试集进行预测</span></span><br><span class="line">y_pred = dt_classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型性能</span></span><br><span class="line"><span class="comment"># 准确率</span></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n模型在测试集上的准确率: <span class="subst">&#123;accuracy:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分类报告 (包含精确率、召回率、F1分数)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n分类报告:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred, target_names=target_names))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 混淆矩阵</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n混淆矩阵:&quot;</span>)</span><br><span class="line">cm = confusion_matrix(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(cm)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化混淆矩阵 (可选)</span></span><br><span class="line"><span class="comment"># import seaborn as sns</span></span><br><span class="line"><span class="comment"># plt.figure(figsize=(6, 4))</span></span><br><span class="line"><span class="comment"># sns.heatmap(cm, annot=True, fmt=&#x27;d&#x27;, cmap=&#x27;Blues&#x27;, xticklabels=target_names, yticklabels=target_names)</span></span><br><span class="line"><span class="comment"># plt.xlabel(&#x27;Predicted Label&#x27;)</span></span><br><span class="line"><span class="comment"># plt.ylabel(&#x27;True Label&#x27;)</span></span><br><span class="line"><span class="comment"># plt.title(&#x27;Confusion Matrix&#x27;)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure>
<h3 id="4-5-可视化决策树">4.5 可视化决策树</h3>
<p>理解决策树如何做出决策的一个好方法是将其可视化。</p>
<h4 id="a-使用-plot-tree-需要-Matplotlib">a) 使用 <code>plot_tree</code> (需要 Matplotlib)</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">10</span>)) <span class="comment"># 设置图形大小</span></span><br><span class="line">plot_tree(dt_classifier,</span><br><span class="line">          filled=<span class="literal">True</span>, <span class="comment"># 填充颜色以表示类别纯度</span></span><br><span class="line">          feature_names=feature_names, <span class="comment"># 显示特征名称</span></span><br><span class="line">          class_names=target_names, <span class="comment"># 显示类别名称</span></span><br><span class="line">          rounded=<span class="literal">True</span>, <span class="comment"># 节点框使用圆角</span></span><br><span class="line">          fontsize=<span class="number">10</span>) <span class="comment"># 字体大小</span></span><br><span class="line">plt.title(<span class="string">&quot;Decision Tree for Iris Classification (Gini)&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="b-使用-export-text-输出文本表示">b) 使用 <code>export_text</code> 输出文本表示</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tree_rules = export_text(dt_classifier, feature_names=<span class="built_in">list</span>(feature_names))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n决策树规则 (文本表示):&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(tree_rules)</span><br></pre></td></tr></table></figure>
<h3 id="4-6-探索剪枝-示例">4.6 探索剪枝 (示例)</h3>
<p>尝试添加预剪枝参数，例如限制最大深度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建带预剪枝的决策树</span></span><br><span class="line">dt_classifier_pruned = DecisionTreeClassifier(criterion=<span class="string">&#x27;gini&#x27;</span>, max_depth=<span class="number">3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">dt_classifier_pruned.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_pred_pruned = dt_classifier_pruned.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估</span></span><br><span class="line">accuracy_pruned = accuracy_score(y_test, y_pred_pruned)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n剪枝后 (max_depth=3) 模型准确率: <span class="subst">&#123;accuracy_pruned:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化剪枝后的树</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">plot_tree(dt_classifier_pruned, filled=<span class="literal">True</span>, feature_names=feature_names, class_names=target_names, rounded=<span class="literal">True</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Pruned Decision Tree (max_depth=3)&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>剪枝后的树通常更简单，有时准确率可能会略有下降，但泛化能力可能更好（在这个简单的 Iris 数据集上可能不明显）。</p>
<h2 id="5-决策树回归">5. 决策树回归</h2>
<p>决策树不仅能用于分类问题，还能用于回归问题。**</p>
<h3 id="5-1-最小二乘回归树">5.1 最小二乘回归树</h3>
<p>对于回归问题，决策树会在每个叶节点保存该节点的均值。在构建过程中，决策树将选择能够最小化节点内部 <strong>均方误差（MSE）</strong> 的特征和分割点作为划分标准。</p>
<ul>
<li>
<p><strong>目标：</strong> 通过递归划分，使得每个子集（节点）内的目标值（y）尽可能接近其平均值，从而最小化整体的平方误差。</p>
</li>
<li>
<p><strong>损失函数：</strong> 用于衡量一个节点（数据集 D）的“不纯度”或方差，即节点内所有样本目标值与该节点目标值均值之间的平方误差之和。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>D</mi></mrow></munder><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mi>D</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">L(D) = \sum_{i \in D} (y_i - \bar{y}_D)^2
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3717em;vertical-align:-1.3217em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8557em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3217em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是节点 D 中第 i 个样本的真实目标值，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mi>D</mi></msub></mrow><annotation encoding="application/x-tex">\bar{y}_D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7622em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是节点 D 中所有样本目标值的均值。</p>
</li>
<li>
<p><strong>划分标准：</strong> 在选择特征和分割点时，回归树会遍历所有可能的特征和分割点，计算按该点划分后，左右子节点加权后的总均方误差（或称为平方误差的减少量）。选择使总均方误差最小的划分点。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mrow><mi>A</mi><mo separator="true">,</mo><mi>s</mi></mrow></munder><mrow><mo fence="true">[</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><msub><mi>D</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></munder><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><msub><mi>D</mi><mn>1</mn></msub></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><msub><mi>D</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></munder><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><msub><mi>D</mi><mn>2</mn></msub></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\min_{A, s} \left[ \sum_{i \in D_1(A, s)} (y_i - \bar{y}_{D_1})^2 + \sum_{i \in D_2(A, s)} (y_i - \bar{y}_{D_2})^2 \right]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.6em;vertical-align:-1.55em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.3557em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">s</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.05em;"><span class="pstrut" style="height:5.6em;"></span><span style="width:0.667em;height:3.600em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M403 1759 V84 H666 V0 H319 V1759 v0 v1759 h347 v-84
H403z M403 1759 V0 H319 V1759 v0 v1759 h84z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.809em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">A</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.809em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">A</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.05em;"><span class="pstrut" style="height:5.6em;"></span><span style="width:0.667em;height:3.600em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M347 1759 V0 H0 V84 H263 V1759 v0 v1759 H0 v84 H347z
M347 1759 V0 H263 V1759 v0 v1759 h84z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 是特征，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span></span></span></span> 是分割点，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">D_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">D_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是划分后的两个子集，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mo>∗</mo><msub><mi>D</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\bar{y}*{D_1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7622em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mo>∗</mo><msub><mi>D</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\bar{y}*{D_2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7622em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> 分别是子集 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">D_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">D_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的目标值均值。</p>
</li>
<li>
<p><strong>实现示例：</strong> Scikit-learn 中使用 <code>DecisionTreeRegressor</code> 类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设 y_train_continuous 是连续的目标值</span></span><br><span class="line"><span class="comment"># reg = DecisionTreeRegressor(criterion=&#x27;squared_error&#x27;, max_depth=5, random_state=42)</span></span><br><span class="line"><span class="comment"># reg.fit(X_train, y_train_continuous)</span></span><br><span class="line"><span class="comment"># y_pred_reg = reg.predict(X_test)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估回归模型</span></span><br><span class="line"><span class="comment"># mse = mean_squared_error(y_test_continuous, y_pred_reg)</span></span><br><span class="line"><span class="comment"># r2 = r2_score(y_test_continuous, y_pred_reg)</span></span><br><span class="line"><span class="comment"># print(f&quot;\n回归树 MSE: &#123;mse:.4f&#125;, R2: &#123;r2:.4f&#125;&quot;)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>评估指标：</strong> 均方误差（MSE）、均方根误差（RMSE）、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>R</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">R^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 分数。</p>
</li>
</ul>
<h3 id="5-2-分类树与回归树的区别">5.2 分类树与回归树的区别</h3>
<ul>
<li>目标变量类型:
<ul>
<li><strong>分类树:</strong> 离散型（类别标签）。</li>
<li><strong>回归树:</strong> 连续型（数值）。</li>
</ul>
</li>
<li>叶节点输出:
<ul>
<li><strong>分类树:</strong> 叶节点通常代表一个类别标签（该节点中样本最多的类别）或类别的概率分布。</li>
<li><strong>回归树:</strong> 叶节点代表一个预测数值，通常是该节点中所有样本目标值的均值。</li>
</ul>
</li>
<li>划分标准/损失函数:
<ul>
<li><strong>分类树:</strong> 使用衡量“纯度”的指标，如信息增益、增益率、基尼指数，目标是最大化纯度（最小化不纯度）。</li>
<li><strong>回归树:</strong> 使用衡量“方差”或“误差”的指标，如均方误差（MSE）或平均绝对误差（MAE），目标是最小化节点内误差。</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th><strong>对比维度</strong></th>
<th><strong>分类树（Classification Tree）</strong></th>
<th><strong>回归树（Regression Tree）</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>目标变量类型</strong></td>
<td>离散型（类别标签）</td>
<td>连续型（数值）</td>
</tr>
<tr>
<td><strong>叶节点输出</strong></td>
<td>类别标签（或类别概率分布）</td>
<td>预测数值（如均值、中位数等）</td>
</tr>
<tr>
<td><strong>划分标准/损失函数</strong></td>
<td>信息增益、增益率、基尼指数（衡量纯度）</td>
<td>均方误差（MSE）、平均绝对误差（MAE）（衡量误差）</td>
</tr>
<tr>
<td><strong>适用问题类型</strong></td>
<td>分类问题（如判断是否购买商品）</td>
<td>回归问题（如预测房价、温度等）</td>
</tr>
<tr>
<td><strong>示例应用场景</strong></td>
<td>客户流失预测、垃圾邮件识别</td>
<td>房价预测、销售额预测</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="6-小结">6. 小结</h2>
<p>决策树是一种强大且直观的机器学习模型。理解其核心原理（信息熵、信息增益、基尼指数）、构建过程（递归划分）以及防止过拟合的方法（剪枝）至关重要。通过 Scikit-learn 等库可以方便地实现和应用决策树解决分类和回归问题。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.icjlu.eu.org">Yuxico</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.icjlu.eu.org/post/decision-tree.html">https://blog.icjlu.eu.org/post/decision-tree.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://blog.icjlu.eu.org" target="_blank">Stay hungry. Stay foolish.</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/">决策树</a></div><div class="post-share"><div class="social-share" data-image="https://e3f49eaa46b57.cdn.sohucs.com/2025/5/27/21/30/MTAwMTIyXzE3NDgzNTI2MzI1MjY=.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/post/divisible-and-non-divisible-sums-difference.html" title="LeetCode每日一题2025-05-27"><img class="cover" src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://s2.loli.net/2025/05/27/rVoBPIDf8jOylvp.png" onerror="onerror=null;src='/img/404.png'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">LeetCode每日一题2025-05-27</div></div><div class="info-2"><div class="info-item-1">2894. 分类求和并作差 E 给你两个正整数 n 和 m 。 现定义两个整数 num1 和 num2 ，如下所示：  num1：范围 [1, n] 内所有 无法被 m 整除...</div></div></div></a><a class="pagination-related" href="/post/Ensemble-Learning.html" title="集成学习RF-Adaboost-GBDT"><img class="cover" src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://pic1.imgdb.cn/item/6835c05958cb8da5c812c6f7.webp" onerror="onerror=null;src='/img/404.png'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">集成学习RF-Adaboost-GBDT</div></div><div class="info-2"><div class="info-item-1">集成学习 1. 集成学习 (Ensemble Learning) 集成学习（Ensemble Learning）是一种机器学习范式，其核心思想是 组合多个学习器 (Individual...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/post/CatBoost.html" title="CatBoost内容补充"><img class="cover" src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://pic1.imgdb.cn/item/6835c06258cb8da5c812c6f9.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-27</div><div class="info-item-2">CatBoost内容补充</div></div><div class="info-2"><div class="info-item-1">CatBoost内容补充 1. CatBoost (Categorical Boosting) CatBoost (Categorical Boosting) 是俄罗斯搜索巨头 Yandex...</div></div></div></a><a class="pagination-related" href="/post/LightGBM.html" title="LightGBM内容补充"><img class="cover" src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://pic1.imgdb.cn/item/6835c05e58cb8da5c812c6f8.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-27</div><div class="info-item-2">LightGBM内容补充</div></div><div class="info-2"><div class="info-item-1">LightGBM内容补充 1. LightGBM (Light Gradient Boosting Machine) LightGBM (Light Gradient Boosting...</div></div></div></a><a class="pagination-related" href="/post/XGBoost.html" title="XGBoost内容补充"><img class="cover" src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://e3f49eaa46b57.cdn.sohucs.com/2025/5/27/21/30/MTAwMTIyXzE3NDgzNTI2MzQ0Nzk=.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-27</div><div class="info-item-2">XGBoost内容补充</div></div><div class="info-2"><div class="info-item-1">XGB内容补充 1. 集成学习 (Ensemble Learning)  2. Boosting 方法的核心优化思想 Boosting 方法，尤其是像 GBDT 和 XGBoost...</div></div></div></a><a class="pagination-related" href="/post/Ensemble-Learning.html" title="集成学习RF-Adaboost-GBDT"><img class="cover" src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://pic1.imgdb.cn/item/6835c05958cb8da5c812c6f7.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-27</div><div class="info-item-2">集成学习RF-Adaboost-GBDT</div></div><div class="info-2"><div class="info-item-1">集成学习 1. 集成学习 (Ensemble Learning) 集成学习（Ensemble Learning）是一种机器学习范式，其核心思想是 组合多个学习器 (Individual...</div></div></div></a><a class="pagination-related" href="/post/cross-stack-blend.html" title="交叉验证与模型堆叠混合"><img class="cover" src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://pic1.imgdb.cn/item/6835c06658cb8da5c812c6fb.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-27</div><div class="info-item-2">交叉验证与模型堆叠混合</div></div><div class="info-2"><div class="info-item-1">交叉验证与模型堆叠混合 1. 交叉验证...</div></div></div></a><a class="pagination-related" href="/post/data-cleaning.html" title="Python 与数据清洗"><img class="cover" src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://e3f49eaa46b57.cdn.sohucs.com/2025/5/19/21/38/MTAwMTIyXzE3NDc2NjE4OTc3NTA=.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-19</div><div class="info-item-2">Python 与数据清洗</div></div><div class="info-2"><div class="info-item-1">Python 与数据清洗 1....</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/54/MTAwMTIyXzE3NDQ1NTI0NDMwMzk=.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Yuxico</div><div class="author-info-description">生如逆旅，一苇以航</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">78</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">62</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Yuxcoo"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Yuxcoo" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:yuxicon@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="https://space.bilibili.com/533860721" target="_blank" title="Bilibili"><i class="fab fa-bilibili" style="color: #00aeec;"></i></a><a class="social-icon" href="https://twitter.com/yxico_cjlu" target="_blank" title="Twitter"><i class="fab fa-x-twitter" style="color: #0f1419;"></i></a><a class="social-icon" href="https://t.me/+Z8s3eL8dhgA3YWRl" target="_blank" title="Telegram"><i class="fab fa-telegram" style="color: #4b9dee;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">请赐予我宁静，<br>
去接受我所不能改变的；<br>
赐予我勇气，<br>
去改变我所能改变的；<br>
并赐予我智慧，<br>
去分辨这两者的差别。
</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">决策树学习笔记</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%BB%80%E4%B9%88%E6%98%AF%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">1. 什么是决策树？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%86%B3%E7%AD%96%E6%A0%91%E5%AD%A6%E4%B9%A0%E5%8E%9F%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">2. 决策树学习原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%AD%A6%E4%B9%A0%E6%AD%A5%E9%AA%A4%E6%A6%82%E8%A7%88"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 学习步骤概览</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E6%9C%80%E4%BC%98%E7%89%B9%E5%BE%81%EF%BC%9F%E2%80%94%E2%80%94-%E5%88%92%E5%88%86%E9%80%89%E6%8B%A9"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 如何选择最优特征？—— 划分选择</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#a-%E4%BF%A1%E6%81%AF%E7%86%B5-Information-Entropy"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">a) 信息熵 (Information Entropy)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#b-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A-Information-Gain-ID3-%E7%AE%97%E6%B3%95"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">b) 信息增益 (Information Gain) - ID3 算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#c-%E5%A2%9E%E7%9B%8A%E7%8E%87-Gain-Ratio-C4-5-%E7%AE%97%E6%B3%95"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">c) 增益率 (Gain Ratio) - C4.5 算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#d-%E5%9F%BA%E5%B0%BC%E6%8C%87%E6%95%B0-Gini-Index-CART-%E7%AE%97%E6%B3%95"><span class="toc-number">1.2.2.4.</span> <span class="toc-text">d) 基尼指数 (Gini Index) - CART 算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-%E8%BF%9E%E7%BB%AD%E7%89%B9%E5%BE%81%E7%9A%84%E5%A4%84%E7%90%86"><span class="toc-number">1.2.2.5.</span> <span class="toc-text">2.2.1 连续特征的处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-%E7%BA%BF%E6%90%9C%E7%B4%A2-Line-Search-%E8%BF%87%E7%A8%8B"><span class="toc-number">1.2.2.6.</span> <span class="toc-text">2.2.2 线搜索 (Line Search) 过程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-%E4%BA%8C%E7%B1%BB%E5%88%86%E7%B1%BB%E4%B8%AD%E4%B8%89%E7%A7%8D%E7%BA%AF%E5%BA%A6%E5%BA%A6%E9%87%8F%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.2.2.7.</span> <span class="toc-text">2.2.2 二类分类中三种纯度度量的关系</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E5%81%9C%E6%AD%A2%E6%9D%A1%E4%BB%B6"><span class="toc-number">1.2.3.</span> <span class="toc-text">2.3 停止条件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E7%BC%BA%E5%A4%B1%E5%80%BC%E7%9A%84%E5%A4%84%E7%90%86"><span class="toc-number">1.2.4.</span> <span class="toc-text">2.4 缺失值的处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-1-%E5%9C%A8%E7%AE%97%E6%B3%95%E5%B1%82%E9%9D%A2%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E7%BC%BA%E5%A4%B1%E5%80%BC"><span class="toc-number">1.2.4.1.</span> <span class="toc-text">2.4.1 在算法层面如何处理缺失值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-2-%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%88%92%E5%88%86%E7%89%B9%E5%BE%81%EF%BC%88%E5%BD%93%E7%89%B9%E5%BE%81%E6%9C%89%E7%BC%BA%E5%A4%B1%E5%80%BC%E6%97%B6%EF%BC%89"><span class="toc-number">1.2.4.2.</span> <span class="toc-text">2.4.2 如何选择划分特征（当特征有缺失值时）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-%E5%A4%84%E7%90%86%E8%BF%87%E6%8B%9F%E5%90%88-%E5%89%AA%E6%9E%9D%E4%B8%8E-Bagging"><span class="toc-number">1.2.5.</span> <span class="toc-text">2.5 处理过拟合 (剪枝与 Bagging)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#a-%E9%A2%84%E5%89%AA%E6%9E%9D-Pre-pruning"><span class="toc-number">1.2.5.1.</span> <span class="toc-text">a) 预剪枝 (Pre-pruning)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#b-%E5%90%8E%E5%89%AA%E6%9E%9D-Post-pruning"><span class="toc-number">1.2.5.2.</span> <span class="toc-text">b) 后剪枝 (Post-pruning)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#c-Bagging-Bootstrap-Aggregating"><span class="toc-number">1.2.5.3.</span> <span class="toc-text">c) Bagging (Bootstrap Aggregating)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-6-%E4%BA%8C%E5%8F%89%E6%A0%91%E5%92%8C%E5%A4%9A%E5%8F%89%E6%A0%91"><span class="toc-number">1.2.5.4.</span> <span class="toc-text">2.6 二叉树和多叉树</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-6-1-%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B8%8E%E5%A4%9A%E5%8F%89%E6%A0%91%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">1.2.5.4.1.</span> <span class="toc-text">2.6.1 二叉树与多叉树的区别</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-6-2-%E9%80%89%E6%8B%A9%E4%BA%8C%E5%8F%89%E6%A0%91%E8%BF%98%E6%98%AF%E5%A4%9A%E5%8F%89%E6%A0%91"><span class="toc-number">1.2.5.4.2.</span> <span class="toc-text">2.6.2 选择二叉树还是多叉树</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-7-%E4%BA%8C%E5%88%86%E7%B1%BB%E5%92%8C%E5%A4%9A%E5%88%86%E7%B1%BB"><span class="toc-number">1.2.5.5.</span> <span class="toc-text">2.7 二分类和多分类</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-7-1-%E4%BA%8C%E5%88%86%E7%B1%BB"><span class="toc-number">1.2.5.5.1.</span> <span class="toc-text">2.7.1 二分类</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-7-2-%E5%A4%9A%E5%88%86%E7%B1%BB"><span class="toc-number">1.2.5.5.2.</span> <span class="toc-text">2.7.2 多分类</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">1.3.</span> <span class="toc-text">3. 决策树的优缺点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E4%BC%98%E7%82%B9"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E7%BC%BA%E7%82%B9"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E4%BD%BF%E7%94%A8-Scikit-learn-%E5%AE%9E%E7%8E%B0%E5%86%B3%E7%AD%96%E6%A0%91-Iris-%E6%95%B0%E6%8D%AE%E9%9B%86%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.4.</span> <span class="toc-text">4. 使用 Scikit-learn 实现决策树 (Iris 数据集示例)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-0-%E5%86%B3%E7%AD%96%E6%A0%91%E5%9C%A8-Scikit-learn-%E4%B8%AD%E7%9A%84%E4%B8%BB%E8%A6%81%E5%8F%82%E6%95%B0%E3%80%81%E5%B1%9E%E6%80%A7%E4%B8%8E%E6%96%B9%E6%B3%95"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.0 决策树在 Scikit-learn 中的主要参数、属性与方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E5%AF%BC%E5%85%A5%E6%89%80%E9%9C%80%E5%BA%93"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.1 导入所需库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E5%8A%A0%E8%BD%BD%E5%92%8C%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE"><span class="toc-number">1.4.3.</span> <span class="toc-text">4.2 加载和准备数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E5%88%9B%E5%BB%BA%E5%92%8C%E8%AE%AD%E7%BB%83%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.4.4.</span> <span class="toc-text">4.3 创建和训练决策树模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E4%B8%8E%E8%AF%84%E4%BC%B0"><span class="toc-number">1.4.5.</span> <span class="toc-text">4.4 模型预测与评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">1.4.6.</span> <span class="toc-text">4.5 可视化决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#a-%E4%BD%BF%E7%94%A8-plot-tree-%E9%9C%80%E8%A6%81-Matplotlib"><span class="toc-number">1.4.6.1.</span> <span class="toc-text">a) 使用 plot_tree (需要 Matplotlib)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#b-%E4%BD%BF%E7%94%A8-export-text-%E8%BE%93%E5%87%BA%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA"><span class="toc-number">1.4.6.2.</span> <span class="toc-text">b) 使用 export_text 输出文本表示</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-6-%E6%8E%A2%E7%B4%A2%E5%89%AA%E6%9E%9D-%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.4.7.</span> <span class="toc-text">4.6 探索剪枝 (示例)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%86%B3%E7%AD%96%E6%A0%91%E5%9B%9E%E5%BD%92"><span class="toc-number">1.5.</span> <span class="toc-text">5. 决策树回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E5%9B%9E%E5%BD%92%E6%A0%91"><span class="toc-number">1.5.1.</span> <span class="toc-text">5.1 最小二乘回归树</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E5%88%86%E7%B1%BB%E6%A0%91%E4%B8%8E%E5%9B%9E%E5%BD%92%E6%A0%91%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">1.5.2.</span> <span class="toc-text">5.2 分类树与回归树的区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E5%B0%8F%E7%BB%93"><span class="toc-number">1.6.</span> <span class="toc-text">6. 小结</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/post/find-the-lexicographically-largest-string-from-the-box-i.html" title="LeetCode每日一题2025-06-04"><img src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://s2.loli.net/2025/06/04/SBWk5AlGeRC2oab.png" onerror="this.onerror=null;this.src='/img/404.png'" alt="LeetCode每日一题2025-06-04"/></a><div class="content"><a class="title" href="/post/find-the-lexicographically-largest-string-from-the-box-i.html" title="LeetCode每日一题2025-06-04">LeetCode每日一题2025-06-04</a><time datetime="2025-06-04T12:09:39.000Z" title="发表于 2025-06-04 20:09:39">2025-06-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/maximum-candies-you-can-get-from-boxes.html" title="LeetCode每日一题2025-06-03"><img src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://s2.loli.net/2025/06/03/PCfrqZbvDJugWKA.png" onerror="this.onerror=null;this.src='/img/404.png'" alt="LeetCode每日一题2025-06-03"/></a><div class="content"><a class="title" href="/post/maximum-candies-you-can-get-from-boxes.html" title="LeetCode每日一题2025-06-03">LeetCode每日一题2025-06-03</a><time datetime="2025-06-03T11:59:55.000Z" title="发表于 2025-06-03 19:59:55">2025-06-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/distribute-candy.html" title="LeetCode每日一题2025-06-02"><img src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://s2.loli.net/2025/06/02/OfCJgFqA7iPchIL.png" onerror="this.onerror=null;this.src='/img/404.png'" alt="LeetCode每日一题2025-06-02"/></a><div class="content"><a class="title" href="/post/distribute-candy.html" title="LeetCode每日一题2025-06-02">LeetCode每日一题2025-06-02</a><time datetime="2025-06-02T09:10:44.000Z" title="发表于 2025-06-02 17:10:44">2025-06-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/distribute-candies-among-children-ii.html" title="LeetCode每日一题2025-06-01"><img src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://s2.loli.net/2025/06/01/YEScex5NkPT2aRu.png" onerror="this.onerror=null;this.src='/img/404.png'" alt="LeetCode每日一题2025-06-01"/></a><div class="content"><a class="title" href="/post/distribute-candies-among-children-ii.html" title="LeetCode每日一题2025-06-01">LeetCode每日一题2025-06-01</a><time datetime="2025-06-01T11:19:40.000Z" title="发表于 2025-06-01 19:19:40">2025-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/snakes-and-ladders.html" title="LeetCode每日一题2025-05-31"><img src= "https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/28/MTAwMTIyXzE3NDQ1NTA4OTQ1MjI=.gif" data-lazy-src="https://s2.loli.net/2025/05/31/j8HozPZbNyhDMTF.png" onerror="this.onerror=null;this.src='/img/404.png'" alt="LeetCode每日一题2025-05-31"/></a><div class="content"><a class="title" href="/post/snakes-and-ladders.html" title="LeetCode每日一题2025-05-31">LeetCode每日一题2025-05-31</a><time datetime="2025-05-31T11:20:11.000Z" title="发表于 2025-05-31 19:20:11">2025-05-31</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://e3f49eaa46b57.cdn.sohucs.com/2025/4/13/21/21/MTAwMTIyXzE3NDQ1NTA0NjkyNTM=.png);"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2025 By Yuxico</div><div class="runtime"><span id="runtimeshow"><i class="fas fa-clock"></i><span class="runtime-text">时间已奔赴 </span><span id="runtime_days"></span><span>天 </span><span id="runtime_hours"></span><span>小时 </span><span id="runtime_minutes"></span><span>分钟 </span><span id="runtime_seconds"></span><span>秒</span></span></div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div><script>function updateRuntime() {
  const start = new Date("2022-01-01 00:00:00");
  const now = new Date();
  const diff = now - start;
  
  const days = Math.floor(diff / (1000 * 60 * 60 * 24));
  const hours = Math.floor((diff % (1000 * 60 * 60 * 24)) / (1000 * 60 * 60));
  const minutes = Math.floor((diff % (1000 * 60 * 60)) / (1000 * 60));
  const seconds = Math.floor((diff % (1000 * 60)) / 1000);
  
  document.getElementById("runtime_days").innerHTML = days;
  document.getElementById("runtime_hours").innerHTML = hours;
  document.getElementById("runtime_minutes").innerHTML = minutes;
  document.getElementById("runtime_seconds").innerHTML = seconds;
}

setInterval(updateRuntime, 1000);
updateRuntime();</script></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat-btn" type="button" title="聊天" style="display:none"><i class="fas fa-message"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'neutral'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.cjlus.eu.org',
      region: 'auto',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = (el = document, path = location.pathname) => {
    twikoo.init({
      el: el.querySelector('#twikoo-wrap'),
      envId: 'https://twikoo.cjlus.eu.org',
      region: 'auto',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      },
      ...option,
      path: isShuoshuo ? path : (option && option.path) || path
    })

    

    isShuoshuo && (window.shuoshuoComment.destroyTwikoo = () => {
      if (el.children.length) {
        el.innerHTML = ''
        el.classList.add('no-comment')
      }
    })
  }

  const loadTwikoo = (el, path) => {
    if (typeof twikoo === 'object') setTimeout(() => init(el, path), 0)
    else btf.getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(() => init(el, path))
  }

  if (isShuoshuo) {
    'Twikoo' === 'Twikoo'
      ? window.shuoshuoComment = { loadComment: loadTwikoo }
      : window.loadOtherComment = loadTwikoo
    return
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="Ruby,Python,JavaScript,TypeScript,HTML,CSS,Vue,React,Node.js,R,C#,C++,Matlab,SAS,PHP,Go,SQL" data-fontsize="16px" data-random="true" async="async"></script><script>(() => {
  btf.getScript('//code.tidio.co/gcpmbfallv68ddoa0zzuekn6jcrc5m5v.js').then(() => {
    const isChatBtn = true
    const isChatHideShow = true

    if (isChatBtn) {
      let isShow = false
      const close = () => {
        window.tidioChatApi.hide()
        isShow = false
      }
      
      const open = () => {
        window.tidioChatApi.open()
        window.tidioChatApi.show()
        isShow = true
      }

      const onTidioChatApiReady = () => {
        window.tidioChatApi.hide()
        window.tidioChatApi.on("close", close)
      }
      if (window.tidioChatApi) {
        window.tidioChatApi.on("ready", onTidioChatApiReady)
      } else {
        document.addEventListener("tidioChat-ready", onTidioChatApiReady)
      }

      window.chatBtnFn = () => {
        if (!window.tidioChatApi) return
        isShow ? close() : open()
      }

      document.getElementById('chat-btn').style.display = 'block'

    } else if (isChatHideShow) {
      window.chatBtn = {
        hide: () => window.tidioChatApi && window.tidioChatApi.hide(),
        show: () => window.tidioChatApi && window.tidioChatApi.show()
      }
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章或任意内容..." type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!--– 在页面底部手动插入 AI 摘要的脚本--><script defer src="/hexo-ai-summaries/gemini.js"></script><!--– 仅在 AI 翻译页面加载 translate.js--></body></html>